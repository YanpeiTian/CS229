Id,CreationDate,Score,ViewCount,Body,OwnerUserId,LastEditorUserId,LastEditDate,CommentCount,BodyLength,UserDisplayName,UserCreationDate,UserReputation,UserViews,UserUpVotes,UserDownVotes,ParentId,ParentAcceptedAnswerId,ParentCreationDate,ParentScore,ParentViewCount,ParentBody,ParentOwnerUserId,ParentLastEditorUserId,ParentLastEditDate,ParentTitle,ParentTags,ParentAnswerCount,ParentCommentCount,ParentBodyLength
"49040616","2018-03-01 00:00:55","2","","<p>What's happening here is two things<br>
1. items was created as a class variable<br>
2. leaf1 was added as a Component: <code>Composite('leaf1')</code> and therefore possesses the class variable <code>items</code>   </p>

<p>These two together mean that leaf1.print2() will recursively call itself forever </p>
","2507197","","","0","314","Alter","2013-06-20 23:44:44","1885","314","329","9","49040518","49040587","2018-02-28 23:48:57","2","1443","<p>I don't understand python's behavior, I've got many the same errors:</p>

<blockquote>
  <p>File ""./start.py"", line 20, in print2<br>
     item.print2()<br>
  RuntimeError: maximum recursion depth exceeded</p>
</blockquote>

<p>My code is the following:</p>

<pre><code>#!/usr/bin/python

class Component:
    def print2(self):
        pass

class Composite(Component):
    items = []
    name = 'composite'

    def __init__(self, name):
        self.name = name

    def add(self, item):
        self.items.append(item)

    def print2(self):
        if self.items:
            for item in self.items:
                item.print2()
        else:
            print self.name

class Leaf(Component):
    name = 'leaf'

    def __init__(self, name):
        self.name = name

    def print2(self):
        print self.name

category = Composite('category1')
leaf = Composite('leaf1')
category.add(leaf)
leaf = Leaf('leaf2')
category.add(leaf)

category.print2()
</code></pre>

<p>When I add <code>self.items = []</code> in the constructor ( <code>__init__</code> ), it works fine. Could you explain the behavior?</p>
","9210255","9210255","2019-08-29 21:09:13","Python's initialization a list in a class","<python><class>","3","2","1118"
"49040672","2018-03-01 00:06:43","3","","<p>Ummm find a interesting way <code>get_dummies</code></p>

<pre><code>(df.fruit.str.replace(' ','').str.get_dummies(',')+df.choice.str.get_dummies()).gt(1).any(1)
Out[726]: 
0    False
1    False
2     True
3     True
4     True
5     True
6     True
7     True
8     True
9    False
dtype: bool
</code></pre>

<p>After assign it back </p>

<pre><code>df['New']=(df.fruit.str.replace(' ','').str.get_dummies(',')+df.choice.str.get_dummies()).gt(1).any(1).astype(int)
df
Out[728]: 
   ID     choice             fruit  New
0   1     orange     apple, banana    0
1   2     orange             apple    0
2   3      apple             apple    1
3   4  pineapple         pineapple    1
4   5      apple  apple, pineapple    1
5   6     orange            orange    1
6   7     orange     apple, orange    1
7   8     orange            orange    1
8   9     banana            banana    1
9  10     banana      apple, peach    0
</code></pre>
","7964527","","","1","937","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49040364","49040419","2018-02-28 23:30:47","4","83","<p>I have a series with some strings in a pandas dataframe. I would like to search for the existence of that string within an adjacent column.</p>

<p>In the below example I would like to search for if the string in 'choice' series is contained within the 'fruit' series, returning either true (1) or false (0) in a new column 'choice_match'.</p>

<p>Example DataFrame:</p>

<pre><code>import pandas as pd
d = {'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'fruit': [
'apple, banana', 'apple', 'apple', 'pineapple', 'apple, pineapple',            'orange', 'apple, orange', 'orange', 'banana', 'apple, peach'],
'choice': ['orange', 'orange', 'apple', 'pineapple', 'apple', 'orange',  'orange', 'orange', 'banana', 'banana']}
df = pd.DataFrame(data=d)
</code></pre>

<p>Desired DataFrame:</p>

<pre><code>import pandas as pd
d = {'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'fruit': [
'apple, banana', 'apple', 'apple', 'pineapple', 'apple, pineapple',   'orange', 'apple, orange', 'orange', 'banana', 'apple, peach'],
'choice': ['orange', 'orange', 'apple', 'pineapple', 'apple', 'orange',      'orange', 'orange', 'banana', 'banana'],
'choice_match': [0, 0, 1, 1, 1, 1, 1, 1, 1, 0]}
df = pd.DataFrame(data=d)
</code></pre>
","8784015","9209546","2018-04-19 20:21:07","String contains across two pandas series","<python><string><pandas><dataframe>","4","0","1212"
"49040674","2018-03-01 00:06:46","0","","<ul>
<li>No Need of sorting in this solution </li>
<li><p>Small Solution:</p>

<pre><code>import numpy as np 
n = 5
x = [('herr', 1),
     ('dapao', 1),
     ('cino', 1),
     ('o', 38),
     ('tiao', 2),
     ('tut', 1),
     ('poh', 6),
     ('micheal', 1),
     ('orh', 1),
     ('horlick', 3),
     ('si', 1),
     ('tai', 1),
     ('titlo', 1),
     ('siew', 17),
     ('da', 1),
     ('halia', 2)]

x = np.array(x)  # make the list a numpy array
names = x[:, 0]   
numbers = x[:, 1].astype(int)
least_count = np.take(names, np.where(numbers == np.min(numbers)))[0][-n:]
print(least_count)
</code></pre></li>
<li><p>output of above solution:</p>

<pre><code>['orh', 'si', 'tai', 'titlo', 'da']
</code></pre></li>
<li><p>Explanation of solution with comments</p>

<pre><code>import numpy as np 

x = [('herr', 1),
 ('dapao', 1),
 ('cino', 1),
 ('o', 38),
 ('tiao', 2),
 ('tut', 1),
 ('poh', 6),
 ('micheal', 1),
 ('orh', 1),
 ('horlick', 3),
 ('si', 1),
 ('tai', 1),
 ('titlo', 1),
 ('siew', 17),
 ('da', 1),
 ('halia', 2)]

x = np.array(x)  # make the list a numpy array
# ==========================================
# split the array into names and numbers
# ==========================================
names = x[:, 0]   
numbers = x[:, 1].astype(int)

mini = np.min(numbers)  # find the minimum in the numbers array
idx = np.where(numbers == mini)   # Find the indices where minimum occurs in the numbers array
least_count = np.take(names, idx)[0] # Use the indices found from numbers array in the above line to access names array
print(least_count)
least_count = least_count.tolist()  # to convert the numpy array to list
n = 5   # say n is 5
print(least_count[-n:]) # now you can do simple slicing to extract the last n element 
</code></pre></li>
<li><p>output of above explaination:</p>

<pre><code>['herr' 'dapao' 'cino' 'tut' 'micheal' 'orh' 'si' 'tai' 'titlo' 'da']
['orh', 'si', 'tai', 'titlo', 'da']
</code></pre></li>
</ul>
","5361479","5361479","2018-03-01 18:00:00","0","1939","Jai","2015-09-22 01:45:52","1962","405","318","19","48745169","","2018-02-12 11:16:04","7","417","<p>The input is an unsorted list of tuples: </p>

<pre><code>x = [('herr', 1),
     ('dapao', 1),
     ('cino', 1),
     ('o', 38),
     ('tiao', 2),
     ('tut', 1),
     ('poh', 6),
     ('micheal', 1),
     ('orh', 1),
     ('horlick', 3),
     ('si', 1),
     ('tai', 1),
     ('titlo', 1),
     ('siew', 17),
     ('da', 1),
     ('halia', 2)]
</code></pre>

<p>The goal is to find the last <code>n</code> keys with the least counts, i.e. desired output:</p>

<pre><code>['orh', 'si', 'tai', 'titlo', 'da']
</code></pre>

<p>I've tried doing this by:</p>

<ul>
<li>first convert the list of tuples to a dict</li>
<li>cast the dict into a Counter</li>
<li>then find the <code>[-n:]</code> list of tuples from the <code>Counter.most_common()</code></li>
<li>cast the list of tuples from the <code>[-n:]</code> to a dict</li>
<li>get the keys and then convert it into a list</li>
</ul>

<p>i.e. </p>

<pre><code>n = 5
list(dict(Counter(dict(x)).most_common()[-n:]).keys())
</code></pre>

<p><strong>Is there a less convoluted way to get the same output?</strong> </p>

<hr>

<p>I could also do this:</p>

<pre><code>from operator import itemgetter
output, *_ = zip(*sorted(x, key=itemgetter(1))[n:])
list(output)
</code></pre>

<p>But now I've merely swapped out the <code>Counter.most_common</code> with <code>sorted</code> and <code>itemgetter</code>. Then I would still need to <code>zip(*list)</code> to extract the keys through unpacking the first value from each list of tuples after the zip.</p>

<p><strong>There must be a simpler way.</strong></p>

<hr>

<h1>NOTE</h1>

<p>Note that the question is not asking to sort, it's to extract the list first element in the original list of tuples given. And the criterion to extract is based on the last nth items with the lowest value in the 2nd element.</p>

<p>The <a href=""https://stackoverflow.com/questions/10695139"">answers from the possible duplicate linked</a> still requires the step to unpack the list of sorted tuples and and the extract the top nth of the list of first elements. </p>
","610569","7848065","2018-03-01 00:43:34","Getting the keys of items with the least counts from a list of tuples of key-value pairs - Python","<python><list><dictionary><counter>","12","14","2051"
"49040681","2018-03-01 00:08:02","5","","<p>The pattern:</p>

<pre><code>pattern = '^[A-Z.-]*(\d[A-Z.-]*){4,}$'
</code></pre>

<ul>
<li><code>^</code> - start of the word</li>
<li><code>[A-Z.-]*</code> - any number of optional non-digit ""good characters"": letters, periods or dashes</li>
<li><code>(\d[A-Z.-]*){4,}</code> - 4 or more groups of a digit and other ""good characters""; this part provides at least 4 digits</li>
<li><code>$</code> - end of the word</li>
</ul>

<p>Examples:</p>

<pre><code>re.match(pattern, ""ART-4.5-11"")
# &lt;_sre.SRE_Match object; span=(0, 10), match='ART-4.5-11'&gt;    
re.match(pattern, ""ART5411"")
# &lt;_sre.SRE_Match object; span=(0, 7), match='ART5411'&gt;
re.match(pattern, ""aRT-4!5-11"") # No match
re.match(pattern, ""76543"")
# &lt;_sre.SRE_Match object; span=(0, 5), match='76543'&gt;
</code></pre>
","4492932","4492932","2018-03-01 00:30:12","3","797","DYZ","2015-01-25 21:05:25","32030","6496","2364","2881","49040641","49040681","2018-03-01 00:03:45","4","827","<p>I want a regular expression for python that matches a string which must contain 4 digits, it may not contain any special character other than ""-"" or ""."", and it may only contain uppercase letters. I know the following matches text with 4 digits or more. How would I add the rest of the criteria?</p>

<p><code>[0-9]{4,}</code></p>

<p>An example would be:
<strong>ART-4.5-11</strong> is good, <strong>ART5411</strong> is good, <strong>76543</strong> is good, but <strong>aRT-4!5-11</strong> is bad since it contains a lowercase char and a special char that is not ""-"" or "".""</p>
","4133567","","","Regular expression must contain and may only contain","<python><regex>","1","2","582"
"49040693","2018-03-01 00:09:53","2","","<p>Suppose you have a function <code>tokenize</code> that transforms the strings to a list of words. Then you can <code>flatMap</code> <code>documents</code> to get an <code>RDD</code> of tuples <code>(word, document id)</code>:</p>

<pre><code>flattened_docs = documents.flatMap(lambda x: [(word, x[0]) for word in tokenize(x[1])])
</code></pre>

<p>Then joining with <code>words</code> will give you <code>(word, (document id, vector))</code> tuples, and you can drop the words at this point:</p>

<pre><code>doc_vectors = flattened_docs.join(words).values
</code></pre>

<p>Note that this is an inner join, so you're throwing away an words that do not have embeddings. Since you presumably want to count those words in your average, a left join is likely more appropriate and you'll then have to replace any resulting <code>None</code>s with the zero vector (or whatever vector of your choice).</p>

<p>We can group by document id to get an rdd of <code>(document id, [list of vectors])</code> and then average (I'll assume you have a function called <code>average</code>).</p>

<pre><code>final_vectors = doc_vectors.groupByKey().mapValues(average)
</code></pre>

<p>(Please excuse my Scala-influenced Python. It's been a while since I've used pyspark and I haven't checked if it's <code>flatMap</code> or <code>flat_map</code> and so on.)</p>
","424173","","","0","1348","hoyland","2010-08-18 15:11:27","1517","119","37","8","49039956","49040693","2018-02-28 22:49:02","2","125","<p>I'm trying to implement a simple Doc2Vec algorithm in PySpark using a pre-trained GloVe model from <a href=""https://nlp.stanford.edu/projects/glove/"" rel=""nofollow noreferrer"">https://nlp.stanford.edu/projects/glove/</a>.</p>

<p>I have two RDDs: </p>

<ul>
<li><p>A pair RDD called <code>documents</code> in the form (K:[V]) where K is the document ID, and [V] is a list of all the words in that document, for example 
<code>
('testDoc1':'i am using spark')
('testDoc2':'testing spark')
</code></p></li>
<li><p>A pair RDD called <code>words</code> representing the word embeddings in the form K:V where K is a word and V is the vector that represents the word, for example 
<code>
('i',       [0.1, 0.1, 0.1])
('spark':   [0.2, 0.2, 0.2]) 
('am',      [0.3, 0.3, 0.3])
('testing', [0.5, 0.5, 0.5])
('using',   [0.4, 0.4, 0.4])
</code></p></li>
</ul>

<p>What is the correct way to iterate through the words in <code>documents</code> to get an average vector sum for all of the words? In the above example, the end result would look like:
<code>
('testDoc1':[0.25, 0.25, 0.25])
('testDoc2':[0.35, 0.35, 0.35])
</code></p>
","5811270","5811270","2018-02-28 23:11:16","Averaging vectors in Pyspark with lookup table","<python><apache-spark><pyspark>","1","2","1125"
"49040695","2018-03-01 00:10:03","5","","<p>It's possible to disable verification using the public <code>ssl</code> APIs existing on Python 2.7.9+:</p>

<pre><code>import xmlrpclib
import ssl

ssl_ctx = ssl.create_default_context()
ssl_ctx.check_hostname = False
ssl_ctx.verify_mode = ssl.CERT_NONE
test = xmlrpclib.ServerProxy('https://admin:bz15h9v9n@localhost:9999/API',
                             verbose=False, use_datetime=True, 
                             context=ssl_ctx)
test.list_satellites()
</code></pre>
","33795","33795","2018-03-01 01:03:29","0","480","Benjamin Peterson","2008-11-03 23:02:47","11489","715","40","13","30461969","30467956","2015-05-26 14:50:40","8","19955","<p>I try to make a local HTTPS connection to a XMLRPC api. Since I upgrade to python 2.7.9 that <a href=""https://www.python.org/dev/peps/pep-0476/"" rel=""noreferrer"">enable by default certificates verification</a>, I got a CERTIFICATE_VERIFY_FAILED error when I use my API</p>

<pre><code>&gt;&gt;&gt; test=xmlrpclib.ServerProxy('https://admin:bz15h9v9n@localhost:9999/API',verbose=False, use_datetime=True)
&gt;&gt;&gt; test.list_satellites()
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/usr/local/lib/python2.7/xmlrpclib.py"", line 1233, in __call__
    return self.__send(self.__name, args)
  File ""/usr/local/lib/python2.7/xmlrpclib.py"", line 1591, in __request
    verbose=self.__verbose
  File ""/usr/local/lib/python2.7/xmlrpclib.py"", line 1273, in request
    return self.single_request(host, handler, request_body, verbose)
  File ""/usr/local/lib/python2.7/xmlrpclib.py"", line 1301, in single_request
    self.send_content(h, request_body)
  File ""/usr/local/lib/python2.7/xmlrpclib.py"", line 1448, in send_content
    connection.endheaders(request_body)
  File ""/usr/local/lib/python2.7/httplib.py"", line 997, in endheaders
    self._send_output(message_body)
  File ""/usr/local/lib/python2.7/httplib.py"", line 850, in _send_output
    self.send(msg)
  File ""/usr/local/lib/python2.7/httplib.py"", line 812, in send
    self.connect()
  File ""/usr/local/lib/python2.7/httplib.py"", line 1212, in connect
    server_hostname=server_hostname)
  File ""/usr/local/lib/python2.7/ssl.py"", line 350, in wrap_socket
    _context=self)
  File ""/usr/local/lib/python2.7/ssl.py"", line 566, in __init__
    self.do_handshake()
  File ""/usr/local/lib/python2.7/ssl.py"", line 788, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:581)
&gt;&gt;&gt; import ssl
&gt;&gt;&gt; ssl._create_default_https_context = ssl._create_unverified_context
&gt;&gt;&gt; test.list_satellites()
[{'paired': True, 'serial': '...', 'enabled': True, 'id': 1, 'date_paired': datetime.datetime(2015, 5, 26, 16, 17, 6)}]
</code></pre>

<p>Does exists a pythonic way to disable default certificate verification in python 2.7.9 ?</p>

<p>I don't realy know if it's good to change ""private"" global SSL attribute (<code>ssl._create_default_https_context = ssl._create_unverified_context</code>)</p>
","866886","","","disable default certificate verification in python 2.7.9","<python><ssl>","3","0","2389"
"49040697","2018-03-01 00:10:12","4","","<p>I came across the same problem and it's been solved by adding passing the train dataframe column name to the test dataframe via adding the following code: </p>

<pre><code>test_df = test_df[train_df.columns]
</code></pre>
","3673947","1056563","2018-10-14 20:06:52","0","225","CathyQian","2014-05-25 15:30:58","347","51","72","0","42338972","","2017-02-20 07:43:24","12","12293","<p>I have trained an XGBoostRegressor model. When I have to use this trained model for predicting for a new input, the predict() function throws a feature_names mismatch error, although the input feature vector has the same structure as the training data.</p>

<p>Also, in order to build the feature vector in the same structure as the training data, I am doing a lot inefficient processing such as adding new empty columns (if data does not exist) and then rearranging the data columns so that it matches with the training structure. Is there a better and cleaner way of formatting the input so that it matches the training structure?</p>
","4612964","","","ValueError: feature_names mismatch: in xgboost in the predict() function","<python><pandas><machine-learning><regression><xgboost>","8","0","640"
"49040747","2018-03-01 00:16:18","2","","<p>You can't. The SSL context isn't shared between processes; without it, the encryption state gets out of sync.</p>

<p>If you need to perform multiple concurrent operations on the same IMAP inbox, you will need to make multiple connections to the server.</p>
","149341","","","0","261","duskwuff","2008-10-24 09:45:27","158002","8267","564","3550","49039332","49040747","2018-02-28 22:01:37","0","381","<p>I want to reuse imaplib.IMAP4_SSL instance over many processes so I don't have to login multiple times.
Here is some code:</p>

<pre><code>import imaplib
from multiprocessing import Process

def fetch(mail_client):
    mail_client.uid('fetch', b'1', 'BODY[TEXT]')

def main():
    c = imaplib.IMAP4_SSL('imap.gmail.com')
    c.login(user='**', password='***')
    c.select('inbox')

    procs = [Process(target=fetch, args=(c,)) for _ in range(100)]
    for p in procs:
        p.start()

    for p in procs:
        p.join()

if __name__ == '__main__':
    main()
</code></pre>

<p>But I get the errors that are related to socket:</p>

<blockquote>
  <p>imaplib.IMAP4.abort: socket error: [Errno 32] Broken pipe</p>
</blockquote>

<p>I thought that this is because processes is writing to the same socket, that imaplib.IMAP4_SSL has, so i tried to add multiprocessing.Lock to prevent simultaneous access:</p>

<pre><code>import imaplib
from multiprocessing import Process, Lock


def fetch(mail_client, lock):
    with lock:
        mail_client.uid('fetch', b'1', 'BODY[TEXT]')


def main():
    c = imaplib.IMAP4_SSL('imap.gmail.com')
    c.login(user='engineering@epallet.com', password='Qwe=1dSAzxc+%')
    c.select('inbox')
    lock = Lock()

    procs = [Process(target=fetch, args=(c, lock)) for _ in range(100)]
    for p in procs:
        p.start()

    for p in procs:
        p.join()


if __name__ == '__main__':
    main()
</code></pre>

<p>But the error persists.
Some further investigation has shown that the first process calls mail.uid successfully, but second process gets <code>imaplib.IMAP4.abort: command: UID =&gt; socket error: EOF</code> anyway.</p>

<p>I am using Ubuntu 16.04.
Any suggestions are highly appreciated.</p>

<p>Update: found another exception in stacktrace, maybe it causes all other exceptions:</p>

<blockquote>
  <p>ssl.SSLError: [SSL: DECRYPTION_FAILED_OR_BAD_RECORD_MAC] decryption failed or bad record mac (_ssl.c:2217)`</p>
</blockquote>

<p>Seems like this issue is related 
<a href=""https://stackoverflow.com/questions/3724900/python-ssl-problem-with-multiprocessing"">Python ssl problem with multiprocessing</a></p>
","6627564","6627564","2018-02-28 22:30:05","using imaplib.IMAP4_SSL in multiple processes","<python><sockets><multiprocessing><imaplib>","2","0","2168"
"49040781","2018-03-01 00:20:16","1","","<p>As per OP’s comment, the NA is a string rather than NaN. So <code>dropna()</code> is no good here. One of many possible options for filtering out the string value ‘NA’ is:</p>

<pre><code>df = df[df[""_c2""] != ""NA""]
</code></pre>

<p>A better option to catch inexact matches (e.g. with trailing spaces) as suggested by @DJK in the comments:</p>

<pre><code>df = df[~df[""_c2""].str.contains('NA')]
</code></pre>

<p>This one should remove any strings rather than only ‘NA’:</p>

<pre><code>df = df[df[“_c2”].apply(lambda x: x.isnumeric())]
</code></pre>
","6866811","6866811","2018-03-01 01:25:04","9","554","thesilkworm","2016-09-22 20:17:18","3845","151","1210","248","49040742","","2018-03-01 00:15:19","0","838","<p>When I run the code below I get the error:</p>

<p>TypeError: 'NoneType' object has no attribute '<strong>getitem</strong>'</p>

<pre><code>    import pyarrow 
    import pandas
    import pyarrow.parquet as pq

    df = pq.read_table(""file.parquet"").to_pandas()
    df = df.iloc[1:,:]
    df = df.dropna (how=""any"", inplace = True) # modifies it in place, creates new dataset without NAN

    average_age = df[""_c2""].mean()
    print average_age
</code></pre>

<p>The dataframe looks like this:</p>

<pre><code>         _c0     _c1  _c2    
    0  RecId   Class  Age   
    1      1      1st   29   
    2      2      1st   NA   
    3      3      1st   30  
</code></pre>

<p>If I print the df after calling the dropna method, I get 'None'.</p>

<p>Shouldn't it be creating a new dataframe without the 'NA' in it, which would then allow me to get the average age without throwing an error?</p>
","6036687","","","pandas dropna not working as expected on finding mean","<python><pandas>","2","3","899"
"49040788","2018-03-01 00:20:56","10","","<p>In Python 2, <code>print</code> is a <a href=""https://docs.python.org/2/reference/lexical_analysis.html#keywords"" rel=""nofollow noreferrer"">keyword</a>. It can only be used for its intended purpose. I can't be the name of a variable or a function.</p>

<p>In Python 3, <code>print</code> is a <a href=""https://docs.python.org/3/library/functions.html#print"" rel=""nofollow noreferrer"">built-in function</a>, not a keyword. So methods, for example, can have the name <code>print</code>.</p>

<p>If you are using Python 2 and want to override its default behavior, you can import Python 3's behavior from <a href=""https://docs.python.org/2/reference/simple_stmts.html#future"" rel=""nofollow noreferrer""><code>__future__</code></a>:</p>

<pre><code>from __future__ import print_function
class MyClass:
    def print(self):
        print ('MyClass')

a = MyClass()
a.print()
</code></pre>
","8747","8747","2018-03-01 05:39:05","2","886","Robᵩ","2008-09-15 16:47:33","124214","7724","5618","743","49040765","49040788","2018-03-01 00:18:13","4","1216","<p>I can't execute <code>print</code> function in the class:</p>

<pre><code>#!/usr/bin/python
import sys

class MyClass:
    def print(self):
        print 'MyClass'

a = MyClass()
a.print()
</code></pre>

<p>I'm getting the following error:</p>

<pre><code>File ""./start.py"", line 9
    a.print()
          ^
SyntaxError: invalid syntax
</code></pre>

<p>Why is it happening?</p>
","9210255","2864740","2018-03-01 00:21:22","Python's print function in a class","<python><python-2.x>","3","8","382"
"49040792","2018-03-01 00:21:07","8","","<p>You are using Python 2 (which you really shouldn't, unless you have a very good reason).</p>

<p>In Python 2, <code>print</code> is a statement, so <code>print</code> is actually a reserved word. Indeed, a SyntaxError <em>should</em> have been thrown when you tried to define a function with the name <code>print</code>, i.e.:</p>

<pre><code>In [1]: class MyClass:
   ...:     def print(self):
   ...:         print 'MyClass'
   ...:
   ...: a = MyClass()
   ...: a.print()
  File ""&lt;ipython-input-1-15822827e600&gt;"", line 2
    def print(self):
            ^
SyntaxError: invalid syntax
</code></pre>

<p>So, I'm curious as to what exact version of Python 2 you are using. the above output was from a Python 2.7.13 session...</p>

<p>So note, in Python 3:</p>

<pre><code>&gt;&gt;&gt; class A:
...    def print(self):
...       print('A')
...
&gt;&gt;&gt; A().print()
A
</code></pre>
","5014455","","","0","892","juanpa.arrivillaga","2015-06-16 08:18:23","42745","9720","6722","648","49040765","49040788","2018-03-01 00:18:13","4","1216","<p>I can't execute <code>print</code> function in the class:</p>

<pre><code>#!/usr/bin/python
import sys

class MyClass:
    def print(self):
        print 'MyClass'

a = MyClass()
a.print()
</code></pre>

<p>I'm getting the following error:</p>

<pre><code>File ""./start.py"", line 9
    a.print()
          ^
SyntaxError: invalid syntax
</code></pre>

<p>Why is it happening?</p>
","9210255","2864740","2018-03-01 00:21:22","Python's print function in a class","<python><python-2.x>","3","8","382"
"49040829","2018-03-01 00:26:36","2","","<p>I tried your code on Python 3 like this:</p>

<pre><code>class MyClass:
    def print(self):
        print ('MyClass')

a = MyClass()
a.print()
</code></pre>

<p>It worked !!</p>

<p>Output:</p>

<pre><code>MyClass
</code></pre>

<p>Running your code as is gives me Syntax Error. Because of missing parenthesis in print. Also, note that print is a reserved keyword in Python 2 but a built-in-function in Python 3.</p>
","4877653","","","0","421","Ankit Malik","2015-05-08 05:26:48","75","19","2","0","49040765","49040788","2018-03-01 00:18:13","4","1216","<p>I can't execute <code>print</code> function in the class:</p>

<pre><code>#!/usr/bin/python
import sys

class MyClass:
    def print(self):
        print 'MyClass'

a = MyClass()
a.print()
</code></pre>

<p>I'm getting the following error:</p>

<pre><code>File ""./start.py"", line 9
    a.print()
          ^
SyntaxError: invalid syntax
</code></pre>

<p>Why is it happening?</p>
","9210255","2864740","2018-03-01 00:21:22","Python's print function in a class","<python><python-2.x>","3","8","382"
"49040832","2018-03-01 00:26:50","0","","<p>Change <code>string.lower</code> to <code>string.lower()</code>. <code>string.lower</code> references the functions. Put the letters in quotes. You don't have those variables defined.</p>

<p>A better version of the function:</p>

<pre><code>def countvowels(x):
    return sum([1 for a in x if a in ""AEIOUaeiou""])
</code></pre>
","7848065","7848065","2018-03-01 00:32:14","0","331","whackamadoodle3000","2017-04-11 02:43:46","5059","1791","4415","3","49040796","49040834","2018-03-01 00:21:17","0","572","<p>I am attempting to run a for loop in a function that is designed to count the vowels in a user inputted string. However, the error ""builtins: TypeError"" keeps appearing. I have tried simply using the length of the string, using the len function, but the error simply won't go away, and the code is ultimately broken because of this. Is there a solution to this? <a href=""https://i.stack.imgur.com/adXTN.png"" rel=""nofollow noreferrer"">Screenshot of the code with the error message showing</a></p>

<p>For instance, I first ask the user to input a string. It is then supposed to use the function, called in the print statement, to count the vowels in the user inputted string. Currently, when typing a string, such as Kay, it produces an error code on line 6 that states ""for char in (string):"" which is the beginning of the for loop. The purpose of this loop is to ensure all letters are being checked for vowels before the code quits. There is a proper indentation, indicated by the lack of error and the principles of computer science and programming. The user inputted portion, which states ""string= input(""Please enter a phrase. "")"" defines the variable string, and is placed at the top of the code.</p>
","9201867","9201867","2018-03-01 00:29:39","For Loop in a Function for Counting Vowels in a User Inputted String","<python><python-3.x><function><for-loop>","7","1","1210"
"49040834","2018-03-01 00:27:03","1","","<p>Here is a reworked version of your code. </p>

<pre><code>mystr = input('Please enter a phrase:\n')

def countvowels(x):
    counter = 0
    for i in x.lower():
        if i in set('aeiou'):
            counter += 1
    return counter

print(countvowels(mystr))
</code></pre>

<p><strong>Explanation</strong></p>

<ul>
<li>Do not name variables after classes or built-in functions, e.g. use <code>counter</code> instead of <code>sum</code>.</li>
<li>Use <code>x.lower()</code>. Notice the brackets afterwards, indicating you want to function to execute.</li>
<li><code>set('aeiou')</code> creates a set of vowels, i.e. <code>{'a', 'e', 'i', 'o', 'u'}</code>. Checking if a variable is efficient with O(1) complexity.</li>
<li><code>input()</code> by default returns a string, so there is no need to convert to <code>str</code> manually.</li>
</ul>
","9209546","9209546","2018-03-01 00:46:13","2","851","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49040796","49040834","2018-03-01 00:21:17","0","572","<p>I am attempting to run a for loop in a function that is designed to count the vowels in a user inputted string. However, the error ""builtins: TypeError"" keeps appearing. I have tried simply using the length of the string, using the len function, but the error simply won't go away, and the code is ultimately broken because of this. Is there a solution to this? <a href=""https://i.stack.imgur.com/adXTN.png"" rel=""nofollow noreferrer"">Screenshot of the code with the error message showing</a></p>

<p>For instance, I first ask the user to input a string. It is then supposed to use the function, called in the print statement, to count the vowels in the user inputted string. Currently, when typing a string, such as Kay, it produces an error code on line 6 that states ""for char in (string):"" which is the beginning of the for loop. The purpose of this loop is to ensure all letters are being checked for vowels before the code quits. There is a proper indentation, indicated by the lack of error and the principles of computer science and programming. The user inputted portion, which states ""string= input(""Please enter a phrase. "")"" defines the variable string, and is placed at the top of the code.</p>
","9201867","9201867","2018-03-01 00:29:39","For Loop in a Function for Counting Vowels in a User Inputted String","<python><python-3.x><function><for-loop>","7","1","1210"
"49040856","2018-03-01 00:29:38","0","","<p>You have two problems. </p>

<p>First, <code>lower</code> is a function, you have to call it by putting parentheses after it.</p>

<pre><code>string = string.lower()
</code></pre>

<p>Your code is just setting <code>string</code> to the function itself, not running it and using the result.</p>

<p>Second, when you test whether the character is a vowel, you need to put quotes around them. Otherwise, you're trying to use variables named <code>a</code>, <code>e</code>, etc. which you've never defined.</p>

<pre><code>if char == 'a' or char == 'e' or char == 'i' or char == 'o' or char == 'u':
</code></pre>

<p>You could also simplify that to:</p>

<pre><code>if char in 'aeiou':
</code></pre>
","1491895","7848065","2018-03-01 00:36:59","0","700","Barmar","2012-06-29 18:12:29","477375","68451","6422","3351","49040796","49040834","2018-03-01 00:21:17","0","572","<p>I am attempting to run a for loop in a function that is designed to count the vowels in a user inputted string. However, the error ""builtins: TypeError"" keeps appearing. I have tried simply using the length of the string, using the len function, but the error simply won't go away, and the code is ultimately broken because of this. Is there a solution to this? <a href=""https://i.stack.imgur.com/adXTN.png"" rel=""nofollow noreferrer"">Screenshot of the code with the error message showing</a></p>

<p>For instance, I first ask the user to input a string. It is then supposed to use the function, called in the print statement, to count the vowels in the user inputted string. Currently, when typing a string, such as Kay, it produces an error code on line 6 that states ""for char in (string):"" which is the beginning of the for loop. The purpose of this loop is to ensure all letters are being checked for vowels before the code quits. There is a proper indentation, indicated by the lack of error and the principles of computer science and programming. The user inputted portion, which states ""string= input(""Please enter a phrase. "")"" defines the variable string, and is placed at the top of the code.</p>
","9201867","9201867","2018-03-01 00:29:39","For Loop in a Function for Counting Vowels in a User Inputted String","<python><python-3.x><function><for-loop>","7","1","1210"
"49040869","2018-03-01 00:31:17","1","","<p>You can use the <a href=""https://en.m.wikipedia.org/wiki/Sieve_of_Eratosthenes"" rel=""nofollow noreferrer"">Sieve of Eratosthenes</a>.  It's a much faster method to find the first <em>n</em> prime numbers.</p>
","3295264","","","4","211","dshus","2014-02-11 01:16:40","135","22","4","0","49040843","","2018-03-01 00:28:06","1","351","<p>I'm running the following code to find the sum of the first 10,000,000 prime numbers.
How can I optimize it such that it doesn't take forever to obtain the result(the sum of prime numbers)?</p>

<pre><code>sum=0
num=2
iterator=0

while iterator&lt;10000000:
    prime = True

    for i in range(2,num):
        if (num%i==0):
            prime = False

    if prime:
        sum=sum+num
         # print (num, sum, iterator)
        iterator=iterator+1
    num=num+1

print(sum)
</code></pre>
","3019388","1953800","2018-03-01 00:36:44","Prime numbers sum - for loop and big numbers","<python><for-loop><optimization><primes>","3","4","496"
"49040887","2018-03-01 00:33:45","0","","<p>I think you want to use ""in"" here:</p>

<pre><code>string = raw_input('Please enter a phrase. ')
def countvowels(string):
  string = str(string).lower()
  sum = 0
  for char in string:
    if char in ('a', 'e', 'i', 'o', 'u'):
      sum += 1
  print(sum)
  return sum


countvowels(string)
</code></pre>
","2460780","","","0","307","kjmerf","2013-06-06 17:45:39","3260","302","2014","6","49040796","49040834","2018-03-01 00:21:17","0","572","<p>I am attempting to run a for loop in a function that is designed to count the vowels in a user inputted string. However, the error ""builtins: TypeError"" keeps appearing. I have tried simply using the length of the string, using the len function, but the error simply won't go away, and the code is ultimately broken because of this. Is there a solution to this? <a href=""https://i.stack.imgur.com/adXTN.png"" rel=""nofollow noreferrer"">Screenshot of the code with the error message showing</a></p>

<p>For instance, I first ask the user to input a string. It is then supposed to use the function, called in the print statement, to count the vowels in the user inputted string. Currently, when typing a string, such as Kay, it produces an error code on line 6 that states ""for char in (string):"" which is the beginning of the for loop. The purpose of this loop is to ensure all letters are being checked for vowels before the code quits. There is a proper indentation, indicated by the lack of error and the principles of computer science and programming. The user inputted portion, which states ""string= input(""Please enter a phrase. "")"" defines the variable string, and is placed at the top of the code.</p>
","9201867","9201867","2018-03-01 00:29:39","For Loop in a Function for Counting Vowels in a User Inputted String","<python><python-3.x><function><for-loop>","7","1","1210"
"49040912","2018-03-01 00:36:21","3","","<p>the 10,000,000 th prime is approximately  <code>n * ln(n) + n * ln( ln(n) )</code> or  <code>~188980383</code> ... then you can use a sieve to find all primes under that value (discard any extras ... (ie you will get about 50k extra prime numbers when using 10million, note this took approximately 8 seconds for me))</p>

<p>see also : <a href=""https://stackoverflow.com/questions/4911777/finding-first-n-primes"">Finding first n primes?</a></p>

<p>see also : <a href=""https://stackoverflow.com/questions/2068372/fastest-way-to-list-all-primes-below-n"">Fastest way to list all primes below N</a></p>
","541038","541038","2018-03-01 00:41:46","0","603","Joran Beasley","2010-12-13 20:25:48","78235","8961","4223","838","49040843","","2018-03-01 00:28:06","1","351","<p>I'm running the following code to find the sum of the first 10,000,000 prime numbers.
How can I optimize it such that it doesn't take forever to obtain the result(the sum of prime numbers)?</p>

<pre><code>sum=0
num=2
iterator=0

while iterator&lt;10000000:
    prime = True

    for i in range(2,num):
        if (num%i==0):
            prime = False

    if prime:
        sum=sum+num
         # print (num, sum, iterator)
        iterator=iterator+1
    num=num+1

print(sum)
</code></pre>
","3019388","1953800","2018-03-01 00:36:44","Prime numbers sum - for loop and big numbers","<python><for-loop><optimization><primes>","3","4","496"
"49040927","2018-03-01 00:38:30","0","","<p>I used regex to find the <code>td</code> that contains the word 'Ether' and just parsed that tag.</p>

<p>Code:</p>

<pre><code>import bs4, requests, re

res = requests.get('https://etherscan.io/address/0x93673eeed88fda9423b8037374164383df54aec1')
res.raise_for_status()

soup = bs4.BeautifulSoup(res.text, 'html.parser')
ethBal = soup.find('td', text=re.compile('Ether')).text

print('The ETH blance is '+ ethBal)
</code></pre>

<p>Output:</p>

<pre><code>The ETH blance is 
0 Ether
</code></pre>
","5365862","","","0","501","Ali","2015-09-23 02:41:52","1167","164","509","31","49040814","49042666","2018-03-01 00:23:49","-1","842","<p>New to Python and am trying to use BeautifulSoup to pull the ""ETH Balance"" from the an etherscan.com webpage with this code:</p>

<pre><code>import bs4, requests

res = requests.get('https://etherscan.io/address/0x93673eeed88fda9423b8037374164383df54aec1')
res.raise_for_status()

soup = bs4.BeautifulSoup(res.text, 'html.parser')
ethBal = soup.find(""td"", text=""ETH Balance"").find_next(""td"").text

print('The ETH blance is '+ ethBal)
</code></pre>

<p>However I keep getting and error that reads:</p>

<pre><code>Traceback (most recent call last):
  File ""/Users/tfountain/Desktop/python_work/c2.py"", line 7, in &lt;module&gt;
    ethBal = soup.find(""td"", text=""ETH Balance"").find_next(""td"").text
AttributeError: 'NoneType' object has no attribute 'find_next'
</code></pre>

<p>Where am I going wrong and what would be the best way to get the ETH Balance?</p>
","9426337","","","How to get next td value in BeautifulSoup","<python><beautifulsoup>","2","3","863"
"49040955","2018-03-01 00:43:35","0","","<p>The kernel code can also be stored in a <strong>.c</strong> file as <strong>foo.c</strong>.
That way its easier to edit in editors like xcode. 
It can be read the same way</p>

<pre><code>prg = cl.Program(ctx, open('foo.c').read()).build()
</code></pre>
","3842788","","","0","257","Aseem","2014-07-15 22:05:53","1232","259","570","6","39644821","39646088","2016-09-22 16:57:19","3","433","<p>I'm trying to store the kernel part of the code, with the 3 """""" , in a different file. I tried saving it as a text file and a bin file, and reading it in, but I didn't find success with it. It started giving me an error saying """""" is missing, or ) is missing. ""However, if i just copy paste the kernel code into cl.Program(, it works. </p>

<p>So, is there a way to abstract long kernel code out into another file? This is specific to python, thank you!</p>

<pre><code>#Kernel function
prg = cl.Program(ctx, """"""
__kernel void sum(__global double *a, __global double *b, __global double *c)
{
  int gid = get_global_id(0);
  c[gid] = 1;

}
"""""").build()
</code></pre>

<p>So pretty much everything inside """"""  """""", the second argument of cl.Program() function, I wan't to move into a different file.</p>
","6785536","6785536","2016-09-22 17:47:31","Storing Kernel in Separate File - PyOpenCL","<python><opencl><pycuda><pyopencl>","2","2","806"
"49040985","2018-03-01 00:47:17","0","","<p>In my case, when I installed sklearn, it was by default pointing to python3.5 where I wanted to use it with python 2.7. Following suggestion by Vitor, I ran the following command: </p>

<pre><code>    sudo python -m pip install -U scikit-learn
</code></pre>

<p>and it worked for me!</p>
","1103444","","","0","291","AUKhan","2011-12-17 12:33:02","38","10","26","0","48180251","48180616","2018-01-10 04:20:20","0","855","<p>I wanted to upgrade sklearn in python 2.7 with pip but I couldn't because since a day or two pip seems to be pointing to python 3.4, not python 2.7: </p>

<pre><code>&gt; pip install -U scikit-learn
Requirement already up-to-date: scikit-learn in /home/kinkyboy/.local/lib/python3.4/site-packages
Cleaning up...
</code></pre>

<p>This shows my current pip* commands:</p>

<pre><code>&gt; pip -V
pip 1.5.4 from /usr/lib/python3/dist-packages (python 3.4)
&gt; pip2 -V
pip 1.5.4 from /usr/lib/python2.7/dist-packages (python 2.7)
&gt; pip3 -V
pip 1.5.4 from /usr/lib/python3/dist-packages (python 3.4)
</code></pre>

<p>and this shows that python is using python 2.7: </p>

<pre><code>&gt; which python
python is /usr/bin/python
python is /home/kinkyboy/conda/bin/python
&gt; ls -l /usr/bin/python
lrwxrwxrwx 1 root root 9 Jan  6  2016 /usr/bin/python -&gt; python2.7*
</code></pre>

<p>I managed to upgrade sklearn using pip2, but how to point pip back to python 2.7? </p>

<p><strong>Update</strong>:
I tried the following and I get a permission denied error. </p>

<pre><code>&gt; python -m pip install -U --force-reinstall pip
Collecting pip
  Using cached pip-9.0.1-py2.py3-none-any.whl
Installing collected packages: pip
  Found existing installation: pip 9.0.1
    Uninstalling pip-9.0.1:
Exception:
Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/usr/local/lib/python2.7/dist-packages/pip/commands/install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""/usr/local/lib/python2.7/dist-packages/pip/req/req_set.py"", line 778, in install
    requirement.uninstall(auto_confirm=True)
  File ""/usr/local/lib/python2.7/dist-packages/pip/req/req_install.py"", line 754, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/usr/local/lib/python2.7/dist-packages/pip/req/req_uninstall.py"", line 115, in remove
    renames(path, new_path)
  File ""/usr/local/lib/python2.7/dist-packages/pip/utils/__init__.py"", line 267, in renames
    shutil.move(old, new)
  File ""/usr/lib/python2.7/shutil.py"", line 303, in move
    os.unlink(src)
OSError: [Errno 13] Permission denied: '/usr/bin/pip'
</code></pre>

<p>Even if I know using sudo is bad (though I might have used it in the past), I tried to run the same command with sudo (it worked), i tried to give '/usr/bin/pip' 777 permission (but it still did not help to run the normal uninstall above), and I also did a sudo uninstall python-pip (did not help the normal uninstall above). After these attempts I put everything back to what it was.</p>
","3592827","3592827","2018-01-11 00:16:19","Cannot upgrade sklearn, pip pointing to python3","<python><python-2.7><pip>","4","5","2635"
"49041010","2018-03-01 00:51:23","0","","<pre><code>X = np.zeros((1, length, EMBED_DIM))
</code></pre>

<p><code>X</code> is 3d.</p>

<pre><code>X[0, i]
</code></pre>

<p>selects on first 2 dir, so it is (EMBED_DIM,), which according to the error is (50,).</p>

<p>The error thinks <code>y_embed</code> is (2,50), 2 columns of 50.  Apparently it was created by the last iteration.</p>

<pre><code>my_model.predict(X[:, :i+1, :])[0] 
</code></pre>

<p>With <code>i==1</code>, it is giving <code>predict</code> <code>X[:,:2,:]</code>, a (2,50) array.  I don't know what <code>predict</code> does, but I don't think it's a coincidence that the output has the same shape as the input.</p>
","901925","","","0","644","hpaulj","2011-08-19 06:44:39","130801","8991","3044","37","49038401","","2018-02-28 20:56:24","0","750","<p>Here's the first part of my function that wants to generate text from a trained LSTM and a word embedding of dim 50. The problem comes when I try to set row i of X equal to the embedding vector y_embed. However, that problem only comes up on the third iteration of the for loop. That's strange to me, because I'd expect every row of X to have the same shape.</p>

<pre><code>def generate_text(my_model, length):
    ix = np.random.randint(VOCAB_SIZE) #start generating by some 
         random index
    y_word = [reverse_dictionary[ix]] #get the word with that index
    y_embed = w2vec[ix] #get the embedding vector
    print(y_embed.shape)

    X = np.zeros((1, length, EMBED_DIM)) #make our numpy array
    print(X[0,2].shape)
    for i in range(length): #however many words we want
        print(""i is ""+str(i))
        X[0, i] = y_embed #current row of X is current word embedding
        y_embed = my_model.predict(X[:, :i+1, :])[0] 
        #input what we've generated so far, model.predict gives us a list, take the first one
        #we'll add it to our input on the next loop iteration

        y_word.append(vec2w(y_embed)) #lookup the word by its embedding
</code></pre>

<p>The for loop works for its first two iterations, and then throws this error when i=2:  </p>

<pre><code> X[0, i] = y_embed #current row of X is current word embedding  
 ValueError: could not broadcast input array from shape (2,50) into shape (50)
</code></pre>

<p>So that's why I have it print the shape of y_embed and X[0,2] beforehand, and the console prints:</p>

<pre><code>(50,)

(50,)
</code></pre>

<p>So as far as I can tell, they DO have the same shape. I'm still pretty new to numpy, so maybe it's something obvious, but I can't figure this one out. I should add that I'm using Keras, and model.predict expects a 3D tensor, which is why X is defined the way it is. I also tried setting X[0,i,:] = y_embed but that produced the same error at the same time.</p>
","9425747","901925","2018-03-01 00:48:49","Unable to broadcast numpy array, but .shape says they have the same shape","<python><arrays><numpy><shape><broadcast>","1","0","1963"
"49041042","2018-03-01 00:54:59","0","","<p>The input request and the drawing logic ought to be separated.<br>
Here is one approach that returns the turtle at the start at each turn, after increasing the side length.</p>

<pre><code>import turtle

num_squares = 3
t = turtle.Turtle()
t.pendown()
side = side_unit = 30

while True:
    try:
        num_squares = int(input('input the number of squares'))
    except ValueError:
        print(""please enter an integer"")
    if num_squares &gt; 3:
        break

for sq in range(1, num_squares + 1):
    t.left(90)
    t.forward(side)
    t.left(90)
    t.forward(side)
    t.left(90)
    t.forward(side)
    t.left(90)
    side = side_unit + 3 * sq  # increase the size of the side

    t.goto(0,0)                # return to base

turtle.done()
</code></pre>
","2875563","","","1","767","Reblochon Masque","2013-10-13 07:06:56","23302","2751","885","2671","49038809","49041042","2018-02-28 21:23:49","0","2187","<p>I am trying to create a loop that takes an input by a user and draws however many squares but it increases the size of the squares with each loop, however 2 sides are stay connected.  I'll include the graphic to better explain.</p>

<p><a href=""https://i.stack.imgur.com/zgv0m.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zgv0m.png"" alt=""enter image description here""></a></p>

<pre><code>    import turtle

squares = 1
while squares &gt;= 1:
    squares = int(input('How many squares would you like drawn?:'))
    if squares == 0:
        print(""You must have at-least 1 square."")
        squares = int(input('How many squares would you like drawn?:'))
    else:
        for count in range(squares):
            turtle.forward(30)
            turtle.left(90)
            turtle.forward(30)
            turtle.left(90)
            turtle.forward(30)
            turtle.left(90)
            turtle.forward(30)
            turtle.left(90)


turtle.done()
</code></pre>
","8277566","3001761","2018-02-28 21:24:52","Turtle Graphics: Repeating Squares","<python><python-3.x><turtle-graphics>","2","4","992"
"49041045","2018-03-01 00:55:31","0","","<p>I see one obvious problem. I've used <code>ctypes</code> successfully but cannot claim to be an expert so it's possible there is some other problem as well.</p>

<p>I think you must be defining the argument prototype for <code>libc.accept</code> some place, but that's not in your posted source code so I will assume it's correct. Assuming the prototype is consistent with the libc binding: <code>accept's</code> third argument (<code>addrlen</code>) is a <em>pointer</em> to <code>socklen_t</code>, but you're just passing a length (<em>not a pointer to a length</em>). </p>

<p>The usual way this is done is that you create a <code>socklen_t</code> variable and fill it in with the size of your <code>addr</code> buffer, then <code>accept</code> (as it's completing) copies the peer's address into your <code>addr</code> buffer, truncating if it's too large, but <em>updating</em> the passed <code>addrlen</code> with the actual size. From (linux version of) <code>accept(2)</code>:</p>

<blockquote>
  <p>The  <code>addrlen</code> argument is a value-result argument: the caller must initialize it to contain the size (in bytes) of the structure pointed to by <code>addr</code>; on return it will contain the actual size of the peer address.</p>
  
  <p>The returned address is truncated if the buffer provided is too small; in this case, <code>addrlen</code> will return a value greater than was supplied to the call.</p>
</blockquote>

<p>So, in summary, it is likely the <em>third</em> argument which is causing your <code>EFAULT</code> - not the second. This is supported by your <code>truss</code> output which shows <code>addrlen</code> being passed to the kernel as <code>0x10</code>: that is usually not a valid memory address.</p>
","1076479","","","1","1746","Gil Hamilton","2011-12-01 23:19:46","9571","712","161","103","49039607","","2018-02-28 22:22:08","0","87","<p>The normal python socket module does not support protocols besides AF_INET when creating sockets:</p>

<p><em>From cpython socketmodule.c</em>:</p>

<ul>
<li>Only AF_INET, AF_INET6 and AF_UNIX address families are supported in a<br>
portable manner, though AF_PACKET, AF_NETLINK and AF_TIPC are supported<br>
under Linux. </li>
</ul>

<p>So I have gone about manually calling the normal BSD socket library's socket, bind, listen, and accept calls directly from libc using ctypes.
I can create the socket, bind the socket to an address, and put the socket in listen mode which require casting references to the Structure inherited SockAddr_In class that I have made:</p>

<pre><code>CharArr14 = c_char * 14                                                                                                       
In_Addr = c_uint32                                                                                                            
CharArr8 = c_char * 8                                                                                                         


class SockAddr(Structure):                                                                                                    
    _fields_ = [                                                                                                              
        ('sa_len', c_uint8),                                                                                                  
        ('sa_family', c_uint8),                                                                                               
        ('sa_data', CharArr14)                                                                                                
    ]                                                                                                                         


class SockAddr_In(Structure):                                                                                                 
    _fields_ = [                                                                                                              
        ('sa_len', c_uint8),                                                                                                  
        ('sa_family', c_uint8),                                                                                               
        ('sin_port', c_uint16),                                                                                               
        ('sin_addr', In_Addr),                                                                                                
        ('sin_zero', CharArr8)                                                                                                
    ]  
</code></pre>

<p>But when I attempt to call accept, which has an address passed that the kernel will write the connecting socket's SockAddr_In structure information, I am receiving EFAULT (errno 14) which corresponds to bad memory address.</p>

<pre><code>def accept_sdp_sock(self):                                                                                                
    accept = libc.accept                                                                                                  
    logger.debug(""Accepting socket on: {}"".format(self.ip_addr))                                                          
    # int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);                                                  
    # Why is this a bad address? Is it being deallocated?                                                                 
    # Maybe it isn't allocating until we fill it with data?                                                               

    addr = SockAddr_In()                                                                                                  
    logger.debug(""Memory address of addr struct: {}"".format(addr))                                                        
    afd = accept(self.fd,                                                                                                 
                 cast(byref(addr), POINTER(SockAddr)),                                                                    
                 sizeof(SockAddr_In))                                                                                     
    # Check accept fd for errors                                                                                          
    if afd == -1:                                                                                                         
        self.errno = get_errno()                                                                                          
        logger.debug(""Accept call failed: {} "".format(self.errno))                                                        

    return afd
</code></pre>

<p>So that we are seeing this output with the memory addresses outlined by the program</p>

<pre><code>#truss -fead -s65535 -o truss_out python sdp_sock_cmd.py -l --address 192.168.66.140 --debug
2018-02-28 13:59:40,008 - DEBUG - This is a debug message
2018-02-28 13:59:40,009 - INFO - And an info
2018-02-28 13:59:40,009 - DEBUG - Creating SDP socket 
2018-02-28 13:59:40,010 - DEBUG - Binding SDP socket to : 192.168.66.140
2018-02-28 13:59:40,011 - DEBUG - Memory address of addr struct: &lt;ib_socks.SockAddr_In object at 0x80385d9e0&gt;
2018-02-28 13:59:40,012 - DEBUG - Socket listening on: 192.168.66.140
2018-02-28 13:59:40,013 - DEBUG - Accepting socket on: 192.168.66.140
2018-02-28 13:59:40,014 - DEBUG - Memory address of addr struct: &lt;ib_socks.SockAddr_In object at 0x80385d9e0&gt;
2018-02-28 13:59:40,015 - DEBUG - Accept call failed: 14
</code></pre>

<p>In the truss output we see this:</p>

<pre><code>18105: 0.288079361 accept(3,0x80385da30,0x10)    ERR#14 'Bad address'
</code></pre>

<p>I've tried allocating using malloc from libc making a string buffer using create_string_buffer() from ctypes but I am seeing the EFAULT in both of those cases. Why am I seeing a EFAULT in this case? How can I allocate a data structure with python using ctypes to allow the kernel to move data to userspace? </p>
","8457310","","","EFAULT when using ctypes with python and calling libc accept","<python><sockets><ctypes><cpython>","1","1","6186"
"49041083","2018-03-01 01:00:57","0","","<p>reduce would work on a list instead of a dictionary.</p>

<p>Try this:</p>

<p>Create a list of data frames (df)</p>

<pre><code>import pandas as pd
import subprocess
import os
from functools import reduce

path='C:\Users\ra\Desktop\Px\a\'

df = []
x = [#vector that contains the name of the csv files as string]
for j in x:
    df.append(pd.read_csv(path+j+'.csv')) 

df_merged = functools.reduce(lambda left, right: pd.merge(left, right, how= 'outer', on = ['D']), df)
</code></pre>
","4877653","4877653","2018-03-01 07:48:32","6","488","Ankit Malik","2015-05-08 05:26:48","75","19","2","0","49040837","49053359","2018-03-01 00:27:11","0","1583","<p>The data that I'm using looks like this:</p>

<pre><code>csv1 = pd.DataFrame({'D': [1-10, 2-10, 3-10, 4-10,...], #dates
...:                'C': [#, #, #, #,...]} #values

csv2 = pd.DataFrame({'D': [3-10, 4-10, 5-10, 6-10,...], #dates
...:                'C': [#, #, #, #,...]} #values

csv3 = pd.DataFrame({'D': [5-10, 6-10, 7-10, 8-10,...], #dates
...:                'C': [#, #, #, #,...]} #values
.
.
.
csv100 = pd.DataFrame({'D': [5-10, 6-10, 7-10, 8-10,...], #dates
...:                'C': [#, #, #, #,...]} #values
</code></pre>

<p>I want a data frame like this:</p>

<pre><code>df_merged = pd.DataFrame({'D': [1-10,2-10,3-10,4-10,5-10,6-10...] #dates
...:                  'C1': [#, #, #, #, #, #...]} #values
                      'C2': [#, #, #, #, #, #...]} #values
                      'C3': [#, #, #, #, #, #...]} #values
                      .
                      .
                      .
                      'C100': [#, #, #, #, #, #]} #values
</code></pre>

<p>I have been trying to merge multiple data frames, around 100, that have the same columns but different rows (they don’t have the same order), I would like to do it by the column 'date' (to merge every row with the same date). Because the amount of data frames is high, and changes over time (today I could have 110, tomorrow I could have 90...), the method of using a loop to merge each one of them is too slow. By researching for a solution, I found that the consensus is to use dictionaries. I applied this solution to my code but I got an error and I don’t know how to solve it. The code is the following</p>

<pre><code>import pandas as pd
import subprocess
import os
from functools import reduce

path=r'C:\Users\ra\Desktop\Px\a' #Folder 'a' path

df = {} #Dictionary of data frames from csv files in Folder 'a'
x = [#vector that contains the name of the csv file as string]
i = 0
for j in range(len(x)):
    df['df%s' %j] = (pd.read_csv(os.path.join(path,r'%s.csv' % x[i]))) #Assigns a key to the data frame Ex.:'df1' (the key is a string and I think this is the problem)
    df['df%s' %j].rename(columns={'C': '%s' % x[i]}, inplace=True) #Renames the column 'C' of every data frame to the name of the file
    i += 1

df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['D'],how='outer'),df) #Merges every data frame to a single data frame 'df_merged' by column 'D' that represents the date.
</code></pre>

<p>The problem is in the last line, the output is the following:</p>

<pre><code>---&gt; df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['D'],how='outer'),df)
.
.
.
ValueError: can not merge DataFrame with instance of type &lt;class 'str'&gt;
</code></pre>

<p>If I change the key from string to integer (by changing the vector x to simple numbers 'j') I get the following output:</p>

<pre><code>---&gt; df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['D'],how='outer'),df)
.
.
.
ValueError: can not merge DataFrame with instance of type &lt;class 'int'&gt;
</code></pre>

<p>To make the code work, I tried to find a way to convert the string keys to names. But, apparently, that is a sin. Also, according to @AnkitMalik the 'reduce' method can't be used with dictionaries. How can I merge all this data frames by the column 'D' in a pythonic way if the keys in the dictionary are strings/integers? Or, How can I make a dynamic list of data frames if their number changes over time depending on the amount of csv files in folder 'a'?</p>
","9370758","7851470","2019-04-25 09:26:39","Merge multiple pandas data frames in a dictionary if keys are strings/integers","<python><pandas><dataframe><dictionary><merge>","3","4","3483"
"49041134","2018-03-01 01:07:02","0","","<p>Figured out the way to use or in query :</p>

<pre><code>q = Q(""regexp"", text_en='someword.*') | Q(""regexp"", title_en='someword.*')

c = Search().query(q)
response = c.execute()
</code></pre>
","5881884","","","0","195","DevB2F","2016-02-04 07:45:39","2207","217","474","29","49040720","49041134","2018-03-01 00:12:48","0","56","<p>I have been using basic queries in python for elasticsearch like this:</p>

<pre><code>from elasticsearch import Elasticsearch
from elasticsearch_dsl import Search
es = Elasticsearch()

def someView(request):
    s = Search().query(""regexp"", title_en=""someword.*"")
    response = s.execute()
</code></pre>

<p>I would like to combine a query to check if someword exists in either of the fields ""title_en"" or ""text_en"" 
Any idea how to accomplish this?</p>

<p>In <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/6.2/query-dsl-bool-query.html"" rel=""nofollow noreferrer"">this</a> link I saw an example of a bool query using JSON, but I don´t understand how something similar could be done with python code.</p>

<pre><code>{
  ""query"": {
    ""bool"" : {
      ""must"" : {
        ""term"" : { ""user"" : ""kimchy"" }
      },
      ""filter"": {
        ""term"" : { ""tag"" : ""tech"" }
      },
      ""must_not"" : {
        ""range"" : {
          ""age"" : { ""gte"" : 10, ""lte"" : 20 }
        }
      },
      ""should"" : [
        { ""term"" : { ""tag"" : ""wow"" } },
        { ""term"" : { ""tag"" : ""elasticsearch"" } }
      ],
      ""minimum_should_match"" : 1,
      ""boost"" : 1.0
    }
  }
}
</code></pre>
","5881884","","","change JSON elasticsearch query to python","<python><json><django><elasticsearch>","1","0","1200"
"49041142","2018-03-01 01:08:09","22","","<p>First of all, pardon the overkill; I had fun with your question. If the description is too long, feel free to skip to the bottom, I defined a function that does everything I describe.</p>

<p>Your problem would be relatively straightforward if your arrays were the same length. In that case, all you would have to do is find the average between the corresponding x values in each array, and the corresponding y values in each array. </p>

<p>So what we can do is <em>create</em> arrays of the same length, that are more or less good estimates of your original arrays. We can do this by fitting a polynomial to the arrays you have. As noted in comments and other answers, the midline of your original arrays is not specifically defined, so a good estimate should fulfill your needs.</p>

<p>Note: In all of these examples, I've gone ahead and named the two arrays that you posted <code>a1</code> and <code>a2</code>.</p>

<h3>Step one: Create new arrays that estimate your old lines</h3>

<p>Looking at the data you posted: </p>

<p><a href=""https://i.stack.imgur.com/dam3Q.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/dam3Q.png"" alt=""the data""></a></p>

<p>These aren't particularly complicated functions, it looks like a 3rd degree polynomial would fit them pretty well. We can create those using <code>numpy</code>:</p>

<pre><code>import numpy as np

# Find the range of x values in a1
min_a1_x, max_a1_x = min(a1[:,0]), max(a1[:,0])
# Create an evenly spaced array that ranges from the minimum to the maximum
# I used 100 elements, but you can use more or fewer. 
# This will be used as your new x coordinates
new_a1_x = np.linspace(min_a1_x, max_a1_x, 100)
# Fit a 3rd degree polynomial to your data
a1_coefs = np.polyfit(a1[:,0],a1[:,1], 3)
# Get your new y coordinates from the coefficients of the above polynomial
new_a1_y = np.polyval(a1_coefs, new_a1_x)

# Repeat for array 2:
min_a2_x, max_a2_x = min(a2[:,0]), max(a2[:,0])
new_a2_x = np.linspace(min_a2_x, max_a2_x, 100)
a2_coefs = np.polyfit(a2[:,0],a2[:,1], 3)
new_a2_y = np.polyval(a2_coefs, new_a2_x)
</code></pre>

<p>The result:</p>

<p><a href=""https://i.stack.imgur.com/T8GGw.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/T8GGw.png"" alt=""Fitted Arrays""></a></p>

<p>That's not bad so bad! If you have more complicated functions, you'll have to fit a higher degree polynomial, or find some other adequate function to fit to your data.</p>

<p>Now, you've got two sets of arrays of the same length (I chose a length of 100, you can do more or less depending on how smooth you want your midpoint line to be). These sets represent the x and y coordinates of the <em>estimates</em> of your original arrays. In the example above, I named these <code>new_a1_x</code>, <code>new_a1_y</code>, <code>new_a2_x</code> and <code>new_a2_y</code>.</p>

<h3>Step two: calculate the average between each x and each y in your new arrays</h3>

<p>Then, we want to find the average x and average y value for each of our estimate arrays. Just use <code>np.mean</code>:</p>

<pre><code>midx = [np.mean([new_a1_x[i], new_a2_x[i]]) for i in range(100)]
midy = [np.mean([new_a1_y[i], new_a2_y[i]]) for i in range(100)]
</code></pre>

<p><code>midx</code> and <code>midy</code> now represent the midpoint between our 2 estimate arrays. Now, just plot your original (not estimate) arrays, alongside your midpoint array:</p>

<pre><code>plt.plot(a1[:,0], a1[:,1],c='black')
plt.plot(a2[:,0], a2[:,1],c='black')
plt.plot(midx, midy, '--', c='black')
plt.show()
</code></pre>

<p>And voilà:</p>

<p><a href=""https://i.stack.imgur.com/QIqZA.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/QIqZA.png"" alt=""final product""></a></p>

<p>This method still works with more complex, noisy data (but you have to fit the function thoughtfully):</p>

<p><a href=""https://i.stack.imgur.com/Zifue.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Zifue.png"" alt=""noisy data""></a></p>

<h3>As a function:</h3>

<p>I've put the above code in a function, so you can use it easily. It returns an array of your estimated midpoints, in the format you had your original arrays in.</p>

<p>The arguments: <code>a1</code> and <code>a2</code> are your 2 input arrays, <code>poly_deg</code> is the degree polynomial you want to fit, <code>n_points</code> is the number of points you want in your midpoint array, and <code>plot</code> is a boolean, whether you want to plot it or not.</p>

<pre><code>import matplotlib.pyplot as plt
import numpy as np

def interpolate(a1, a2, poly_deg=3, n_points=100, plot=True):

    min_a1_x, max_a1_x = min(a1[:,0]), max(a1[:,0])
    new_a1_x = np.linspace(min_a1_x, max_a1_x, n_points)
    a1_coefs = np.polyfit(a1[:,0],a1[:,1], poly_deg)
    new_a1_y = np.polyval(a1_coefs, new_a1_x)

    min_a2_x, max_a2_x = min(a2[:,0]), max(a2[:,0])
    new_a2_x = np.linspace(min_a2_x, max_a2_x, n_points)
    a2_coefs = np.polyfit(a2[:,0],a2[:,1], poly_deg)
    new_a2_y = np.polyval(a2_coefs, new_a2_x)

    midx = [np.mean([new_a1_x[i], new_a2_x[i]]) for i in range(n_points)]
    midy = [np.mean([new_a1_y[i], new_a2_y[i]]) for i in range(n_points)]

    if plot:
        plt.plot(a1[:,0], a1[:,1],c='black')
        plt.plot(a2[:,0], a2[:,1],c='black')
        plt.plot(midx, midy, '--', c='black')
        plt.show()

    return np.array([[x, y] for x, y in zip(midx, midy)])
</code></pre>

<p><strong>[EDIT]:</strong></p>

<p>I was thinking back on this question, and I overlooked a simpler way to do this, by ""densifying"" both arrays to the same number of points using <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html"" rel=""noreferrer""><code>np.interp</code></a>. This method follows the same basic idea as the line-fitting method above, but instead of approximating lines using <code>polyfit</code> / <code>polyval</code>, it just densifies:</p>

<pre><code>min_a1_x, max_a1_x = min(a1[:,0]), max(a1[:,0])
min_a2_x, max_a2_x = min(a2[:,0]), max(a2[:,0])

new_a1_x = np.linspace(min_a1_x, max_a1_x, 100)
new_a2_x = np.linspace(min_a2_x, max_a2_x, 100)

new_a1_y = np.interp(new_a1_x, a1[:,0], a1[:,1])
new_a2_y = np.interp(new_a2_x, a2[:,0], a2[:,1])

midx = [np.mean([new_a1_x[i], new_a2_x[i]]) for i in range(100)]
midy = [np.mean([new_a1_y[i], new_a2_y[i]]) for i in range(100)]

plt.plot(a1[:,0], a1[:,1],c='black')
plt.plot(a2[:,0], a2[:,1],c='black')
plt.plot(midx, midy, '--', c='black')
plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/DS47q.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/DS47q.png"" alt=""enter image description here""></a></p>
","6671176","6671176","2018-08-16 20:05:18","4","6606","sacuL","2016-08-03 07:43:41","32843","1871","2095","286","49037902","49038999","2018-02-28 20:21:59","11","2344","<p>Note: I asked this question before but it was closed as a duplicate, however, I, along with several others believe it was unduely closed, I explain why in an edit in my original <a href=""https://stackoverflow.com/questions/47493154/interpolating-a-line-between-two-other-lines-in-python"">post</a>. So I would like to re-ask this question here again.</p>

<p>Does anyone know of a python library that can interpolate between two lines. For example, given the two solid lines below, I would like to produce the dashed line in the middle. In other words, I'd like to get the centreline. The input is a just two <code>numpy</code> arrays of coordinates with size <code>N x 2</code> and <code>M x 2</code> respectively.</p>

<p><a href=""https://i.stack.imgur.com/yGZH9.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/yGZH9.png"" alt=""enter image description here""></a></p>

<p>Furthermore, I'd like to know if someone has written a function for this in some optimized python library. Although optimization isn't exactly a necessary.</p>

<p>Here is an example of two lines that I might have, you can assume they do not overlap with each other and an x/y can have multiple y/x coordinates.</p>

<pre><code>array([[ 1233.87375018,  1230.07095987],
       [ 1237.63559365,  1253.90749041],
       [ 1240.87500801,  1264.43925132],
       [ 1245.30875975,  1274.63795396],
       [ 1256.1449357 ,  1294.48254424],
       [ 1264.33600095,  1304.47893299],
       [ 1273.38192911,  1313.71468591],
       [ 1283.12411536,  1322.35942538],
       [ 1293.2559388 ,  1330.55873344],
       [ 1309.4817002 ,  1342.53074698],
       [ 1325.7074616 ,  1354.50276051],
       [ 1341.93322301,  1366.47477405],
       [ 1358.15898441,  1378.44678759],
       [ 1394.38474581,  1390.41880113]])

array([[ 1152.27115094,  1281.52899302],
       [ 1155.53345506,  1295.30515742],
       [ 1163.56506781,  1318.41642169],
       [ 1168.03497425,  1330.03181319],
       [ 1173.26135672,  1341.30559949],
       [ 1184.07110925,  1356.54121651],
       [ 1194.88086178,  1371.77683353],
       [ 1202.58908737,  1381.41765447],
       [ 1210.72465255,  1390.65097106],
       [ 1227.81309742,  1403.2904646 ],
       [ 1244.90154229,  1415.92995815],
       [ 1261.98998716,  1428.56945169],
       [ 1275.89219696,  1438.21626352],
       [ 1289.79440676,  1447.86307535],
       [ 1303.69661656,  1457.50988719],
       [ 1323.80994319,  1470.41028655],
       [ 1343.92326983,  1488.31068591],
       [ 1354.31738934,  1499.33260989],
       [ 1374.48879779,  1516.93734053],
       [ 1394.66020624,  1534.54207116]])
</code></pre>

<p>Visualizing this we have:
<a href=""https://i.stack.imgur.com/kiHiG.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/kiHiG.png"" alt=""enter image description here""></a></p>

<p>So my attempt at this has been using the <code>skeletonize</code> function in the <code>skimage.morphology</code> library by first rasterizing the coordinates into a filled in polygon. However, I get branching at the ends like this:</p>

<p><a href=""https://i.stack.imgur.com/JgXlh.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/JgXlh.png"" alt=""enter image description here""></a></p>
","2158231","2158231","2018-02-28 21:37:56","How to interpolate a line between two other lines in python","<python><algorithm><math><geometry><interpolation>","2","4","3206"
"49041152","2018-03-01 01:09:10","1","","<p>you must have installed numpy manually using setup.py and apt pkg as well
you could do:</p>

<pre><code>import sys
print(sys.path)
sys.path.remove('/usr/lib/python/path/2/numpy')

in your app/__init__.py
</code></pre>

<p>set PYTHONHOME to your preference.  you could also use virtualenv to keep multiple python environments and switch between them.</p>
","9345307","","","0","357","Arkadiusz Tymieniecki","2018-02-11 09:33:00","96","39","0","0","49041028","","2018-03-01 00:53:48","0","22","<p>I have installed numpy on my debian machine using pip. Additionally, I think an older version of numpy is installed through <code>apt-get</code>.</p>

<p>Different users on my machine see the same numpy file, but have different versions of the software. For example, when I run <code>python -c 'import os,numpy;print(numpy.__file__); print(numpy.version.version)'</code>, both users print <code>/usr/local/lib/python2.7/dist-packages/numpy/__init__.pyc</code>, but one of them has version 1.12.1 and the other has 1.14.</p>

<p>I tried to remove numpy version that is installed through apt-get, but it will remove some other software as well. So I am hoping to find a solution that avoids removing the version installed through apt-get.</p>

<p>Has anyone experienced a similar issue before?</p>
","4231538","","","Different users on a machine have different versions of numpy","<python><numpy>","1","0","799"
"49041154","2018-03-01 01:09:12","0","","<p>My own spin. Uses collections which is more efficient. Useful if you're parsing an entire book</p>

<pre><code>from collections import Counter

user_input = input(""Please enter a string: "")

# counter occurances of each letter
counter = Counter(user_input)

# drop non vowels
vowels_only = {k : v for k, v in counter.items() if k in ""aeiou""}

# sum
vowels_total = sum(vowels_only.values())

print(""Total vowels:"", vowels_total)
</code></pre>

<h2>Quick solution</h2>

<p>Here is a simple, though non-pythonic (messy) solution</p>

<pre><code>user_input = input(""Please enter a string: "")

# filter out everything that isn't a vowel, then count the len of what's left
vowel_count = len(list(filter(lambda x: x in ""aeiou"", list(user_input))))

print(vowel_count)
</code></pre>
","2507197","2507197","2018-03-01 01:20:26","0","778","Alter","2013-06-20 23:44:44","1885","314","329","9","49040796","49040834","2018-03-01 00:21:17","0","572","<p>I am attempting to run a for loop in a function that is designed to count the vowels in a user inputted string. However, the error ""builtins: TypeError"" keeps appearing. I have tried simply using the length of the string, using the len function, but the error simply won't go away, and the code is ultimately broken because of this. Is there a solution to this? <a href=""https://i.stack.imgur.com/adXTN.png"" rel=""nofollow noreferrer"">Screenshot of the code with the error message showing</a></p>

<p>For instance, I first ask the user to input a string. It is then supposed to use the function, called in the print statement, to count the vowels in the user inputted string. Currently, when typing a string, such as Kay, it produces an error code on line 6 that states ""for char in (string):"" which is the beginning of the for loop. The purpose of this loop is to ensure all letters are being checked for vowels before the code quits. There is a proper indentation, indicated by the lack of error and the principles of computer science and programming. The user inputted portion, which states ""string= input(""Please enter a phrase. "")"" defines the variable string, and is placed at the top of the code.</p>
","9201867","9201867","2018-03-01 00:29:39","For Loop in a Function for Counting Vowels in a User Inputted String","<python><python-3.x><function><for-loop>","7","1","1210"
"49041162","2018-03-01 01:10:24","2","","<p>Yes, it is possible. You could use method <a href=""https://docs.microsoft.com/zh-cn/python/api/azure.mgmt.resource.resources.v2017_05_10.operations.resourcesoperations?view=azure-python#azure_mgmt_resource_resources_v2017_05_10_operations_ResourcesOperations_list"" rel=""nofollow noreferrer"">list</a> to get disks in your subscription.</p>

<p>For example:</p>

<pre><code>from azure.common.credentials import ServicePrincipalCredentials
from azure.mgmt.compute import ComputeManagementClient
from azure.mgmt.resource import ResourceManagementClient, SubscriptionClient

# Tenant ID for your Azure Subscription
TENANT_ID = ''

# Your Service Principal App ID
CLIENT = ''

# Your Service Principal Password
KEY = ''

credentials = ServicePrincipalCredentials(
    client_id = CLIENT,
    secret = KEY,
    tenant = TENANT_ID
)

subscription_id = ''

compute_client = ComputeManagementClient(credentials, subscription_id)

disks = compute_client.disks.list()
for disk in disks:
    print disk
</code></pre>

<p>Note: It will return all disks in your subscription. But it is possible some disks are not OS disk, they maybe Data disk or a disk that not attach for a VM.</p>
","6997262","","","4","1172","Shui shengbao","2016-10-11 09:43:44","14759","2156","334","10","49030127","49041162","2018-02-28 12:55:54","2","472","<p>I am fetching a list of OS Disks attached to VMs in Azure in all resource groups of specific subscription. I found a <a href=""https://docs.microsoft.com/en-us/cli/azure/disk?view=azure-cli-latest#az_disk_list"" rel=""nofollow noreferrer"">AZ utility</a> to fetch the list in json format.</p>

<p>Using below sequence I am able to get the list in json format, Is there any similar way to get this achieved using any python module ?</p>

<pre><code>az login
az account set --subscription &lt;subscription&gt;
az disk list
</code></pre>
","1164911","6997262","2018-03-02 01:46:37","Get a list of Azure OS Disks attached to VMs in specific subscription","<python><azure><disk><azure-cli>","1","0","534"
"49041164","2018-03-01 01:10:55","0","","<p>This is one way to create a <code>numpy</code> structured array from a csv file:</p>

<pre><code>import pandas as pd

arr = pd.read_csv('file.csv').to_records(index=False)

# rec.array([('a', 1, 3), ('b', 2, 4), ('c', 3, 2), ('a', 1, 3), ('b', 2, 1),
#            ('c', 3, 2)], 
#           dtype=[('Name', 'O'), ('Class', '&lt;i8'), ('Numbers', '&lt;i8')])
</code></pre>

<p>You can then work with <code>numpy</code> or (easier) <code>pandas</code> to perform your calculations.</p>
","9209546","","","0","487","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49041110","49042184","2018-03-01 01:04:29","0","416","<pre class=""lang-none prettyprint-override""><code>Name Class Species
a     1      3
b     2      4
c     3      2
a     1      3
b     2      1
c     3      2
</code></pre>

<p>This above mentioned data will be from CSV file. need to convert this to structured array using numpy. need header from the csv become the columns labels for the array.</p>

<p>Need to print the mean occurrences of each names in each class (the mean of each species for class 1, class 2, and class 3)</p>

<p>I used <code>numpy.genfromtxt()</code>.</p>
","9305276","355230","2019-01-12 09:48:16","CSV data to Numpy structured array?","<python><python-3.x><numpy>","2","4","530"
"49041227","2018-03-01 01:20:30","0","","<p>Why not just reconnect every N sec. In my ajax lookahead/database services whose are 30-40 lines of bottle I reconnect every hour to get the updates,
there are better databases suited if you need to work on live data:</p>

<pre><code>t0 = time.time()
con = None
connect_interval_in_sec = 3600

def myconnect(dbfile=&lt;path to dbfile&gt;):
    try:
        mycon = sqlite3.connect(dbfile)
        cur = mycon.cursor()
        cur.execute('SELECT SQLITE_VERSION()')
        data = cur.fetchone()
    except sqlite3.Error as e:
        print(""Error:{}"".format(e.args[0]))
        sys.exit(1)
    return mycon
</code></pre>

<p>And in main loop:</p>

<pre><code>if con is None or time.time()-t0 &gt; connect_interval_in_sec:
    con = myconnect()
    t0 = time.time()
&lt;do your query stuff on con&gt;
</code></pre>
","536262","","","0","817","MortenB","2010-12-09 10:32:21","637","106","691","7","14511337","14520670","2013-01-24 21:42:19","10","6844","<p>I currently am working on a web server in tornado, but am having issues with different bits of code trying to access the database at once.</p>

<p>I have simplified this by simply having a query function which basically does this (but slightly more advanced):</p>

<pre><code>def query(command, arguments = []):
    db = sqlite3.open(""models/data.db"")
    cursor = db.cursor()
    cursor.execute(command, arguments)
    result = cursor.findall()
    db.close()
    return result
</code></pre>

<p>I'm just wondering how efficient it is to reopen the database after every query (I would guess it is a very large constant time operation, or would it cache things or something?), and whether there's a better way to do this.</p>
","2009095","","","Efficiency of reopening sqlite database after each query","<python><sqlite>","4","2","729"
"49041236","2018-03-01 01:22:19","1","","<p>If I understand correctly, you would like <code>generated_username</code> to be called on a particular page, and generate a string. 
Later, on a different page, you want to use that earlier generated string in <code>new_full_list</code>. </p>

<p>To do this, you could create a class variable to hold this string. </p>

<pre><code>class Users():
    user_string = """"
</code></pre>

<p>Then, when on the correct page (I'm not sure what the rest of your code looks like/how you control the flow/when functions are called), you call <code>generated_username(driver)</code>.
We will modify <code>generated_username</code> to set the class variable we created earlier. </p>

<pre><code>def generated_username(self, driver):
    ...
    &lt;s&gt;return username&lt;/s&gt;
    this.user_string = username
</code></pre>

<p>When you later call <code>new_full_list(driver)</code> on a different page, you want it to use this previous value. We can do that as follows: </p>

<pre><code>def new_full_list(self,driver):
    l = driver.find_elements_by_xpath(""//*[@class='odd' or @class='even']/td[2]/a"")
    l = [x.text for x in l]
    l.append(self.user_string)
</code></pre>

<p>Right now, you are calling <code>generated_username</code> inside <code>new_full_list</code>, which means the entire function runs, including the <code>find_element</code> etc. </p>
","4339781","","","1","1354","Windmill","2014-12-09 03:10:30","2077","80","176","9","49020361","49041236","2018-02-28 00:56:50","0","40","<p>I have class method <code>generated_username</code> which is generate string and return that string, and I need to use this output in another method <code>new_full_list</code>, but I get run the whole method not just its output
Here is my code:</p>

<pre><code>class Users():

def generated_username(self, driver):
    username = driver.find_element_by_css_selector(""[id=systemUser_employeeName_empName]"").get_attribute('value')
    username = username.replace(' ', '').lower()
    username = username + ''.join(random.choice(string.digits) for i in range(3))
    return username

def new_full_list(self,driver):
    l = driver.find_elements_by_xpath(""//*[@class='odd' or @class='even']/td[2]/a"")
    l = [x.text for x in l]
    l.append(self.generated_username(driver))
</code></pre>
","6939940","6939940","2018-02-28 03:31:42","Python Hot to use output form one class method in another class method","<python><function><selenium><methods>","1","2","788"
"49041241","2018-03-01 01:23:11","4","","<p>From the source code, it appears to be implemented as a <code>dict</code> with a doubly linked list of keys for ordering, as well as another <code>dict</code> that maps keys to their position in the list.</p>

<ul>
<li>Insertion just adds to the end of the list.</li>
<li>Deletion uses the second dict to remove an element from the list.</li>
<li>Iteration iterates over the linked list.</li>
</ul>
","5770658","5770658","2018-03-01 01:28:40","1","402","internet_user","2016-01-10 19:03:16","2791","268","408","864","49041169","49041241","2018-03-01 01:11:36","4","89","<p>I'm curious as to <em>how</em> OrderedDict from the collections library keeps key/pair order? I looked around online and couldn't find an answer.</p>
","7619353","9209546","2018-03-01 01:20:17","How does OrderedDict keep things in Order in Python","<python><dictionary><data-structures><ordereddictionary>","1","3","153"
"49041285","2018-03-01 01:30:26","0","","<p>This is probably happening because you assume that <em>all</em> the packets in the pcap are TCP. You need to make sure that a packet is infact TCP before you parse its headers for <code>flags</code>. This can be done by checking for the <code>p</code> field in the <code>ip</code> header to be <code>6</code> (<code>dpkt.ip.IP_PROTO_TCP</code>):</p>

<pre><code>import dpkt

def parse_pcap(filepath):
    f = open(filepath)
    pcap = dpkt.pcap.Reader(f)
    for num, (ts, buff) in  enumerate(pcap):
        eth = dpkt.ethernet.Ethernet(buff)
        if eth.type != dpkt.ethernet.ETH_TYPE_IP:
            # We are only interested in IP packets
            continue
        ip = eth.data
        if ip.p != dpkt.ip.IP_PROTO_TCP:
            # We are only interested in TCP
            continue
        tcp = ip.data
        if ((tcp.flags &amp; dpkt.tcp.TH_SYN) and (tcp.flags &amp; dpkt.tcp.TH_ACK)):
            # TCP SYN and ACK
            print('Found TCP SYN &amp; ACK in Packet #%d'%num)
        print('Packet #{1:d} : {0:b} = 0x{0:x}'.format(tcp.flags, num))
</code></pre>

<p>I just tried this on the <code>http.pcap</code> file available <a href=""https://github.com/kbandla/dpkt/tree/master/examples/data"" rel=""nofollow noreferrer"">here</a> and here is the result:</p>

<pre><code>Packet #0 : 10 = 0x2
Found TCP SYN &amp; ACK in Packet #1
Packet #1 : 10010 = 0x12
Packet #2 : 10000 = 0x10
Packet #3 : 11000 = 0x18
</code></pre>
","539491","","","0","1440","Kiran Bandla","2010-05-27 16:20:27","546","174","5","0","49039653","49041285","2018-02-28 22:25:22","0","1839","<p>I used the dpkt python package to parse a pcap file, and did the following to get the tcp packets:</p>

<pre><code>f = open(fname)
pcap = dpkt.pcap.Reader(f)
tcps = []
for ts, buff in pcap_in:
    eth = dpkt.ethernet.Ethernet(buff)
    ip = eth.data
    tcp = ip.data
</code></pre>

<p>Now I want to see which ones had both SYN and ACK flags. I tried to put those with both of those flags in a list as follows:</p>

<pre><code>syn_plus_ack = []
for tcp in tcps:
    if ((tcp.flags &amp; dpkt.tcp.TH_SYN) and (tcp.flags &amp; dpkt.tcp.TH_ACK)):
        syn_plus_ack.append(tcp)
</code></pre>

<p>I am not sure if this is doing what I want it to do, because I tried it on a sample pcap file and there were so many packets with a high number of SYNs but no ACK+SYNs. </p>

<p>I noticed the value of tcp.flags in those in syn_plus_ack is 18, dpkt.tcp.TH_SYN is 2, and dpkt.tcp.TH_ACK is 16. Is the tcp.flags value the sum of the value of all flags in the packet? Is there something I am doing wrong?</p>
","9425966","","","What does the value of 'flags' attribute of tcp packet in pcap represent when read by dpkt in python?","<python><tcp><tcp-ip><tcpdump><dpkt>","1","2","1003"
"49041347","2018-03-01 01:38:01","1","","<p>I have taken your code, and I could see a few errors with it. With some manipulation, I have managed to make it work. This is the result:</p>

<pre><code>import Tkinter as tk
root = tk.Tk()
button3 = tk.Button(text=""Quit"", command=lambda: quit_program())
def quit_program():
    root.destroy()
button3.pack()
root.mainloop()
</code></pre>

<p>Good luck!</p>

<p>Jordan.</p>

<p>----- EDIT -----</p>

<p>Sorry, I failed to read your question fully. Hopefully this will aid your endeavours.</p>

<p>I put Brian's code into a program, and I added the destroy function just as you said. I then added a button in the class <code>StartPage</code>, in the function <code>__init__</code>. It can be found here, with the name <code>button3</code>.</p>

<pre><code>class StartPage(tk.Frame):

    def __init__(self, parent, controller):
        tk.Frame.__init__(self, parent)
        self.controller = controller
        label = tk.Label(self, text=""This is the start page"", 
font=controller.title_font)
        label.pack(side=""top"", fill=""x"", pady=10)

        button1 = tk.Button(self, text=""Go to Page One"",
                        command=lambda: 
controller.show_frame(""PageOne""))
        button2 = tk.Button(self, text=""Go to Page Two"",
                        command=lambda: 
controller.show_frame(""PageTwo""))
        button3 = tk.Button(self, text=""Quit"",
                        command=lambda: 
controller.quit_program())
        button1.pack()
        button2.pack()
        button3.pack()
</code></pre>

<p>My code ended up working perfectly, where when you press the button, it quits the program. I think you'll find that when you were calling on the <code>quit_program</code> function, you were calling it like: <code>controller.quitprogram</code>, where you should be adding in the parentheses after it, as it is a function, like: <code>controller.quit_program()</code>. I haven't seen what you have actually put into your code, but in your question, you did not include the parentheses in your call.</p>

<p>Hope this helps!</p>

<p>Jordan. </p>
","9425961","9425961","2018-03-01 02:14:02","4","2058","Jordan Mattiuzzo","2018-02-28 21:49:04","56","4","2","0","49041160","49041347","2018-03-01 01:10:02","0","84","<p>I'm planning on making a fairly complex GUI in Python using Tkinter for a senior project. I came across <a href=""https://stackoverflow.com/questions/7546050/switch-between-two-frames-in-tkinter"">this</a> link that provides a great structured way to go about handling switching between frames by stacking them.</p>

<p>I want to make a simple quit button that exits the program when pressed because the GUI I plan to make will not have the window frame around it to minimize, maximize or exit. If I add a function such as this:</p>

<pre><code>def quit_program(self):

    self.destroy()
</code></pre>

<p>And I put that function below the show_frame function and then in another class call upon it like so:</p>

<pre><code>button3 = tk.Button(self, text=""Quit"",
                        command=lambda: controller.quit_program)
</code></pre>

<p>It doesn't work. Why is that? And how would I go about making a quit button with this frame structure? </p>
","9426359","","","Python/Tkinter quit button for stacked frames","<python><python-3.x><tkinter>","2","0","956"
"49041352","2018-03-01 01:39:00","0","","<p>I believe this is what you want (create new axis and use broadcasting for full vectorization):</p>

<pre><code>import numpy as np

particles = np.arange(12).reshape((-1,3))
moved = np.array([0,2])
np.linalg.norm(particles[moved][:,None,:]-particles[None,:,:], axis=-1)

array([[  0.        ,   5.19615242,  10.39230485,  15.58845727],
       [ 10.39230485,   5.19615242,   0.        ,   5.19615242]])
</code></pre>
","4565947","4565947","2018-03-01 01:45:32","0","418","Julien","2015-02-14 07:01:34","8263","1977","449","3580","49040621","","2018-03-01 00:01:44","1","366","<p>I am a bit new to numpy and I am trying to calculate the pairwaise distance between some of the elements of a numpy array.</p>

<p>I have a numpy n x 3 array with n 3D cartesian coordinates (x,y,z) representing particles in a grid. Some of these particles move as the program runs and I need to keep track of the distances of the ones that move. I hold a list of integers with the index of the particles that have moved. </p>

<p>I am aware of pdist but this calculates the distance between every pair of particles, which would be inefficient as only some of them have moved. Ideally, for example, if only 1,2 have moved then I would only calculate the distance of 1 with 2...N and 2 with 3...N</p>

<p>What would be the most efficient way of doing this? Right now I have a double loop which doesn't seem ideal...</p>

<p><code>for i in np.nditer(particles_moved):
    particles = particles[particles!=i]
    for j in np.nditer(particles):
        distance(xyz,i, j)</code></p>

<p>Thanks</p>
","9426281","","","Calculating the Euclidean distance between SOME entries of numpy array","<python><arrays><numpy><distance>","2","3","996"
"49041355","2018-03-01 01:39:24","0","","<p>2 1d arrays:</p>

<pre><code>In [79]: x1=np.array([1,2,3])
In [80]: x2=np.array([4,5,6])
</code></pre>

<p>Make new array - 2d, with 2 rows</p>

<pre><code>In [81]: x12 = np.array((x1,x2))
In [82]: x12
Out[82]: 
array([[1, 2, 3],
       [4, 5, 6]])
</code></pre>

<p><code>np.array([[1,2,3],[4,5,6]])</code> does the same thing.</p>

<p>The arrays can be summed, element by element:</p>

<pre><code>In [83]: x1 + x2
Out[83]: array([5, 7, 9])
</code></pre>

<p>rows of the 2d array can also be summed:</p>

<pre><code>In [84]: x12.sum(axis=0)
Out[84]: array([5, 7, 9])
</code></pre>
","901925","","","0","585","hpaulj","2011-08-19 06:44:39","130801","8991","3044","37","49039113","49041355","2018-02-28 21:45:17","0","60","<p>I am not very familiar with python so I apologise in advance. Is it at all possible to have a numpy array such as <code>numpy.array([a, b, c])</code> and add that array to an empty numpy array as an element?</p>

<p>Assuming this is possible, is it possible to then sum the first value of each element of multiple arrays within the main numpy array. For instance, </p>

<p><code>numpy.array([numpy.array([a,b,c]), numpy.array([d,e,f])])</code></p>

<p>to then become </p>

<p><code>numpy.array([a + d, b + e, c + f])</code></p>

<p>I hope I have managed to explain clearly if unsure please feel free to ask me to expand.</p>

<p>Many Thanks :-)</p>
","9425862","6053728","2018-02-28 22:43:16","Can a numpy array have elements that are numpy arrays themselves?","<python><arrays><python-3.x><numpy>","2","4","652"
"49041414","2018-03-01 01:49:38","0","","<p>You can use <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html"" rel=""nofollow noreferrer""><code>.to_excel</code></a> with <code>index=False</code> and <code>header=False</code>.</p>

<pre><code>df.to_excel('test.xlsx', index=False, header=False)
</code></pre>

<p>But you may need to turn on 'Wrap Text' by yourself.</p>
","3494669","","","0","368","pe-pe-rry","2014-04-03 16:21:17","1824","199","871","21","49039057","49041414","2018-02-28 21:41:08","3","296","<pre><code>df=pd.DataFrame(['abc\n123\n232','1\n2\n3\n4\n5\n6'])
df.to_csv('text.csv')
</code></pre>

<p>I would like to have in a single cell in the xlsx (Edited: not csv):</p>

<pre><code>abc
123
232
</code></pre>

<p>The desired output is A1 cell <strong>only</strong> being filled.</p>

<p>The dataframe has only 1 cell.
But the above code would result in the xlsx (Edited: not csv) printing that 1 cell into multiple cells.
Is there a way to format and write the xlsx (Edited: not csv) into <strong>multilines</strong> <em>within</em> <strong><em>each</em> cell</strong>?</p>

<p>Edit:
I shall clarify my problem. There is nothing wrong with my dataframe definition. I would like the ""\n"" within the strings in each cell of the dataframe to become a line break within the xlsx (Edited: not csv) cell. this is another example.</p>

<pre><code>df=pd.DataFrame(['abc\n123\n232','1\n2\n3\n4\n5\n6'])
df.to_csv('text.csv')
</code></pre>

<p>The desired output is A1 and A2 cells <strong>only</strong> being filled.</p>

<p>Edit 2:
Not in csv but <strong>xlsx</strong>.</p>
","5406956","5406956","2018-03-01 00:54:24","Pandas: Write dataframe containing strings to xlsx with multiline format","<python><pandas><csv><xlsx>","1","2","1073"
"49041429","2018-03-01 01:51:43","0","","<p>I had exactly the problem as you described. I also wish someone can sharing his/her thoughts. The test images for training is black ground color, the figure is white. But once I predict the model with my data, it always shows the wrong number. I had tried to change background color but it predicts not right. Even the accuracy is pretty good after training. The image was gathered from web resources and drawn by myself, it is clearly readable and eligible. I pasted my predict code here:</p>

<pre><code>import tensorflow as tf
import pandas as pd
from cnn_mnist import cnn_model_fn
import numpy as np
import cv2

# Predict the image
#mnist = tf.contrib.learn.datasets.load_dataset(""mnist"")
#train_labels = np.asarray(mnist.train.labels, dtype=np.int32)
#eval_data = mnist.test.images
model = cnn_model_fn
mnist_classifier = tf.estimator.Estimator(
     model_fn=model, model_dir=""/tmp/mnist_convnet_model"")

im = cv2.imread(""D:\\tf_exe_2\\img_9.jpg"")
#im2 = np.reshape(im, [-1, 28, 28, 1])
pred_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={""x"": np.float32(im)}, 
    shuffle=False)
pred = list(mnist_classifier.predict(input_fn=pred_input_fn))
for el in pred:
    print(el)
#print(next(pred))
</code></pre>

<p>And the result is wrong. It should be zero in the image content.</p>

<pre><code>==================== RESTART: D:\tf_exe_2\cnn_predict.py ====================
INFO:tensorflow:Using default config.
INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_service': None, '_task_id': 0, '_session_config': None, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_num_worker_replicas': 1, '_model_dir': '/tmp/mnist_convnet_model', '_num_ps_replicas': 0, '_task_type': 'worker', '_is_chief': True, '_save_checkpoints_secs': 600, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x000001B2CD51E588&gt;, '_master': ''}
INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\model.ckpt-21020
{'probabilities': array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 'classes': 2}
{'probabilities': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), 'classes': 8}
{'probabilities': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), 'classes': 8}
&gt;&gt;&gt; 
</code></pre>

<p>All the training steps and configuration are followed by the Tensorflow tutorial. Maybe it shall try to carry on modifying the training parameters, such as shuffle or another configuration?</p>

<p>Here is the cnn_mnist.py, exactly same as TensorFlow tutorial:</p>

<pre><code>from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

#imports
import numpy as np
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)

def cnn_model_fn(features, labels, mode):
    """"""Model function for CNN""""""
    #Input Layer
    input_layer = tf.reshape(features[""x""], [-1,28,28,1])
    #Convolutional Layer #1
    conv1 = tf.layers.conv2d(
        inputs = input_layer,
        filters = 32,
        kernel_size=[5,5],
        padding = ""same"",
        activation=tf.nn.relu)

    #Pooling Layer #1
    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2,2], strides=2)

    #Convolutional Layer #2 and Pooling Layer #2
    conv2 = tf.layers.conv2d(
        inputs=pool1,
        filters=64,
        kernel_size=[5,5],
        padding=""same"",
        activation=tf.nn.relu)
    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2,2], strides=2)

    #Dense Layer
    pool2_flat = tf.reshape(pool2, [-1,7*7*64])
    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)
    dropout = tf.layers.dropout(
        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)

    #Logits Layer
    logits = tf.layers.dense(inputs=dropout, units=10)

    predictions = {
        #Generate predictions (for PREDICT and EVAL mode)
        ""classes"": tf.argmax(input=logits, axis=1),
        #Add 'softmax_tensor' to the graph. It is used for PREDICT and by the
        #'logging_hook'
        ""probabilities"": tf.nn.softmax(logits, name=""softmax_tensor"")
    }

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

    # Calculate Loss (for both TRAIN and EVAL modes
    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)


# Configure the Training Op (for TRAIN mode)
    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
        train_op = optimizer.minimize(
            loss=loss,
            global_step=tf.train.get_global_step())
        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

    # Add evaluation metrics (for EVAL mode)
    eval_metric_ops = {
        ""accuracy"": tf.metrics.accuracy(
            labels=labels, predictions=predictions[""classes""])}
    return tf.estimator.EstimatorSpec(
        mode=mode, loss=loss,eval_metric_ops=eval_metric_ops)

def main(unused_argv):
    #Load training and eval data
    mnist = tf.contrib.learn.datasets.load_dataset(""mnist"")
    train_data = mnist.train.images
    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)
    eval_data = mnist.test.images
    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)
    #Create the Estimator
    mnist_classifier = tf.estimator.Estimator(
        model_fn=cnn_model_fn, model_dir=""/tmp/mnist_convnet_model"")
    # Set up logging for predictions
    tensor_to_log = {""probabilities"": ""softmax_tensor""}
    logging_hook = tf.train.LoggingTensorHook(
        tensors=tensor_to_log, every_n_iter=50)
    # Train the model
    train_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"": train_data},
        y=train_labels,
        batch_size=100,
        num_epochs=None,
        shuffle=True)
    mnist_classifier.train(
        input_fn=train_input_fn,
        #original steps are 20000
        steps=20000, 
        hooks=[logging_hook])
    # Evaluate the model and print results
    eval_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"": eval_data},
        y=eval_labels,
        num_epochs=1,
        shuffle=False)
    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)
    print(eval_results)

if __name__ == ""__main__"":
    tf.app.run()
</code></pre>
","9418182","9418182","2018-03-01 07:33:32","0","6479","Willy","2018-02-27 10:43:02","78","8","0","0","49014208","","2018-02-27 17:07:34","0","347","<p>I've copied the code from the Tensorflow tutorial on using tf.layers basically verbatim, using the mnist training data and all that. The training and evaluation code, the prediction dictionary and the eval metrics are all left untouched. The problem I have is that I've been getting really irregular outputs on all of my own images that I've tried to feed to the network and get predictions on. There's two major problems I've faced so far:</p>

<p>1) Every image that I've fed to the network individually (after modifying them as shown in point 2) keeps giving me an output as: class [8]. That means that the network identifies it as the number '8', doesn't it? I've tried inputting a 4,7,0, etc but every time it gets read as an 8. The weird part is that after training, the network claims to have a very high accuracy rating but it doesn't even give me different outputs for different input digits. I'm wondering where exactly I've gone wrong. </p>

<p>2) I'm reading a .jpg image using the opencv imread function and converting it to float 64 first(with scikit-image) and then converting my image to a float 32 image with the numpy astype. I'm doing that so that the prediction actually goes through. For some reason, the network refuses to predict my regular uint8 image that gets read initially by opencv. The error message says that it will only take a float16, bfloat16 or float32 type image as the input.</p>

<p>Anyway, that's why I tried to tweak the original image as best I could and visually verified that the image doesn't appear to have changed compared to my original input image. Thus, with a float32 image input, the program gave me outputs but they were all the same(all were class [8]) and I'm thinking that I've made a mistake somewhere in the code.</p>

<p>Here's the source code, with my own tf.estimator.predict(). I am using Python 3.6.3 on Windows 10, both 64 bit if that's relevant.</p>

<pre><code>from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import tensorflow as tf
import cv2
import skimage


tf.logging.set_verbosity(tf.logging.INFO)


image1=cv2.imread(""E:\Predict_images\image (5).jpg"")
image2=skimage.util.img_as_float(image1)
image3=image2.astype(np.float32)
cv2.imshow('image1',image1)
cv2.imshow('image2',image2)
cv2.imshow('image 3',image3)

def cnn_model_fn(features, labels, mode):
  """"""Model function for CNN.""""""
  # Input Layer
  # Reshape X to 4-D tensor: [batch_size, width, height, channels]
  # MNIST images are 28x28 pixels, and have one color channel
  input_layer = tf.reshape(features[""x""], [-1, 28, 28, 1])

  # Convolutional Layer #1
  # Computes 32 features using a 5x5 filter with ReLU activation.
  # Padding is added to preserve width and height.
  # Input Tensor Shape: [batch_size, 28, 28, 1]
  # Output Tensor Shape: [batch_size, 28, 28, 32]
  conv1 = tf.layers.conv2d(
      inputs=input_layer,
      filters=32,
      kernel_size=[5, 5],
      padding=""same"",
      activation=tf.nn.relu)

  # Pooling Layer #1
  # First max pooling layer with a 2x2 filter and stride of 2
  # Input Tensor Shape: [batch_size, 28, 28, 32]
  # Output Tensor Shape: [batch_size, 14, 14, 32]
  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

  # Convolutional Layer #2
  # Computes 64 features using a 5x5 filter.
  # Padding is added to preserve width and height.
  # Input Tensor Shape: [batch_size, 14, 14, 32]
  # Output Tensor Shape: [batch_size, 14, 14, 64]
  conv2 = tf.layers.conv2d(
      inputs=pool1,
      filters=64,
      kernel_size=[5, 5],
      padding=""same"",
      activation=tf.nn.relu)

  # Pooling Layer #2
  # Second max pooling layer with a 2x2 filter and stride of 2
  # Input Tensor Shape: [batch_size, 14, 14, 64]
  # Output Tensor Shape: [batch_size, 7, 7, 64]
  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

  # Flatten tensor into a batch of vectors
  # Input Tensor Shape: [batch_size, 7, 7, 64]
  # Output Tensor Shape: [batch_size, 7 * 7 * 64]
  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])

  # Dense Layer
  # Densely connected layer with 1024 neurons
  # Input Tensor Shape: [batch_size, 7 * 7 * 64]
  # Output Tensor Shape: [batch_size, 1024]
  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)

  # Add dropout operation; 0.6 probability that element will be kept
  dropout = tf.layers.dropout(
      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)

  # Logits layer
  # Input Tensor Shape: [batch_size, 1024]
  # Output Tensor Shape: [batch_size, 10]
  logits = tf.layers.dense(inputs=dropout, units=10)

  predictions = {
      # Generate predictions (for PREDICT and EVAL mode)
      ""classes"": tf.argmax(input=logits, axis=1),
      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the
      # `logging_hook`.
      ""probabilities"": tf.nn.softmax(logits, name=""softmax_tensor"")
  }
  if mode == tf.estimator.ModeKeys.PREDICT:
    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

  # Calculate Loss (for both TRAIN and EVAL modes)
  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)

  # Configure the Training Op (for TRAIN mode)
  if mode == tf.estimator.ModeKeys.TRAIN:
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
    train_op = optimizer.minimize(
        loss=loss,
        global_step=tf.train.get_global_step())
    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

  # Add evaluation metrics (for EVAL mode)
  eval_metric_ops = {
      ""accuracy"": tf.metrics.accuracy(
          labels=labels, predictions=predictions[""classes""])}
  return tf.estimator.EstimatorSpec(
      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)


def main(unused_argv):
  # Load training and eval data
  mnist = tf.contrib.learn.datasets.load_dataset(""mnist"")
  train_data = mnist.train.images  # Returns np.array
  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)
  eval_data = mnist.test.images  # Returns np.array
  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)

  # Create the Estimator
  mnist_classifier = tf.estimator.Estimator(
      model_fn=cnn_model_fn, model_dir=""/tmp/mnist_convnet_model"")

  # Set up logging for predictions
  # Log the values in the ""Softmax"" tensor with label ""probabilities""
  tensors_to_log = {""probabilities"": ""softmax_tensor""}
  logging_hook = tf.train.LoggingTensorHook(
      tensors=tensors_to_log, every_n_iter=50)

  # Train the model
  train_input_fn = tf.estimator.inputs.numpy_input_fn(
      x={""x"": train_data},
      y=train_labels,
      batch_size=100,
      num_epochs=None,
      shuffle=True)
  mnist_classifier.train(
      input_fn=train_input_fn,
      steps=20000,
      hooks=[logging_hook])

  # Evaluate the model and print results
  eval_input_fn = tf.estimator.inputs.numpy_input_fn(
      x={""x"": eval_data},
      y=eval_labels,
      num_epochs=1,
      shuffle=False)
  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)
  print(eval_results)

  #Predict the result for new images
  pred_input_fn=tf.estimator.inputs.numpy_input_fn(
    x={""x"": image3},
    shuffle=False)
  pred = mnist_classifier.predict(input_fn=pred_input_fn)
  print (list(pred))

if __name__ == ""__main__"":
  tf.app.run()
</code></pre>

<p>This is the output given in the shell when i run this <a href=""https://i.stack.imgur.com/biWlc.jpg"" rel=""nofollow noreferrer"">It's an image of '1'</a>  float 32 image through it:</p>

<pre><code>INFO:tensorflow:Saving checkpoints for 20000 into /tmp/mnist_convnet_model\model.ckpt.
INFO:tensorflow:Loss for final step: 0.040543813.
INFO:tensorflow:Starting evaluation at 2018-02-25-19:40:57
INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\model.ckpt-20000
INFO:tensorflow:Finished evaluation at 2018-02-25-19:40:59
INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.9717, global_step = 20000, loss = 0.09776818
{'accuracy': 0.9717, 'loss': 0.09776818, 'global_step': 20000}
INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\model.ckpt-20000
[{'classes': 8, 'probabilities': array([4.6938831e-07, 3.4720117e-07, 5.8355248e-03, 7.6848278e-03,
   1.0895459e-06, 2.9385969e-06, 1.8598693e-06, 1.2013125e-09,
   9.8647296e-01, 5.2439987e-08], dtype=float32)}, {'classes': 8, 'probabilities': array([4.8870197e-07, 3.7765903e-07, 6.4324187e-03, 8.6945957e-03,
   6.3728720e-07, 3.2801559e-06, 1.5783016e-06, 1.3214099e-09,
   9.8486656e-01, 5.1528065e-08], dtype=float32)}, {'classes': 8, 'probabilities': array([5.9954516e-07, 3.2683863e-07, 7.1799601e-03, 8.4864357e-03,
   8.9206560e-07, 2.3296870e-06, 1.4247992e-06, 9.8779152e-10,
   9.8432791e-01, 7.0583980e-08], dtype=float32)}]
</code></pre>

<p>Edit: I'm just leaving a few more sample images I was using to try and make predictions. All of them show up as class 8.</p>

<p><a href=""https://i.stack.imgur.com/xyEYO.jpg"" rel=""nofollow noreferrer"">Two</a>  <a href=""https://i.stack.imgur.com/IBEVc.jpg"" rel=""nofollow noreferrer"">Six</a>  <a href=""https://i.stack.imgur.com/ktD7V.jpg"" rel=""nofollow noreferrer"">Three</a>  <a href=""https://i.stack.imgur.com/AOxbo.jpg"" rel=""nofollow noreferrer"">Four</a></p>
","9409823","3938208","2018-05-03 23:09:01","I get the same wrong output every time I try to make single image predictions in the example tf.layers. What am I doing wrong?","<python><tensorflow><machine-learning><mnist>","1","2","9320"
"49041433","2018-03-01 01:52:13","1","","<p>Use <code>order</code> parameter:</p>

<pre><code>order = [""Sunday"", ""Monday"", ""Tuesday"", ""Wednesday"", ""Thursday"", ""Friday"", ""Saturday""]
sns.boxplot(x=df.index.weekday_name, y=df.value, order=order)
</code></pre>

<p>If your dates are complete and contains data for every weekday, you will get something like:</p>

<p><a href=""https://i.stack.imgur.com/HBptj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HBptj.png"" alt=""enter image description here""></a></p>

<p>If say you don't have data for one of the weekday and still call the same code, you get something like:</p>

<p><a href=""https://i.stack.imgur.com/iDUms.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/iDUms.png"" alt=""enter image description here""></a></p>

<p>which is totally fine (at least for me), and you can also clearly see that there's no data for Tuesday, which tells you more about your data as well.</p>
","3216980","3216980","2018-03-01 13:25:30","0","921","Yilun Zhang","2014-01-20 22:22:55","3929","358","173","44","49034829","49041433","2018-02-28 16:58:03","0","726","<p>I have a simple dataset with days on it:</p>

<pre><code>dt, value, coltype
2017-01-01, 10, A 
2017-01-02, 11, B
2017-01-03, 30, A
2017-01-04, 90, C
2017-01-05, 9,  A
2017-01-06, 13, E
2017-01-07, 12, C
2017-01-08, 10, B
</code></pre>

<p>and I want to create a simple boxplot based on weekdays:</p>

<pre><code>import seaborn as sns
import pandas as pd

df = read_csv('mycsv.txt')
df.index = pd.to_datetime(df.dt)
sns.boxplot(x=df.index.weekday_name, y=value)
</code></pre>

<p>and what I get is a boxplot but with the week days not ordered:
<a href=""https://i.stack.imgur.com/e2m3o.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/e2m3o.png"" alt=""boxplot""></a></p>

<p>Is there a way do it directly on the boxplot function, without creating another column?</p>
","307283","","","Keep weekdays ordered on pandas boxplot using seaborn","<python><pandas><matplotlib><seaborn>","1","7","784"
"49041439","2018-03-01 01:52:47","1","","<p>On Fedora 27 in order to get pyaudio from a default python3 installation I did the following</p>

<pre><code>sudo dnf install python3-devel
sudo dnf install portaudio-devel
sudo pip3 install pyaudio
</code></pre>
","8133663","7311767","2018-03-01 02:13:08","1","216","Kaleb McGregor","2017-06-08 20:40:22","41","4","1","0","5921947","5922091","2011-05-07 15:17:36","49","49322","<p>I'm running Ubuntu 11.04, Python 2.7.1 and wanted to install Pyaudio. So I ran,</p>

<pre>$ sudo easy_install pyaudio</pre>

<p>in the terminal and the process exited with following error messages,</p>

<pre>
Searching for pyaudio
Reading http://pypi.python.org/simple/pyaudio/
Reading http://people.csail.mit.edu/hubert/pyaudio/
Best match: pyaudio 0.2.4
Downloading http://people.csail.mit.edu/hubert/pyaudio/packages/pyaudio-0.2.4.tar.gz
Processing pyaudio-0.2.4.tar.gz
Running PyAudio-0.2.4/setup.py -q bdist_egg --dist-dir /tmp/easy_install-0Tetss/PyAudio-0.2.4/egg-dist-tmp-PYy9T8
In file included from /usr/include/python2.7/Python.h:8:0,
                 from src/_portaudiomodule.c:30:
/usr/include/python2.7/pyconfig.h:1155:0: warning: ""_POSIX_C_SOURCE"" redefined
/usr/include/features.h:214:0: note: this is the location of the previous definition
src/_portaudiomodule.c:31:23: fatal error: portaudio.h: No such file or directory
compilation terminated.
error: Setup script exited with error: command 'gcc' failed with exit status 1
</pre>

<p>I wasn't sure whether to post this on askubuntu.com or here in stackoveflow, but anyway here it is in stackoverflow. Also I google'd a bit this question and found by installing python-dev have solved the problem for some. I've already installed python-dev. What may have gone wrong? </p>

<p><strong>UPDATE</strong></p>

<p>Following are the new errors I get after installing libportaudio-dev,</p>

<pre>
Searching for pyaudio
Reading http://pypi.python.org/simple/pyaudio/
Reading http://people.csail.mit.edu/hubert/pyaudio/
Best match: pyaudio 0.2.4
Downloading http://people.csail.mit.edu/hubert/pyaudio/packages/pyaudio-0.2.4.tar.gz
Processing pyaudio-0.2.4.tar.gz
Running PyAudio-0.2.4/setup.py -q bdist_egg --dist-dir /tmp/easy_install-LMpsIy/PyAudio-0.2.4/egg-dist-tmp-AExlqd
In file included from /usr/include/python2.7/Python.h:8:0,
                 from src/_portaudiomodule.c:30:
/usr/include/python2.7/pyconfig.h:1155:0: warning: ""_POSIX_C_SOURCE"" redefined
/usr/include/features.h:214:0: note: this is the location of the previous definition
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_hostApi’:
src/_portaudiomodule.c:211:38: error: ‘PaDeviceInfo’ has no member named ‘hostApi’
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_defaultLowInputLatency’:
src/_portaudiomodule.c:253:42: error: ‘PaDeviceInfo’ has no member named ‘defaultLowInputLatency’
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_defaultLowOutputLatency’:
src/_portaudiomodule.c:267:42: error: ‘PaDeviceInfo’ has no member named ‘defaultLowOutputLatency’
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_defaultHighInputLatency’:
src/_portaudiomodule.c:282:42: error: ‘PaDeviceInfo’ has no member named ‘defaultHighInputLatency’
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_defaultHighOutputLatency’:
src/_portaudiomodule.c:296:42: error: ‘PaDeviceInfo’ has no member named ‘defaultHighOutputLatency’
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_defaultSampleRate’:
src/_portaudiomodule.c:310:42: error: ‘PaDeviceInfo’ has no member named ‘defaultSampleRate’
src/_portaudiomodule.c: At top level:
src/_portaudiomodule.c:465:3: error: expected specifier-qualifier-list before ‘PaHostApiInfo’
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_structVersion’:
src/_portaudiomodule.c:475:13: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c:481:29: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_type’:
src/_portaudiomodule.c:489:13: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c:495:36: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_name’:
src/_portaudiomodule.c:503:13: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c:503:32: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c:509:34: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_deviceCount’:
src/_portaudiomodule.c:517:13: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c:523:29: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_defaultInputDevice’:
src/_portaudiomodule.c:531:13: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c:537:29: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_defaultOutputDevice’:
src/_portaudiomodule.c:545:13: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c:551:29: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_dealloc’:
src/_portaudiomodule.c:569:7: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c: At top level:
src/_portaudiomodule.c:910:3: error: expected specifier-qualifier-list before ‘PaStreamParameters’
src/_portaudiomodule.c: In function ‘_is_open’:
src/_portaudiomodule.c:921:23: error: ‘_pyAudio_Stream’ has no member named ‘is_open’
src/_portaudiomodule.c: In function ‘_cleanup_Stream_object’:
src/_portaudiomodule.c:932:19: error: ‘_pyAudio_Stream’ has no member named ‘streamInfo’
src/_portaudiomodule.c:933:17: error: ‘_pyAudio_Stream’ has no member named ‘streamInfo’
src/_portaudiomodule.c:935:19: error: ‘_pyAudio_Stream’ has no member named ‘inputParameters’
src/_portaudiomodule.c:936:22: error: ‘_pyAudio_Stream’ has no member named ‘inputParameters’
src/_portaudiomodule.c:937:17: error: ‘_pyAudio_Stream’ has no member named ‘inputParameters’
src/_portaudiomodule.c:940:19: error: ‘_pyAudio_Stream’ has no member named ‘outputParameters’
src/_portaudiomodule.c:941:22: error: ‘_pyAudio_Stream’ has no member named ‘outputParameters’
src/_portaudiomodule.c:942:17: error: ‘_pyAudio_Stream’ has no member named ‘outputParameters’
src/_portaudiomodule.c:946:15: error: ‘_pyAudio_Stream’ has no member named ‘is_open’
src/_portaudiomodule.c: In function ‘_pyAudio_Stream_get_structVersion’:
src/_portaudiomodule.c:973:13: error: ‘_pyAudio_Stream’ has no member named ‘streamInfo’
src/_portaudiomodule.c:981:29: error: ‘_pyAudio_Stream’ has no member named ‘streamInfo’
src/_portaudiomodule.c: In function ‘_pyAudio_Stream_get_inputLatency’:
src/_portaudiomodule.c:998:13: error: ‘_pyAudio_Stream’ has no member named ‘streamInfo’
src/_portaudiomodule.c:1006:33: error: ‘_pyAudio_Stream’ has no member named ‘streamInfo’
src/_portaudiomodule.c: In function ‘_pyAudio_Stream_get_outputLatency’:
src/_portaudiomodule.c:1023:13: error: ‘_pyAudio_Stream’ has no member named ‘streamInfo’
src/_portaudiomodule.c:1031:33: error: ‘_pyAudio_Stream’ has no member named ‘streamInfo’
src/_portaudiomodule.c: In function ‘_pyAudio_Stream_get_sampleRate’:
src/_portaudiomodule.c:1048:13: error: ‘_pyAudio_Stream’ has no member named ‘streamInfo’
src/_portaudiomodule.c:1056:33: error: ‘_pyAudio_Stream’ has no member named ‘streamInfo’
src/_portaudiomodule.c: In function ‘pa_get_version’:
src/_portaudiomodule.c:1168:3: warning: implicit declaration of function ‘Pa_GetVersion’
src/_portaudiomodule.c: In function ‘pa_get_version_text’:
src/_portaudiomodule.c:1177:3: warning: implicit declaration of function ‘Pa_GetVersionText’
src/_portaudiomodule.c:1177:3: warning: passing argument 1 of ‘PyString_FromString’ makes pointer from integer without a cast
/usr/include/python2.7/stringobject.h:63:24: note: expected ‘const char *’ but argument is of type ‘int’
src/_portaudiomodule.c: In function ‘pa_get_host_api_count’:
src/_portaudiomodule.c:1221:3: error: ‘PaHostApiIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1221:3: note: each undeclared identifier is reported only once for each function it appears in
src/_portaudiomodule.c:1221:18: error: expected ‘;’ before ‘count’
src/_portaudiomodule.c:1226:3: error: ‘count’ undeclared (first use in this function)
src/_portaudiomodule.c:1226:3: warning: implicit declaration of function ‘Pa_GetHostApiCount’
src/_portaudiomodule.c: In function ‘pa_get_default_host_api’:
src/_portaudiomodule.c:1248:3: error: ‘PaHostApiIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1248:18: error: expected ‘;’ before ‘index’
src/_portaudiomodule.c:1253:3: warning: implicit declaration of function ‘Pa_GetDefaultHostApi’
src/_portaudiomodule.c:1253:3: error: lvalue required as left operand of assignment
src/_portaudiomodule.c:1265:7: warning: passing argument 1 of ‘Pa_GetErrorText’ makes integer from pointer without a cast
/usr/include/portaudio.h:93:13: note: expected ‘PaError’ but argument is of type ‘char * (*)(const char *, int)’
src/_portaudiomodule.c:1269:3: warning: passing argument 1 of ‘PyInt_FromLong’ makes integer from pointer without a cast
/usr/include/python2.7/intobject.h:38:24: note: expected ‘long int’ but argument is of type ‘char * (*)(const char *, int)’
src/_portaudiomodule.c: In function ‘pa_host_api_type_id_to_host_api_index’:
src/_portaudiomodule.c:1275:3: error: ‘PaHostApiTypeId’ undeclared (first use in this function)
src/_portaudiomodule.c:1275:19: error: expected ‘;’ before ‘typeid’
src/_portaudiomodule.c:1276:3: error: ‘PaHostApiIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1276:18: error: expected ‘;’ before ‘index’
src/_portaudiomodule.c:1278:37: error: ‘typeid’ undeclared (first use in this function)
src/_portaudiomodule.c:1281:3: warning: implicit declaration of function ‘Pa_HostApiTypeIdToHostApiIndex’
src/_portaudiomodule.c:1293:7: warning: passing argument 1 of ‘Pa_GetErrorText’ makes integer from pointer without a cast
/usr/include/portaudio.h:93:13: note: expected ‘PaError’ but argument is of type ‘char * (*)(const char *, int)’
src/_portaudiomodule.c:1297:3: warning: passing argument 1 of ‘PyInt_FromLong’ makes integer from pointer without a cast
/usr/include/python2.7/intobject.h:38:24: note: expected ‘long int’ but argument is of type ‘char * (*)(const char *, int)’
src/_portaudiomodule.c: In function ‘pa_host_api_device_index_to_device_index’:
src/_portaudiomodule.c:1303:3: error: ‘PaHostApiIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1303:18: error: expected ‘;’ before ‘apiIndex’
src/_portaudiomodule.c:1305:3: error: ‘PaDeviceIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1305:17: error: expected ‘;’ before ‘devIndex’
src/_portaudiomodule.c:1308:38: error: ‘apiIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1311:3: error: ‘devIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1311:3: warning: implicit declaration of function ‘Pa_HostApiDeviceIndexToDeviceIndex’
src/_portaudiomodule.c: In function ‘pa_get_host_api_info’:
src/_portaudiomodule.c:1332:3: error: ‘PaHostApiIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1332:18: error: expected ‘;’ before ‘index’
src/_portaudiomodule.c:1333:3: error: ‘PaHostApiInfo’ undeclared (first use in this function)
src/_portaudiomodule.c:1333:18: error: ‘_info’ undeclared (first use in this function)
src/_portaudiomodule.c:1339:27: error: expected expression before ‘)’ token
src/_portaudiomodule.c:1345:7: error: ‘paInvalidHostApi’ undeclared (first use in this function)
src/_portaudiomodule.c:1350:10: error: ‘_pyAudio_paHostApiInfo’ has no member named ‘apiInfo’
src/_portaudiomodule.c: In function ‘pa_get_device_count’:
src/_portaudiomodule.c:1364:3: error: ‘PaDeviceIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1364:17: error: expected ‘;’ before ‘count’
src/_portaudiomodule.c:1369:3: error: ‘count’ undeclared (first use in this function)
src/_portaudiomodule.c:1369:3: warning: implicit declaration of function ‘Pa_GetDeviceCount’
src/_portaudiomodule.c: In function ‘pa_get_default_input_device’:
src/_portaudiomodule.c:1390:3: error: ‘PaDeviceIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1390:17: error: expected ‘;’ before ‘index’
src/_portaudiomodule.c:1395:3: warning: implicit declaration of function ‘Pa_GetDefaultInputDevice’
src/_portaudiomodule.c:1395:3: error: lvalue required as left operand of assignment
src/_portaudiomodule.c:1396:13: warning: comparison between pointer and integer
src/_portaudiomodule.c:1409:7: warning: passing argument 1 of ‘Pa_GetErrorText’ makes integer from pointer without a cast
/usr/include/portaudio.h:93:13: note: expected ‘PaError’ but argument is of type ‘char * (*)(const char *, int)’
src/_portaudiomodule.c:1413:3: warning: passing argument 1 of ‘PyInt_FromLong’ makes integer from pointer without a cast
/usr/include/python2.7/intobject.h:38:24: note: expected ‘long int’ but argument is of type ‘char * (*)(const char *, int)’
src/_portaudiomodule.c: In function ‘pa_get_default_output_device’:
src/_portaudiomodule.c:1419:3: error: ‘PaDeviceIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1419:17: error: expected ‘;’ before ‘index’
src/_portaudiomodule.c:1424:3: warning: implicit declaration of function ‘Pa_GetDefaultOutputDevice’
src/_portaudiomodule.c:1424:3: error: lvalue required as left operand of assignment
src/_portaudiomodule.c:1425:13: warning: comparison between pointer and integer
src/_portaudiomodule.c:1438:7: warning: passing argument 1 of ‘Pa_GetErrorText’ makes integer from pointer without a cast
/usr/include/portaudio.h:93:13: note: expected ‘PaError’ but argument is of type ‘char * (*)(const char *, int)’
src/_portaudiomodule.c:1442:3: warning: passing argument 1 of ‘PyInt_FromLong’ makes integer from pointer without a cast
/usr/include/python2.7/intobject.h:38:24: note: expected ‘long int’ but argument is of type ‘char * (*)(const char *, int)’
src/_portaudiomodule.c: In function ‘pa_get_device_info’:
src/_portaudiomodule.c:1448:3: error: ‘PaDeviceIndex’ undeclared (first use in this function)
src/_portaudiomodule.c:1448:17: error: expected ‘;’ before ‘index’
src/_portaudiomodule.c:1455:3: warning: passing argument 1 of ‘Pa_GetDeviceInfo’ makes integer from pointer without a cast
/usr/include/portaudio.h:182:21: note: expected ‘PaDeviceID’ but argument is of type ‘char * (*)(const char *, int)’
src/_portaudiomodule.c:1460:30: error: ‘paInvalidDevice’ undeclared (first use in this function)
src/_portaudiomodule.c: In function ‘pa_open’:
src/_portaudiomodule.c:1601:3: error: ‘PaStreamParameters’ undeclared (first use in this function)
src/_portaudiomodule.c:1601:23: error: ‘outputParameters’ undeclared (first use in this function)
src/_portaudiomodule.c:1602:23: error: ‘inputParameters’ undeclared (first use in this function)
src/_portaudiomodule.c:1606:28: error: expected expression before ‘)’ token
src/_portaudiomodule.c:1622:9: error: ‘paInvalidDevice’ undeclared (first use in this function)
src/_portaudiomodule.c:1643:28: error: expected expression before ‘)’ token
src/_portaudiomodule.c:1679:3: error: ‘PaStreamInfo’ undeclared (first use in this function)
src/_portaudiomodule.c:1679:17: error: ‘streamInfo’ undeclared (first use in this function)
src/_portaudiomodule.c:1696:9: warning: passing argument 5 of ‘Pa_OpenStream’ makes pointer from integer without a cast
/usr/include/portaudio.h:325:9: note: expected ‘void *’ but argument is of type ‘int’
src/_portaudiomodule.c:1696:9: warning: passing argument 7 of ‘Pa_OpenStream’ makes integer from pointer without a cast
/usr/include/portaudio.h:325:9: note: expected ‘int’ but argument is of type ‘void *’
src/_portaudiomodule.c:1696:9: warning: passing argument 8 of ‘Pa_OpenStream’ makes integer from pointer without a cast
/usr/include/portaudio.h:325:9: note: expected ‘PaSampleFormat’ but argument is of type ‘void *’
src/_portaudiomodule.c:1696:9: error: too few arguments to function ‘Pa_OpenStream’
/usr/include/portaudio.h:325:9: note: declared here
src/_portaudiomodule.c:1712:31: error: expected expression before ‘)’ token
src/_portaudiomodule.c:1724:15: error: ‘_pyAudio_Stream’ has no member named ‘inputParameters’
src/_portaudiomodule.c:1725:15: error: ‘_pyAudio_Stream’ has no member named ‘outputParameters’
src/_portaudiomodule.c:1726:15: error: ‘_pyAudio_Stream’ has no member named ‘is_open’
src/_portaudiomodule.c:1727:15: error: ‘_pyAudio_Stream’ has no member named ‘streamInfo’
src/_portaudiomodule.c: In function ‘pa_is_format_supported’:
src/_portaudiomodule.c:1791:3: error: ‘PaStreamParameters’ undeclared (first use in this function)
src/_portaudiomodule.c:1791:22: error: expected ‘;’ before ‘inputParams’
src/_portaudiomodule.c:1792:22: error: expected ‘;’ before ‘outputParams’
src/_portaudiomodule.c:1812:5: error: ‘inputParams’ undeclared (first use in this function)
src/_portaudiomodule.c:1820:5: error: ‘outputParams’ undeclared (first use in this function)
src/_portaudiomodule.c:1827:3: warning: implicit declaration of function ‘Pa_IsFormatSupported’
src/_portaudiomodule.c:1831:16: error: ‘paFormatIsSupported’ undeclared (first use in this function)
src/_portaudiomodule.c: In function ‘pa_start_stream’:
src/_portaudiomodule.c:1870:16: error: ‘paStreamIsNotStopped’ undeclared (first use in this function)
src/_portaudiomodule.c: In function ‘pa_stop_stream’:
src/_portaudiomodule.c:1911:16: error: ‘paStreamIsStopped’ undeclared (first use in this function)
src/_portaudiomodule.c: In function ‘pa_abort_stream’:
src/_portaudiomodule.c:1952:16: error: ‘paStreamIsStopped’ undeclared (first use in this function)
src/_portaudiomodule.c: In function ‘pa_is_stream_stopped’:
src/_portaudiomodule.c:1994:3: warning: implicit declaration of function ‘Pa_IsStreamStopped’
src/_portaudiomodule.c: In function ‘pa_is_stream_active’:
src/_portaudiomodule.c:2039:3: warning: implicit declaration of function ‘Pa_IsStreamActive’
src/_portaudiomodule.c: In function ‘pa_get_stream_time’:
src/_portaudiomodule.c:2086:3: warning: implicit declaration of function ‘Pa_GetStreamTime’
src/_portaudiomodule.c: In function ‘pa_get_stream_cpu_load’:
src/_portaudiomodule.c:2118:3: warning: implicit declaration of function ‘Pa_GetStreamCpuLoad’
src/_portaudiomodule.c: In function ‘pa_write_stream’:
src/_portaudiomodule.c:2167:3: warning: implicit declaration of function ‘Pa_WriteStream’
src/_portaudiomodule.c:2171:16: error: ‘paOutputUnderflowed’ undeclared (first use in this function)
src/_portaudiomodule.c: In function ‘pa_read_stream’:
src/_portaudiomodule.c:2233:3: error: ‘PaStreamParameters’ undeclared (first use in this function)
src/_portaudiomodule.c:2233:23: error: ‘inputParameters’ undeclared (first use in this function)
src/_portaudiomodule.c:2233:53: error: ‘_pyAudio_Stream’ has no member named ‘inputParameters’
src/_portaudiomodule.c:2253:3: warning: implicit declaration of function ‘Pa_ReadStream’
src/_portaudiomodule.c:2259:15: error: ‘paInputOverflowed’ undeclared (first use in this function)
src/_portaudiomodule.c:2265:22: error: ‘paOutputUnderflowed’ undeclared (first use in this function)
src/_portaudiomodule.c: In function ‘pa_get_stream_write_available’:
src/_portaudiomodule.c:2309:3: warning: implicit declaration of function ‘Pa_GetStreamWriteAvailable’
src/_portaudiomodule.c: In function ‘pa_get_stream_read_available’:
src/_portaudiomodule.c:2334:3: warning: implicit declaration of function ‘Pa_GetStreamReadAvailable’
src/_portaudiomodule.c: In function ‘init_portaudio’:
src/_portaudiomodule.c:2384:49: error: ‘paInDevelopment’ undeclared (first use in this function)
src/_portaudiomodule.c:2385:47: error: ‘paDirectSound’ undeclared (first use in this function)
src/_portaudiomodule.c:2386:39: error: ‘paMME’ undeclared (first use in this function)
src/_portaudiomodule.c:2387:40: error: ‘paASIO’ undeclared (first use in this function)
src/_portaudiomodule.c:2388:48: error: ‘paSoundManager’ undeclared (first use in this function)
src/_portaudiomodule.c:2389:45: error: ‘paCoreAudio’ undeclared (first use in this function)
src/_portaudiomodule.c:2390:39: error: ‘paOSS’ undeclared (first use in this function)
src/_portaudiomodule.c:2391:40: error: ‘paALSA’ undeclared (first use in this function)
src/_portaudiomodule.c:2392:38: error: ‘paAL’ undeclared (first use in this function)
src/_portaudiomodule.c:2393:40: error: ‘paBeOS’ undeclared (first use in this function)
src/_portaudiomodule.c:2394:41: error: ‘paWDMKS’ undeclared (first use in this function)
src/_portaudiomodule.c:2395:40: error: ‘paJACK’ undeclared (first use in this function)
src/_portaudiomodule.c:2396:42: error: ‘paWASAPI’ undeclared (first use in this function)
src/_portaudiomodule.c:2410:50: error: ‘paNotInitialized’ undeclared (first use in this function)
src/_portaudiomodule.c:2412:6: error: ‘paUnanticipatedHostError’ undeclared (first use in this function)
src/_portaudiomodule.c:2417:49: error: ‘paInvalidDevice’ undeclared (first use in this function)
src/_portaudiomodule.c:2433:6: error: ‘paIncompatibleHostApiSpecificStreamInfo’ undeclared (first use in this function)
src/_portaudiomodule.c:2434:51: error: ‘paStreamIsStopped’ undeclared (first use in this function)
src/_portaudiomodule.c:2435:54: error: ‘paStreamIsNotStopped’ undeclared (first use in this function)
src/_portaudiomodule.c:2436:51: error: ‘paInputOverflowed’ undeclared (first use in this function)
src/_portaudiomodule.c:2437:53: error: ‘paOutputUnderflowed’ undeclared (first use in this function)
src/_portaudiomodule.c:2438:51: error: ‘paHostApiNotFound’ undeclared (first use in this function)
src/_portaudiomodule.c:2439:50: error: ‘paInvalidHostApi’ undeclared (first use in this function)
src/_portaudiomodule.c:2441:6: error: ‘paCanNotReadFromACallbackStream’ undeclared (first use in this function)
src/_portaudiomodule.c:2443:6: error: ‘paCanNotWriteToACallbackStream’ undeclared (first use in this function)
src/_portaudiomodule.c:2445:6: error: ‘paCanNotReadFromAnOutputOnlyStream’ undeclared (first use in this function)
src/_portaudiomodule.c:2447:6: error: ‘paCanNotWriteToAnInputOnlyStream’ undeclared (first use in this function)
src/_portaudiomodule.c:2449:6: error: ‘paIncompatibleStreamHostApi’ undeclared (first use in this function)
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_defaultOutputDevice’:
src/_portaudiomodule.c:552:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_defaultInputDevice’:
src/_portaudiomodule.c:538:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_deviceCount’:
src/_portaudiomodule.c:524:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_type’:
src/_portaudiomodule.c:496:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_structVersion’:
src/_portaudiomodule.c:482:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_paHostApiInfo_get_name’:
src/_portaudiomodule.c:510:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_defaultSampleRate’:
src/_portaudiomodule.c:311:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_defaultHighOutputLatency’:
src/_portaudiomodule.c:297:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_defaultHighInputLatency’:
src/_portaudiomodule.c:283:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_defaultLowOutputLatency’:
src/_portaudiomodule.c:268:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_defaultLowInputLatency’:
src/_portaudiomodule.c:254:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_paDeviceInfo_get_hostApi’:
src/_portaudiomodule.c:212:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_Stream_get_sampleRate’:
src/_portaudiomodule.c:1057:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_is_open’:
src/_portaudiomodule.c:922:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_Stream_get_outputLatency’:
src/_portaudiomodule.c:1032:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_Stream_get_inputLatency’:
src/_portaudiomodule.c:1007:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘_pyAudio_Stream_get_structVersion’:
src/_portaudiomodule.c:982:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘pa_is_format_supported’:
src/_portaudiomodule.c:1841:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘pa_get_device_count’:
src/_portaudiomodule.c:1385:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘pa_host_api_device_index_to_device_index’:
src/_portaudiomodule.c:1327:1: warning: control reaches end of non-void function
src/_portaudiomodule.c: In function ‘pa_get_host_api_count’:
src/_portaudiomodule.c:1243:1: warning: control reaches end of non-void function
error: Setup script exited with error: command 'gcc' failed with exit status 1
</pre>
","391496","391496","2011-05-07 15:27:20","Pyaudio installation error - 'command 'gcc' failed with exit status 1'","<python><linux><gcc><pyaudio>","9","0","25745"
"49041463","2018-03-01 01:56:06","1","","<p>Well I'm an idiot. I was right about being wrong but I was wrong about how wrong I was. Let me explain.</p>

<p>Within the backwards training method I got the last layer trained correctly, but all layers after that wasn't trained correctly, hence why the above network was coming up with a result, it was indeed training, but only one layer.</p>

<p>So what did i do wrong? Well I was <strong>only</strong> multiplying by the local graident of the Weights with respect to the output, and thus the chain rule was partially correct. </p>

<p>Lets say the loss function was this:</p>

<p>t = Y-X2</p>

<p>loss = 1/2*(t)^2</p>

<p>a2 = X1W2 + b</p>

<p>X2 = activation(a2)</p>

<p>a1 = X0W1 + b</p>

<p>X1 = activation(a1)</p>

<p>We know that the the derivative of loss with respect to W2 would be -(Y-X2)*X1. This was done in the first part of my training function:</p>

<pre><code>def train(self,X,Y,loss,epoch=5000000):
    for i in range(epoch):
        #First part
        YHat = self.forward(X)
        delta = -(Y-YHat)
        loss.append(sum(Y-YHat))
        err = np.sum(np.dot(self.__layers[-1].localGrad,delta.T), axis=1)
        err.shape = (self.__hiddenDimensions[-1][0],1)
        self.__layers[-1].adjustWeights(err)
        i=0
        #Second part
        for l in reversed(self.__layers[:-1]):
            err = np.dot(l.localGrad, err)
            l.adjustWeights(err)
            i += 1
</code></pre>

<p>However the second part is where I screwed up. In order to calculate the loss with respect to W1, I must multiply the original error -(Y-X2) by W2 as W2 is the local X Gradient of the last layer, and due to the chain rule this must be done first. <strong>Then</strong> I could multiply by the local W gradient (X1) to get the loss with respect to W1. I failed to do the multiplication of the local X gradient first, so the last layer was indeed training, but all layers after that had an error that magnified as the layer increased. </p>

<p>To solve this I updated the train method:</p>

<pre><code>def train(self,X,Y,loss,epoch=10000):
    for i in range(epoch):
        YHat = self.forward(X)
        err = -(Y-YHat)
        loss.append(sum(Y-YHat))
        werr = np.sum(np.dot(self.__layers[-1].localWGrad,err.T), axis=1)
        werr.shape = (self.__hiddenDimensions[-1][0],1)
        self.__layers[-1].adjustWeights(werr)
        for l in reversed(self.__layers[:-1]):
            err = np.multiply(err, l.localXGrad)
            werr = np.sum(np.dot(l.weights,err.T),axis=1)
            l.adjustWeights(werr)
</code></pre>

<p>Now the loss graph I got looks like this:</p>

<p><a href=""https://i.stack.imgur.com/mFMrf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mFMrf.png"" alt=""enter image description here""></a></p>
","4416430","4416430","2018-03-01 02:55:52","1","2775","James","2015-01-04 03:34:04","624","125","23","6","48970179","49015373","2018-02-25 04:20:56","10","232","<p>I have this neural network that I've trained seen bellow, it works, or at least appears to work, but the problem is with the training. I'm trying to train it to act as an OR gate, but it never seems to get there, the output tends to looks like this:</p>

<pre><code>prior to training:

 [[0.50181624]
 [0.50183743]
 [0.50180414]
 [0.50182533]]

post training:

 [[0.69641759]
 [0.754652  ]
 [0.75447178]
 [0.79431198]]

expected output:

 [[0]
 [1]
 [1]
 [1]]
</code></pre>

<p>I have this loss graph: </p>

<p><a href=""https://i.stack.imgur.com/lwRUT.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/lwRUT.png"" alt=""enter image description here""></a></p>

<p>Its strange it appears to be training, but at the same time not quite getting to the expected output. I know that it would never really achieve the 0s and 1s, but at the same time I expect it to manage and get something a little bit closer to the expected output. </p>

<p>I had some issues trying to figure out how to back prop the error as I wanted to make this network have any number of hidden layers, so I stored the local gradient in a layer, along side the weights, and sent the error from the end back.</p>

<p>The main functions I suspect are the culprits are NeuralNetwork.train and both forward methods.</p>

<pre><code>import sys
import math
import numpy as np
import matplotlib.pyplot as plt
from itertools import product


class NeuralNetwork:
    class __Layer:
        def __init__(self,args):
            self.__epsilon = 1e-6
            self.localGrad = 0
            self.__weights = np.random.randn(
                args[""previousLayerHeight""],
                args[""height""]
            )*0.01
            self.__biases = np.zeros(
                (args[""biasHeight""],1)
            )

        def __str__(self):
            return str(self.__weights)

        def forward(self,X):
            a = np.dot(X, self.__weights) + self.__biases
            self.localGrad = np.dot(X.T,self.__sigmoidPrime(a))
            return self.__sigmoid(a)

        def adjustWeights(self, err):
            self.__weights -= (err * self.__epsilon)

        def __sigmoid(self, z):
            return 1/(1 + np.exp(-z))

        def __sigmoidPrime(self, a):
            return self.__sigmoid(a)*(1 - self.__sigmoid(a))

    def __init__(self,args):
        self.__inputDimensions = args[""inputDimensions""]
        self.__outputDimensions = args[""outputDimensions""]
        self.__hiddenDimensions = args[""hiddenDimensions""]
        self.__layers = []
        self.__constructLayers()

    def __constructLayers(self):
        self.__layers.append(
            self.__Layer(
                {
                    ""biasHeight"": self.__inputDimensions[0],
                    ""previousLayerHeight"": self.__inputDimensions[1],
                    ""height"": self.__hiddenDimensions[0][0] 
                        if len(self.__hiddenDimensions) &gt; 0 
                        else self.__outputDimensions[0]
                }
            )
        )

        for i in range(len(self.__hiddenDimensions)):
            self.__layers.append(
                self.__Layer(
                    {
                        ""biasHeight"": self.__hiddenDimensions[i + 1][0] 
                            if i + 1 &lt; len(self.__hiddenDimensions)
                            else self.__outputDimensions[0],
                        ""previousLayerHeight"": self.__hiddenDimensions[i][0],
                        ""height"": self.__hiddenDimensions[i + 1][0] 
                            if i + 1 &lt; len(self.__hiddenDimensions)
                            else self.__outputDimensions[0]
                    }
                )
            )

    def forward(self,X):
        out = self.__layers[0].forward(X)
        for i in range(len(self.__layers) - 1):
            out = self.__layers[i+1].forward(out)
        return out  

    def train(self,X,Y,loss,epoch=5000000):
        for i in range(epoch):
            YHat = self.forward(X)
            delta = -(Y-YHat)
            loss.append(sum(Y-YHat))
            err = np.sum(np.dot(self.__layers[-1].localGrad,delta.T), axis=1)
            err.shape = (self.__hiddenDimensions[-1][0],1)
            self.__layers[-1].adjustWeights(err)
            i=0
            for l in reversed(self.__layers[:-1]):
                err = np.dot(l.localGrad, err)
                l.adjustWeights(err)
                i += 1

    def printLayers(self):
        print(""Layers:\n"")
        for l in self.__layers:
            print(l)
            print(""\n"")

def main(args):
    X = np.array([[x,y] for x,y in product([0,1],repeat=2)])
    Y = np.array([[0],[1],[1],[1]])
    nn = NeuralNetwork(
        {
            #(height,width)
            ""inputDimensions"": (4,2),
            ""outputDimensions"": (1,1),
            ""hiddenDimensions"":[
                (6,1)
            ]
        }
    )

    print(""input:\n\n"",X,""\n"")
    print(""expected output:\n\n"",Y,""\n"")
    nn.printLayers()
    print(""prior to training:\n\n"",nn.forward(X), ""\n"")
    loss = []
    nn.train(X,Y,loss)
    print(""post training:\n\n"",nn.forward(X), ""\n"")
    nn.printLayers()
    fig,ax = plt.subplots()

    x = np.array([x for x in range(5000000)])
    loss = np.array(loss)
    ax.plot(x,loss)
    ax.set(xlabel=""epoch"",ylabel=""loss"",title=""logic gate training"")

    plt.show()

if(__name__==""__main__""):
    main(sys.argv[1:])
</code></pre>

<p>Could someone please point out what I'm doing wrong here, I strongly suspect it has to do with the way I'm dealing with matrices but at the same time I don't have the slightest idea what's going on.</p>

<p>Thanks for taking the time to read my question, and taking the time to respond (if relevant).</p>

<p>edit:
Actually quite a lot is wrong with this but I'm still a bit confused over how to fix it. Although the loss graph looks like its training, and it kind of is, the math I've done above is wrong. </p>

<p>Look at the training function. </p>

<pre><code>def train(self,X,Y,loss,epoch=5000000):
        for i in range(epoch):
            YHat = self.forward(X)
            delta = -(Y-YHat)
            loss.append(sum(Y-YHat))
            err = np.sum(np.dot(self.__layers[-1].localGrad,delta.T), axis=1)
            err.shape = (self.__hiddenDimensions[-1][0],1)
            self.__layers[-1].adjustWeights(err)
            i=0
            for l in reversed(self.__layers[:-1]):
                err = np.dot(l.localGrad, err)
                l.adjustWeights(err)
                i += 1
</code></pre>

<p>Note how I get delta = -(Y-Yhat) and then dot product it with the ""local gradient"" of the last layer. The ""local gradient"" is the local W gradient. </p>

<pre><code>def forward(self,X):
    a = np.dot(X, self.__weights) + self.__biases
    self.localGrad = np.dot(X.T,self.__sigmoidPrime(a))
    return self.__sigmoid(a)
</code></pre>

<p>I'm skipping a step in the chain rule. I should really be multiplying by W* sigprime(XW + b) first as that's the local gradient of X, then by the local W gradient. I tried that, but I'm still getting issues, here is the new forward method (note the __init__ for layers needs to be initialised for the new vars, and I changed the activation function to tanh)</p>

<pre><code>def forward(self, X):
    a = np.dot(X, self.__weights) + self.__biases
    self.localPartialGrad = self.__tanhPrime(a)
    self.localWGrad = np.dot(X.T, self.localPartialGrad)
    self.localXGrad = np.dot(self.localPartialGrad,self.__weights.T)            
    return self.__tanh(a)
</code></pre>

<p>and updated the training method to look something like this:</p>

<pre><code>def train(self, X, Y, loss, epoch=5000):
    for e in range(epoch):
        Yhat = self.forward(X)
        err = -(Y-Yhat)
        loss.append(sum(err))
        print(""loss:\n"",sum(err))
        for l in self.__layers[::-1]:
            l.adjustWeights(err)
            if(l != self.__layers[0]):
                err = np.multiply(err,l.localPartialGrad)
                err = np.multiply(err,l.localXGrad)
</code></pre>

<p>The new graphs I'm getting are all over the place, I have no idea what's going on. Here is the final bit of code I changed:</p>

<pre><code>def adjustWeights(self, err):
    perr = np.multiply(err, self.localPartialGrad)  
    werr = np.sum(np.dot(self.__weights,perr.T),axis=1)
    werr = werr * self.__epsilon
    werr.shape = (self.__weights.shape[0],1)
    self.__weights = self.__weights - werr
</code></pre>
","4416430","4416430","2018-03-01 01:02:00","Neural network backprop not fully training","<python><numpy><matrix><machine-learning><neural-network>","2","3","8477"
"49041477","2018-03-01 01:57:43","0","","<p>I don't believe that is any reason for you to put a <code>while</code> loop within your two-level <code>for</code> loop. With two <code>for</code> loops, you should be able to iterate through your list and use some other conditional-checker (hint: that you have already used in this script you've shown) to determine whether the current list element is in the right spot (for the moment - may be shuffled around later). You could look in to:</p>

<blockquote class=""spoiler"">
  <p> bubble sort</p>
</blockquote>
","9264848","9264848","2018-03-01 02:06:53","3","515","hscratch","2018-01-25 00:17:37","16","1","0","0","49041423","49041477","2018-03-01 01:51:02","0","50","<p>I am taking a beginners programming class using JES which I believe is Python 2.
My teacher has asked that we create an empty list and then add random numbers to it, then sort it from lowest to highest.  That part I have done correctly.  The extra credit is to add a nested for loop that will count the reps it takes to sort the list.
This is what I have:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>from random import *

def main():

# create list of 25 (this can be changed to number of your choice) random numbers from -100 to 100
# print list with message ""list before shuffling""
  numList = []
  count = 0
  while count &lt; 15:
    num = randint( -100 , 100 )
    numList.append(num)
    count = count + 1
  printNow(""the List before shuffling:  "" +str(numList))
  n = len(numList)
  add = 0
# Randomly shuffle list with items only moving if a lower number is being switched with a larger number
# do this 1000 times ( this can be changed to number of your choice)
# print list with message ""list after shuffling""
  for reps in range (0 , 500):
    i = randrange(0, n)
    j = randrange(0, n)
# extra credit, add nested for loop to count number of reps it takes to sort the list    
    for sort in range(0, len(numList)):
      for item in range(sort+1, len(numList)):
        while numList[sort] &lt; numList[item] or add &lt; reps:
          add = add + 1
       
    if i &lt; j:
      if numList[i] &gt; numList[j]:
        temp = numList[i]
        numList[i] = numList[j]            
        numList[j] = temp
    elif j &lt; i:
      if numList[i] &lt; numList[j]:
        temp = numList[j]
        numList[j] = numList[i]
        numList[i] = temp
        
  print("" List was sorted in "" + str(add) + "" reps."")
  printNow(""The List after shuffling:  "" +str(numList))</code></pre>
</div>
</div>
</p>

<p>My teacher says that I have too many loops in my extra credit section.  I am stuck and am looking for someone to explain what I am doing wrong.
I DO NOT want someone to solve it for me, but tell me what I am doing wrong.</p>
","9426532","","","In JES which I believe is Python 2, how do I do a nested for loop to count reps until a list is sorted","<python><jes>","1","0","2239"
"49041481","2018-03-01 01:58:24","3","","<p>ROIPooling layer is typically used for object detection networks such as <a href=""https://arxiv.org/abs/1311.2524"" rel=""nofollow noreferrer"">R-CNN</a> and its variants (<a href=""https://arxiv.org/abs/1504.08083"" rel=""nofollow noreferrer"">Fast R-CNN</a> and <a href=""https://arxiv.org/abs/1506.01497"" rel=""nofollow noreferrer"">Faster R-CNN</a>). The essential part of all these architectures is a component (neural or classical CV) that generates region proposals. These region proposals are basically ROIs that need to be fed into the ROIPooling layer. The output of ROIPooling layer is going to be a batch of tensors, where each tensor represents one cropped area of an image. Each of these tensors are processed independently for classification. For example, in R-CNN, these tensors are crops of the image in RGB, which are then run through a classification network. In Fast R-CNN and Faster R-CNN, tensors are features out of a convolutional network, for example ResNet34.</p>

<p>In your example, whether through a classic computer vision algorithm (as in R-CNN and Fast R-CNN) or using a Region Proposal Network (as in Faster R-CNN), you need to generate some ROIs that are <em>candidates</em> for containing object of interest. Once you have these ROIs for each image in one mini-batch, you then need to combine them into one NDArray of <code>[[batch_index, x1, y1, x2, y2]]</code>. What this dimensioning means is that you can basically have as many ROIs as you want, and for each ROI, you must specify which image in the batch to crop (hence the <code>batch_index</code>) and what coordinates to crop it at (hence the <code>(x1, y1)</code> for top-left-corner and <code>(x2,y2)</code> for bottom-right-corner coordinates).</p>

<p>So based on the above, if you're implementing something similar to R-CNN, you would be passing your images directly into the RoiPooling layer:</p>

<pre><code>class ClassifyObjects(gluon.HybridBlock):
    def __init__(self, num_classes, pooled_size):
        super(ClassifyObjects, self).__init__()
        self.classifier = gluon.model_zoo.vision.resnet34_v2(classes=num_classes)
        self.pooled_size = pooled_size

    def hybrid_forward(self, F, imgs, rois):
        return self.classifier(
            F.ROIPooling(
                imgs, rois, pooled_size=self.pooled_size, spatial_scale=1.0))


# num_classes are 10 categories plus 1 class for ""no-object-in-this-box"" category
net = ClassifyObjects(num_classes=11, pooled_size=(64, 64))
# Initialize parameters and overload pre-trained weights
net.collect_params().initialize()
pretrained_net = gluon.model_zoo.vision.resnet34_v2(pretrained=True)
net.classifier.features = pretrained_net.features
</code></pre>

<p>Now if we send dummy data through the network, you can see that if roi array contains 4 rois, the output is going to contain 4 classification results:</p>

<pre><code># Dummy forward pass through the network
imgs = x = nd.random.uniform(shape=(2, 3, 128, 128))  # shape is (batch_size, channels, height, width)
rois = nd.array([[0, 10, 10, 100, 100], [0, 20, 20, 120, 120],
                 [1, 15, 15, 110, 110], [1, 25, 25, 128, 128]])
out = net(imgs, rois)
print(out.shape)
</code></pre>

<p>Outputs:</p>

<pre><code>(4, 11)
</code></pre>

<p>If you want to, however, use ROIPooling with similar to Fast R-CNN or Faster R-CNN model, you need access to the features of the network before they are average pooled. These features are then ROIPooled before being passed up to classification. Here an example where the features are from the pre-trained network, the ROIPooling's <code>pooled_size</code> is 4x4, and a simple GlobalAveragePooling followed by a Dense layer is used for classification after ROIPooling. Note that because the image is max-pooled by a factor of 32 through the ResNet network, <code>spatial_scale</code> is set to <code>1.0/32</code> to let the ROIPooling layer automatically compensate the rois for that.</p>

<pre><code>def GetResnetFeatures(resnet):
    resnet.features._children.pop()  # Pop Flatten layer
    resnet.features._children.pop()  # Pop GlobalAveragePooling layer
    return resnet.features


class ClassifyObjects(gluon.HybridBlock):
    def __init__(self, num_classes, pooled_size):
        super(ClassifyObjects, self).__init__()
        # Add a placeholder for features block
        self.features = gluon.nn.HybridSequential()
        # Add a classifier block
        self.classifier = gluon.nn.HybridSequential()
        self.classifier.add(gluon.nn.GlobalAvgPool2D())
        self.classifier.add(gluon.nn.Flatten())
        self.classifier.add(gluon.nn.Dense(num_classes))
        self.pooled_size = pooled_size

    def hybrid_forward(self, F, imgs, rois):
        features = self.features(imgs)
        return self.classifier(
            F.ROIPooling(
                features, rois, pooled_size=self.pooled_size, spatial_scale=1.0/32))


# num_classes are 10 categories plus 1 class for ""no-object-in-this-box"" category
net = ClassifyObjects(num_classes=11, pooled_size=(4, 4))
# Initialize parameters and overload pre-trained weights
net.collect_params().initialize()
net.features = GetResnetFeatures(gluon.model_zoo.vision.resnet34_v2(pretrained=True))
</code></pre>

<p>Now if we send dummy data through the network, you can see that if roi array contains 4 rois, the output is going to contain 4 classification results:</p>

<pre><code># Dummy forward pass through the network
# shape of each image is (batch_size, channels, height, width)
imgs = x = nd.random.uniform(shape=(2, 3, 128, 128))
# rois is the output of region proposal module of your architecture
# Each ROI entry contains [batch_index, x1, y1, x2, y2]
rois = nd.array([[0, 10, 10, 100, 100], [0, 20, 20, 120, 120],
                 [1, 15, 15, 110, 110], [1, 25, 25, 128, 128]])
out = net(imgs, rois)
print(out.shape)
</code></pre>

<p>Outputs:</p>

<pre><code>(4, 11)
</code></pre>
","9015998","","","3","5921","Sina Afrooze","2017-11-27 17:11:55","1027","121","7","2","48272913","49041481","2018-01-16 01:30:19","9","501","<p>Assume  I have a Resnet34 pretained model in MXNet and I want to add to it the premade ROIPooling Layer included in the API:</p>

<p><a href=""https://mxnet.incubator.apache.org/api/python/ndarray/ndarray.html#mxnet.ndarray.ROIPooling"" rel=""nofollow noreferrer"">https://mxnet.incubator.apache.org/api/python/ndarray/ndarray.html#mxnet.ndarray.ROIPooling</a></p>

<p>If the code for initializing Resnet is the following, how can I add ROIPooling at the last layer of the Resnet features before the classifier?</p>

<p>Actually, how can I utilize the ROIPooling function in my model in general?</p>

<p>How can I incorporate multiple different ROIs in the ROIpooling layer? How should they be stored? <strong>How should the data iterator be changed in order to give me the Batch index required by the ROIPooling function ?</strong></p>

<p>Let us assume that I use this along with the VOC 2012 Dataset for the task of action recognition</p>

<pre><code>batch_size = 40
num_classes = 11
init_lr = 0.001
step_epochs = [2]

train_iter, val_iter, num_samples = get_iterators(batch_size,num_classes)
resnet34 = vision.resnet34_v2(pretrained=True, ctx=ctx)

net = vision.resnet34_v2(classes=num_classes)

class ROIPOOLING(gluon.HybridBlock):
    def __init__(self):
        super(ROIPOOLING, self).__init__()

    def hybrid_forward(self, F, x):
        #print(x)
        a = mx.nd.array([[0, 0, 0, 7, 7]]).tile((40,1))
        return F.ROIPooling(x, a, (2,2), 1.0)

net_cl = nn.HybridSequential(prefix='resnetv20')
with net_cl.name_scope():
    for l in xrange(4):
        net_cl.add(resnet34.classifier._children[l])
    net_cl.add(nn.Dense(num_classes,  in_units=resnet34.classifier._children[-1]._in_units))

net.classifier = net_cl
net.classifier[-1].collect_params().initialize(mx.init.Xavier(rnd_type='gaussian', factor_type=""in"", magnitude=2), ctx=ctx)

net.features = resnet34.features
net.features._children.append(ROIPOOLING())

net.collect_params().reset_ctx(ctx)
</code></pre>
","1351721","1351721","2018-01-24 19:45:29","Using ROIPooling layer with a pretrained ResNet34 model in MxNet-Gluon","<python><deep-learning><mxnet><resnet>","1","0","1984"
"49041502","2018-03-01 02:01:43","10","","<p>You can use <code>r'$\textcolor{blue}{e^{-x/5}} + \textcolor{green}{e^{-x/1}}$'</code> to make the text half blue, half green. Using your own code for example:</p>

<p><a href=""https://i.stack.imgur.com/hxUlU.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/hxUlU.png"" alt=""enter image description here""></a></p>

<p>The image is generated by the following code. Testd with matplotlib v2.1.2 with the default <code>matplotlibrc</code> settings.</p>

<pre><code>import matplotlib as matplotlib
matplotlib.use('pgf')
matplotlib.rc('pgf', texsystem='pdflatex')  # from running latex -v
preamble = matplotlib.rcParams.setdefault('pgf.preamble', [])
preamble.append(r'\usepackage{color}')

from numpy import *
from matplotlib.pyplot import *

x=arange(0,4,0.1)

exp1 = e**(-x/5)
exp2 = e**(-x/1)
exp3 = e**(-x/5) +e**(-x/1) 

figure()
plot(x,exp1)
plot(x,exp2)
plot(x,exp1+exp2)
title('Exponential Decay')


annotate(r'$e^{-x/5}$', xy=(x[10], exp1[10]), xytext=(-20,-25), 
         textcoords='offset points', ha='center', va='bottom',color='blue',
         bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.3),
         arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3,rad=0.95', 
                            color='b'))

annotate(r'$e^{-x/1}$', xy=(x[10], exp2[10]), xytext=(25,20), 
         textcoords='offset points', ha='center', va='bottom',color='green',
         bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.3),
         arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3,rad=-0.5', 
                            color='g'))

annotate(r'$\textcolor{blue}{e^{-x/5}} + \textcolor[rgb]{0.0, 0.5, 0.0}{e^{-x/1}}$', 
         xy=(x[10], exp2[10]+exp1[10]), xytext=(40,20), 
         textcoords='offset points', ha='center', va='bottom',
         bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.3),
         arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3,rad=-0.5', 
                            color='red'))

savefig('test.png')
</code></pre>

<p>It is mainly your code with the following changes:</p>

<ol>
<li>You need to use a <code>pgf</code> backend.</li>
<li>Usepackage <code>color</code> in <code>pgf.preamble</code></li>
<li>There's some overlapping with the 1st and 2nd annotations, so <code>xytext</code> is changed.</li>
<li>The <code>color='g'</code> in te 2nd annotation actually didn't use the pure ""Green"" color like (0, 255, 0) of rgb. <code>\textcolor[rgb]{0.0, 0.5, 0.0}</code> makes it looking alike.</li>
</ol>
","3898460","","","4","2496","gepcel","2014-08-01 07:20:33","641","36","24","0","24108063","49041502","2014-06-08 16:07:46","18","17072","<p>I am trying to create a figure in python and make is so that the same annonate text will have two colors, half of the annonate will be blue and the other half will be red.</p>

<p>I think the code explain itself. I have 3 lines 1 green with green annonate, 1 blue with blue annonate. </p>

<p>The 3rd is red its the summation of plot 1 and plot 2, and I want it to have half annonate blue and half green.</p>

<p>ipython -pylab</p>

<pre><code>x=arange(0,4,0.1)

exp1 = e**(-x/5)
exp2 = e**(-x/1)
exp3 = e**(-x/5) +e**(-x/1) 

figure()
plot(x,exp1)
plot(x,exp2)
plot(x,exp1+exp2)
title('Exponential Decay')


annotate(r'$e^{-x/5}$', xy=(x[10], exp1[10]), xytext=(-20,-35), 
         textcoords='offset points', ha='center', va='bottom',color='blue',
          bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.3),
          arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3,rad=0.95', 
                            color='b'))

annotate(r'$e^{-x/1}$', xy=(x[10], exp2[10]), xytext=(-5,20), 
         textcoords='offset points', ha='center', va='bottom',color='green',
          bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.3),
          arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3,rad=-0.5', 
                            color='g'))

annotate(r'$e^{-x/5} + e^{-x/1}$', xy=(x[10], exp2[10]+exp1[10]), xytext=(40,20), 
         textcoords='offset points', ha='center', va='bottom',
          bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.3),
          arrowprops=dict(arrowstyle='-&gt;', connectionstyle='arc3,rad=-0.5', 
                            color='red'))
</code></pre>

<p>Is it possible?</p>
","3720002","","","matplotlib two different colors in the same annotate","<python><matplotlib>","2","2","1654"
"49041522","2018-03-01 02:05:28","0","","<p>I don't think it's possible.</p>

<p>First you should read this: <a href=""https://docs.python.org/3.3/howto/descriptor.html"" rel=""nofollow noreferrer"">https://docs.python.org/3.3/howto/descriptor.html</a> , to know the difference of function vs method.</p>

<p>In your code, the key equals <code>self</code> of a method.</p>

<pre><code>def decorator(key):
    def wrapper(funct):
        self.dictionary[key] = funct
        return funct
    return wrapper
</code></pre>

<p>If you want to use a class's property, you should refer by <code>cls</code>. Correct code might be:</p>

<pre><code>@classmethod
def decorator(cls, key):
    def wrapper(funct):
        self.dictionary[key] = funct
        return funct
    return wrapper
</code></pre>

<p>So let's say if you want to update a class property, you must have <code>cls</code> reference. I have tried the code below, make the <code>decorator_maker</code> a classmethod.</p>

<pre><code>class SomeClass:

    dictionary = {}

    @classmethod
    def decorator_maker(cls, key):
        print(cls, key)
        def decorator(funct):
            cls.dictionary[key] = funct
            return funct
        return decorator

    @decorator_maker(""some_val1"")
    def function_1(self):
       ...

    @decorator_maker(""some_val2"")
    def function_2(self):
       ...

    @decorator_maker(""some_val3"")
    def function_3(self):
       ...

    def execute_all_functions(self):
        for key, _ in self.dictionary.items():
            self.dictionary[key]()
</code></pre>

<p>And you will get an error like <code>TypeError: 'classmethod' object is not callable</code>. Same as this question: <a href=""https://stackoverflow.com/questions/11058686/classmethod-object-is-not-callable"">&#39;classmethod&#39; object is not callable</a>. AKA, you can't call a classmethod until the class is defined.</p>

<p>So you may want to make the decorator outside the class. But for the same reason, you can't get a reference of <code>cls</code> until the classmethod. <code>method</code> is also an attribute of class, you can't dynamic change an attribute while define another. see <a href=""https://stackoverflow.com/questions/37832228/python-class-method-run-when-another-method-is-invoked"">Python class method run when another method is invoked</a>.</p>

<p>It would be easier if you move <code>dictionary</code> outside the class.</p>
","6931919","","","0","2382","scriptboy","2016-10-06 12:31:07","507","127","114","10","49034111","49041522","2018-02-28 16:21:17","2","84","<p>I'm writing some code and I have a dictionary where the key is any string, and the value is a function.  I then loop through each key in the dictionary and call the functions, like so:</p>

<pre><code>class SomeClass:

    dictionary = {}

    # Not sure how to use this decorator function
    def decorator(key):
        def wrapper(funct):
            self.dictionary[key] = funct
            return funct
        return wrapper


    @decorator(""some_val1"")
    def function_1(self):
       ...

    @decorator(""some_val2"")
    def function_2(self):
       ...

    @decorator(""some_val3"")
    def function_3(self):
       ...

    def execute_all_functions(self):
        for key, _ in self.dictionary.items():
            self.dictionary[key]()


if __name__ == ""__main__"":
    sclass = SomeClass()
    sclass.execute_all_functions()
</code></pre>

<p>So this should populate <code>dictionary</code> with:</p>

<pre><code>{
   ""some_val1"": function_1(),
   ""some_val2"": function_2(),
   ""some_val3"": function_3()
}
</code></pre>

<p>I'm getting this error though</p>

<pre><code>self.dictionary[key] = funct
NameError: name 'self' is not defined
</code></pre>

<p>How would I be able to do this.  Help appreciated.</p>
","1960118","","","Using decorator in class method and populate variable","<python><python-3.x>","2","1","1227"
"49041537","2018-03-01 02:06:48","3","","<p>The problem occurs due to <code>DMatrix..num_col()</code> only returning the amount of non-zero columns in a sparse matrix. Hence, if both train &amp; test data have the same amount of non-zero columns, everything works fine. Otherwise, you end up with different feature names lists. There're currently three solutions to work around this problem:</p>

<ol>
<li><p>realign the columns names of the train dataframe and test dataframe using </p>

<pre><code>test_df = test_df[train_df.columns]
</code></pre></li>
<li><p>save the model first and then load the model</p></li>
<li><p>change the test data into array before feeding into the model:</p>

<pre><code>use test_df.values
</code></pre>

<p>instead of </p>

<pre><code>test_df
</code></pre></li>
</ol>
","3673947","7311767","2018-03-01 02:27:09","0","759","CathyQian","2014-05-25 15:30:58","347","51","72","0","45425934","","2017-07-31 21:58:32","2","1663","<p>I'm struggling big-time to get my XGBoost model to predict an article's engagement time from its text.  First, I get a dataframe representing the features I extracted from the article like this:</p>

<pre><code>article_features = pd.concat([tfidf_df, numeric_df_normalized], axis=1)
</code></pre>

<p>I then train my model and get the relevant correct columns (features):</p>

<pre><code>with open('correct_columns') as fp:
        correct_columns = pickle.load(fp)
</code></pre>

<p>Then I go through all of the required features and set them to <code>0.0</code> if they're not already in <code>article_features</code>:</p>

<pre><code>for col in correct_columns:
        if col not in article_features.columns:
            article_features[col] = 0.0
</code></pre>

<p>Finally, I delete features that were extracted from this article that don't exist in the training data:    </p>

<pre><code>for col in article_features:
    if col not in correct_columns:
        del article_features[col]
</code></pre>

<p>So now <code>article_features</code> has the correct number of features.  I try to run:</p>

<pre><code>model.predict(article_features)
</code></pre>

<p>And I get:</p>

<pre><code>ValueError: feature_names mismatch:...
</code></pre>

<p>So I Google around and try converting my dataframe to :</p>

<pre><code>model.predict(article_features.as_matrix())
</code></pre>

<p>But I get the same error.</p>

<p>I was then worried about order of columns in <code>article_features</code> not being the same as <code>correct_columns</code> so I did:</p>

<pre><code>article_features.sort_index(axis=1, inplace=True)
</code></pre>

<p>But got the same error.</p>

<p>Any idea how to fix?</p>

<p>Thanks!</p>
","1316501","","","XGBoost: Feature Names Mismatch","<python><pandas><xgboost>","2","1","1713"
"49041548","2018-03-01 02:07:24","0","","<p>So PyCharm is fun. But essentially you don’t need to do anything. It should work “out of the box”. If you’re experiencing issues, post the error output so we can better assist you!</p>

<p>In general though pycharm will try and use a venv so make sure that you’re selecting your system interpreter. If it’s installed in your system then you don’t need to get it “through” pycharm because it’s just doing the same thing as pip (for the most part).</p>

<p>That said, because you’re using python 3+ you need to</p>

<pre><code>pip install pyttsx3 
</code></pre>

<p>Then </p>

<pre><code>import pyttsx3
</code></pre>

<p>pyttsx was not made for python 3+ and has some serious incompatibilities with it. Whereas pyttsx3 is the updated version that was made for python 3+.</p>
","5959072","","","0","776","Afflicted","2016-02-21 15:23:06","653","163","28","18","48675883","","2018-02-08 01:04:53","0","427","<p>I am wondering if I can use pyttsx with PyCharm. I have installed it via terminal and it works in the terminal python shell. I have tried, though Im not sure this is the correct way, but going into PyCharm/Preferences and gone to project interpreter, clicked + and searched for pyttsx, then downloaded and tried, with no luck. I need this to work the same as terminal in PyCharm. If you can tell me how to do this in IDLE, that would be ok to, but not ideal. I am using the latest IDLE (3.6.4) and PyCharm build #PC-153.4301.16. I am looking for this to work with python. I have looked around the internet and have found nothing. Here is a snippet of what I am trying to do: <code>import pyttsx
 engine = pyttsx.init()
 engine.say('Good morning.')
 engine.runAndWait()</code><br>
I have looked on other stack overflow pages, none of witch have helped. I have also looked on the PyCharm website.    </p>
","9311010","9311010","2018-02-08 02:48:26","pyttsx setup on pycharm","<python><pycharm><pyttsx>","1","0","906"
"49041615","2018-03-01 02:15:31","1","","<p>If you want to catch keys only, group it right:</p>

<pre><code>pattern = r""((?:Mon|Tues|Wednes|Thurs|Fri)day), (February|March) ([0-9]{2}), ([0-9]{4})\s*Day ([0-9]{1})""
</code></pre>

<p>Will get:</p>

<pre><code>[('Wednesday', 'February', '28', '2018', '4'), ('Thursday', 'March', '01', '2018', '5'), ('Friday', 'March', '02', '2018', '6'), ('Monday', 'March', '05', '2018', '1'), ('Tuesday', 'March', '06', '2018', '2')] 
</code></pre>

<p>If you want to catch whole match string, don't group it, (like @ekhumoro said use <code>?:</code> before a group):</p>

<pre><code>pattern = r""(?:Mon|Tues|Wednes|Thurs|Fri)day, (?:February|March) [0-9]{2}, [0-9]{4}\s*Day [0-9]{1}""
</code></pre>

<p>Will get a list of <code>str</code>:</p>

<pre><code>['Wednesday, February 28, 2018 \nDay 4', 'Thursday, March 01, 2018 \nDay 5', 'Friday, March 02, 2018 \nDay 6', 'Monday, March 05, 2018 \nDay 1', 'Tuesday, March 06, 2018 \nDay 2']
</code></pre>
","6931919","","","0","942","scriptboy","2016-10-06 12:31:07","507","127","114","10","49040728","49041615","2018-03-01 00:13:50","-2","49","<pre><code>pattern = r""(Mon|Tues|Wednes|Thurs|Fri)day, (February|March) [0-9]{2}, [0-9]{4}\s*Day [0-9]{1}""

line = """"""
Wednesday, February 28, 2018 
Day 4 3:00 Dismissal 
All Day 

Thursday, March 01, 2018 
Day 5 1:30PM Dismissal 
All Day 

Friday, March 02, 2018 
Day 6 3:00 Dismissal 
All Day 

Monday, March 05, 2018 
Day 1 1:30 Dismissal 
All Day 

Tuesday, March 06, 2018 
Day 2 3:00 Dismissal 
All Day 
Tuesday, March 06, 2018""""""

result = re.findall(pattern, line)
print(result)
</code></pre>

<p>Won't work.</p>
","8318780","984421","2018-03-01 01:59:30","How can I use regular expressions","<python><regex>","1","3","520"
"49041639","2018-03-01 02:18:40","3","","<pre><code>&gt;&gt;&gt; def solution(a, b):
...     while a &gt;= b:
...         a -= b
...     return a
... 
&gt;&gt;&gt; solution(11, 5) == (11 % 5)
True
&gt;&gt;&gt; solution(763, 47) == (763 % 47)
True
</code></pre>
","8079103","","","2","220","G_M","2017-05-29 00:31:33","3102","440","139","287","49041588","49041639","2018-03-01 02:12:29","-2","352","<p>I'm really stuck on this. I could do it with integer division and multiplication but I have no idea how to find the remainder without any of these operators. (can't import anything either. the main premise is to use while loops).</p>
","9426643","","","Python - How to write a program to get the remainder of the quotient of two numbers without using %, //, / or any multiplication?","<python><modulo>","2","2","237"
"49041651","2018-03-01 02:20:03","2","","<p>add project folder to sys.path</p>

<pre><code>import sys
sys.path.append('/project/folder')
import Maths
</code></pre>
","9345307","","","3","123","Arkadiusz Tymieniecki","2018-02-11 09:33:00","96","39","0","0","49041602","","2018-03-01 02:13:58","0","47","<p>The below is what my folder for my project looks like. The code itself relies on the files that are contained within the Project folder - so my question is simple.</p>

<p>What is the simplest way to use <code>import Maths</code> from a differant directory? I have gotten it to work before, but it never loads the files as well.</p>

<pre><code>Project (Main Folder):

resources
    bg.png
    student.png
    stylesheet.css
    template.html

configFile.pickle
Maths.pyw
userKeycodes.pickle
</code></pre>
","9347645","","","Importing a python module from another directory","<python><import><directory>","1","0","509"
"49041736","2018-03-01 02:31:01","2","","<p>This is a complex problem. To capture the nuances around negation, you need to step into the world of <strong>dependency parsing</strong> and <strong>relationship extraction</strong>. Couple of paths you can take to add sophistication to your current approach and the add-on by @Jordan are:</p>

<ol>
<li>Using a relationship extraction NLP library (e.g. Watson, Core-NLP, Spacy) that you train with example sentences like the one you gave to extract triplet relations like (John, prescribed, ibuprofen) and (John, not tolerate, paracetamol). This will require investment in annotating sample data.</li>
<li>Rolling your own relationship extractor by starting with the dependency parse that shows how different parts of the sentence are related. This will require both programming time as well as training.</li>
</ol>

<p>Handling negation in relations is not a solved problem. The state of the art around this is usually associated with sentiment analysis. An introduction on using dependency parsing to identify and handle negation is available at this <a href=""http://nlp.stanford.edu:8080/sentiment/rntnDemo.html"" rel=""nofollow noreferrer"">Stanford NLP Sentiment Analysis using RNN page</a></p>
","5597065","","","0","1202","Adnan S","2015-11-23 21:41:35","1207","164","86","84","49039586","49041736","2018-02-28 22:20:27","0","987","<p>I am working on information extraction from medical texts (very new to NLP!). At the moment I am interested to find and extract the medications which are mentioned in a predefined list of drugs. For example, consider the text:</p>

<blockquote>
  <p>""John was prescribed aspirin due to hight temperature""</p>
</blockquote>

<p>Thus, given the list of medications (in Python language): </p>

<pre><code>list_of_meds = ['aspirin', 'ibuprofen', 'paracetamol']
</code></pre>

<p>The extracted drug is <code>aspirin</code>. That's fine. </p>

<p>Now consider another case:</p>

<blockquote>
  <p>""John was prescribed ibuprofen, because he could not tolerate paracetamol""</p>
</blockquote>

<p>Now, if I extract the drugs using the list (for example with regular expression), then the extracted drugs are <code>ibuprofen</code> and <code>paracetamol</code>.</p>

<p><strong>QUESTION</strong> How to separate actually prescribed and untolerated drugs? Is there a way to label prescribed (used) and other mentioned drugs?</p>
","5550203","5550203","2018-02-28 22:55:50","Find negation of particular keywords in text","<python><nlp><regex-negation><data-extraction>","2","0","1021"
"49041758","2018-03-01 02:35:07","0","","<p>It's pretty simple:</p>

<pre><code>s = ""string""
l = len(s)
self.textbuffer.set_text(s, l) 
</code></pre>

<p>The <a href=""http://lazka.github.io/pgi-docs/Gtk-3.0/classes/TextBuffer.html#Gtk.TextBuffer.set_text"" rel=""nofollow noreferrer"">docs</a> .</p>
","6150775","","","1","256","theGtknerd","2016-04-03 02:26:21","2646","407","191","15","49040404","49077204","2018-02-28 23:34:58","1","301","<p>i can get richtext from textbuffer with this:</p>

<pre><code>exported = self.textbuffer.serialize(
                         self.textbuffer,
                         self.textbuffer.register_serialize_tagset(),
                         start_iter,
                         end_iter
                         )
</code></pre>

<p>how can i set text into textBuffer?</p>
","8206667","8206667","2019-09-19 10:23:41","Python Gtk3 set text in textview","<python><textview><gtk><gtk3>","2","2","371"
"49041771","2018-03-01 02:37:08","1","","<p>You should check you terminal character encoding.</p>

<p>On my terminal, first i set character encoding to utf-8, everything is alright.</p>

<p>When i set it to GBK, the result is '鍝堝搱'.</p>
","2663302","","","0","196","yaiba","2013-08-08 06:06:47","11","6","0","0","2688020","2688045","2010-04-22 03:18:29","12","44589","<p>This is my code:</p>

<pre><code>print '哈哈'.decode('gb2312').encode('utf-8')
</code></pre>

<p>...and it prints:</p>

<pre><code>SyntaxError: Non-ASCII character '\xe5' in file D:\zjm_code\a.py on line 2, but no encoding declared; see http://www.python.org/peps/pep-0263.html for details
</code></pre>

<p>How do I print '哈哈'?</p>

<p><strong>Update:</strong>  When I use the following code:</p>

<pre><code>#!/usr/bin/python
# -*- coding: utf-8 -*-

print '哈哈'
</code></pre>

<p>... it prints <code>鍝堝搱</code>.  That isn't what I wanted to get.</p>

<p>My IDE is Ulipad,  is this a bug with the IDE?</p>

<p><strong>Second Update:</strong></p>

<p>This code will print the characters right:</p>

<pre><code>#!/usr/bin/python
# -*- coding: utf-8 -*-


print u'哈哈'.encode('gb2312')
</code></pre>

<p>...and when I use this:</p>

<pre><code>#!/usr/bin/python
# -*- coding: utf-8 -*-

a='哈哈'
print a.encode('gb2312')
Traceback (most recent call last):
  File ""D:\zjm_code\a.py"", line 5, in &lt;module&gt;
    print a.encode('gb2312')
UnicodeDecodeError: 'ascii' codec can't decode byte 0xe5 in position 0: ordinal not in range(128)
</code></pre>

<p>...or...</p>

<pre><code>#!/usr/bin/python
# -*- coding: utf-8 -*-

a='哈哈'
print unicode(a).encode('gb2312')
Traceback (most recent call last):
  File ""D:\zjm_code\a.py"", line 5, in &lt;module&gt;
    print unicode(a).encode('gb2312')
UnicodeDecodeError: 'ascii' codec can't decode byte 0xe5 in position 0: ordinal not in range(128)
</code></pre>

<p>...it doesn't work.  How would I print the variable <code>a</code> appropriately?</p>

<p>thanks</p>
","234322","1079354","2012-05-05 03:00:16","how to print chinese word in my code.. using python","<python><cjk>","6","1","1602"
"49041774","2018-03-01 02:37:26","0","","<p>This is a simple demo about what I said:</p>

<pre><code>class Holder(object):
    def __init__(self, init_dict):
        self.dict = init_dict

    def increase(self, key):
        if key in self.dict:
            d = {key: self.dict[key] + 1}
            self.update(d)

    def update(self, d):
        self.dict.update(d)
        self.print_prompt()

    def print_prompt(self):
        for key in sorted(self.dict.keys()):
            print '%s: %d' % (key, self.dict[key])
        print


def main():
    sounds = {
        'sound1.mp3': 0,
        'sound2.mp3': 0,
        'sound3.mp3': 0
    }

    holder = Holder(sounds)
    holder.print_prompt()
    holder.increase('sound1.mp3')

    holder.update({
        'sound1.mp3': 3,
        'sound2.mp3': 2,
        'sound3.mp3': 1
    })


if __name__ == '__main__':
    main()
</code></pre>

<p>The output is:</p>

<pre><code>sound1.mp3: 0
sound2.mp3: 0
sound3.mp3: 0

sound1.mp3: 1
sound2.mp3: 0
sound3.mp3: 0

sound1.mp3: 3
sound2.mp3: 2
sound3.mp3: 1
</code></pre>
","1730599","1730599","2018-03-01 02:43:36","0","1027","DDGG","2012-10-09 04:34:32","491","95","65","0","49041551","","2018-03-01 02:07:50","-1","33","<p>Is there a way to do this?</p>

<p>ex:</p>

<p>I have a dict</p>

<pre><code>sounds = {
        'sound1.mp3': 0,
        'sound2.mp3': 0,
        'sound3.mp3': 0
    }
</code></pre>

<p>when a keys value (sound1 in this ex) gets updated, the command prompt will go from</p>

<pre><code>sound1.mp3: 0
sound2.mp3: 0
sound3.mp3: 0

to

sound1.mp3: 1
sound2.mp3: 0
sound3.mp3: 0
</code></pre>
","7764497","","","live updating command prompt text","<python>","2","5","392"
"49041815","2018-03-01 02:42:14","7","","<p>This is a Python 3.x solution with setuptools.</p>

<pre><code>from setuptools import setup
from setuptools.command.build_ext import build_ext


# Avoid a gcc warning below:
# cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid
# for C/ObjC but not for C++
class BuildExt(build_ext):
    def build_extensions(self):
        if '-Wstrict-prototypes' in self.compiler.compiler_so:
            self.compiler.compiler_so.remove('-Wstrict-prototypes')
        super().build_extensions()

setup(
    ...
    cmdclass={'build_ext': BuildExt},
    ...
)
</code></pre>
","5588463","5588463","2019-04-30 08:22:42","1","580","Yan QiDong","2015-11-21 06:59:38","546","17","73","0","8106258","8106847","2011-11-12 17:36:06","36","26158","<p>I am building a C++ extension for use in Python. I am seeing this warning being generated during the compilation process - when a type:</p>

<pre><code>python setup.py build_ext -i
</code></pre>

<p>What is causing it, and how do I fix it?</p>

<p>BTW, here is a copy of my setup file:</p>

<pre><code>#!/usr/bin/env python

    """"""
    setup.py file for SWIG example
    """"""

    from distutils.core import setup, Extension


    example_module = Extension('_foolib',
                               sources=['example_wrap.cxx', 
                                        '../wrapper++/src/Foo.cpp'
                                       ],
                               libraries=[""foopp""]
                               )

    setup (name = 'foolib',
           version = '0.1',
           author      = ""Me, Myself and I"",
           description = """"""Example"""""",
           ext_modules = [example_module],
           py_modules = [""example""],
           )
</code></pre>

<p>I am using gcc 4.4.3 on Ubuntu</p>
","962891","","","cc1plus: warning: command line option ""-Wstrict-prototypes"" is valid for Ada/C/ObjC but not for C++","<c++><python><gcc><swig>","7","0","1014"
"49041824","2018-03-01 02:43:20","1","","<p>Merging or appending each DataFrame is very expensive, so it's important to make as few of calls as possible.</p>

<p>What you can do however, is make the date column of each DataFrame the index of the DataFrame, put them in a list, and then make one call to <code>pandas.concat()</code> for all of them. </p>

<p>You will of course have to fiddle with the column names and what they represent, as unless you want a specific entry to be a tuple, you'll have some common columns.</p>

<p>Example:</p>

<pre><code>&gt;&gt;&gt; import pandas
&gt;&gt;&gt; df_0 = pandas.DataFrame(
        {
            'a': pandas.date_range('20180101', '20180105'), 
            'b': range(5, 10)
        }, 
        index=range(5)
    )
&gt;&gt;&gt; df_0
           a  b
0 2018-01-01  5
1 2018-01-02  6
2 2018-01-03  7
3 2018-01-04  8
4 2018-01-05  9
&gt;&gt;&gt; df_1 = pandas.DataFrame(
        {
            'a': pandas.date_range('20180103', '20180107'), 
            'b': range(5, 10)
        }, 
        index=range(5)
    )
&gt;&gt;&gt; df_2 = pandas.DataFrame(
        {
            'a': pandas.date_range('20180105', '20180109'), 
            'b': range(5, 10)
        }, 
        index=range(5)
    )
&gt;&gt;&gt; df_0 = df_0.set_index('a')
&gt;&gt;&gt; df_1 = df_1.set_index('a')
&gt;&gt;&gt; df_2 = df_2.set_index('a')
&gt;&gt;&gt; pandas.concat([df_0, df_1, df_2], axis=1)  # this is where the magic happens
              b    b    b
a
2018-01-01  5.0  NaN  NaN
2018-01-02  6.0  NaN  NaN
2018-01-03  7.0  5.0  NaN
2018-01-04  8.0  6.0  NaN
2018-01-05  9.0  7.0  5.0
2018-01-06  NaN  8.0  6.0
2018-01-07  NaN  9.0  7.0
2018-01-08  NaN  NaN  8.0
2018-01-09  NaN  NaN  9.0
</code></pre>
","3457926","","","2","1682","the_constant","2014-03-25 02:30:15","571","153","45","36","49040837","49053359","2018-03-01 00:27:11","0","1583","<p>The data that I'm using looks like this:</p>

<pre><code>csv1 = pd.DataFrame({'D': [1-10, 2-10, 3-10, 4-10,...], #dates
...:                'C': [#, #, #, #,...]} #values

csv2 = pd.DataFrame({'D': [3-10, 4-10, 5-10, 6-10,...], #dates
...:                'C': [#, #, #, #,...]} #values

csv3 = pd.DataFrame({'D': [5-10, 6-10, 7-10, 8-10,...], #dates
...:                'C': [#, #, #, #,...]} #values
.
.
.
csv100 = pd.DataFrame({'D': [5-10, 6-10, 7-10, 8-10,...], #dates
...:                'C': [#, #, #, #,...]} #values
</code></pre>

<p>I want a data frame like this:</p>

<pre><code>df_merged = pd.DataFrame({'D': [1-10,2-10,3-10,4-10,5-10,6-10...] #dates
...:                  'C1': [#, #, #, #, #, #...]} #values
                      'C2': [#, #, #, #, #, #...]} #values
                      'C3': [#, #, #, #, #, #...]} #values
                      .
                      .
                      .
                      'C100': [#, #, #, #, #, #]} #values
</code></pre>

<p>I have been trying to merge multiple data frames, around 100, that have the same columns but different rows (they don’t have the same order), I would like to do it by the column 'date' (to merge every row with the same date). Because the amount of data frames is high, and changes over time (today I could have 110, tomorrow I could have 90...), the method of using a loop to merge each one of them is too slow. By researching for a solution, I found that the consensus is to use dictionaries. I applied this solution to my code but I got an error and I don’t know how to solve it. The code is the following</p>

<pre><code>import pandas as pd
import subprocess
import os
from functools import reduce

path=r'C:\Users\ra\Desktop\Px\a' #Folder 'a' path

df = {} #Dictionary of data frames from csv files in Folder 'a'
x = [#vector that contains the name of the csv file as string]
i = 0
for j in range(len(x)):
    df['df%s' %j] = (pd.read_csv(os.path.join(path,r'%s.csv' % x[i]))) #Assigns a key to the data frame Ex.:'df1' (the key is a string and I think this is the problem)
    df['df%s' %j].rename(columns={'C': '%s' % x[i]}, inplace=True) #Renames the column 'C' of every data frame to the name of the file
    i += 1

df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['D'],how='outer'),df) #Merges every data frame to a single data frame 'df_merged' by column 'D' that represents the date.
</code></pre>

<p>The problem is in the last line, the output is the following:</p>

<pre><code>---&gt; df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['D'],how='outer'),df)
.
.
.
ValueError: can not merge DataFrame with instance of type &lt;class 'str'&gt;
</code></pre>

<p>If I change the key from string to integer (by changing the vector x to simple numbers 'j') I get the following output:</p>

<pre><code>---&gt; df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['D'],how='outer'),df)
.
.
.
ValueError: can not merge DataFrame with instance of type &lt;class 'int'&gt;
</code></pre>

<p>To make the code work, I tried to find a way to convert the string keys to names. But, apparently, that is a sin. Also, according to @AnkitMalik the 'reduce' method can't be used with dictionaries. How can I merge all this data frames by the column 'D' in a pythonic way if the keys in the dictionary are strings/integers? Or, How can I make a dynamic list of data frames if their number changes over time depending on the amount of csv files in folder 'a'?</p>
","9370758","7851470","2019-04-25 09:26:39","Merge multiple pandas data frames in a dictionary if keys are strings/integers","<python><pandas><dataframe><dictionary><merge>","3","4","3483"
"49041875","2018-03-01 02:51:12","0","","<p>I think you need to use two <code>ColumnDataSource</code>:</p>

<pre><code>from bokeh.io import show, output_notebook
from bokeh.models import LabelSet, HoverTool
from bokeh.plotting import figure
import numpy as np
from math import pi
output_notebook()

from bokeh.models import ColumnDataSource
y1 = [1,2,3]
y2 = [-1,-2,-3]
x = ['c0','c1','c2']


xr = range(len(x))

source1 = ColumnDataSource(dict(
    y = y1,
    xr1 = xr,
    y1adj = np.array(y1)/2,
    labels = x,
    title = [""proft""] * len(y1),
    color = [""blue""] * len(y1)
    )
)

source2 = ColumnDataSource(dict(
    y = np.abs(y2),
    xr2 = np.array(xr) + .5,
    y2adj = np.array(y2)/2,
    labels = x,
    title = [""loss""] * len(y2),
    color = [""red""] * len(y2)
    )
)


labels = LabelSet(x=""xr1"", y=0, text='labels', level='glyph',
              x_offset=5, y_offset=-5,  render_mode='canvas',source = source,angle = -pi/2)

hover = HoverTool(tooltips= '&lt;b style=""color:@color;""&gt;@title&lt;/b&gt;: @y',)


p = figure(tools = [hover])
p.rect(x='xr1',y='y1adj',height='y',width=.45, source = source1, color = 'blue')
p.rect(x='xr2',y='y2adj',height='y',width=.45, source = source2, color = 'red')
p.add_layout(labels)
show(p)
</code></pre>
","772649","","","0","1219","HYRY","2011-05-27 07:38:27","71257","2164","76","1","49041338","","2018-03-01 01:36:37","0","241","<p>so I'm making a dual histogram, like a profit and a  loss.  I want to hover over a blue bar (profit) and show only profit, and a red bar and show only loss.
Right now, it shows both profit and loss whenever I hover over a particular category.  Using <code>output_notebook()</code> in Jupyter if that's important</p>

<pre><code>from bokeh.models import ColumnDataSource
y1 = [1,2,3]
y2 = [-1,-2,-3]
x = ['c0','c1','c2']


xr = range(len(x))

source = ColumnDataSource(dict(
    y1 = y1,
    y2 = np.abs(y2),
    xr1 = xr,
    xr2 = np.array(xr) + .5,
    y1adj = np.array(y1)/2,
    y2adj = np.array(y2)/2,
    labels = x
    )
    )


labels = LabelSet(x=""xr1"", y=0, text='labels', level='glyph',
              x_offset=5, y_offset=-5,  render_mode='canvas',source = source,angle = -pi/2)

hover = HoverTool(tooltips = [('proft','@y1'),('loss','@y2')])


p = figure(tools = [hover])
p.rect(x='xr1',y='y1adj',height='y1',width=.45, source = source,color = 'blue')


p.rect(x='xr2',y='y2adj',height='y2',width=.45, source = source,color = 'red')
p.add_layout(labels)
show(p)
</code></pre>
","2539738","","","bokeh, adding hover tool on different rect","<python><histogram><jupyter><bokeh>","1","0","1091"
"49041892","2018-03-01 02:53:04","0","","<p>If you're working on the terminal, you can use the <code>\r</code> character (carriage return) to return the output to the start of the line.</p>

<p>For example, we can do</p>

<pre><code>for i in range(10):
    time.sleep(1)
    print(i, end=""\r"")
</code></pre>

<p>Note that the prompt (in IDLE) will then overwrite the last iteration with <code>&gt;&gt;&gt;</code>. This is because on a command prompt it literally moves the next character pointer to the beginning of the line.</p>

<p>If you want to avoid this, simply print a blank line afterwards.</p>

<p>As far as I know, the only way to re-print previous lines is to clear the screen. See <a href=""https://stackoverflow.com/questions/2084508/clear-terminal-in-python"">This question</a> or <a href=""https://stackoverflow.com/questions/4810537/how-to-clear-the-screen-in-python"">This question</a> for how to clear the entire screen.</p>
","871980","","","0","898","Snakes and Coffee","2011-07-31 22:34:07","6782","1034","332","37","49041551","","2018-03-01 02:07:50","-1","33","<p>Is there a way to do this?</p>

<p>ex:</p>

<p>I have a dict</p>

<pre><code>sounds = {
        'sound1.mp3': 0,
        'sound2.mp3': 0,
        'sound3.mp3': 0
    }
</code></pre>

<p>when a keys value (sound1 in this ex) gets updated, the command prompt will go from</p>

<pre><code>sound1.mp3: 0
sound2.mp3: 0
sound3.mp3: 0

to

sound1.mp3: 1
sound2.mp3: 0
sound3.mp3: 0
</code></pre>
","7764497","","","live updating command prompt text","<python>","2","5","392"
"49041899","2018-03-01 02:53:36","0","","<p>For the first time pass a get variable first_time=yes. Then check <code>if first_time == ""yes""</code>, Show this page <code>elif request.user.is_authenticated</code> return back to index page <code>else</code> redirect to login page. </p>

<p>url should look like this</p>

<pre><code>localhost:8000/success-signup/?first_time=yes
</code></pre>

<p>views.py</p>

<pre><code>def success_signup(request):
   first_time = request.GET.get('first_time')

   if first_time == ""yes"":
        """"""Account created with success.""""""
        return render(request, ""account/success.html"")
   elif request.user.is_authenticated:
        return HttpResponseRedirect(reverse('index'))
   else:
        return HttpResponseRedirect(reverse('signup'))
</code></pre>
","5303981","","","0","750","SOBIR N","2015-09-05 14:45:33","301","65","9","1","49040717","49041899","2018-03-01 00:12:40","-1","134","<p>In my Django Project user is redirect to specific template with content: </p>

<blockquote>
  <p>""Thanks for your registration""</p>
</blockquote>

<pre><code>def success_signup(request):
    """"""Account created with success.""""""
    return render(request, ""account/success.html"")
</code></pre>

<p>when he register new account with <strong>success</strong>.</p>

<p>I want to make this template/view <em>temporary</em>.</p>

<p>I.E When the user/somebody go to </p>

<blockquote>
  <p>""account/success.html""</p>
</blockquote>

<p>again should be redirected to the homepage instead of the success.html template.</p>

<p>Unfortunately, I can not find this in the documentation. Thanks in advance!</p>
","","","","Django temporary view","<python><django>","1","0","700"
"49041903","2018-03-01 02:54:06","0","","<p>I meet this problem too, you shouldn't set your source file in the same path with the library, change the path of the source file, hope can help you.</p>
","9426767","","","1","157","user9426767","2018-03-01 02:50:00","1","1","0","0","38508662","","2016-07-21 15:43:08","2","916","<p>I am using Python 3.4 and I just installed psutil. When I import this module using</p>

<pre><code>import psutil
</code></pre>

<p>in the shell I get the following error:</p>

<pre><code>Traceback (most recent call last):
File ""&lt;pyshell#3&gt;"", line 1, in &lt;module&gt;
    import psutil
  File ""F:\Python34\lib\site-packages\psutil\__init__.py"", line 28, in &lt;module&gt;
    from . import _common
ImportError: cannot import name '_common'
</code></pre>

<p>I have found multiple post about this kind of error, but they were all about an error with a library they made themself so I'm wondering how to fix this then as i just downloaded this and didn't change anything myself.</p>
","6415988","","","ImportError cannot import name _common(Python 3.4)","<python><importerror><psutil>","1","0","690"
"49041920","2018-03-01 02:56:10","0","","<p>The problem is that you are only creating <em>one</em> object <code>db_sigle</code> which gets appended every time and only the values keep changing.</p>

<p>You have to make this change:</p>

<pre><code> ...
 for i,data in enumerate(x):
     db_single={}
     db_single[tab_d[0]] = data[0]
 ...
</code></pre>

<p>Otherwise your referencing and changing the same object</p>
","2933645","2933645","2018-03-01 02:58:27","4","377","damores","2013-10-29 19:24:09","1618","171","1278","27","49041870","","2018-03-01 02:50:24","0","36","<p>Hi i got a problem while writing a python programme, below is the code -</p>

<pre><code> import json as j
 import _collections
 x=[('Victor','Microsoft',7),('David','Facebook','5'),('Stephen','Google',8)]
 tab_d=['Name','Company','Exp']
 db_data=[]
 db_single={}
 for i,data in enumerate(x):
     db_single[tab_d[0]] = data[0]
     db_single[tab_d[1]] = data[1]
     db_single[tab_d[2]] = data[2]
     db_data.append(db_single)
 j=j.dumps(db_data)
 file = open('firstjson.js', 'w')
 file.write(j)
</code></pre>

<p>The o/p shows me <code>[{""Name"": ""Stephen"", ""Company"": ""Google"", ""Exp"": 8}, {""Name"": ""Stephen"", ""Company"": ""Google"", ""Exp"": 8}, {""Name"": ""Stephen"", ""Company"": ""Google"", ""Exp"": 8}]</code> i.e. Stephen is adding three times instead of adding all members. Can some one plls suggest me what wrong i am doing?</p>
","6878138","6878138","2018-03-24 15:56:24","python : collection in python saving duplicate data - why?","<python><json>","1","4","828"
"49041921","2018-03-01 02:56:23","1","","<p>In python, function is also an object, so of course you can set attributes of a function.</p>

<p>But the function's attributes are not related to function's logic, so you may want to define them outside the function. <code>decorator</code> might be a good choice.</p>

<pre><code>def function_mark(**kwargs):
    def decoractor(func):
        func._my_info = kwargs
        return func
    return decoractor

@function_mark(order=1)
def test():
    pass

print(test._my_info)
</code></pre>
","6931919","","","0","494","scriptboy","2016-10-06 12:31:07","507","127","114","10","49041841","49041921","2018-03-01 02:46:38","1","32","<p>How to set function properties/attributes from within the function definition?</p>

<p>For example is there a way to achieve this from within the function definition:</p>

<pre><code>def test():
    pass

test.order = 1
</code></pre>

<p>So something along the lines of:</p>

<pre><code>def test():
    self.order = 1
    pass

print(test.order)
</code></pre>
","4605629","","","How to set function properties/attributes from within the function definition?","<python><function><functools>","1","2","363"
"49041925","2018-03-01 02:56:53","0","","<p>If you are trying to achieve this with scrapy or with derivation of <code>cURL</code> or <code>urrlib</code> I am afraid that you can't do this. Python has another external packages such selenium that allow you to interact with the javascript of the page, but the problem with selenium is too slow, if you want something similar to scrapy you could check how the site works (as i can see it works through ajax or websockets) and fetch the info that you want through <code>urllib</code>, like you would do with an API.</p>

<p>Please let me know if you understand me or i misunderstood your question</p>
","8196244","","","0","606","Mauricio Cortazar","2017-06-21 19:34:55","2627","271","798","12","49041589","49041925","2018-03-01 02:12:42","0","560","<p>I have a problem getting javascript content into HTML to use it for scripting. I used multiple methods as phantomjs or python QT library and they all get most of the content in nicely but the problem is that there are javascript buttons inside the page like this:</p>

<p><a href=""https://i.stack.imgur.com/6hYVH.png"" rel=""nofollow noreferrer"">Pls see screenshot here</a></p>

<p>Now when I load this page from a script these buttons won't default to any value so I am getting back 0 for all SELL/NEUTRAL/BUY values below. Is there a way to set these values when you load the page from a script?</p>

<p>Example page with all the values is: <a href=""https://www.tradingview.com/symbols/NEBLBTC/technicals/"" rel=""nofollow noreferrer"">https://www.tradingview.com/symbols/NEBLBTC/technicals/</a></p>

<p>Any help would be greatly appreciated.</p>
","1435354","","","Scraping webpage generated by javascript","<python><web-scraping><scrapy><web-crawler><screen-scraping>","2","1","847"
"49041941","2018-03-01 02:58:56","1","","<p>This will work, also if you the NA in your df is  NaN (np.nan), this will not affect your getting the mean of the column, only if your NA is 'NA', which is string</p>

<pre><code>(df.apply(pd.to_numeric,errors ='coerce',axis=1)).describe()
Out[9]: 
       _c0  _c1        _c2
count  3.0  0.0   2.000000
mean   2.0  NaN  29.500000
std    1.0  NaN   0.707107
min    1.0  NaN  29.000000
25%    1.5  NaN  29.250000
50%    2.0  NaN  29.500000
75%    2.5  NaN  29.750000
max    3.0  NaN  30.000000
</code></pre>

<p>More info </p>

<pre><code>df.apply(pd.to_numeric,errors ='coerce',axis=1)# all object change to NaN and will not affect getting mean
Out[10]: 
   _c0  _c1   _c2
0  NaN  NaN   NaN
1  1.0  NaN  29.0
2  2.0  NaN   NaN
3  3.0  NaN  30.0
</code></pre>
","7964527","","","0","761","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49040742","","2018-03-01 00:15:19","0","838","<p>When I run the code below I get the error:</p>

<p>TypeError: 'NoneType' object has no attribute '<strong>getitem</strong>'</p>

<pre><code>    import pyarrow 
    import pandas
    import pyarrow.parquet as pq

    df = pq.read_table(""file.parquet"").to_pandas()
    df = df.iloc[1:,:]
    df = df.dropna (how=""any"", inplace = True) # modifies it in place, creates new dataset without NAN

    average_age = df[""_c2""].mean()
    print average_age
</code></pre>

<p>The dataframe looks like this:</p>

<pre><code>         _c0     _c1  _c2    
    0  RecId   Class  Age   
    1      1      1st   29   
    2      2      1st   NA   
    3      3      1st   30  
</code></pre>

<p>If I print the df after calling the dropna method, I get 'None'.</p>

<p>Shouldn't it be creating a new dataframe without the 'NA' in it, which would then allow me to get the average age without throwing an error?</p>
","6036687","","","pandas dropna not working as expected on finding mean","<python><pandas>","2","3","899"
"49042005","2018-03-01 03:08:11","3","","<p>You are almost correct, the only problem with your code is that you keep adding elements to <code>list2</code>. Instead, you should create a new list every time:</p>

<pre><code>list1 = []

for i in range(3):
    list2 = []
    for j in range(5, 7):
        list2.append(j)
    list1.append(list2)
</code></pre>
","2933645","","","2","315","damores","2013-10-29 19:24:09","1618","171","1278","27","49041981","","2018-03-01 03:04:36","-1","56","<p>I just began learning Python. So I am a beginner. I have a question about ""for statement."" I think I still don't know the rule of it.
Please see below.</p>

<p>example:</p>

<pre><code>list1 = []
list2 = []

def forStatement():
    for i in range(3):
        for j in range(5, 7):
            list2.append(j)
        list1.append(list2)
    return list1
</code></pre>

<p>The result I am looking for is;</p>

<pre><code>[[5, 6], [5, 6], [5, 6]]
</code></pre>

<p>But when I run that code, it turns out like this.</p>

<pre><code>[[5, 6, 5, 6, 5, 6], [5, 6, 5, 6, 5, 6], [5, 6, 5, 6, 5, 6]]
</code></pre>

<p>Can anyone help me? How can I get that result?
Thank you so much.</p>
","8977072","6779307","2018-03-01 15:41:25","Python rule of for statement","<python><for-loop>","3","2","681"
"49042022","2018-03-01 03:10:17","0","","<p>Just an efficient one:</p>

<pre><code>def mod(a, b):
    if a &gt;= b:
        a = mod(a, b + b)
    if a &lt; b:
        return a
    return a - b
</code></pre>

<p>Demo:</p>

<pre><code>&gt;&gt;&gt; a, b = 75349157395712349036170927572349157024, 543791534729045
&gt;&gt;&gt; mod(a, b)
510757213184524
&gt;&gt;&gt; a % b
510757213184524
</code></pre>
","1672429","","","0","356","Stefan Pochmann","2012-09-14 20:32:22","18750","6274","1147","2742","49041588","49041639","2018-03-01 02:12:29","-2","352","<p>I'm really stuck on this. I could do it with integer division and multiplication but I have no idea how to find the remainder without any of these operators. (can't import anything either. the main premise is to use while loops).</p>
","9426643","","","Python - How to write a program to get the remainder of the quotient of two numbers without using %, //, / or any multiplication?","<python><modulo>","2","2","237"
"49042058","2018-03-01 03:14:16","0","","<p>You are appending in the loop, where you want to reset list2 each iteration of i</p>

<pre><code>list1 = []

for i in range(3):
    list2 = []
    for j in range(5, 7):
        list2.append(j)
    list1.append(list2)

&gt;&gt;&gt; print list1
[[5, 6], [5, 6], [5, 6]]
</code></pre>
","9353006","","","0","285","Jared B.","2018-02-13 04:19:00","76","4","8","0","49041981","","2018-03-01 03:04:36","-1","56","<p>I just began learning Python. So I am a beginner. I have a question about ""for statement."" I think I still don't know the rule of it.
Please see below.</p>

<p>example:</p>

<pre><code>list1 = []
list2 = []

def forStatement():
    for i in range(3):
        for j in range(5, 7):
            list2.append(j)
        list1.append(list2)
    return list1
</code></pre>

<p>The result I am looking for is;</p>

<pre><code>[[5, 6], [5, 6], [5, 6]]
</code></pre>

<p>But when I run that code, it turns out like this.</p>

<pre><code>[[5, 6, 5, 6, 5, 6], [5, 6, 5, 6, 5, 6], [5, 6, 5, 6, 5, 6]]
</code></pre>

<p>Can anyone help me? How can I get that result?
Thank you so much.</p>
","8977072","6779307","2018-03-01 15:41:25","Python rule of for statement","<python><for-loop>","3","2","681"
"49042072","2018-03-01 03:16:00","1","","<p>i tried this, you can try out my fixed version.</p>

<pre><code>import easygui
easygui.msgbox(""This programe asks for your info and stores them"")
name = easygui.enterbox(""What is your name?"")
hNumber = easygui.enterbox(""What is your house number"")
street = easygui.enterbox(""What is your post number?"")
city = easygui.enterbox(""What is your city?"")
country = easygui.enterbox(""What is your country?"")
easygui.msgbox(name + '\n' + hNumber + '\n' + street + '\n' + city + '\n' + country)
</code></pre>
","9422101","","","0","503","Haoyang Song","2018-02-28 04:45:46","102","15","77","0","45268785","","2017-07-23 18:53:38","2","335","<p>In this code:</p>

<pre><code>#! street.py
# A simple program which tests GUI

import easygui

easygui.msgbox(""This programe asks for your info and stores them"")
name = easygui.enterbox(""What is your name?"")
hNumber = easygui.enterbox(""What is your house number"")
street = easygui.enterbox(""What is your post number?"")
city = easygui.enterbox(""What is your city?"")
country = easygui.enterbox(""What is your country?"")

easygui.msgbox(name +  
               hNumber +
               street +
               city +
               country)
</code></pre>

<p>I have problems with the last window(easygui.msgbox(....), I want to display all info in a single window at different lines but I can only get it to display on a single line.<br>
<code>\n</code> and similar doesn't work.</p>
","7533754","1656850","2017-07-24 22:24:43","Python easygui module","<python><easygui>","4","1","783"
"49042099","2018-03-01 03:19:28","1","","<p>If you want to discard the exception context, <a href=""https://www.python.org/dev/peps/pep-0409/"" rel=""nofollow noreferrer"">you can explicitly discard it using <code>from None</code></a>, e.g.:</p>

<pre><code>try:
    value = max(dictionary.values())
except TypeError:
    raise TypeError(""some error"") from None
</code></pre>

<p>That said, it's usually best to leave the context in place; the only time you'll see it is if the exception is uncaught and the default logging occurs, or you try to log the exception (e.g. with <code>logger.exception</code>). That additional information is often useful, especially for extremely broad exception types like <code>TypeError</code> and <code>ValueError</code> (where you intend to catch specific known subtypes, and unexpectedly catch one caused in a completely different way).</p>

<p>To be clear, this only works on Python 3, but then, exception context chaining only <em>exists</em> on Python 3; on Python 2, the context is lost automatically.</p>
","364696","364696","2018-03-01 03:25:18","0","1001","ShadowRanger","2010-06-11 15:51:22","75261","5377","1249","1821","49041912","","2018-03-01 02:54:37","1","340","<p>right now I have a problem where I want to raise a specific TypeError if there is one. However, what ends up happening is the interpreter sees the first error, and then in the middle of handling it it raises the other one as well saying ""During handling of the above exception, another exception occurred:""</p>

<p>this is what I have</p>

<pre><code>  def function(dictionary)
    try:
        value = max(dictionary.values())
    except TypeError:
        raise TypeError(""some error"")
</code></pre>

<p>I plug in the following into the shell: </p>

<pre><code>function({1:'a', 2:3})
</code></pre>

<p>How can I approach this?</p>
","9171920","364696","2018-03-01 03:20:00","How to raise exception within a try/except block properly","<python><python-3.x><exception-handling>","2","2","636"
"49042115","2018-03-01 03:21:30","0","","<p>I find chunking to be painful for instances like this in Python. This approach has worked for me frequently:</p>

<pre><code>import requests
import shutil

def download_file(url, filename):
    r = requests.get(url, stream=True)
    with open(filename, 'wb') as f:
        shutil.copyfileobj(r.raw, f)
</code></pre>

<p>This streams the whole file to memory then writes it. So wouldn't work for huge files, but you are only talking about a couple of MB should work fine.</p>
","4777872","","","1","478","Lost","2015-04-11 19:10:53","923","83","373","72","49041914","","2018-03-01 02:55:29","1","120","<p>New to python and attempting to download the NIST NVD JSON files. I have tried several methods but it only write about 324 bytes file. If I do one file that does in fact work but there are several files to download for this.</p>

<p>I did try to adjust the chunk_size but still can't get a 1 to 6mb zip file to download</p>

<pre><code>from requests import get

def download(url, filename):
    response = get(url, stream = True)
    with open(filename, ""wb"") as file:
        for chunk in response.iter_content(chunk_size=1024):
            if chunk:
                file.write(chunk)
    print('Downloaded! ', filename)

with open('NVD_JSON_SOURCE_URLS.txt') as f:
    for line in f:    
        filename = line.split('/')[-1]
        url = line
        download(url, filename)
</code></pre>

<p>The input works and it starts the downloads, just never completes them. Clearly I am missing something frustratingly simple here but after 2 days I am not getting any closer. Thanks.</p>
","9426759","8196244","2018-03-01 02:59:21","Python file downloading fails","<python><python-requests>","3","6","988"
"49042122","2018-03-01 03:22:53","-1","","<p>Since you are raising the exception while handling it, the exception is sent back to the caller function.</p>

<p>If you just want to handle it and print the error and move on with rest of the execution, you can do sth like this</p>

<pre><code>except TypeError as t:
    print (""Error"", t)
</code></pre>
","6840794","","","0","308","hsnsd","2016-09-16 19:02:49","1062","164","18","6","49041912","","2018-03-01 02:54:37","1","340","<p>right now I have a problem where I want to raise a specific TypeError if there is one. However, what ends up happening is the interpreter sees the first error, and then in the middle of handling it it raises the other one as well saying ""During handling of the above exception, another exception occurred:""</p>

<p>this is what I have</p>

<pre><code>  def function(dictionary)
    try:
        value = max(dictionary.values())
    except TypeError:
        raise TypeError(""some error"")
</code></pre>

<p>I plug in the following into the shell: </p>

<pre><code>function({1:'a', 2:3})
</code></pre>

<p>How can I approach this?</p>
","9171920","364696","2018-03-01 03:20:00","How to raise exception within a try/except block properly","<python><python-3.x><exception-handling>","2","2","636"
"49042127","2018-03-01 03:24:04","0","","<p>Here is one way to do that.  This makes the assumption, which matches the context of your question, that we can describe the possible conditions as the previous value was less than or greater than the current value.</p>

<h3>Code:</h3>

<pre><code>def met_condition_at(test_df, tests):
    # for each column apply the conditional test and then cumsum()
    deltas = [getattr(test_df.diff()[col], test)(0).cumsum() for col, test
              in zip(test_df.columns, tests)]

    # the first time the condition is true, cumsum() == 1
    return (pd.concat(deltas, axis=1) == 1).idxmax()
</code></pre>

<h3>How?</h3>

<ol>
<li>We take the <code>.diff()</code> of each column   </li>
<li>We then apply the test to see when the diff changes signs</li>
<li>We then <code>.cumsum()</code> on the Boolean result and find when it is <code>== 1</code></li>
<li>The index when <code>== 1</code> is the index when it first changed direction</li>
</ol>

<h3>Test Code:</h3>

<pre><code>import pandas as pd

df = pd.read_fwf(StringIO(u""""""
       A      B      C
       0.96   1.2    0.75
       0.94   1.3    0.72
       0.92   1.15   0.68
       0.90   1.0    0.73""""""), header=1)
print(df)

tests = ('lt', 'lt', 'gt')
print(met_condition_at(df, tests))

print(''.join(met_condition_at(df, tests).sort_values().index.values))
</code></pre>

<h3>Results:</h3>

<pre><code>      A     B     C
0  0.96  1.20  0.75
1  0.94  1.30  0.72
2  0.92  1.15  0.68
3  0.90  1.00  0.73

A    1
B    2
C    3
dtype: int64

ABC
</code></pre>
","7311767","","","1","1515","Stephen Rauch","2016-12-18 02:06:51","33601","12784","4195","3857","49031333","49042127","2018-02-28 14:01:13","-1","38","<p>Say I have a set of data like so in a <code>pandas.DataFrame</code>:</p>

<pre><code>    A      B      C
1   0.96   1.2    0.75
2   0.94   1.3    0.72
3   0.92   1.15   0.68
4   0.90   1.0    0.73
...
</code></pre>

<p>and I'd like to figure out the order in which the data meets conditions. If I were looking for A decreasing, B decreasing, and C increasing in the example above, I would get ABC, as A is first to meet its condition, B is second, and C is third.</p>

<p>Right now I'm running through a loop trying to figure this out, but is there a better way to do this leveraging the capabilities of Pandas? </p>
","993812","7311767","2018-03-01 03:24:55","Finding order of conditions met in dataframe","<python><pandas>","1","1","620"
"49042132","2018-03-01 03:24:22","1","","<p>See following example (works for both <strong>Python2</strong> and <strong>Python3</strong>):</p>

<pre class=""lang-none prettyprint-override""><code>[STEP 114] # cat foo.py
import pexpect

def input_filter(s):
    if s == b'\x03':
        return b'\r: r u going to kill me? press ctrl-d to exit!\r'
    elif s == b'\x04':
        return b'\r: ok, bye; exit\r'
    else:
        return s

proc = pexpect.spawn('bash --norc')
proc.interact(input_filter=input_filter)
proc.expect(pexpect.EOF)
[STEP 115] # python foo.py
bash-4.4# ps                      &lt;-- user input
   PID TTY          TIME CMD
 77616 pts/56   00:00:00 bash
 77617 pts/56   00:00:00 ps
bash-4.4#                         &lt;-- press CTRL-C
bash-4.4# : r u going to kill me? press ctrl-d to exit!
bash-4.4#                         &lt;-- press CTRL-D
bash-4.4# : ok, bye; exit
exit
[STEP 116] #
</code></pre>
","900078","900078","2018-03-02 08:32:55","5","881","pynexj","2011-08-18 07:17:06","10796","772","185","1525","49040123","49042132","2018-02-28 23:03:51","2","223","<p>This is sort of a clunky question as I can't figure out a good way to describe it, but in expect you can do something like this:</p>

<pre><code>interact {
    \001 {do_something}
    \003 {do_something_else}
    ""?"" {
      set timeout 1
      expect_user {
                   ""?"" {send ""?""}
                   timeout {send_user ""show a menu of the things you can do""}
      }
      stty raw -echo
      set timeout 60
    }
    \035 {send ""^]""
      send ""quit\r""
      send_user ""\n""
      exit
    }
  }
</code></pre>

<p>which would create an interactive session where the user could go about business as usual, but upon pressing keyboard combos (<kbd>ctrl</kbd>+<kbd>a</kbd>, <kbd>ctrl</kbd>+<kbd>c</kbd>, <kbd>ctrl</kbd>+<kbd>e</kbd>, ?, etc) execute actions or display text describing the possible shortcuts.</p>

<p>I'm trying to update a number of scripts to python &amp; pexpect but haven't been able to figure out if this is possible in pexpect.  I tried putzing around with an input filter but it seems this isn't really the 'right' place to do it, or maybe I just can't seem to find any good examples of it in action.</p>

<p>@pynexj: tried your script, though I'm not getting anything on stdout from the ctrl commands.</p>

<pre><code>16:51:16 ~/scripts $ p3 testInputFilter.py | tee testInput.txt
16:51:19 ~/scripts $ ps u
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
usr 45721  0.0  0.0 109620  1876 pts/1    Ss   16:49   0:00 -ksh
usr 46622  0.0  0.0 108436  1776 pts/1    S    16:51   0:00 bash
usr 46734  5.5  0.0 135728  7688 pts/1    S+   16:51   0:00 python3.6 testI
usr 46735  0.0  0.0 100912   632 pts/1    S+   16:51   0:00 tee testInput.t
usr 46736  0.0  0.0 108336  1692 pts/5    Ss   16:51   0:00 /bin/bash --nor
usr 46759  0.0  0.0 110236  1132 pts/5    R+   16:51   0:00 ps u
16:51:21 ~/scripts $ ^C
16:51:42 ~/scripts $ exit
16:51:43 ~/scripts $ cat testInput.txt
16:51:19 ~/scripts $ ps u
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
usr 45721  0.0  0.0 109620  1876 pts/1    Ss   16:49   0:00 -ksh
usr 46622  0.0  0.0 108436  1776 pts/1    S    16:51   0:00 bash
usr 46734  5.5  0.0 135728  7688 pts/1    S+   16:51   0:00 python3.6 testI
usr 46735  0.0  0.0 100912   632 pts/1    S+   16:51   0:00 tee testInput.t
usr 46736  0.0  0.0 108336  1692 pts/5    Ss   16:51   0:00 /bin/bash --nor
usr 46759  0.0  0.0 110236  1132 pts/5    R+   16:51   0:00 ps u
16:51:21 ~/scripts $ ^C
16:51:42 ~/scripts $ exit
16:51:57 ~/scripts $
</code></pre>
","1622949","9317830","2018-03-02 19:02:09","Creating interactive options in pexpect","<python><expect><pexpect>","1","2","2535"
"49042165","2018-03-01 03:27:54","2","","<p>Put the <code>JWTManager</code> in a different file, and initialize it with the <code>jwt.init_app</code> function</p>

<p>As an example, see:</p>

<p><a href=""https://github.com/vimalloc/flask-jwt-extended/blob/master/examples/database_blacklist/extensions.py"" rel=""nofollow noreferrer"">https://github.com/vimalloc/flask-jwt-extended/blob/master/examples/database_blacklist/extensions.py</a></p>

<p>and</p>

<p><a href=""https://github.com/vimalloc/flask-jwt-extended/blob/master/examples/database_blacklist/app.py"" rel=""nofollow noreferrer"">https://github.com/vimalloc/flask-jwt-extended/blob/master/examples/database_blacklist/app.py</a></p>
","272689","","","4","648","vimalloc","2010-02-14 08:34:05","1508","115","291","19","49039479","49076689","2018-02-28 22:12:45","2","977","<p>I'm trying to create API tokens for my flask API with flask-jwt-extended. I'm trying to initialize the <a href=""http://flask-jwt-extended.readthedocs.io/en/latest/api.html#flask_jwt_extended.JWTManager.token_in_blacklist_loader"" rel=""nofollow noreferrer"">token_in_blacklist_loader</a> but can't figure out the right way to do that.</p>

<p>The problem is that <code>token_in_blacklist_loader</code> is implemented as a decorator. It is supposed to be used in the following way:</p>

<pre><code>@jwt.token_in_blacklist_loader
def check_if_token_in_blacklist(decrypted_token):
    jti = decrypted_token['jti']
    return jti in blacklist
</code></pre>

<p>^ <a href=""http://flask-jwt-extended.readthedocs.io/en/latest/blacklist_and_token_revoking.html"" rel=""nofollow noreferrer"">from the docs here</a></p>

<p>Where <code>jwt</code> is defined as:</p>

<pre><code>jwt = JWTManager(app)
</code></pre>

<p>But if using the <code>create_app</code> pattern, then <code>jwt</code> variable is hidden inside a function, and cannot be used in the global scope for decorators.</p>

<p>What is the right way to fix this / work around this?</p>
","755934","","","Using flask-jwt-extended callbacks with flask-restful and create_app","<python><flask><jwt><flask-restful><flask-jwt-extended>","2","0","1136"
"49042184","2018-03-01 03:30:24","0","","<p>Using latest numpy (1.14) on Py3.</p>

<p>Your sample, cleaned up:</p>

<pre><code>In [93]: txt = """"""Name --- Class --- Numbers
    ...: a    ---------- 1    -------- 3
    ...: b    ---------- 2    -------- 4
    ...: c    ---------- 3    -------- 2
    ...: a    ---------- 1    -------- 3
    ...: b    ---------- 2     ------- 1
    ...: c    ---------- 3   --------- 2""""""
In [94]: data = np.genfromtxt(txt.splitlines(), dtype=None, names=True, encoding=None)
In [95]: data
Out[95]: 
array([('a', '----------', 1, '--------', 3),
       ('b', '----------', 2, '--------', 4),
       ('c', '----------', 3, '--------', 2),
       ('a', '----------', 1, '--------', 3),
       ('b', '----------', 2, '-------', 1),
       ('c', '----------', 3, '---------', 2)],
      dtype=[('Name', '&lt;U1'), ('f0', '&lt;U10'), ('Class', '&lt;i8'), ('f1', '&lt;U9'), ('Numbers', '&lt;i8')])
</code></pre>

<p>Or skipping the dashed columns:</p>

<pre><code>In [96]: data = np.genfromtxt(txt.splitlines(), dtype=None, names=True, encoding=None, usecols=[0,2,4])
In [97]: data
Out[97]: 
array([('a', 1, 3), 
       ('b', 2, 4), 
       ('c', 3, 2), 
       ('a', 1, 3), 
       ('b', 2, 1),
       ('c', 3, 2)],
      dtype=[('Name', '&lt;U1'), ('Class', '&lt;i8'), ('Numbers', '&lt;i8')])
</code></pre>
","901925","","","0","1294","hpaulj","2011-08-19 06:44:39","130801","8991","3044","37","49041110","49042184","2018-03-01 01:04:29","0","416","<pre class=""lang-none prettyprint-override""><code>Name Class Species
a     1      3
b     2      4
c     3      2
a     1      3
b     2      1
c     3      2
</code></pre>

<p>This above mentioned data will be from CSV file. need to convert this to structured array using numpy. need header from the csv become the columns labels for the array.</p>

<p>Need to print the mean occurrences of each names in each class (the mean of each species for class 1, class 2, and class 3)</p>

<p>I used <code>numpy.genfromtxt()</code>.</p>
","9305276","355230","2019-01-12 09:48:16","CSV data to Numpy structured array?","<python><python-3.x><numpy>","2","4","530"
"49042217","2018-03-01 03:34:53","5","","<p>Ok. The issue is resolved. I had to use global variables to resolve it. Please find the modified code below for reference.</p>

<p><em>main.py</em></p>

<pre><code>from sanic import Sanic
from DAO import Motor_Connection
from REST import User_REST
import commons


app = Sanic()


@app.listener('before_server_start')
def init(sanic, loop):
    commons.db = Motor_Connection()


app.add_route(User_REST.as_view(), '/')


if __name__ == ""__main__"":
    app.run(host=""0.0.0.0"", port=8000, workers=3, debug=True)
</code></pre>

<p><em>commons.globals.py</em></p>

<pre><code>db = None
</code></pre>

<p><em>user_DAO.py</em></p>

<pre><code>import commons


class User_DAO(object):
    async def register_user(self, serialized_user):
        result = await commons.db.users.insert_one(serialized_user)
        return result.inserted_id
</code></pre>

<p><strong>Explanation:</strong> While the motor connection class was a singleton and returned the same instance, as it was initialized during the imports, Sanic could not get a handle on the event loop. Sanic has to be initialized first to be able to get a handle on the event loop.</p>

<p>By using a global variable and initializing it in the before_server_start block, Sanic gets the handle. Now when you use the same variable in the DAO class, you have access to Sanic's event loop.</p>
","2586098","","","0","1342","Mangesh","2013-07-16 06:41:48","72","11","6","0","49029907","49042217","2018-02-28 12:44:21","3","1189","<p>I am new to Sanic and I am trying to get it to work with Motor. I did manage to get everything to work in a single file, however, when I try it out within my project structure, I am running into the below issues.</p>

<pre><code>[2018-02-28 17:26:58 +0530] [3720] [ERROR] Traceback (most recent call 
last):
File ""/usr/local/lib/python3.6/site-packages/sanic/app.py"", line 556, in 
handle_request
response = await response
File ""/usr/src/Python-3.6.4/Lib/asyncio/coroutines.py"", line 129, in throw
return self.gen.throw(type, value, traceback)
File ""/home/msambare/Documents/Projects/Snippets/Sanic-Motor-
Issue/IAC/src/MyPackgae/REST/user_REST.py"", line 42, in post
request.json['last']
File ""/usr/src/Python-3.6.4/Lib/asyncio/coroutines.py"", line 129, in throw
return self.gen.throw(type, value, traceback)
File ""/home/msambare/Documents/Projects/Snippets/Sanic-Motor-
Issue/IAC/src/MyPackgae/DAO/user_DAO.py"", line 40, in register_user
result = await db.users.insert_one(serialized_user)
RuntimeError: Task &lt;Task pending coro=&lt;Sanic.handle_request() running at 
/usr/local/lib/python3.6/site-packages/sanic/app.py:556&gt; created at 
/usr/local/lib/python3.6/site-packages/sanic/server.py:299&gt; got Future 
&lt;Future pending cb=[run_on_executor.&lt;locals&gt;._call_check_cancel() at 
/usr/local/lib/python3.6/site-
packages/motor/frameworks/asyncio/__init__.py:85]&gt; attached to a different 
loop
</code></pre>

<p>I did some research and as mentioned on the GitHub pages of Sanic, tried the 'before-server-block' section for db setup. That works in a single file, however, not in my project structure.</p>

<p>My project structure looks something like:</p>

<p><a href=""https://i.stack.imgur.com/lq7q0.jpg"" rel=""nofollow noreferrer"">Project Structure</a></p>

<p>Below is my code. I have recreated the issue in a simpler structure without losing the essence.</p>

<p><em>src/MyPackage/Model/user.py</em></p>

<pre><code>class User(object):
def __init__(self, first, last):
    self.first = first
    self.last = last
</code></pre>

<p><em>src/MyPackage/UC/user_uc.py</em></p>

<pre><code>from Model import User
from DAO import User_DAO


class User_UC(object):
    def __init__(self):
        self._user = None

    def create_user(self, first, last):
        self._user = User(first, last)
        ud = User_DAO()
        id = ud.register_user(
            {
                'first': first,
                'last': last
            }
        )
        return id
</code></pre>

<p><em>src/DAO/motor_connection.py</em></p>

<pre><code>import uvloop
import asyncio
import motor.motor_asyncio


asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())


class Motor_Connection(object):
    """""" Provides a MongoDB connection and sets the DB to be used.

    The class implements the Singleton pattern.
    """"""

    __instance = None

    def __new__(cls):
        if Motor_Connection.__instance is None:
            Motor_Connection.__instance = object.__new__(cls)

            Motor_Connection.__instance.client = \
                motor.motor_asyncio.AsyncIOMotorClient(
                    'localhost',
                    27017,
                    io_loop=asyncio.get_event_loop()
                )

            Motor_Connection.__instance.db = \
                Motor_Connection.__instance.client.test_database

        return Motor_Connection.__instance.db
</code></pre>

<p><em>src/DAO/user_DAO.py</em></p>

<pre><code>from DAO import Motor_Connection


db = Motor_Connection()


class User_DAO(object):
    async def register_user(self, serialized_user):
        result = await db.users.insert_one(serialized_user)
        return result.inserted_id
</code></pre>

<p><em>src/MyPackage/REST/user_REST.py</em></p>

<pre><code>from sanic.views import HTTPMethodView
from sanic.response import text
from UC import User_UC


class User_REST(HTTPMethodView):
    async def post(self, request):
        user_uc = User_UC()
        id = await user_uc.create_user(
            request.json['first'],
            request.json['last']
        )
        return text(id)
</code></pre>

<p>and finally the main program...</p>

<p><em>src/MyPackage/main.py</em></p>

<pre><code>from sanic import Sanic
from DAO import Motor_Connection
from REST import User_REST


app = Sanic()


@app.listener('before_server_start')
def init(sanic, loop):
    global db
    db = Motor_Connection()


app.add_route(User_REST.as_view(), '/')


if __name__ == ""__main__"":
    app.run(host=""0.0.0.0"", port=8000, workers=3, debug=True)
</code></pre>

<p>I have not included the <strong>init</strong>.py files of any of the sub-packages. The only thing that I have done in those files is bringing the classes to the sub-package level.</p>

<p>From what I have been able to figure out, it seems in main.py when the User_Rest class is imported which in turn imports the User_UC class which imports the User_DAO class which in turn imports the Motor_Connection class - this is where the mess happens. This creates a separate event loop which is not shared by Sanic.</p>

<p>So, if my understanding is correct, all the chained imported classes use one event loop and Sanic uses another event loop. I know we cannot have 2 event loops but I am unable to figure out what needs to be done to sort this out.</p>

<p>Please help. Thanks in advance.</p>
","2586098","","","Sanic and Motor use different event loops","<python><motordriver><sanic>","1","0","5331"
"49042220","2018-03-01 03:35:09","0","","<p>For your code, <code>list1</code> is a container object which takes references to an object to which <code>list2</code> is bound. (Usually, such a object is mentioned as <code>list2</code> for brevity.) After the execution of the code, <code>list1</code> finally contains three elements (i.e. references to <code>list2</code>) and <code>list2</code> obviously contains triple (outer loop executed 3 times) consecutive 5, 6 (every execution of inner loop append 5 and 6 to <code>list2</code>).</p>

<p>The following code should be what you expect: </p>

<pre><code>list1 = []

list2 = None

for i in range(3):
    list2 = [] # To create a new empty list object and let it bound to the variable list2 every outer loop.
    for j in range(5, 7):
        list2.append(j)
    list1.append(list2)
</code></pre>

<p>In this code, after the execution, <code>list1</code> contains three elements that are distinct objects. But they were all bound to the variable <code>list2</code> in the past.</p>
","5488616","","","0","993","Dummmy","2015-10-26 09:39:27","48","4","33","0","49041981","","2018-03-01 03:04:36","-1","56","<p>I just began learning Python. So I am a beginner. I have a question about ""for statement."" I think I still don't know the rule of it.
Please see below.</p>

<p>example:</p>

<pre><code>list1 = []
list2 = []

def forStatement():
    for i in range(3):
        for j in range(5, 7):
            list2.append(j)
        list1.append(list2)
    return list1
</code></pre>

<p>The result I am looking for is;</p>

<pre><code>[[5, 6], [5, 6], [5, 6]]
</code></pre>

<p>But when I run that code, it turns out like this.</p>

<pre><code>[[5, 6, 5, 6, 5, 6], [5, 6, 5, 6, 5, 6], [5, 6, 5, 6, 5, 6]]
</code></pre>

<p>Can anyone help me? How can I get that result?
Thank you so much.</p>
","8977072","6779307","2018-03-01 15:41:25","Python rule of for statement","<python><for-loop>","3","2","681"
"49042230","2018-03-01 03:36:54","0","","<pre><code>for match in re.finditer('&lt;form1?&gt;(.*?)&lt;/form1?&gt;', line, re.S):
    print(match.group(1))
</code></pre>

<p>I modify the code:</p>

<pre><code>for match in re.finditer('(&lt;form&gt;(.*?)&lt;/form&gt;)|(&lt;form1&gt;(.*?)&lt;/form1&gt;)', line, re.S):
    if None != match.group(4):
        print(match.group(4))
    else:
        print(match.group(2))
</code></pre>
","1902886","1902886","2018-03-01 04:14:25","3","390","William Feirie","2012-12-14 03:13:55","424","36","6","1","49042181","49042230","2018-03-01 03:30:11","0","373","<p>I'm trying to extract some lines from an HTML source file. The one below is simplified but it's the same idea. Using the sample below, I am trying to get it to output in numerical order...that is Form 1, Form 2, Form 3, Form 4. The problem is that the second loop restarts at the second round. So I get: Form 1, Form 2, Form 3, Form 2. How can I edit so that the second loop continues to extract the Form 4 text? </p>

<h2>Code</h2>

<pre><code>import re

line = 'bla bla bla&lt;form&gt;Form 1&lt;/form&gt; some text...&lt;form1&gt;Form 
2&lt;/form1&gt; more text?bla bla bla&lt;form&gt;Form 3&lt;/form&gt; some text...
&lt;form1&gt;Form 4&lt;/form1&gt; more text?'

for match in re.finditer('&lt;form&gt;(.*?)&lt;/form&gt;', line, re.S):
  print match.group(1)
  for match1 in re.finditer('&lt;form1&gt;(.*?)&lt;/form1&gt;', line, re.S):
    print match1.group(1)
    break
</code></pre>
","9426824","","","Python - Using Regex to find multiple matches and report in a certain order","<python><regex><loops><break>","3","1","892"
"49042234","2018-03-01 03:37:23","1","","<p>You can do this way:</p>

<pre><code>url(r'^register/(?P&lt;location_id&gt;[\w.-]+)/$', RegisterView.as_view(), name='regist
</code></pre>

<p>and then,</p>

<pre><code>def post(self, request, *args, **kwargs):
    self.location_id = kwargs.get('location_id', ""any_default"")
    location = Location.objects.get(id=self.location_id)
    # Now assign to user

    if serializer.is_valid():
        user = serializer.save()
        user.location = location
        user.save()
</code></pre>
","6794568","6794568","2018-03-01 03:49:59","6","491","Astik Anand","2016-09-05 01:20:45","7759","1083","647","134","49042185","49042234","2018-03-01 03:30:28","3","437","<p>I'm new to django thus the question.
This is my Location object,</p>

<pre><code>class Location(models.Model):
    country = models.CharField(max_length=255)
    city = models.CharField(max_length=255, unique=True)
    latitude = models.CharField(max_length=255)
    longitude = models.CharField(max_length=255)
</code></pre>

<p>And this is my modified User object</p>

<pre><code>class User(AbstractBaseUser, PermissionsMixin):
    email = models.EmailField(unique=True, max_length=255)
    mobile = PhoneNumberField(null=True)
    username = models.CharField(max_length=255, null=True)
    full_name = models.CharField(max_length=255, blank=True, null=True)
    is_staff = models.BooleanField(default=False)
    is_superuser = models.BooleanField(default=False)
    is_active = models.BooleanField(default=False)
    is_mobile_verified = models.BooleanField(default=False)
    location = models.ForeignKey(Location, on_delete=models.SET_NULL, null=True)
</code></pre>

<p>This is the User Registration API view</p>

<pre><code>class RegisterView(views.APIView):
    def post(self, request):
        serializer = UserSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.save()

            subject = ""Please Activate Your Account!""
            token = self._generate()
            link = HOST + PREFIX + str(user.id) + SUFFIX + token
            message = 'Please use the following link to activate your account.\n\n{}'.format(link)
            from_email = settings.EMAIL_HOST_USER
            to_list = [user.email, 'melissa@gmail.com']
            send_mail(subject, message, from_email, to_list, fail_silently=True)

            Token.objects.create(user=user, token=token)
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        else:
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
</code></pre>

<p>And this is the relevant url </p>

<pre><code>url(r'^register/$', RegisterView.as_view(), name='register')
</code></pre>

<p>Now I want to modify this endpoint to take a location id as a path param and then add the logic in my UserCreation function that the user is added to the location as described by the id.
Can someone help me do this ?</p>
","7551257","7551257","2018-03-01 03:40:18","Many-to-one relationship in Django","<python><django><django-rest-framework>","1","0","2262"
"49042244","2018-03-01 03:38:09","1","","<p>Testing with MXNet 1.1.0, the following code shows that the problem doesn't happen:</p>

<pre><code>for _ in range(10):
    predictions = nd.random.uniform(shape=(100, 100000))
    labels = nd.array(np.random.randint(0, 99999, size=(100, 1)))

    scores = mx.nd.sort(predictions, axis=1, is_ascend=0)
    scores = mx.nd.slice_axis(scores, axis=1, begin=0, end=6)

    label_score = mx.nd.pick(predictions, labels, axis=1)
    equal = label_score.asnumpy() &lt;= scores.asnumpy()[:, 0]

    if not np.all(equal):
        print(""ERROR"")
</code></pre>
","9015998","","","0","553","Sina Afrooze","2017-11-27 17:11:55","1027","121","7","2","44910776","","2017-07-04 16:38:41","3","138","<p>I'm predicting roughly one of 100K possible outputs with a MXNet model, using a fairly standard softmax output. I want to compare the probability assigned to the true label versus the top predictions under the model. To get the former I'm using the pick operator; the later I've tried the cheap version (topk operator) and the expensive version (sort/argsort + slice).</p>

<p>In both cases I'm getting contradictory results. Specifically, there are numerous cases where the probability of the true label (retrieved with pick) is significantly higher than the highest probability output (retrieved with topk/sort). I think this means I'm doing something wrong but don't understand what. It does not happen for all predictions, but it does for a significant fraction.</p>

<p>Can anybody give me a hint as to what is going on?</p>

<p>Code follows:</p>

<pre><code>for batch in data_iter:
    model.forward(batch, is_train=False)
    predictions = model.get_outputs()[0]
    labels = batch.label[0].as_in_context(predictions.context)

    # scores = mx.nd.topk(predictions, axis=1, k=6, ret_typ='value')
    scores = mx.nd.sort(predictions, axis=1, is_ascend=0)
    scores = mx.nd.slice_axis(scores, axis=1, begin=0, end=6)

    label_score = mx.nd.pick(predictions, labels, axis=1)
    equal = label_score.asnumpy() &lt;= scores.asnumpy()[:, 0]

    if not np.all(equal):
        #I think this should never happen but it does frequently
</code></pre>
","1740708","","","Apparently contradictory results from topk/sort and pick","<python><mxnet>","1","1","1454"
"49042251","2018-03-01 03:39:23","1","","<pre><code>&gt;&gt;&gt; dataset = [
...     [1, 2],
...     [1, 2],
...     [1, 2]
... ]
&gt;&gt;&gt; column = 1
&gt;&gt;&gt; class_values = [row[column] for row in dataset]
&gt;&gt;&gt; class_values
[2, 2, 2]
&gt;&gt;&gt; unique = set(class_values)
&gt;&gt;&gt; unique
{2}
</code></pre>
","8079103","","","0","288","G_M","2017-05-29 00:31:33","3102","440","139","287","49042221","","2018-03-01 03:35:25","0","81","<pre><code>`# Convert string column to integer
def str_column_to_int(dataset, column):
      class_values = [row[column] for row in dataset]
      unique = set(class_values)
      lookup = dict()
      for i, value in enumerate(unique):
        lookup[value] = i
      for row in dataset:
        row[column] = lookup[row[column]]
    return lookup`
</code></pre>

<p>The above code is the most basic machine learning snippet to convert a column of string to integers(or one hot encoding).However I am having difficulty understanding the code esp. <code>class_values = [row[column] for row in dataset]
unique = set(class_values)</code> what does these two lines do that makes it to do one hot encoding?</p>
","8554727","","","Converting a column of String to integers?","<python><algorithm><machine-learning>","2","0","707"
"49042265","2018-03-01 03:41:02","0","","<p>if you know id of element try with:    </p>

<pre><code>driver.find_element_by_id('popup_ok').click()
</code></pre>
","9345307","","","0","119","Arkadiusz Tymieniecki","2018-02-11 09:33:00","96","39","0","0","49041839","","2018-03-01 02:46:35","0","179","<p>First of all, sorry for my English. I'm from Buenos Aires, and I've started learning Python just a few weeks ago. Furthermore, I have a really basic knowledge in programming. All I was able to do so far was by getting the info from internet (no formal education in this matter-I was studying Accounting last year).</p>

<p>As of this post, I want to find an element in a web page but I can't seem to get it right. I've even tried to click on ""space"" key-the simplest thing to do in this case. </p>

<p>I want to click on ""OK"" button.</p>

<p>I have from ""Inspect element"":</p>

<pre><code>&lt;div class=""alert"" id=""popup_content""&gt;
  &lt;div id=""popup_message""&gt;No Pending Documents&lt;/div&gt;
  &lt;div id=""popup_panel""&gt;
    &lt;input id=""popup_ok"" type=""button"" value=""OK""&gt;
  &lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p><a href=""https://i.stack.imgur.com/VCRFt.jpg"" rel=""nofollow noreferrer"">print:</a>
I've tried these 5 codes:</p>

<pre class=""lang-py prettyprint-override""><code>from selenium.webdriver.common.action_chains import ActionChains
element_ok = driver.find_element_by_xpath(""//input[@id='popup_ok']"")
Action.Chains(driver).move_to_element(element_ok).perform()
element.click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_xpath("".//*[@id='popup_ok']/div/input"").click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_css_selector("".button_main[value='OK']"").click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>clear_button = driver.find_element_by_xpath(""//input[@id='popup_panel'][@type='button']"")
clear_button = driver.find_element_by_xpath(""//form[@id='popup_ok']/input[1]"")
</code></pre>

<pre class=""lang-py prettyprint-override""><code>import keyboard
keyboard.press_and_release('shift+s, space')
</code></pre>

<p>Would someone help me get through this?</p>

<p>PS: I'm using selenium (read from it in the book 'Automate the Boring Stuff with Python. Practical Programming for Total Beginners'. And chrome webdriver.</p>
","9426664","199806","2018-03-01 12:25:06","Unable to find_element in web through Python (selenium)","<python><selenium>","4","0","2058"
"49042271","2018-03-01 03:42:01","0","","<p>So <code>class_values = [row[column] for row in dataset]</code> is what is called a list comprehension. It is shorthand way to create a list in python. This statement is the equivalent of saying:</p>

<pre><code>class_values = []
for row in dataset:
    class_values.append(row[column])
</code></pre>

<p>These are extremely common in Python, so definitely read about them and practice with them. They make your code cleaner and save time.</p>

<p>Set can be ready about here: <a href=""https://docs.python.org/3/tutorial/datastructures.html#sets"" rel=""nofollow noreferrer"">Sets</a></p>

<p>In short, they are a grouping that is unique. So if you make a set of a list you get an object with all the unique values from the list</p>
","4777872","","","1","733","Lost","2015-04-11 19:10:53","923","83","373","72","49042221","","2018-03-01 03:35:25","0","81","<pre><code>`# Convert string column to integer
def str_column_to_int(dataset, column):
      class_values = [row[column] for row in dataset]
      unique = set(class_values)
      lookup = dict()
      for i, value in enumerate(unique):
        lookup[value] = i
      for row in dataset:
        row[column] = lookup[row[column]]
    return lookup`
</code></pre>

<p>The above code is the most basic machine learning snippet to convert a column of string to integers(or one hot encoding).However I am having difficulty understanding the code esp. <code>class_values = [row[column] for row in dataset]
unique = set(class_values)</code> what does these two lines do that makes it to do one hot encoding?</p>
","8554727","","","Converting a column of String to integers?","<python><algorithm><machine-learning>","2","0","707"
"49042308","2018-03-01 03:46:15","1","","<p>well you can try my updated version</p>

<pre><code>import easygui
import random

AdditionAnswers = 0
IncorrectAnswers = 0
while True:
    quest = 10 - AdditionAnswers
    quest = str(quest)
if ""Addition"":
    easygui.msgbox (""Please enter the correct answer to earn a point, there are "" + quest + "" questions in this quiz(type quit to quit)"")
    a = random.randint(1, 20)
    b = random.randint(1, 20)
    ab = a + b
    PlayerAnswer = easygui.enterbox (""What is "" + str(a) + "" + "" + str(b) + ""?"")
    ab = str(ab)
if PlayerAnswer == ab:
    AdditionAnswers += 1
    easygui.msgbox (""Correct! Your score is ""+str(AdditionAnswers))
elif PlayerAnswer == 'quit':
    break
else:
    AdditionAnswers += 0
    IncorrectAnswers += 1
    easygui.msgbox (""Sorry, incorrect! Your score is still ""+str(AdditionAnswers))
    easygui.msgbox (""You scored "" +str(AdditionAnswers)+ "" out of 10"")
</code></pre>
","9422101","10635285","2018-11-14 02:48:49","0","900","Haoyang Song","2018-02-28 04:45:46","102","15","77","0","33928501","33928548","2015-11-25 23:58:05","-3","1383","<p>I am trying to figure out how to add two random numbers together. I am making a maths game and I am importing random numbers to make up the equation, but because they are random I will need the programme to calculate the answer and give the player a correct or incorrect score. Here is my coding so far:</p>

<pre><code>if ""Addition"":
    easygui.msgbox (""Please enter the correct answer to earn a point, there are 10 questions in this quiz"")
for number in range(0,20):
    Figure1 = random.randrange(0,11)
    Figure2 = random.randrange(0,11)
PlayerAnswer = easygui.enterbox (""What is "" +str(Figure1)+ "" + "" +str(Figure2)+ ""?"")

if PlayerAnswer ==(""+Figure1+"" + ""+Figure2+""):
    AdditionAnswers += 1
    easygui.msgbox (""Correct! Your score is ""+str(AdditionAnswers))
else:
    AdditionAnswers += 0
    IncorrectAnswers += 1
easygui.msgbox (""Sorry, incorrect! Your score is still ""+str(AdditionAnswers))
easygui.msgbox (""You scored "" +str(AdditionAnswers)+ "" out of 10"")
</code></pre>

<p>I have tried turning the Figure1 and Figure2 into <code>(+str(Figure1)+ "" + "" +str(Figure2)+""):</code> in the PlayerAnswer line, but that does not calculate it either 😭
Any help trying to figure this out will be really appreciated!! ❤️‍</p>
","4267876","","","Add two random numbers together?","<python><string><random><easygui>","3","3","1236"
"49042326","2018-03-01 03:48:31","1","","<p>If you want the ""time"" variable redefinable and accessible in multiple scopes, you'll need to use the <a href=""https://stackoverflow.com/questions/4693120/use-of-global-keyword-in-python"">global</a> key word. See my answer <a href=""https://stackoverflow.com/questions/48192290/why-does-python-behave-this-way-with-variables/48192698#48192698"">here</a>.</p>

<p>Hope it helps. </p>
","6023988","","","0","384","Stephen Collins","2016-03-06 01:38:13","448","39","26","1","49042180","","2018-03-01 03:29:55","1","67","<p>When looping through the contents of a CSV file I am trying to create a start time and an end time;</p>

<p>I know the forms submitted based on the <code>row['form']</code> and I log the time of submitting for those forms, I am trying to create a <code>start</code> and <code>end</code> time so I can later get an average time for the completion of their forms.</p>

<pre><code>for row in rows:
    branch = Branch(row['user_id'], row['form'], row['time'])
    if branch.id == row['user_id']:
        if branch.form == 'signup':
            time = {i: {'start': branch.time}}
            print(time)
        elif branch.form == 'submit':
            time = {i: {'end': branch.time}}
            print(time)

        print(time) # line 27
</code></pre>

<p>The problem with the code snippet above is that for the <code>print()</code> <strong>inside</strong> of the conditional statements it works just fine; I get the start time as well as the end time.</p>

<p>But when I try to print it <strong>outside</strong> of the conditional statement it does not work:</p>

<pre><code>Traceback (most recent call last):
  File ""index.py"", line 27, in &lt;module&gt;
    print(time)
NameError: name 'time' is not defined
</code></pre>

<p>Now, if I <code>print</code> <code>time</code> outside of the <code>for</code> loop then it gives me the last value; I cannot get any of the previous values.</p>
","1527252","","","Variable written within if/else scope is undefined outside","<python><for-loop><conditional>","1","8","1394"
"49042336","2018-03-01 03:49:46","0","","<p>You can always use the <code>find()</code> method.</p>

<pre><code>def replaceWord(word, sentence):
    # find the starting position
    posStart = sentence.find(word)

    # find the ending position
    posEnd = posStart + sentence[posStart:].find("" "") - 1

    # Get the word
    new_word = sentence[posStart:posEnd+1]

    # Turn word into a list
    list_word = list(new_word)

    # Find length of word
    word_length = len(sentence[posStart:posEnd + 1])

    # replace the word with ""*""
    star = """"
    for i in list_word:
        star = star + i.replace(i, ""*"")

    # Add back in sentence
    new_sentence = sentence[0:posStart - 1] + "" "" + star + "" "" + sentence[posEnd +2:]
    return new_sentence

print(replaceWord(""fox"", ""The fox is there""))
</code></pre>
","8774203","","","0","774","wolfbagel","2017-10-14 02:33:46","134","44","110","3","48980503","48980545","2018-02-26 02:06:32","0","51","<p>I am trying to write a function that will convert a dedicated word within a string into asterisks. Basically, I want to censor a word from a string (ex. change ""Hello World"" into ""Hello *****"" if I made ""World"" the dedicated word). I tried to write the following code, but the code will not convert words into asterisks. </p>

<pre><code>def censor(text, word):

    a = text.split()

    replace = """"

    for i in word:
        replace += ""*""

    for i in a:
        if i == word:
            i = replace

    result =' '.join(a)

    return result
</code></pre>

<p>Can someone help me? Everything in the code seems to work except for the line <code>i = replace</code>.</p>

<p>Thanks!</p>
","9371814","7228140","2018-02-26 02:11:53","Why can't I change a substring within a string?","<python><python-3.x>","4","3","697"
"49042391","2018-03-01 03:57:39","3","","<p>For file upload you need to specify form's enctype:</p>

<pre><code>&lt;form method='POST' action='' enctype=""multipart/form-data""&gt;{% csrf_token %}
{{ form.as_p }}
&lt;button type=""submit"" class=""btn btn-outline-success""&gt;Save&lt;/button&gt;
&lt;/form&gt;
</code></pre>

<p>And you should pass request's files to form instance in view:</p>

<pre><code>form = EditProfileForm(request.POST, request.FILES, instance=instance)
</code></pre>

<p>Check this <a href=""https://docs.djangoproject.com/en/2.0/topics/http/file-uploads/"" rel=""nofollow noreferrer"">doc</a> for details.</p>
","641249","","","0","585","neverwalkaloner","2011-03-02 13:25:37","28058","1244","1934","0","49042381","49042391","2018-03-01 03:56:03","1","31","<p>I have a model form to update the user profile and everything is saving correctly except of them image. If I use admin it updates fine but when I use my form it just stays as the default profile image.</p>

<p>Here is my form:</p>

<pre><code>class EditProfileForm(forms.ModelForm):  
    birth_date = forms.DateField(label='birth_date', input_formats=['%Y-%m-%d'])

    class Meta:
        model = UserProfile
        fields = (
            ""image"",
            ""bio"",
            ""location"",
            ""birth_date"",
        )
</code></pre>

<p>Here is my model:</p>

<pre><code>class UserProfile(models.Model):
    user = models.OneToOneField(User)
    bio = models.TextField(max_length=500, blank=True)
    location = models.CharField(max_length=30, blank=True)
    birth_date = models.DateField(null=True, blank=True)
    image = models.ImageField(upload_to='profile_image', blank=True)

    def __str__(self):
        return self.user.username

    def create_profile(sender, **kwargs):
        if kwargs['created']:
            user_profile = UserProfile.objects.create(user=kwargs['instance'])

    post_save.connect(create_profile, sender=User)
</code></pre>

<p>Here is my view:</p>

<pre><code>def edit_profile(request):
    instance = get_object_or_404(UserProfile, user=request.user)
    if request.method == 'POST':
        form = EditProfileForm(request.POST, instance=instance)
        if form.is_valid():
            instance = form.save(commit=False)
            instance.user = request.user
            instance.save()

            return redirect('/')
    else:
        form = EditProfileForm(instance=request.user)
    return render(request, 'edit_profile.html', {'form': form})
</code></pre>

<p>And here is my html:</p>

<pre><code>{% extends 'base.html' %}

{% block content %}
&lt;h1&gt;Edit Profile&lt;/h1&gt;

&lt;form method='POST' action=''&gt;{% csrf_token %}
{{ form.as_p }}
&lt;button type=""submit"" class=""btn btn-outline-success""&gt;Save&lt;/button&gt;
&lt;/form&gt;

&lt;/body&gt;

{% endblock %}
</code></pre>
","9181015","","","Image not saving in UserProfileForm (Django)","<python><django>","1","0","2049"
"49042394","2018-03-01 03:58:33","0","","<p>The returned <code>match</code> object has a method <code>start</code> which takes the index of the desired group and returns the starting index of the matched group in the string (i.e. <code>line</code>). And then you can let the inner loop to start at that index rather than the begin of <code>line</code> by slicing <code>line</code> (e.g. <code>line[some_index:]</code>). 
A more proper and simple way is to just let your inner <code>re.finditer</code> take <code>match.group(1)</code> instead of <code>line</code>.</p>

<p>However, it is generally not a good idea to manually handle HTML unless the pattern of targeted HTML is simple enough. You may use some easy-to-use while sophisticated library for parsing and extracting data from HTML.</p>
","5488616","","","0","754","Dummmy","2015-10-26 09:39:27","48","4","33","0","49042181","49042230","2018-03-01 03:30:11","0","373","<p>I'm trying to extract some lines from an HTML source file. The one below is simplified but it's the same idea. Using the sample below, I am trying to get it to output in numerical order...that is Form 1, Form 2, Form 3, Form 4. The problem is that the second loop restarts at the second round. So I get: Form 1, Form 2, Form 3, Form 2. How can I edit so that the second loop continues to extract the Form 4 text? </p>

<h2>Code</h2>

<pre><code>import re

line = 'bla bla bla&lt;form&gt;Form 1&lt;/form&gt; some text...&lt;form1&gt;Form 
2&lt;/form1&gt; more text?bla bla bla&lt;form&gt;Form 3&lt;/form&gt; some text...
&lt;form1&gt;Form 4&lt;/form1&gt; more text?'

for match in re.finditer('&lt;form&gt;(.*?)&lt;/form&gt;', line, re.S):
  print match.group(1)
  for match1 in re.finditer('&lt;form1&gt;(.*?)&lt;/form1&gt;', line, re.S):
    print match1.group(1)
    break
</code></pre>
","9426824","","","Python - Using Regex to find multiple matches and report in a certain order","<python><regex><loops><break>","3","1","892"
"49042410","2018-03-01 04:00:13","0","","<p>Your code is not adding only the hoursWorked inserted on the first record. The remaining days/inputs (i.e. inside the while loop itself) are being added normally. If that's your issue just change the last hoursWorked (inside the loop) to:</p>

<p><code>hoursWorked = int(hoursWorked) + int(input(""Enter hours worked:""))</code></p>
","9377366","","","0","334","Felipe Lanza","2018-02-18 16:00:53","660","31","283","9","49041693","","2018-03-01 02:25:38","0","490","<p>I have figured out the totals and they are running as supposed to. I just can't get the program to stop once I input done. It just keeps looping. I have set the sentinel equal to ""done"". Can someone please help?</p>

<pre><code># SuperMarket.py - This program creates a report that lists weekly hours worked 
# by employees of a supermarket. The report lists total hours for 
# each day of one week. 
# Input:  Interactive
# Output: Report. 
# Declare variables.
HEAD1 = ""WEEKLY HOURS WORKED""
DAY_FOOTER = ""Day Total ""
SENTINEL = ""done""   # Named constant for sentinel value
hoursWorked = 0     # Current record hours
hoursTotal = 0      # Hours total for a day
prevDay = """"        # Previous day of week
notDone = True      # loop control
# Print two blank lines.
print(""\n\n"")
# Print heading.
print(""\t"" + HEAD1)
# Print two blank lines.
print(""\n\n"")

# Read first record 
dayOfWeek = input(""Enter day of week or done to quit: "")
if dayOfWeek  == SENTINEL:
    notDone = False
else:
    prevDay = dayOfWeek
    hoursWorked = input(""Enter hours worked:"")
    while notDone == True:
        dayOfWeek = input(""Enter day of week or done to quit: "")
        hoursTotal = hoursTotal + int(hoursWorked)
        if prevDay != dayOfWeek:
            print(""\t"" + DAY_FOOTER + str(hoursTotal))
            prevDay = dayOfWeek #Include work done in the dayChange()function
            hoursTotal = 0
        hoursWorked = input(""Enter hours worked:"")
</code></pre>
","9365439","9365439","2018-03-01 13:31:44","Setting sentinel value and stopping loop with sentinel value","<python><loops><sentinel><accumulator>","2","0","1462"
"49042414","2018-03-01 04:01:09","0","","<p>I think <code>line</code> has some whitespace characters, so if you remove the whitespace characters from <code>line</code> using <code>strip()</code>, the code should work. </p>

<pre><code>for line in f:    
    line = line.strip()
    ...
</code></pre>

<p>I tested it and it works for me.</p>
","6190930","","","0","300","pgngp","2016-04-12 01:46:09","1100","112","1731","2","49041914","","2018-03-01 02:55:29","1","120","<p>New to python and attempting to download the NIST NVD JSON files. I have tried several methods but it only write about 324 bytes file. If I do one file that does in fact work but there are several files to download for this.</p>

<p>I did try to adjust the chunk_size but still can't get a 1 to 6mb zip file to download</p>

<pre><code>from requests import get

def download(url, filename):
    response = get(url, stream = True)
    with open(filename, ""wb"") as file:
        for chunk in response.iter_content(chunk_size=1024):
            if chunk:
                file.write(chunk)
    print('Downloaded! ', filename)

with open('NVD_JSON_SOURCE_URLS.txt') as f:
    for line in f:    
        filename = line.split('/')[-1]
        url = line
        download(url, filename)
</code></pre>

<p>The input works and it starts the downloads, just never completes them. Clearly I am missing something frustratingly simple here but after 2 days I am not getting any closer. Thanks.</p>
","9426759","8196244","2018-03-01 02:59:21","Python file downloading fails","<python><python-requests>","3","6","988"
"49042415","2018-03-01 04:01:22","1","","<p>You can add a <code>break</code> inside your for loop which will exit the loop. You'll have to include an if/then statement to <code>break</code> after 10001</p>
","1229716","","","0","165","Brian Putt","2012-02-24 01:18:55","820","141","134","1","49042393","49042463","2018-03-01 03:57:45","-4","75","<p>I am creating a code in Python to get the 10001st prime number, and I am looking for a way to stop printing numbers once I have printed 10001 numbers. Is this possible?</p>
","9393832","","","Is there a way to stop my loop once I have printed a certain amount of numbers in python?","<python>","3","3","176"
"49042432","2018-03-01 04:03:38","0","","<p>One thing you could do is that iterate over all the <code>&lt;tr&gt;</code> tags and check if it has a <code>&lt;span&gt;</code> tag with the date or not. If it has the date, update the date else get name and time.</p>

<p>But in Python, it is <a href=""https://docs.quantifiedcode.com/python-anti-patterns/readability/asking_for_permission_instead_of_forgiveness_when_working_with_files.html"" rel=""nofollow noreferrer"">EAFP</a> (easier to ask for forgiveness than permission). So, you could simply use this:</p>

<pre><code>table = soup.find('table', class_='events')
event_date = ''
for row in table.find_all('tr'):
    try:
        event_date = row.td.span.text
        continue
    except AttributeError:
        pass
    event_name = row.find('td', class_='event_name').text
    event_time = row.find('td', class_='event_time').text
    print('Name: {}, Date: {}, Time: {}'.format(event_name, event_date, event_time))
</code></pre>

<p>Output:</p>

<pre><code>Name: Event_1, Date: 28.02.2018, Time: 18:00
Name: Event_2, Date: 28.02.2018, Time: 19:00
Name: Event_3, Date: 01.03.2018, Time: 18:00
Name: Event_4, Date: 01.03.2018, Time: 19:00
Name: Event_5, Date: 01.03.2018, Time: 20:00
</code></pre>
","7832176","","","1","1206","Keyur Potdar","2017-04-07 10:33:50","5988","1260","1872","985","49038444","49042432","2018-02-28 20:59:40","0","148","<p>I have an events table in the following format</p>

<pre><code>&lt;table class=""events""&gt;
&lt;tbody&gt;
    &lt;tr&gt;
        &lt;td""&gt;&lt;span class=""event_date""&gt;28.02.2018&lt;/span&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class=""event""&gt;
        &lt;td class=""event_time""&gt;18:00&lt;/td&gt;
        &lt;td class=""event_name""&gt;Event_1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class=""event""&gt;
        &lt;td class=""event_time""&gt;19:00&lt;/td&gt;
        &lt;td class=""event_name""&gt;Event_2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td""&gt;&lt;span class=""event_date""&gt;01.03.2018&lt;/span&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class=""event""&gt;
        &lt;td class=""event_time""&gt;18:00&lt;/td&gt;
        &lt;td class=""event_name""&gt;Event_3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class=""event""&gt;
        &lt;td class=""event_time""&gt;19:00&lt;/td&gt;
        &lt;td class=""event_name""&gt;Event_4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class=""event""&gt;
        &lt;td class=""event_time""&gt;20:00&lt;/td&gt;
        &lt;td class=""event_name""&gt;Event_5&lt;/td&gt;
    &lt;/tr&gt;
&lt;/tbody&gt;
</code></pre>

<p>
I am able to extract the time and the name easily for each event with following commands</p>

<pre><code>event_container = page_soup.findAll(""tr"", {""class"":""event""})

for event in event_container:
    event_name = event.find(""td"", {""class"":""event_name""})
    event_time = event.find(""td"", {""class"":""event_time""})
</code></pre>

<p>However I'm just not able to assign the event_date correctly to those events</p>

<p>Wanted output</p>

<blockquote>
  <p>Name: Event_1, Date: 28.02.2018, Time: 18:00</p>
  
  <p>Name: Event_2, Date: 28.02.2018, Time: 19:00</p>
  
  <p>Name: Event_3, Date: 01.03.2018, Time: 18:00</p>
  
  <p>Name: Event_4, Date: 01.03.2018, Time: 19:00</p>
  
  <p>Name: Event_5, Date: 01.03.2018, Time: 20:00</p>
</blockquote>

<p>Thank you for your help</p>
","9425707","","","Find first specific HTML tag above the found selection - Python / BeautifulSoup","<python><beautifulsoup><html-parsing>","2","0","1926"
"49042442","2018-03-01 04:05:39","0","","<p>I had the same issue. Those old files are formatted like a tab-delimited file. I've been able to open my problem files with <code>read_table</code>; ie <code>df = pd.read_table('trouble_maker.xls')</code>.</p>
","8121763","","","0","213","mbauer","2017-06-06 19:42:00","56","5","5","0","9623029","9631500","2012-03-08 18:43:13","25","79572","<p>My code: </p>

<pre><code>import xlrd
wb = xlrd.open_workbook(""Z:\\Data\\Locates\\3.8 locates.xls"")
sh = wb.sheet_by_index(0)
print sh.cell(0,0).value
</code></pre>

<p>The error: </p>

<pre><code>Traceback (most recent call last):
File ""Z:\Wilson\tradedStockStatus.py"", line 18, in &lt;module&gt;
wb = xlrd.open_workbook(""Z:\\Data\\Locates\\3.8 locates.xls"")
File ""C:\Python27\lib\site-packages\xlrd\__init__.py"", line 429, in open_workbook
biff_version = bk.getbof(XL_WORKBOOK_GLOBALS)
File ""C:\Python27\lib\site-packages\xlrd\__init__.py"", line 1545, in getbof
bof_error('Expected BOF record; found %r' % self.mem[savpos:savpos+8])
File ""C:\Python27\lib\site-packages\xlrd\__init__.py"", line 1539, in bof_error
raise XLRDError('Unsupported format, or corrupt file: ' + msg)
xlrd.biffh.XLRDError: Unsupported format, or corrupt file: Expected BOF record;
found '&lt;table r'""
</code></pre>

<p>The file doesn't seem to be corrupted or of a different format. 
Anything to help find the source of the issue would be great. </p>
","526633","","","python xlrd unsupported format, or corrupt file.","<python><excel><xlrd>","11","2","1031"
"49042443","2018-03-01 04:05:41","0","","<p>You may try like this:</p>

<pre><code>n = int(input(""Number of inputs: ""))

emptyList = []
while n:
        userInput = float(input(""Enter a Float &gt; ""))
        emptyList.append(userInput)
        n-=1

print(emptyList)
</code></pre>
","3508066","","","1","241","user3508066","2014-04-07 18:38:09","43","23","17","0","49042335","49042942","2018-03-01 03:49:43","0","49","<p>So I'm writing some code for my class and have to have a list of floats that are input by a user and print them out with normal iteration and reverse iteration, and I have basically all of it done. But when it should ask multiple times for the user input, it only asks one time then prints everything out and finishes without asking multiple times. 
Any help would be appreciated as to why it isnt asking multiple times for input even though I have a for loop?
Is there an easier way to get a list of floats from user input that I don't know about?
Thanks</p>

<pre><code>    emptyList = []
    userInput = high = low = total = float(input(""Input a float &gt; ""))
    emptyList.append(userInput)

    for y in range(len(emptyList)-1):
        userInput = float(input(""Input a float &gt; ""))
        emptyList.append(userInput)
        total += emptyList
        if userInput &gt; high:
            high = userInput
        if userInput &lt; low:
            low = userInput

    avg = total / len(emptyList)
    above_avg = below_avg = 0

    for y in range(len(emptyList)):
        if emptyList[y] &gt; avg:
            above_avg += 1
        if emptyList[y] &lt; avg:
            below_avg += 1
</code></pre>
","9422161","","","User Input For List of Floats Not Repeating","<python>","3","0","1214"
"49042454","2018-03-01 04:07:02","1","","<p>A while loop would work here:</p>

<pre><code>primes = []
while len(primes) &lt; 10001:
    #some code to find and print the next prime
    primes.append(next_prime)
</code></pre>
","9353006","","","0","183","Jared B.","2018-02-13 04:19:00","76","4","8","0","49042393","49042463","2018-03-01 03:57:45","-4","75","<p>I am creating a code in Python to get the 10001st prime number, and I am looking for a way to stop printing numbers once I have printed 10001 numbers. Is this possible?</p>
","9393832","","","Is there a way to stop my loop once I have printed a certain amount of numbers in python?","<python>","3","3","176"
"49042463","2018-03-01 04:09:03","1","","<p>Yea, you can create a variable before your loop, and everytime that it gets a prime number, you add 1 to it, then check if it is the 10001st number already to break the loop. Or even something like that:</p>

<pre><code>currentPrime = 0
while currentPrime &lt; 10001:
    #Do your checks here to see if it's a prime, and if it is, do the following code:
    currentPrime = currentPrime + 1
</code></pre>

<p>There's many ways to do it so just find the one that suits you better.</p>
","9225266","","","0","486","Diogo","2018-01-16 16:07:42","141","30","1","0","49042393","49042463","2018-03-01 03:57:45","-4","75","<p>I am creating a code in Python to get the 10001st prime number, and I am looking for a way to stop printing numbers once I have printed 10001 numbers. Is this possible?</p>
","9393832","","","Is there a way to stop my loop once I have printed a certain amount of numbers in python?","<python>","3","3","176"
"49042515","2018-03-01 04:15:02","0","","<p>You are talking about reverse geocoding. The easiest way to do this is to make use of the google maps geocoding API.</p>

<p>You can do this without registering, but you are limited to like 4-5 calls per day. You can register for free for a relatively high number of calls (20-25k last I checked) and if you exceed that you have to pay.</p>

<pre><code>import requests
import json
def getplace(lat, lon):
    url = ""http://maps.googleapis.com/maps/api/geocode/json?""
    url += ""latlng=%s,%s&amp;sensor=false"" % (lat, lon)
    data = {'key': 'your-api-key-goes-here'} # If using your free 5 calls, include no data and just doa  get request on the url
    v = requests.post(url=url, data=data)
    j = json.loads(v.text)
    components = j['results'][0]['address_components']
    country = town = None
    for c in components:
        if ""country"" in c['types']:
            country = c['long_name']
        if ""locality"" in c['types']:
            town = c['long_name']
    return town, country


print(getplace(45.425533, -75.69248))
print(getplace(45.525533, -77.69248))
</code></pre>

<p>The above outputs:
('Ottawa', 'Canada')
(""Barry's Bay"", 'Canada')</p>

<p>You can print out the raw response <code>print(v.text</code> to see the data object and find the fields you actually care about</p>
","4777872","","","1","1300","Lost","2015-04-11 19:10:53","923","83","373","72","49041689","49042515","2018-03-01 02:25:18","0","113","<p>I'm writing a python script that generates random addresses in Canada. To do this, I have to generate random tuples (longitude,latitude) that are within Canadian borders (not in the ocean). 
I figured that I can approximate the borders with small rectangles (just like in calculus). Which does the job, but it is not optimal/accurate. </p>

<p>I couldn't find any academic paper/discussion on the web, maybe my searches did not contain the right keywords. Can you help me find the right resources or even answer this question? The programming part is fine, I just need the math!</p>

<p>Thank you</p>
","8589294","","","Tracing Canadian borders with a function. (longitude and latitude boundaries of Canada)","<python><math><geolocation><latitude-longitude><integral>","1","0","604"
"49042558","2018-03-01 04:19:59","1","","<p>You can append your <code>cut_frame</code> to your original <code>df</code> and then apply <code>groupby</code>:</p>

<pre><code>df[""time_window""] = cut_frame
df.groupby([""location"", ""time_window""]).count().dropna()
</code></pre>
","3216980","","","0","233","Yilun Zhang","2014-01-20 22:22:55","3929","358","173","44","49042293","49042558","2018-03-01 03:44:45","0","387","<p>With a DataFrame like this:</p>

<pre><code>time    location
1       A
1       A
2       B
4       A
9       A
12      B
12      B
12      B
18      A
</code></pre>

<p>I can get a count of the number of occurrences within a time bin by doing the following cut and value_counts operations:</p>

<pre><code>d = {'time': [1,1,2,4,9,12,12,12,18], 'location': ['A','A','B','A','A','B','B','B','A']}
df = pd.DataFrame(d)
time_bins = np.arange(0, 100, 10)
cut_frame = pd.cut(df.time, bins=time_bins)
counts = pd.value_counts(cut_frame,sort=False)
count_frame = pd.DataFrame(counts)
count_frame.index.name = 'time_window'
</code></pre>

<p>The resulting DataFrame looks like this:</p>

<pre><code>time_window time
(0, 10]     5
(10, 20]    4
</code></pre>

<p>How can I break this down further by the <code>location</code> series to get something like this with a MultiIndex?</p>

<pre><code>location  time_window
A    (0, 10]    4
     (10, 20]   1
B    (0, 10]    1
     (10, 20]   3
</code></pre>

<p>Or this?</p>

<pre><code>time_window     location    time
(0, 10]         A           4
(0, 10]         B           1
(10, 20]        A           1
(10, 20]        B           3
</code></pre>
","1431294","","","Pandas: value_counts and cut with groupby multiindex","<python><pandas>","1","0","1192"
"49042561","2018-03-01 04:20:09","-1","","<p>Numpy has 16bit-floats:</p>

<pre><code>In [64]: import numpy

In [65]: a = numpy.float16(0.112312)

In [66]: a
Out[66]: 0.1123
</code></pre>

<p>Maybe you can convert between <code>numpy.float16</code> and <code>RawArray</code></p>

<p><a href=""https://docs.python.org/3.6/library/multiprocessing.html#multiprocessing.sharedctypes.RawArray"" rel=""nofollow noreferrer"">https://docs.python.org/3.6/library/multiprocessing.html#multiprocessing.sharedctypes.RawArray</a></p>

<p><a href=""https://stackoverflow.com/questions/10721915/shared-memory-objects-in-multiprocessing"">Shared-memory objects in multiprocessing</a></p>
","6931919","3666197","2018-03-01 12:08:35","0","623","scriptboy","2016-10-06 12:31:07","507","127","114","10","49042383","","2018-03-01 03:56:26","0","54","<p>I am trying to use the class multiprocessing.Array to share an array of 16-bit floats between processes. It looks however that this class only allows to use a 32-bit float or a 64-bit float (i.e. double). Do you know any ways of dealing with that?</p>
","6780382","","","16bit float shared memory array in python","<python><parallel-processing><multiprocessing>","1","1","255"
"49042603","2018-03-01 04:24:11","0","","<p>While waiting for @ReblochonMasque's solution to finish <strong><em>drawing</em></strong> 100 squares, there's plenty of time to implement an alternate, faster solution based on <strong><em>stamping</em></strong>.</p>

<p>The first thing to note is in the provided instructions it says to draw 100 squares to create the design in the figure, but that figure consists of just under 50 squares.  It's also been scaled in some non integral fashion which makes it appear to have different line thicknesses.</p>

<p>Let's focus on the spirt of the problem rather than the example.  The OP had a 1 square minimum so I've preserved that.  This solution also naturally tends to center the square on the window:</p>

<pre><code>from turtle import Turtle, Screen

DELTA = 3
MINIMUM = DELTA * 2
CURSOR_SIZE = 20

num_squares = -1

while num_squares &lt; 1:
    try:
        num_squares = int(input('Input the number of squares: '))
    except ValueError:
        print(""please enter an integer."")

    if num_squares &lt; 1:
        print(""You must have at least 1 square."")

screen = Screen()
turtle = Turtle(""square"", visible=False)
turtle.fillcolor(""white"")

for size in range(((num_squares - 1) * DELTA) + MINIMUM, MINIMUM - 1, -DELTA):
    turtle.goto(turtle.xcor() + DELTA/2, turtle.ycor() - DELTA/2)
    turtle.shapesize(size / CURSOR_SIZE)
    turtle.stamp()

screen.exitonclick()
</code></pre>

<p>This is clearly not the kind of solution the OP was looking for, but maybe next time a problem like this comes up, it might be one the OP will at least consider.</p>

<p><a href=""https://i.stack.imgur.com/hBcKY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hBcKY.png"" alt=""enter image description here""></a></p>
","5771269","","","0","1732","cdlane","2016-01-10 23:40:41","23572","1435","378","265","49038809","49041042","2018-02-28 21:23:49","0","2187","<p>I am trying to create a loop that takes an input by a user and draws however many squares but it increases the size of the squares with each loop, however 2 sides are stay connected.  I'll include the graphic to better explain.</p>

<p><a href=""https://i.stack.imgur.com/zgv0m.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zgv0m.png"" alt=""enter image description here""></a></p>

<pre><code>    import turtle

squares = 1
while squares &gt;= 1:
    squares = int(input('How many squares would you like drawn?:'))
    if squares == 0:
        print(""You must have at-least 1 square."")
        squares = int(input('How many squares would you like drawn?:'))
    else:
        for count in range(squares):
            turtle.forward(30)
            turtle.left(90)
            turtle.forward(30)
            turtle.left(90)
            turtle.forward(30)
            turtle.left(90)
            turtle.forward(30)
            turtle.left(90)


turtle.done()
</code></pre>
","8277566","3001761","2018-02-28 21:24:52","Turtle Graphics: Repeating Squares","<python><python-3.x><turtle-graphics>","2","4","992"
"49042618","2018-03-01 04:26:43","0","","<p>It turns out the <a href=""https://en.m.wikipedia.org/wiki/Sieve_of_Eratosthenes"" rel=""nofollow noreferrer"">Sieve of Eratosthenes</a> is fairly simple to implement in Python by using correct slicing. So you can use it to recover the <em>n</em> first primes and sum them.</p>

<p>It was pointed out in Joran Beasley's answer that an upper bound for the <em>n</em>-th prime is <code>n * ln(n) + n * ln( ln(n) )</code>, which we can use and then discrard the extra primes. Note that this bound does not work for <em>n</em> smaller than 6.</p>

<pre><code>from math import log

def sum_n_primes(n):
    # Calculate the upper bound
    upper = int(n * ( log(n) + log(log(n))))

    # Prepare our Sieve, for readability we make index match the number by adding 0 and 1
    primes = [False] * 2 + [True] * (upper - 1)

    # Remove non-primes
    for x in range(2, int(upper**(1/2) + 1)):
        if primes[x]:
            primes[2*x::x] = [False] * (upper // x - 1) # Replace // by / in Python2

    # Sum the n first primes
    return sum([x for x, is_prime in enumerate(primes) if is_prime][:n])
</code></pre>

<p>It takes a few seconds, but outputs that the sum of the 10,000,000 first primes is <code>870530414842019</code>.</p>

<p>If you need <em>n</em> to be any higher, one solution would be to <a href=""https://math.stackexchange.com/questions/1270814/bounds-for-n-th-prime"">improve your upper bound</a>.</p>
","5079316","5079316","2018-03-01 14:46:34","0","1414","Olivier Melançon","2015-07-04 00:30:37","15837","1134","1990","511","49040843","","2018-03-01 00:28:06","1","351","<p>I'm running the following code to find the sum of the first 10,000,000 prime numbers.
How can I optimize it such that it doesn't take forever to obtain the result(the sum of prime numbers)?</p>

<pre><code>sum=0
num=2
iterator=0

while iterator&lt;10000000:
    prime = True

    for i in range(2,num):
        if (num%i==0):
            prime = False

    if prime:
        sum=sum+num
         # print (num, sum, iterator)
        iterator=iterator+1
    num=num+1

print(sum)
</code></pre>
","3019388","1953800","2018-03-01 00:36:44","Prime numbers sum - for loop and big numbers","<python><for-loop><optimization><primes>","3","4","496"
"49042666","2018-03-01 04:32:24","0","","<p>Taking a look at the page source, the HTML is:</p>

<pre><code>&lt;td&gt;ETH Balance:
&lt;/td&gt;
&lt;td&gt;
0 Ether
&lt;/td&gt;
</code></pre>

<p>You're searching for <code>text='ETH Balance'</code>. But the text is <code>ETH Balance:</code> with a newline at the end.</p>

<p>So, using this:</p>

<pre><code>eth_bal = soup.find('td', text='ETH Balance:\n').find_next('td').text.strip()
print(eth_bal)
# prints '0 Ether'
</code></pre>
","7832176","7832176","2019-04-01 13:28:00","6","439","Keyur Potdar","2017-04-07 10:33:50","5988","1260","1872","985","49040814","49042666","2018-03-01 00:23:49","-1","842","<p>New to Python and am trying to use BeautifulSoup to pull the ""ETH Balance"" from the an etherscan.com webpage with this code:</p>

<pre><code>import bs4, requests

res = requests.get('https://etherscan.io/address/0x93673eeed88fda9423b8037374164383df54aec1')
res.raise_for_status()

soup = bs4.BeautifulSoup(res.text, 'html.parser')
ethBal = soup.find(""td"", text=""ETH Balance"").find_next(""td"").text

print('The ETH blance is '+ ethBal)
</code></pre>

<p>However I keep getting and error that reads:</p>

<pre><code>Traceback (most recent call last):
  File ""/Users/tfountain/Desktop/python_work/c2.py"", line 7, in &lt;module&gt;
    ethBal = soup.find(""td"", text=""ETH Balance"").find_next(""td"").text
AttributeError: 'NoneType' object has no attribute 'find_next'
</code></pre>

<p>Where am I going wrong and what would be the best way to get the ETH Balance?</p>
","9426337","","","How to get next td value in BeautifulSoup","<python><beautifulsoup>","2","3","863"
"49042702","2018-03-01 04:36:42","0","","<p>I don't believe there is an existing plugin for what you're after, but you can create a plugin for vim which emulates Python's regex. <a href=""http://stevelosh.com/blog/2011/09/writing-vim-plugins/"" rel=""nofollow noreferrer"">Here</a> is a guide for writing vim plugins.</p>
","9264848","","","1","277","hscratch","2018-01-25 00:17:37","16","1","0","0","49042138","","2018-03-01 03:25:05","2","63","<p>Is there a way to change vim' regular expressions to python's regular expressions? I'd like to work with python's regular expressions in my vim. </p>
","9426846","391161","2018-03-01 03:25:35","Change vim's regular expressions","<python><regex><vim>","2","0","153"
"49042725","2018-03-01 04:39:42","1","","<p>Your print function doesn't work.  Change it to print(set(A)) and you'll be golden.  Here's a breakdown why it doesn't work:</p>

<pre><code>def printSet (A):

    # range(len(A)) produces a list of the range of values [0,1,2,3,... len(A)]
    # and then iterates over it, so I starts at 0 in the loop, then goes
    # to 1, then 2, etc.
    for i in range(len(A)):

        # so here, you are checking if 0 is in your set on the first iteration
        # then 1, then 2 etc  and you print out the values of it is.
        if i in A:
            print ((set(A)),end="""")
</code></pre>

<p>so your function fails when there isn't a number in the set that is in the range from zero to the length of your set</p>

<p>for example {32, 24, 10} will never print, because none of the values are equal to 0, 1, or 2 (which are the values in the list created by range(set(A)) in this example)</p>
","7407726","7407726","2018-03-01 05:26:25","2","890","Brett Holman","2017-01-12 03:36:40","163","52","134","3","49042486","","2018-03-01 04:11:34","2","708","<p>I have to print a set using standard set notation. I'm supposed to use recursion and there has to be a base case somewhere. the final answer should come out as a set, and I must print without adding a new line. </p>

<p>this is a function that is supposed to print out a powerset of random integers. the first function builds the random integers and the second function builds the powerset while the last function prints the set. I have the first two functions as well as the last, but when I run the code, it sometimes prints a set and other times comes up empty. I don't know what I'm doing wrong?</p>

<p>The whole things begins like this:</p>

<pre><code>from random import *

def randomSet (n, up):
    return sample(range(up), n)


def powerset (A):
    if A == []:
        return [[]]
    aoba = A[0]
    imax = powerset(A[1:])
    doggo = []
    for set in imax:
        doggo.append([aoba] + set)
    return doggo + imax


def printSet (A):
    for i in range(len(A)):
        if i in A:
          print ((set(A)),end="""")
</code></pre>

<p>There is a tester function that I didn't put here, but the point is that my code will not work right all the time. Sometimes it runs like this:</p>

<pre><code>The powerset of 
{0, 38, 58, 30, 24}
is 
#supposed to show the powerset of the set above but it is always blank
</code></pre>

<p>and other times it runs like this:</p>

<pre><code>The powerset of 
#nothing....just nothing!!!
is 
#never anything here
</code></pre>
","9372077","4985733","2018-03-01 08:36:52","Printing a 'set' using standard set notation","<python><recursion><printing><set>","3","4","1477"
"49042733","2018-03-01 04:40:21","0","","<p>Is this what you want?</p>

<pre><code>&gt;&gt;&gt; for item in re.finditer(r'&lt;form[12]?&gt;([^&lt;]+)',line):
...     item.groups()[0]
...     
'Form 1'
'Form 2'
'Form 3'
'Form 4'
</code></pre>

<p>If it is, just don't tell anyone that it was my idea to use regex for HTML.</p>
","131187","","","1","285","Bill Bell","2009-06-30 16:25:06","16680","2009","764","2","49042181","49042230","2018-03-01 03:30:11","0","373","<p>I'm trying to extract some lines from an HTML source file. The one below is simplified but it's the same idea. Using the sample below, I am trying to get it to output in numerical order...that is Form 1, Form 2, Form 3, Form 4. The problem is that the second loop restarts at the second round. So I get: Form 1, Form 2, Form 3, Form 2. How can I edit so that the second loop continues to extract the Form 4 text? </p>

<h2>Code</h2>

<pre><code>import re

line = 'bla bla bla&lt;form&gt;Form 1&lt;/form&gt; some text...&lt;form1&gt;Form 
2&lt;/form1&gt; more text?bla bla bla&lt;form&gt;Form 3&lt;/form&gt; some text...
&lt;form1&gt;Form 4&lt;/form1&gt; more text?'

for match in re.finditer('&lt;form&gt;(.*?)&lt;/form&gt;', line, re.S):
  print match.group(1)
  for match1 in re.finditer('&lt;form1&gt;(.*?)&lt;/form1&gt;', line, re.S):
    print match1.group(1)
    break
</code></pre>
","9426824","","","Python - Using Regex to find multiple matches and report in a certain order","<python><regex><loops><break>","3","1","892"
"49042736","2018-03-01 04:40:26","0","","<p>When you get to the for loop, emptyList has a length of 1, that's why you are only getting one input display. </p>

<p>Perhaps try something like this:</p>

<pre><code>emptyList = []
userInput = 1
high = low = userInput

while userInput:
    userInput = input(""Input a float (type 'break' to exit)&gt; "")
    if 'break' in userInput:
        break
    userInput = float(userInput)
    emptyList.append(userInput)
    total = sum(emptyList)
    if userInput &gt; high:
        high = userInput
    elif userInput &lt; low:
        low = userInput
</code></pre>
","9377366","","","2","563","Felipe Lanza","2018-02-18 16:00:53","660","31","283","9","49042335","49042942","2018-03-01 03:49:43","0","49","<p>So I'm writing some code for my class and have to have a list of floats that are input by a user and print them out with normal iteration and reverse iteration, and I have basically all of it done. But when it should ask multiple times for the user input, it only asks one time then prints everything out and finishes without asking multiple times. 
Any help would be appreciated as to why it isnt asking multiple times for input even though I have a for loop?
Is there an easier way to get a list of floats from user input that I don't know about?
Thanks</p>

<pre><code>    emptyList = []
    userInput = high = low = total = float(input(""Input a float &gt; ""))
    emptyList.append(userInput)

    for y in range(len(emptyList)-1):
        userInput = float(input(""Input a float &gt; ""))
        emptyList.append(userInput)
        total += emptyList
        if userInput &gt; high:
            high = userInput
        if userInput &lt; low:
            low = userInput

    avg = total / len(emptyList)
    above_avg = below_avg = 0

    for y in range(len(emptyList)):
        if emptyList[y] &gt; avg:
            above_avg += 1
        if emptyList[y] &lt; avg:
            below_avg += 1
</code></pre>
","9422161","","","User Input For List of Floats Not Repeating","<python>","3","0","1214"
"49042767","2018-03-01 04:44:00","0","","<p>There are multiple ways to locate element</p>

<p><strong>1. Use by id</strong></p>

<pre><code>ok_btn = driver.find_element_by_id(""popup_ok"")
</code></pre>

<p><strong>2. Use by xpath</strong></p>

<pre><code>ok_btn = driver.find_element_by_xpath(""//input[@value='OK']"")
</code></pre>

<p>OR</p>

<pre><code>ok_btn = driver.find_element_by_xpath(""//input[@id='popup_ok']"")
</code></pre>
","8164333","199806","2018-03-01 12:27:41","0","391","iamsankalp89","2017-06-15 06:10:35","3860","1035","129","252","49041839","","2018-03-01 02:46:35","0","179","<p>First of all, sorry for my English. I'm from Buenos Aires, and I've started learning Python just a few weeks ago. Furthermore, I have a really basic knowledge in programming. All I was able to do so far was by getting the info from internet (no formal education in this matter-I was studying Accounting last year).</p>

<p>As of this post, I want to find an element in a web page but I can't seem to get it right. I've even tried to click on ""space"" key-the simplest thing to do in this case. </p>

<p>I want to click on ""OK"" button.</p>

<p>I have from ""Inspect element"":</p>

<pre><code>&lt;div class=""alert"" id=""popup_content""&gt;
  &lt;div id=""popup_message""&gt;No Pending Documents&lt;/div&gt;
  &lt;div id=""popup_panel""&gt;
    &lt;input id=""popup_ok"" type=""button"" value=""OK""&gt;
  &lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p><a href=""https://i.stack.imgur.com/VCRFt.jpg"" rel=""nofollow noreferrer"">print:</a>
I've tried these 5 codes:</p>

<pre class=""lang-py prettyprint-override""><code>from selenium.webdriver.common.action_chains import ActionChains
element_ok = driver.find_element_by_xpath(""//input[@id='popup_ok']"")
Action.Chains(driver).move_to_element(element_ok).perform()
element.click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_xpath("".//*[@id='popup_ok']/div/input"").click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_css_selector("".button_main[value='OK']"").click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>clear_button = driver.find_element_by_xpath(""//input[@id='popup_panel'][@type='button']"")
clear_button = driver.find_element_by_xpath(""//form[@id='popup_ok']/input[1]"")
</code></pre>

<pre class=""lang-py prettyprint-override""><code>import keyboard
keyboard.press_and_release('shift+s, space')
</code></pre>

<p>Would someone help me get through this?</p>

<p>PS: I'm using selenium (read from it in the book 'Automate the Boring Stuff with Python. Practical Programming for Total Beginners'. And chrome webdriver.</p>
","9426664","199806","2018-03-01 12:25:06","Unable to find_element in web through Python (selenium)","<python><selenium>","4","0","2058"
"49042774","2018-03-01 04:44:15","1","","<p>I did some sleuthing and mucking about and came up with the following aggregation pipeline. I don't know if it is efficient but it does what I need it to do. I guess I kind-of understand how it works but the double grouping seems like it should be unnecessary.</p>

<pre><code>db.getCollection('test_profiles').aggregate( [
    { $group: { 
        _id : { revision :""$revision"", value : ""$FileIO.Reads"" }
    }},
    { $unwind : ""$_id""},
    { $group: { 
        _id : null,
        values:
        { $push: ""$_id"" }
    }}
])
</code></pre>

<p>This yields the following kind of record:</p>

<pre><code>{
    ""_id"" : null,
    ""values"" : [ 
        {
            ""revision"" : 109999,
            ""value"" : [ 
                0.903873742, 
                0.00723229861, 
                1.23190153
            ]
        }, 
        {
            ""revision"" : 109998,
            ""value"" : [ 
                0.903873742, 
                0.00723229861, 
                1.23190153
            ]
        },
        // .. and on and on 
    ]
}
</code></pre>
","3758488","","","0","1061","Steven","2014-06-20 01:04:07","321","58","35","0","49040969","49042774","2018-03-01 00:45:46","1","265","<p>I have a record which is a dictionary of performance sampling at a specific revision of our source code. I am storing this in our eve database. We do this performance test for every revision. We have over 20,000 revisions.</p>

<p>I can get the values using <a href=""http://host/api/performance?projection="" rel=""nofollow noreferrer"">http://host/api/performance?projection=</a>{""FileIO.Reads"":1,""Revision"":1}, which gives me 20,000 records with the following:</p>

<pre><code>{
    ""_items"" : [
        { ""_id"" : ... ,
          ""_updated"": ...,
          ""_created"":...,
          ""_etag"":...,
          ""Revision"":1000,
          ""FileIO"" : {
            { ""Reads"": [20.34,10,30] } # avg/min/max
          }
        },
        # next item
        { ""_id"" : ... ,
          ""_updated"": ...,
          ""_created"":...,
          ""_etag"":...,
          ""Revision"":1001,
          ""FileIO"" : {
            { ""Reads"": [23,10,50] } # avg/min/max
          }
        }
        # and so on
]
}
</code></pre>

<p>Is there some way to ask Eve, or even better MongoDB, to group all of these into a single value of the form of <code>[ [Revision, Reads], [Revision, Reads]... ]</code> or even <code>[Revision, Avg, Min, Max]</code> to minimize the JSON conversion, performance and bandwidth cost?</p>

<p>Should I do my own processing in the event hooks? If so, in what way?</p>

<p>I think I should be able to do this with aggregation of some type but it isn't clear how to merge my revision with my FileIO Reads.</p>

<p>I don't really have any other ideas how to store this data - we just have a dictionary of performance values per revision.</p>
","3758488","10388629","2019-05-30 00:30:30","Collect records into single array in Eve/mongodb to reduce bandwidth","<python><mongodb><performance><rest><eve>","1","0","1641"
"49042797","2018-03-01 04:47:04","4","","<p>Your <code>Tout</code> must be <code>(tf.float64,tf.float64)</code> instead of <code>[tf.float64]</code></p>

<pre><code>eigval = py_func(calc_second_eigval,
                        [x],
                        (tf.float64,tf.float64),
                        name=name,
                        grad=_SecondEigValGrad) 
</code></pre>

<p>Here is an working demo</p>

<pre><code>import tensorflow as tf

# Function in python
def dummy(x):
    return [x,x]

print(dummy([1.0,2.0]))

tf_fun = tf.py_func(dummy,[[1.0,2.0]],(tf.float32,tf.float32))

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    print(sess.run(tf_fun))
</code></pre>
","1217998","","","3","666","Souradeep Nanda","2012-02-18 11:32:02","1371","278","3084","7","49041971","49042797","2018-03-01 03:02:25","5","2398","<p>I'm trying to set custom gradients using <code>tf.py_func</code> and <code>tf.RegisterGradient</code>. Specifically, I'm trying to take a gradient of an eigen value w.r.t its Laplacian. I got the basic thing working, where my <code>python</code> function returns one value, which is the eigen value. But for the gradient to work, I also need to return the eigen vector. But trying to return 2 values results in <code>pyfunc_1 returns 2 values, but expects to see 1 values</code>. How can I solve this error?</p>

<p>Here's the full code of my custom gradient.</p>

<pre><code>import numpy as np
import networkx as nx
from scipy import sparse
import tensorflow as tf
from tensorflow.python.framework import ops

# python function to calculate the second eigen value
def calc_second_eigval(X):
    G = nx.from_numpy_matrix(X)
    degree_dict = nx.degree(G)
    degree_list = [x[1] for x in degree_dict]
    lap_matrix = sparse.diags(degree_list, 0)-nx.adjacency_matrix(G)
    eigval, eigvec = sparse.linalg.eigsh(lap_matrix, 2, sigma=0, which='LM')
    return float(eigval[0]), eigvec[:,0]

# define custom py_func which takes also a grad op as argument:
def py_func(func, inp, Tout, stateful=True, name=None, grad=None):

    # Need to generate a unique name to avoid duplicates:
    rnd_name = 'PyFuncGrad' + str(np.random.randint(0, 1E+8))

    tf.RegisterGradient(rnd_name)(grad)  # see _MySquareGrad for grad example
    g = tf.get_default_graph()
    with g.gradient_override_map({""PyFunc"": rnd_name}):
        return tf.py_func(func, inp, Tout, stateful=stateful, name=name)

# define custom second_eigval function for tensorflow
def custom_second_eigval(x, name=None):

    with ops.op_scope([x], name, ""SecondEigValGrad"") as name:
        eigval = py_func(calc_second_eigval,
                        [x],
                        [tf.float64],
                        name=name,
                        grad=_SecondEigValGrad)  # &lt;-- here's the call to the gradient
        return eigval[0]

# actual gradient:
def _SecondEigValGrad(op, grad):
    # TODO: this should involve eigen vectors
    x = op.inputs[0]    
    return grad * 20 * x 

X = tf.Variable(tf.random_normal([200,200],dtype=tf.float64))

second_eigval = custom_second_eigval(X)
optimizer = tf.train.AdamOptimizer(0.01)
update = tf.contrib.slim.learning.create_train_op(second_eigval, optimizer,summarize_gradients=True)
with tf.Session() as sess:
    tf.initialize_all_variables().run()
    print(update.eval())
</code></pre>
","6476080","","","Returning mutiple values in the input function for `tf.py_func`","<python><tensorflow><gradient><backpropagation><eigenvector>","1","2","2505"
"49042804","2018-03-01 04:47:28","0","","<p>Here I am using the concept of probability .Those word that have the higher probability of word in a list is the highest similar word in the list .</p>

<p>Try this code ! I am also attach the screenshot of the output .</p>

<pre><code>from difflib import SequenceMatcher

def similar(a, b):
    return SequenceMatcher(None, a, b).ratio()

list1 = ['good']
list2 = ['unspoilt', 'respectable', 'honorable', 'undecomposed', 'goodness', 'well', 'near', 'commodity', 'safe', 'dear', 'just', 'secure', 'in_force', 'practiced', 'trade_good', 'proficient', 'expert', 'good', 'sound', 'soundly', 'effective', 'in_effect', 'beneficial', 'dependable', 'unspoiled', 'estimable', 'salutary', 'adept', 'full', 'ripe','upright', 'skilful', 'right', 'serious', 'skillful', 'thoroughly','honest']
max_similar_list =[]
max=similar(list1[0],list2[1])
max_similar_list=list2[0]
for i in range(1,len(list2)):
  if (max &lt; similar(list1[0],list2[i]) ):
    max=similar(list1[0],list2[i])
    max_similar_list=list2[i]
print(""The highest similarity of words in list is '"" , max_similar_list , ""' with the probabilty of "" , max)
</code></pre>

<p><a href=""https://i.stack.imgur.com/KxUKa.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KxUKa.png"" alt=""enter image description here""></a></p>
","9180179","","","2","1292","Usman","2018-01-06 05:07:36","1411","337","467","84","49042409","","2018-03-01 04:00:10","-1","187","<p>I have a list </p>

<pre><code>list1 = ['good']
</code></pre>

<p>I have another list with synonyms of the word ""good""</p>

<pre><code>list2 = ['unspoilt', 'respectable', 'honorable', 'undecomposed', 'goodness', 'well', 'near', 'commodity', 'safe', 'dear', 'just', 'secure', 'in_force', 'practiced', 'trade_good', 'proficient', 'expert', 'good', 'sound', 'soundly', 'effective', 'in_effect', 'beneficial', 'dependable', 'unspoiled', 'estimable', 'salutary', 'adept', 'full', 'ripe','upright', 'skilful', 'right', 'serious', 'skillful', 'thoroughly','honest']
</code></pre>

<p>Now i wanted to list the word with maximum similarity 
Is it possible?</p>

<p>suppose if the word good has a similarity greater than 0.8 then i wanted to return those words alone in a list</p>

<p>here let me consider unspoilt has similarity around 0.9</p>

<pre><code>max_similar_list = ['unspoilt']
</code></pre>
","9395329","9395329","2018-03-01 04:04:25","How to compare two lists and return the highest similarity of words in a list","<python><similarity>","2","1","896"
"49042805","2018-03-01 04:47:38","2","","<p>You can do that more easily if you use <a href=""https://docs.python.org/3/library/itertools.html#itertools.combinations"" rel=""nofollow noreferrer""><code>itertools.combinations()</code></a> and a <a href=""https://www.python.org/dev/peps/pep-0274/"" rel=""nofollow noreferrer"">dict comprehension</a> to build your columns like:</p>

<h3>Code:</h3>

<pre><code>def build_covars(covar_df):
    columns = {i + "" vs."" + j: covariance_formula(covar_df[i], covar_df[j])
               for i, j in it.combinations(covar_df.columns, 2)}
    return pd.concat(columns, axis=1)
</code></pre>

<h3>Test Code:</h3>

<pre><code>import itertools as it
import pandas as pd

def build_covars(covar_df):
    columns = {i + "" vs."" + j: covariance_formula(covar_df[i], covar_df[j])
               for i, j in it.combinations(covar_df.columns, 2)}
    return pd.concat(columns, axis=1)

def covariance_formula(a, b):
    return (a - a.mean()) * (b - b.mean())

my_list = ['A', 'B', 'C', 'D', 'E']

def create_df():
    return pd.DataFrame(
        np.random.randint(0, 100, size=(5, 5)).astype(float),
        columns=my_list)

df = create_df()
print(build_covars(df))
</code></pre>

<h3>Results:</h3>

<pre><code>    A vs.B  A vs.C  A vs.D   A vs.E  B vs.C  B vs.D  B vs.E  C vs.D  C vs.E  \
0    52.48   49.92  -43.52   323.84   63.96  -55.76  414.92  -53.04  394.68   
1   127.68  123.12  184.68    18.24  120.96  181.44   17.92  174.96   17.28   
2   175.48  124.12  -17.12    98.44   47.56   -6.56   37.72   -4.64   26.68   
3    10.08 -127.68  -57.12  -280.56  -18.24   -8.16  -40.08  103.36  507.68   
4  1370.88  437.92   85.68  1113.84  264.96   51.84  673.92   16.56  215.28   

   D vs.E  
0 -344.08  
1   25.92  
2   -3.68  
3  227.12  
4   42.12 
</code></pre>
","7311767","","","0","1752","Stephen Rauch","2016-12-18 02:06:51","33601","12784","4195","3857","49042278","49042805","2018-03-01 03:42:55","1","79","<p>I want to calculate the co-variance of each of the columns with one another in <code>my_list</code>. The formula is in the function <code>def covariance_formula(...):</code></p>

<p>My code is as follows:</p>

<pre><code>#!/usr/bin/python3

import pandas as pd
import numpy as np

my_list = ['A', 'B', 'C', 'D', 'E']

def create_df():
    return pd.DataFrame(np.random.randint(0,100,size=(5, 5)).astype(float), columns=my_list)


def iterate_list(df):
    for i in range(len(my_list)):
        for j in range(i + 1, len(my_list)):
            column_one = my_list[i]
            column_two = my_list[j]
            col_name = column_one + "" vs."" + column_two

            column_1_value = df[df.columns[df.columns.str.startswith(column_one)]]
            column_2_value = df[df.columns[df.columns.str.startswith(column_two)]]
            column_1_mean = df[df.columns[df.columns.str.startswith(column_one)]].mean(axis=0)
            column_2_mean = df[df.columns[df.columns.str.startswith(column_two)]].mean(axis=0)
            df2[col_name] = covariance_formula(column_1_value, column_2_value, column_1_mean, column_2_mean)

    return df2


def covariance_formula(a, b, mean_a, mean_b):
    covar = (a - mean_a) * (b - mean_b)
    return covar


def main():
    df = create_df()
    # print(df)               ## see OUTPUT A 
    df2 = iterate_list(df)    ## &lt;&lt;&lt; THIS IS WHERE I AM HAVING MY PROBLEM
    # print(df2)              ## see EXPECTED OUTPUT B
    print(df2)


if __name__ == ""__main__"":
    main()
</code></pre>

<p><strong>Questions:</strong></p>

<p>How can I create a new df <code>df2</code> which will have the output of in <em>EXPECTED OUTPUT B</em>? Is there a faster way of doing it?</p>

<p><strong>Current Problem:</strong></p>

<p>The current problem I am facing is that I cannot seem to get rid of this:</p>

<blockquote>
  <p>NameError: name 'df2' is not defined</p>
</blockquote>

<p><strong>Things I have tried:</strong></p>

<ul>
<li><a href=""https://stackoverflow.com/questions/44989425/how-to-calculate-multiple-columns-from-multiple-columns-in-pandas"">How to calculate multiple columns from multiple columns in panda</a></li>
<li><a href=""https://codereview.stackexchange.com/questions/174569/calculating-sum-of-multiple-columns-in-pandas"">Calculating sum of multiple columns in pandas</a></li>
</ul>

<p><strong>OUTPUT A</strong>:</p>

<pre><code>      A     B     C     D     E
0  87.0  92.0  66.0   8.0  67.0
1  84.0  18.0   9.0  80.0  41.0
2  38.0  24.0  53.0  25.0  14.0
3  87.0  25.0  19.0   5.0   0.0
4  91.0  69.0  55.0  14.0  90.0
</code></pre>

<p><strong>EXPECTED OUTPUT B</strong>:</p>

<pre><code>    A vs.B  A vs.C  A vs.D  A vs.E  B vs.C   B vs.D  B vs.E  C vs.D C vs.E  D vs.E
0    445.4   245.8  -176.6   236.2  1187.8   -853.8  1141.4  -471.0  629.8  -452.6
1   -182.2  -207.2   353.8    -9.2   866.6  -1479.4    38.6 -1683.0   44.0   -75.0
2    851.0  -496.4    55.2  1119.0  -272.2     30.2   613.4   -17.6 -357.8    39.8
3   -197.8  -205.4  -205.4  -407.0   440.8    440.8   873.4   458.0  907.4   907.4 
4    318.2   198.6  -168.6   647.4   341.6   -290.2  1113.8  -181.0  695.0  -590.2
</code></pre>
","4504945","4504945","2018-03-01 05:00:36","How do I process 2 columns in Pandas and create a new dataframe with new column names","<python><pandas>","1","1","3167"
"49042814","2018-03-01 04:48:46","0","","<p>For illustrative purposes, here is a general solution that doesn't require 3rd party libraries:</p>

<pre><code>from collections import deque
from datetime import datetime, timedelta


def sliding_window(it, size, dist=(lambda a, b: b - a), index=(lambda x: x)):
    q = deque()
    for item in it:
        i = index(item)
        while q and dist(q[0][0], i) &gt;= size:
            yield [x for _, x in q]
            q.popleft()

        q.append((i, item))

    if q:
        yield [x for _, x in q]


if __name__ == '__main__':
    import pprint
    pprint.pprint(list(sliding_window(
        [
            { ""timestamp"": ""2018-01-18T04:00:00Z"" },
            { ""timestamp"": ""2018-01-18T04:00:01Z"" },
            { ""timestamp"": ""2018-01-18T04:03:00Z"" },
            { ""timestamp"": ""2018-01-18T04:04:00Z"" },
            { ""timestamp"": ""2018-01-18T04:10:00Z"" },
            { ""timestamp"": ""2018-01-18T04:24:00Z"" },
            { ""timestamp"": ""2018-01-18T04:28:00Z"" }
        ],
        timedelta(minutes=7),
        index=lambda x: datetime.strptime(x[""timestamp""], ""%Y-%m-%dT%H:%M:%SZ"")
    )))
</code></pre>

<p>This outputs:</p>

<pre><code>[[{'timestamp': '2018-01-18T04:00:00Z'},
  {'timestamp': '2018-01-18T04:00:01Z'},
  {'timestamp': '2018-01-18T04:03:00Z'},
  {'timestamp': '2018-01-18T04:04:00Z'}],
 [{'timestamp': '2018-01-18T04:00:01Z'},
  {'timestamp': '2018-01-18T04:03:00Z'},
  {'timestamp': '2018-01-18T04:04:00Z'}],
 [{'timestamp': '2018-01-18T04:03:00Z'}, {'timestamp': '2018-01-18T04:04:00Z'}],
 [{'timestamp': '2018-01-18T04:04:00Z'}, {'timestamp': '2018-01-18T04:10:00Z'}],
 [{'timestamp': '2018-01-18T04:10:00Z'}],
 [{'timestamp': '2018-01-18T04:24:00Z'}, {'timestamp': '2018-01-18T04:28:00Z'}]]
</code></pre>
","1142167","1142167","2018-03-01 04:59:25","1","1738","Joel Cornett","2012-01-11 02:03:59","18750","2243","3001","390","49011988","","2018-02-27 15:11:58","0","54","<p>I am relatively new to Python world, was wondering if someone can give me some pointers to resolve my query. </p>

<p>I have a multi index dataframe, sample below:</p>

<pre><code>**IDENTIFIER_VALUE  TIME**  DATE    ASK PRICE   BID PRICE   ask bid
BE0000291972    08:17:14    19/02/2018  145.09  144.82  145.08  144.96
    08:17:18    19/02/2018  145.09  144.95  145.08  144.96
    08:17:18    19/02/2018  145.09  144.95  145.08  144.96
    08:18:18    19/02/2018  145.09  144.95  145.08  144.96
    08:22:18    19/02/2018  145.09  144.95  145.08  144.96
    08:43:18    19/02/2018  145.09  144.95  145.08  144.96
    08:51:18    19/02/2018  145.09  144.95  145.08  144.96
    09:00:18    19/02/2018  145.09  144.95  145.08  144.96
    09:06:18    19/02/2018  145.09  144.95  145.08  144.96
    09:08:18    19/02/2018  145.09  144.95  145.08  144.96
    09:15:18    19/02/2018  145.09  144.95  145.08  144.96
    09:16:18    19/02/2018  145.09  144.95  145.08  144.96
    09:27:18    19/02/2018  145.09  144.95  145.08  144.96
    09:28:18    19/02/2018  145.09  144.94  145.08  144.96
    09:42:18    19/02/2018  145.09  144.94  145.08  144.96
    09:44:18    19/02/2018  145.09  144.94  145.08  144.96
BE0000337460    10:45:04    19/02/2018  102.12  102.06  102.11  102.06
    11:04:04    19/02/2018  102.12  102.06  102.11  102.06
    11:23:04    19/02/2018  102.12  102.06  102.11  102.06
    11:31:04    19/02/2018  102.12  102.06  102.11  102.06
    11:43:04    19/02/2018  102.12  102.06  102.11  102.06
    11:57:04    19/02/2018  102.12  102.06  102.11  102.06
    12:04:04    19/02/2018  102.12  102.06  102.11  102.06
    12:14:04    19/02/2018  102.12  102.06  102.11  102.06
    12:41:04    19/02/2018  102.12  102.06  102.11  102.06
    12:50:04    19/02/2018  102.12  102.06  102.11  102.06
    12:57:04    19/02/2018  102.12  102.06  102.11  102.06
    13:08:04    19/02/2018  102.12  102.06  102.11  102.06
    13:11:04    19/02/2018  102.12  102.06  102.11  102.06
    13:33:04    19/02/2018  102.12  102.06  102.11  102.06
    13:48:04    19/02/2018  102.12  102.06  102.11  102.06
    14:03:04    19/02/2018  102.12  102.06  102.11  102.06
</code></pre>

<p>Question: I want to perform the below:</p>

<p>For each value at level 0 of the Index do the following:
1. Start from the first record. Example:</p>

<pre><code>IDENTIFIER_VALUE    TIME    DATE    ASK PRICE   BID PRICE   ask bid
BE0000291972    08:17:14    19/02/2018  145.09  144.82  145.08  144.96
</code></pre>

<ol start=""2"">
<li><p>Look for all the records in the next 7 min with respect to the time on the first record. So based on above I want to pick all the records from 8:17:14 - 8:24:17 for the same security. So it should give me the following:</p>

<p>IDENTIFIER_VALUE    TIME    DATE    ASK PRICE   BID PRICE   ask bid
BE0000291972    08:17:14    19/02/2018  145.09  144.82  145.08  144.96
    08:17:18    19/02/2018  145.09  144.95  145.08  144.96
    08:17:18    19/02/2018  145.09  144.95  145.08  144.96
    08:18:18    19/02/2018  145.09  144.95  145.08  144.96
    08:22:18    19/02/2018  145.09  144.95  145.08  144.96</p></li>
<li><p>Want to do some calculations on this data set.</p></li>
<li><p>Repeat the step 1-3 using the second record. Repeat till the end of all the records in the dataset.</p></li>
</ol>

<p>Groupby / resample will combine the records for the time frequency, but this is not what I am looking for. I want to extract the records for every 7 min with respect to each entry in the dataframe and do the calcs on that. Hope I am able to explain what I want.</p>

<p>Thanks In advance</p>
","9419231","9209546","2018-02-27 15:15:36","Python: Multiindex recursive calculation","<python><multi-index>","1","4","3611"
"49042817","2018-03-01 04:49:21","2","","<p>Here is some ideas:</p>

<ul>
<li>use <code>CustomJSFilter</code> to wrap a javascript function to do the data
filter. </li>
<li>use only one call of <code>p.circle()</code> to draw all the circles.</li>
<li>use <code>factor_cmap</code> to map Treatment column to colors. </li>
<li>use <code>tags</code>
property to save data in Python and read it in javascript.</li>
</ul>

<p>since there is only one <code>GlyphRenderer</code>, visibility toggle doesn't work with it's legend.</p>

<p>To solve this, create a dummy <code>ColumnDataSource</code> and call <code>p.circle()</code> many times with it to create a list of dummy <code>GlyphRenderer</code>.
Create legend for these dummy <code>GlyphRenderer</code>, and link their visible property change with a <code>CustomJS</code> that calls <code>source.change.emit()</code>
to redraw the figure.</p>

<p>Because all the filter calculation is executed by javascript, you can create a static html file that can interact with user inputs.</p>

<p>Here is the notebook:</p>

<p><a href=""http://nbviewer.jupyter.org/gist/ruoyu0088/01ddf28ed041508304843f49a794d66a"" rel=""nofollow noreferrer"">http://nbviewer.jupyter.org/gist/ruoyu0088/01ddf28ed041508304843f49a794d66a</a></p>

<pre><code>from bokeh.plotting import figure
from bokeh.models import ColumnDataSource, CustomJS, CDSView, CustomJSFilter, HoverTool
from bokeh.models.widgets import CheckboxButtonGroup
from bokeh.io import show, output_notebook
from bokeh.palettes import Set1 
from bokeh.transform import factor_cmap
from bokeh.layouts import widgetbox, layout

import pandas as pd
import numpy as np
import datetime as dt
from itertools import cycle, islice

output_notebook()

N = 24
start_date = dt.date(2016,1,1)
nbdays = int(365 / N)

df = pd.DataFrame({'Date': [start_date + dt.timedelta(days=i*nbdays) for i in range(1,N+1)], 
                   'Rating':    [(100/N)*i for i in range(1,N+1)], 
                   'Plot':      list(islice(cycle(range(1, 9)), 0, N)), 
                   'Treatment': list(islice(cycle(range(1, 7)), 0, N)), 
                   'Trial':     list(islice(cycle(range(1, 4)), 0, N)), 
                   'Name':      list(islice(cycle(""ABCDEF""), 0, N)), 
                   'Target':    list(islice(cycle(""JKLMNOP""), 0, N)), 
                   'Part':      list(islice(cycle(""WXYZ""), 0, N)) 
                   })

columns = 'Plot', 'Trial', 'Name', 'Target', 'Part'
unique_items = [df[col].unique() for col in columns]

df[""Treatment""] = df[""Treatment""].astype(str)

source = ColumnDataSource(data=df)
dummy_source = ColumnDataSource(data={""x"":[], ""y"":[]})

hover = HoverTool(tooltips=[('Date', '@Date{%d/%m/%Y}')] + [(column, '@'+column) 
                            for column in columns], formatters={
                             'Date': 'datetime', # use 'datetime' formatter for 'Date' field
                             })

p = figure(x_axis_type=""datetime"", tools=[hover])
color = factor_cmap(""Treatment"", Set1[9], df.Treatment.unique())

for i, label in enumerate(df.Treatment.unique()):
    dummy_circle = p.circle(x=""x"", y=""y"", source=dummy_source, legend=""Treatment {}"".format(label), color=Set1[9][i])
    dummy_circle.tags = [label]

p.legend.location = ""bottom_right""
p.legend.click_policy = ""hide""

def source_change(source=source):
    source.change.emit()

callback_source_change = CustomJS.from_py_func(source_change)

for item in p.legend[0].items:
    item.renderers[0].js_on_change(""visible"", callback_source_change)

controls = [CheckboxButtonGroup(labels=items.astype(str).tolist(), active=list(range(len(items)))) for items in unique_items]
widgets = widgetbox(*controls)

for name, control in zip(columns, controls):
    control.tags = [name]

def func_filter(source=source, legend=p.legend[0], widgets=widgets):
    window.widgets = widgets
    visible_treatments = [item.renderers[0].tags for item in legend.items if item.renderers[0].visible]
    date = source.data['Date']
    treatments = source.data['Treatment']
    res = []

    selectors = {}
    for widget in widgets.children:
        col = widget.tags[0]
        selectors[col] = dict([(widget.labels[i], i) for i in widget.active])

    for i in range(len(date)):
        flag = treatments[i] in visible_treatments
        for key, val in selectors.items():
            if source.data[key][i] not in val:
                flag = False
                break
        res.append(flag)
    return res

view = CDSView(source=source, filters=[CustomJSFilter.from_py_func(func_filter)])
p.circle(x='Date', y='Rating', source=source, view=view, line_color=color, fill_color=color)  

for control in controls:
    control.js_on_change(""active"", callback_source_change)

show(layout([[p, widgets]]))
</code></pre>
","772649","772649","2018-03-01 04:54:54","1","4739","HYRY","2011-05-27 07:38:27","71257","2164","76","1","49032296","49042817","2018-02-28 14:48:53","1","465","<p>I have a complex multivariate dataset that is similar in structure to this:</p>

<pre><code>import pandas as pd
import numpy as np
import datetime as dt
from itertools import cycle, islice

N = 24
start_date = dt.date(2016,1,1)
nbdays = int(365 / N)

df = pd.DataFrame({'Date': [start_date + dt.timedelta(days=i*nbdays) for i in range(1,N+1)], 
                   'Rating':    [(100/N)*i for i in range(1,N+1)], 
                   'Plot':      list(islice(cycle(range(1, 9)), 0, N)), 
                   'Treatment': list(islice(cycle(range(1, 7)), 0, N)), 
                   'Trial':     list(islice(cycle(range(1, 4)), 0, N)), 
                   'Name':      list(islice(cycle(""ABCDEF""), 0, N)), 
                   'Target':    list(islice(cycle(""JKLMNOP""), 0, N)), 
                   'Part':      list(islice(cycle(""WXYZ""), 0, N)) 
                   })
</code></pre>

<p>I want:</p>

<ul>
<li>to plot <code>Date</code> versus <code>Rating</code>, colored by <code>Treatment</code></li>
<li>to have an interactive legend, so that clicking on a treatment toggles the visibility of the treatment</li>
<li>to have buttons to the side of the plot for the other parameters (<code>Plot</code>, <code>Trial</code>, <code>Name</code>, <code>Target</code>, <code>Part</code>) so that clicking on a button toggles the visibility of corresponding dots</li>
<li>to show all the parameters when you hover over a point</li>
</ul>

<p>This is the code that I have (dataset from above in variable <code>df</code>):</p>

<pre><code>from bokeh.plotting import figure
from bokeh.models import ColumnDataSource
from bokeh.palettes import Set1 
from bokeh.models import (CDSView, BooleanFilter, Legend,
                          DatetimeTickFormatter, Range1d,
                          HoverTool)
from bokeh.models.widgets import CheckboxButtonGroup, Div
from bokeh.layouts import widgetbox, layout
from bokeh.io import curdoc

columns = ['Treatment', 'Plot', 'Trial', 'Name', 'Target', 'Part']
categories = [sorted(df[column].unique()) for column in columns]
all_columns = ['Date', 'Rating'] + columns

treatment_colormap = dict(zip(categories[0], Set1[6])) 

# Create Input controls
divs = [Div(text=column+':') for column in columns[1:]]
controls   = [CheckboxButtonGroup(labels=list(map(str, category)), active=list(range(len(category)))) for category in categories[1:]]

# Create Column Data Source that will be used by the plot
source = ColumnDataSource(data=dict((column, []) for column in all_columns))


def select():
    actives = [control.active for control in controls]
    actives_names = [[category[a] for a in active] for (active, category) in zip(actives, categories[1:])]

    presence = [df[column].isin(active_names) for (column, active_names) in zip(columns[1:], actives_names)]
    result = df[np.logical_and.reduce(presence)] # https://stackoverflow.com/a/49027984/50065
    return result

def update():
    sdf = select()
    source.data = dict((column, sdf[column]) for column in all_columns)

    glyphs = []
    selected_treatments = sorted(sdf['Treatment'].unique())
    for treatment in selected_treatments:
        booleans = [value == treatment for value in source.data['Treatment']]
        view = CDSView(source=source, filters=[BooleanFilter(booleans)])
        color = treatment_colormap[treatment]
        glyphs.append(p.circle(x='Date', y='Rating', source=source, view=view, line_color=color, fill_color=color))

    legend = Legend(items=[
        (""treatment {}"".format(treatment), [glyph]) for treatment, glyph
        in zip(selected_treatments, glyphs)
        ])

    p.add_layout(legend, 'below')
    p.legend.click_policy='hide'
    p.legend.location = 'bottom_center'
    p.legend.orientation = 'horizontal'

for control in controls:
    control.on_change('active', lambda attr, old, new: update())

def datetime_in_miliseconds(date):
    date = dt.datetime.strptime(date, '%d/%m/%Y')
    epoch = dt.datetime.utcfromtimestamp(0)
    return (date - epoch).total_seconds() * 1000.0

hover = HoverTool(tooltips=[('Date', '@Date{%d/%m/%Y}')] + [(column, '@'+column) 
                            for column in all_columns[1:]], formatters={
                             'Date': 'datetime', # use 'datetime' formatter for 'Date' field
                             })


p = figure(x_axis_type=""datetime"", tools=[hover])
p.title.text = 'Date vs Rating'
p.xaxis.axis_label = 'Date'
p.xaxis.formatter = DatetimeTickFormatter(days = ['%d/%m/%y'])
start = datetime_in_miliseconds('01/01/2016')
end = datetime_in_miliseconds('31/12/2016')
p.x_range=Range1d(start, end)
p.yaxis.axis_label = 'Rating'
p.ygrid.band_fill_color=""olive""
p.ygrid.band_fill_alpha = 0.1
p.y_range=Range1d(0,100)

sizing_mode = 'scale_width'
inputs = widgetbox(*sum(zip(divs, controls), tuple()), sizing_mode=sizing_mode)

l = layout([[p, inputs]], sizing_mode=sizing_mode)
update()  # initial load of the data
curdoc().add_root(l)
</code></pre>

<p>which looks like this when you run <code>bokeh serve --show main.py</code> (<code>bokeh</code> version 0.12.10):</p>

<p><a href=""https://i.stack.imgur.com/YkTaw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YkTaw.png"" alt=""plot""></a></p>

<p>What works:</p>

<ul>
<li>Clicking on the legend toggles the visibility of the treatments</li>
</ul>

<p>What doesn't work:</p>

<ul>
<li>the information shown in the hoverlabels is incorrect (the first 6 dots have the same information in their hoverlabels, the next six dots also have identical hoverlabels and so on).</li>
<li>clicking on the right hand buttons messes up the plot: axis labels dissapear, a second legend is show over the plot instead of below it)</li>
</ul>

<p>How do I fix these last two points?</p>
","50065","50065","2018-02-28 15:17:02","Interaction between CheckboxButtonGroup and Legend in complex bokeh plot","<python><pandas><bokeh>","1","0","5732"
"49042846","2018-03-01 04:53:29","1","","<h1>You don't.</h1>

<p>The behavior you desire is completely unexpected and somewhat bizarre. Calling <code>A()</code> is expected to return an instance of <code>A</code>. Doing anything else is confusing and unintuitive, which makes it difficult to read and understand any code invoking it.</p>

<h1>Alternative</h1>

<p>If you really need this behavior, create a factory method:</p>

<pre><code>def make_thing(a, b):
    if 0 == b:
        return int(a)
    else:
        return A(a, b)
</code></pre>

<p>Obviously, you need a better name than <code>make_thing</code>, but without any context, I can't give you any suggestions.</p>

<h1>Avoid the problem if possible</h1>

<p>Since <code>A</code> is not a number and is generally not compatible with <code>int</code>, it is also somewhat strange to store both <code>int</code> and <code>A</code> in the same variable.</p>

<p>If all you're doing is converting to a string, then you don't need a class at all. A simple method outside of a class is the better alternative:</p>

<pre><code>def a_and_b_to_string(a, b):
    if b == 0:
        return str(int(a))
    else:
        return str(a) + "":"" + str(b)
</code></pre>

<p>If you're doing more than that, your calling code will probably end up looking something like this:</p>

<pre><code>x = make_thing(input1, input2)
if isinstance(x, A):
    result = x.some_method_from_a() # Or some other calculation requiring an A
else:
    result = 5 * x # Or some other calculation requiring an `int`
</code></pre>

<p>This is somewhat silly: you write a method to choose the data type and then have to write specialized code for each possible result. You're not getting any benefits from having a function that returns the separate types here. I can think of two simpler alternatives:</p>

<ol>
<li><p>Just move the check to the calling code:</p>

<pre><code>if input2 == 0:
    temp = A(input1, input2)
    result = temp.some_method_from_a() # Or some other calculation requiring an A
else:
    result = 5 * int(input1) # Or some other calculation requiring an int
</code></pre>

<p>If you go this route, you should also modify <code>A.__init__</code> to throw a <code>ValueError</code> if <code>b == 0</code>, since that would be an invalid state for an <code>A</code> to be in.</p></li>
<li><p>Modify <code>A</code> so that it works properly regardless of whether <code>b</code> is <code>0</code>:</p>

<pre><code>class A(object):
    def __init__(self,a,b):
        self.a = a
        self.b = b

    def some_method_from_a():
        if self.b == 0:
            # Some calculation involving only a
            return int(self.a) * 5
        else:
            # Some other more complex calculation involving both a and b
            return self.a * self.b * 6

    def __repr__(self):
        if self.b == 0:
            return str(int(self.a))
        else:
            return str(self.a) + "":"" + str(self.b)
</code></pre>

<p>Then</p>

<pre><code>x = A(a, b)
result = x.some_method_from_a()
</code></pre></li>
</ol>

<p>But again, it's hard to provide recommendations without knowing how you're actually using it.</p>
","1394393","1394393","2018-03-01 06:42:00","0","3119","jpmc26","2012-05-14 18:11:20","16845","3311","1572","1192","49038098","49038249","2018-02-28 20:36:00","1","72","<p>Apologies for incorrect lingo, I am still new to this. </p>

<p>I want to make a class initialiser that, using a conditional, will decide whether or not the instance of said class will collapse into a simple integer.</p>

<p>Simplified Unworking Example:</p>

<pre><code>class A(object): 
    def __init__(self,a,b):
        self.a = a
        self.b = b
        if self.b == 0:
            return int(a)
    def __repr__(self):
        return str(a)+"":""+str(b)

DoesntBecomeAnInt = A(3,4)
WillBecomeAnInt = A(3,0)
print(DoesntBecomeAnInt,WillBecomeAnInt)

##Desired Output:
##3:4, 3
</code></pre>

<p>Any help would be very much appreciated!</p>
","9181800","","","Python 3: Using OOP to change Class to Integer on Conditional Statement","<python><python-3.x><class><oop>","3","0","650"
"49042856","2018-03-01 04:54:12","0","","<p>It seems like the <code>origin</code> element's dropdown covers the radio button you are trying to click. Maybe you could change the order of operations though? Clicking the <code>destination</code> element also opens up the section where the radio button is but it doesn't seem to cover it. This is a quick example of clicking that radio button and then you could go fillout the <code>origin</code> input after.</p>

<pre><code>from selenium import webdriver

driver = webdriver.Chrome()
driver.get('https://www.flytap.com/pt-br/')

destination = driver.find_element_by_id('destination')
destination.click()

miles_box = driver.find_element_by_id('booking-type-2')
miles_box.click()
</code></pre>
","8079103","8079103","2018-03-01 17:14:26","0","701","G_M","2017-05-29 00:31:33","3102","440","139","287","49041461","49043575","2018-03-01 01:55:43","0","461","<p>I am trying to click into a radio button inside a span. Trying to execute:</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.common.keys import Keys 


chromeDriver = webdriver.Chrome()
chromeDriver.get('https://www.flytap.com/pt-br/')

#Works Fine
chromeDriver.find_element_by_id('origin')
origin.click()
origin.clear()
origin.send_keys('(RIO) Rio De Janeiro -  todos os aeroportos , Brasil')
    origin.click()

#Where I got the error
milesBox = chromeDriver.find_element_by_id(""booking-type-2"").click()

#Also tried:
milesBox = chromeDriver.find_element_by_id(""booking-type-2"").send_keys(Keys.ENTER)

#And, finally:
milesBox = chromeDriver.find_element_by_id(""booking-type-2"").send_keys(Keys.SPACE)
</code></pre>

<p>Here is the error I got:</p>

<pre><code>ElementNotVisibleException: Message: element not visible
</code></pre>

<p>HTML code:</p>

<pre><code>&lt;!-- Payment Methods START --&gt;
                &lt;fieldset id=""booking-payment-drag"" class=""booking-payment""&gt;
                    &lt;div class=""toolbar-radio-wrapper""&gt;
                        &lt;legend class=""ipt-label""&gt;Reservar com:&lt;/legend&gt;
                    &lt;/div&gt;
                    &lt;div class=""toolbar-radio-wrapper""&gt;
                        &lt;div class=""radio""&gt;
                            &lt;span class=""checked""&gt;&lt;input type=""radio"" id=""booking-type-1"" name=""booking-type"" value=""1"" checked&gt;&lt;/span&gt;
                        &lt;/div&gt;
                        &lt;label for=""booking-type-1"" class=""ipt-label""&gt;Dinheiro&lt;/label&gt;
                    &lt;/div&gt;
                    &lt;div class=""toolbar-radio-wrapper js-country-not-eligible""&gt;
                        &lt;div class=""radio""&gt;
                            &lt;span class=""""&gt;&lt;input type=""radio"" id=""booking-type-2"" name=""booking-type"" value=""2""&gt;&lt;/span&gt;
                        &lt;/div&gt;
                        &lt;label for=""booking-type-2"" class=""ipt-label""&gt;Milhas&lt;/label&gt;
                    &lt;/div&gt;
                        &lt;div class=""toolbar-radio-wrapper""&gt;
                            &lt;div class=""radio is-disabled js-country-eligible""&gt;
                                &lt;span class=""""&gt;&lt;input type=""radio"" id=""booking-type-3"" name=""booking-type"" value=""3"" disabled&gt;&lt;/span&gt;
                            &lt;/div&gt;
                            &lt;label for=""booking-type-3"" class=""ipt-label""&gt;Miles&amp;Cash&lt;/label&gt;
                                                        &lt;/div&gt;
                &lt;/fieldset&gt;
</code></pre>
","6584846","10388629","2019-05-30 00:28:47","Cannot click a radio button inside a span Selenium Python","<python><selenium><selenium-webdriver><radio-button><radio>","3","1","2635"
"49042872","2018-03-01 04:56:25","0","","<p>You can use this xpath</p>

<pre><code>//div[@class='radio']//span//input[@id='booking-type-1']

//div[@class='radio']//span//input[@id='booking-type-2']

//div[@class='radio is-disabled js-country-eligible']//span//input[@id='booking-type-3']
</code></pre>
","8164333","","","0","261","iamsankalp89","2017-06-15 06:10:35","3860","1035","129","252","49041461","49043575","2018-03-01 01:55:43","0","461","<p>I am trying to click into a radio button inside a span. Trying to execute:</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.common.keys import Keys 


chromeDriver = webdriver.Chrome()
chromeDriver.get('https://www.flytap.com/pt-br/')

#Works Fine
chromeDriver.find_element_by_id('origin')
origin.click()
origin.clear()
origin.send_keys('(RIO) Rio De Janeiro -  todos os aeroportos , Brasil')
    origin.click()

#Where I got the error
milesBox = chromeDriver.find_element_by_id(""booking-type-2"").click()

#Also tried:
milesBox = chromeDriver.find_element_by_id(""booking-type-2"").send_keys(Keys.ENTER)

#And, finally:
milesBox = chromeDriver.find_element_by_id(""booking-type-2"").send_keys(Keys.SPACE)
</code></pre>

<p>Here is the error I got:</p>

<pre><code>ElementNotVisibleException: Message: element not visible
</code></pre>

<p>HTML code:</p>

<pre><code>&lt;!-- Payment Methods START --&gt;
                &lt;fieldset id=""booking-payment-drag"" class=""booking-payment""&gt;
                    &lt;div class=""toolbar-radio-wrapper""&gt;
                        &lt;legend class=""ipt-label""&gt;Reservar com:&lt;/legend&gt;
                    &lt;/div&gt;
                    &lt;div class=""toolbar-radio-wrapper""&gt;
                        &lt;div class=""radio""&gt;
                            &lt;span class=""checked""&gt;&lt;input type=""radio"" id=""booking-type-1"" name=""booking-type"" value=""1"" checked&gt;&lt;/span&gt;
                        &lt;/div&gt;
                        &lt;label for=""booking-type-1"" class=""ipt-label""&gt;Dinheiro&lt;/label&gt;
                    &lt;/div&gt;
                    &lt;div class=""toolbar-radio-wrapper js-country-not-eligible""&gt;
                        &lt;div class=""radio""&gt;
                            &lt;span class=""""&gt;&lt;input type=""radio"" id=""booking-type-2"" name=""booking-type"" value=""2""&gt;&lt;/span&gt;
                        &lt;/div&gt;
                        &lt;label for=""booking-type-2"" class=""ipt-label""&gt;Milhas&lt;/label&gt;
                    &lt;/div&gt;
                        &lt;div class=""toolbar-radio-wrapper""&gt;
                            &lt;div class=""radio is-disabled js-country-eligible""&gt;
                                &lt;span class=""""&gt;&lt;input type=""radio"" id=""booking-type-3"" name=""booking-type"" value=""3"" disabled&gt;&lt;/span&gt;
                            &lt;/div&gt;
                            &lt;label for=""booking-type-3"" class=""ipt-label""&gt;Miles&amp;Cash&lt;/label&gt;
                                                        &lt;/div&gt;
                &lt;/fieldset&gt;
</code></pre>
","6584846","10388629","2019-05-30 00:28:47","Cannot click a radio button inside a span Selenium Python","<python><selenium><selenium-webdriver><radio-button><radio>","3","1","2635"
"49042876","2018-03-01 04:56:52","0","","<p>Firstly, try to make python scripts run in the xampp ..for that change the settings in the httpd.conf file as given in other posts...</p>

<p>Once u get running python scripts in xampp..try to run the python script from browser localhost/xyz.py. and if you get the output then this means xampp can now run python files.</p>

<p>Then in your php script just call exec () function to execute the python script..this one line does wonders.</p>
","9412032","","","0","444","Abhi","2018-02-26 08:01:47","1","2","0","0","48984035","","2018-02-26 08:13:16","-2","639","<p>I have a php script with a text form and a button.on clicking the button the data entered in textform is stored in the phpmyadmin db.i am using xampp for php. another python script is linked to this same table in db taking the text from the table and generating the response.</p>

<p>I want the python script to be called automatically every time after the user has entered the text and clicked the button.how shall I execute this problem and how to run the python script in xampp as I saw some answers but was confused on the use of  exec () calls and other methods..
Using python 3.4
Detailed steps explanation is appreciated.
Python directory:c:\python34
.py file directory:c:\xampp\htdocs
.php file directory; c:\xampp\htdocs  </p>

<p>Please somebody help..</p>
","9412032","","","Calling python script from php.in windows","<php><python><xampp>","1","6","770"
"49042901","2018-03-01 04:59:47","0","","<p>It says that it requires Microsoft Visual C++ 14.0. Have you tried installing that version of Microsoft Visual C++? And do take a look at this post too. <a href=""https://stackoverflow.com/questions/29846087/microsoft-visual-c-14-0-is-required-unable-to-find-vcvarsall-bat"">Microsoft Visual C++ 14.0 is required (Unable to find vcvarsall.bat)</a></p>
","7552217","","","0","353","Sagun Raj Lage","2017-02-12 03:38:02","454","60","14","9","49042878","49042901","2018-03-01 04:56:57","0","552","<p>When I tried to install <code>mysql</code> in python</p>

<p>using this command <code>python -m pip install mysql</code></p>

<p>can anyone help me with this?</p>

<blockquote>
  <p>Collecting mysql   Using cached mysql-0.0.1.tar.gz Collecting
  MySQL-python (from mysql)   Using cached MySQL-python-1.2.5.zip
  Installing collected packages: MySQL-python, mysql   Running setup.py
  install for MySQL-python ... error
      Complete output from command C:\Users\vishnuvardhan12137\AppData\Local\Programs\Python\Python36-32\python.exe
  -u -c ""import setuptools, tokenize;<strong>file</strong>='C:\Users\VISHNU~1\AppData\Local\Temp\pip-build-lw04ypbu\MySQL-python\setup.py';f=getattr(tokenize,
  'open', open)(<strong>file</strong>);code=f.read().replace('\r\n',
  '\n');f.close();exec(compile(code, <strong>file</strong>, 'exec'))"" install
  --record C:\Users\VISHNU~1\AppData\Local\Temp\pip-0awclynb-record\install-record.txt
  --single-version-externally-managed --compile:
      running install
      running build
      running build_py
      creating build
      creating build\lib.win32-3.6
      copying _mysql_exceptions.py -> build\lib.win32-3.6
      creating build\lib.win32-3.6\MySQLdb
      copying MySQLdb__init__.py -> build\lib.win32-3.6\MySQLdb
      copying MySQLdb\converters.py -> build\lib.win32-3.6\MySQLdb
      copying MySQLdb\connections.py -> build\lib.win32-3.6\MySQLdb
      copying MySQLdb\cursors.py -> build\lib.win32-3.6\MySQLdb
      copying MySQLdb\release.py -> build\lib.win32-3.6\MySQLdb
      copying MySQLdb\times.py -> build\lib.win32-3.6\MySQLdb
      creating build\lib.win32-3.6\MySQLdb\constants
      copying MySQLdb\constants__init__.py -> build\lib.win32-3.6\MySQLdb\constants
      copying MySQLdb\constants\CR.py -> build\lib.win32-3.6\MySQLdb\constants
      copying MySQLdb\constants\FIELD_TYPE.py -> build\lib.win32-3.6\MySQLdb\constants
      copying MySQLdb\constants\ER.py -> build\lib.win32-3.6\MySQLdb\constants
      copying MySQLdb\constants\FLAG.py -> build\lib.win32-3.6\MySQLdb\constants
      copying MySQLdb\constants\REFRESH.py -> build\lib.win32-3.6\MySQLdb\constants
      copying MySQLdb\constants\CLIENT.py -> build\lib.win32-3.6\MySQLdb\constants
      running build_ext
      building '_mysql' extension
      error: Microsoft Visual C++ 14.0 is required. Get it with ""Microsoft Visual C++ Build Tools"":
  <a href=""http://landinghub.visualstudio.com/visual-cpp-build-tools"" rel=""nofollow noreferrer"">http://landinghub.visualstudio.com/visual-cpp-build-tools</a></p>
  
  <p>---------------------------------------- Command ""C:\Users\vishnuvardhan12137\AppData\Local\Programs\Python\Python36-32\python.exe
  -u -c ""import setuptools, tokenize;<strong>file</strong>='C:\Users\VISHNU~1\AppData\Local\Temp\pip-build-lw04ypbu\MySQL-python\setup.py';f=getattr(tokenize,
  'open', open)(<strong>file</strong>);code=f.read().replace('\r\n',
  '\n');f.close();exec(compile(code, <strong>file</strong>, 'exec'))"" install
  --record C:\Users\VISHNU~1\AppData\Local\Temp\pip-0awclynb-record\install-record.txt
  --single-version-externally-managed --compile"" failed with error code 1 in
  C:\Users\VISHNU~1\AppData\Local\Temp\pip-build-lw04ypbu\MySQL-python\</p>
</blockquote>
","6180444","4729967","2018-03-01 06:13:26","python mysql installation failed","<python><mysql><database><pip>","2","2","3240"
"49042906","2018-03-01 05:00:38","4","","<p>This can be also another approach:</p>

<pre><code>from hyperopt import fmin, tpe, hp, STATUS_OK, Trials
from sklearn.metrics import roc_auc_score
import sys

X = []
y = []
X_val = []
y_val = []

space = {'choice': hp.choice('num_layers',
                    [ {'layers':'two', },
                    {'layers':'three',
                    'units3': hp.uniform('units3', 64,1024), 
                    'dropout3': hp.uniform('dropout3', .25,.75)}
                    ]),

            'units1': hp.uniform('units1', 64,1024),
            'units2': hp.uniform('units2', 64,1024),

            'dropout1': hp.uniform('dropout1', .25,.75),
            'dropout2': hp.uniform('dropout2',  .25,.75),

            'batch_size' : hp.uniform('batch_size', 28,128),

            'nb_epochs' :  100,
            'optimizer': hp.choice('optimizer',['adadelta','adam','rmsprop']),
            'activation': 'relu'
        }

def f_nn(params):   
    from keras.models import Sequential
    from keras.layers.core import Dense, Dropout, Activation
    from keras.optimizers import Adadelta, Adam, rmsprop

    print ('Params testing: ', params)
    model = Sequential()
    model.add(Dense(output_dim=params['units1'], input_dim = X.shape[1])) 
    model.add(Activation(params['activation']))
    model.add(Dropout(params['dropout1']))

    model.add(Dense(output_dim=params['units2'], init = ""glorot_uniform"")) 
    model.add(Activation(params['activation']))
    model.add(Dropout(params['dropout2']))

    if params['choice']['layers']== 'three':
        model.add(Dense(output_dim=params['choice']['units3'], init = ""glorot_uniform"")) 
        model.add(Activation(params['activation']))
        model.add(Dropout(params['choice']['dropout3']))    

    model.add(Dense(1))
    model.add(Activation('sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'])

    model.fit(X, y, nb_epoch=params['nb_epochs'], batch_size=params['batch_size'], verbose = 0)

    pred_auc =model.predict_proba(X_val, batch_size = 128, verbose = 0)
    acc = roc_auc_score(y_val, pred_auc)
    print('AUC:', acc)
    sys.stdout.flush() 
    return {'loss': -acc, 'status': STATUS_OK}


trials = Trials()
best = fmin(f_nn, space, algo=tpe.suggest, max_evals=50, trials=trials)
print 'best: '
print best
</code></pre>

<p><a href=""https://github.com/keras-team/keras/issues/1591"" rel=""nofollow noreferrer"">Source</a></p>
","2825570","","","0","2421","Jeril","2013-09-28 04:30:48","3706","592","577","2","43533610","","2017-04-21 03:45:37","4","11114","<p>I want to build a non linear regression model using keras to predict a +ve continuous variable.
For the below model how do I select the following hyperparameters?</p>

<ol>
<li>Number of Hidden layers and Neurons</li>
<li>Dropout ratio</li>
<li>Use BatchNormalization or not</li>
<li>Activation function out of linear, relu, tanh, sigmoid</li>
<li>Best optimizer to use among adam, rmsprog, sgd </li>
</ol>

<p><strong><em>Code</em></strong></p>

<pre><code>def dnn_reg():
    model = Sequential()
    #layer 1
    model.add(Dense(40, input_dim=13, kernel_initializer='normal'))
    model.add(Activation('tanh'))
    model.add(Dropout(0.2))
    #layer 2
    model.add(Dense(30, kernel_initializer='normal'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(Dropout(0.4))
    #layer 3
    model.add(Dense(5, kernel_initializer='normal'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(Dropout(0.4))

    model.add(Dense(1, kernel_initializer='normal'))
    model.add(Activation('relu'))
    # Compile model
    model.compile(loss='mean_squared_error', optimizer='adam')
    return model
</code></pre>

<p>I have considered random gridsearch but instead want to use hyperopt which I believe will be faster. I initially implemented the tuning using <a href=""https://github.com/maxpumperla/hyperas"" rel=""nofollow noreferrer"">https://github.com/maxpumperla/hyperas</a>. Hyperas is not working with latest version of keras. I suspect that keras is evolving fast and it's difficult for the maintainer to make it compatible. So I think using hyperopt directly will be a better option.</p>

<p>PS: I am new to bayesian optimization for hyper parameter tuning and hyperopt.</p>
","3424990","3424990","2017-04-23 09:00:33","How to use hyperopt for hyperparameter optimization of Keras deep learning network?","<python><optimization><deep-learning><keras><hyperparameters>","2","0","1743"
"49042942","2018-03-01 05:04:59","0","","<p>I checked your logic and according to that you are running your first for loop to the length of <strong>emptyList-1</strong> so, after adding one element your emptylist's length becomes 1 and 1-1=0 so, your for loop will work only to 0th index and after that it will break.
I tried this </p>

<pre><code>a=[]
b = []
t=0
count = 0
total = 0
for i in range(0,5):
    x= float(input())
    count = count + 1
    total = total+ x
    a.append(x)
print(count)
for i in range(count-1,-1,-1):
    print('Aya')
    print (i)
    b.append(a[i])
for i in range(0,count-1):
    for j in range(i,count):
        if(a[i]&gt;a[j]):
            t=a[i]
            a[i]=a[j]
            a[j]=t


print(a)
print(b)
print(total)
print(total/count)
print(a[0])
</code></pre>

<p>and found it working perfectly fine for me and my for loop is taking values on every iteration.</p>
","7528968","7528968","2018-03-01 06:55:08","8","863","Aniruddh Agarwal","2017-02-07 13:21:23","637","181","28","2","49042335","49042942","2018-03-01 03:49:43","0","49","<p>So I'm writing some code for my class and have to have a list of floats that are input by a user and print them out with normal iteration and reverse iteration, and I have basically all of it done. But when it should ask multiple times for the user input, it only asks one time then prints everything out and finishes without asking multiple times. 
Any help would be appreciated as to why it isnt asking multiple times for input even though I have a for loop?
Is there an easier way to get a list of floats from user input that I don't know about?
Thanks</p>

<pre><code>    emptyList = []
    userInput = high = low = total = float(input(""Input a float &gt; ""))
    emptyList.append(userInput)

    for y in range(len(emptyList)-1):
        userInput = float(input(""Input a float &gt; ""))
        emptyList.append(userInput)
        total += emptyList
        if userInput &gt; high:
            high = userInput
        if userInput &lt; low:
            low = userInput

    avg = total / len(emptyList)
    above_avg = below_avg = 0

    for y in range(len(emptyList)):
        if emptyList[y] &gt; avg:
            above_avg += 1
        if emptyList[y] &lt; avg:
            below_avg += 1
</code></pre>
","9422161","","","User Input For List of Floats Not Repeating","<python>","3","0","1214"
"49042951","2018-03-01 05:06:09","1","","<p>You mean that you want to execute the tasks asynchronously. Synchronously means executing everything in order, on the same thread.</p>

<p>Depending on your version of Python, you can check out the multiprocessing module: <a href=""https://docs.python.org/2/library/multiprocessing.html"" rel=""nofollow noreferrer"">https://docs.python.org/2/library/multiprocessing.html</a>.</p>
","6780853","","","1","380","sbrannon","2016-08-31 22:56:15","76","3","43","0","49042917","","2018-03-01 05:02:10","0","223","<p>So this is my last 2 lines in one of my endpoint:</p>

<pre><code>self.send_activation_mail(request, user=user)
return self.response(request, status=201, title='Created', description='Please check your email for activation', data=user_data)
</code></pre>

<p>returning self.response will be return the my rest client a response of 201. My problem is the <code>send_activation_mail</code> seems like takes time to run so the my endpoint to signup process takes so much time. I tried to find the way to execute those tasks at the same time asynchronously in Python.Does anyone has any experience with this kind of situation before and how do you solve it?</p>
","6501597","6501597","2018-03-01 05:12:48","Run Multiple Tasks Asynchronously in Python","<python><asynchronous><python-multithreading>","2","1","661"
"49043016","2018-03-01 05:13:26","0","","<p><code>EXCLUDED</code> is available in the <code>UPDATE</code> section, but not in the <code>VALUES</code> section.</p>

<p>This is <a href=""https://www.depesz.com/2015/05/10/waiting-for-9-5-add-support-for-insert-on-conflict-do-nothingupdate/"" rel=""nofollow noreferrer"">a good tutorial about UPSERT</a></p>

<p>And there's always the official docs for <a href=""https://www.postgresql.org/docs/current/static/sql-insert.html#SQL-ON-CONFLICT"" rel=""nofollow noreferrer"">INSERT ON CONFLICT</a></p>
","968244","","","0","497","isapir","2011-09-28 02:56:12","9047","718","2053","15","49040371","","2018-02-28 23:31:01","0","99","<p>Disclaimer: I recently took over someone else's codebase so some of the code you see here was already premade. I've also changed certain variable names to more generic code names that probably wouldn't actually work.</p>

<p>I am trying to bulk upsert on a postgres DB using SQLAlchemy but am having trouble. It seems that when SQLAlchemy goes to access the data it needs to update the table (excluded.columnName) It is unable to be found. </p>

<p>First here is the error I'm getting:</p>

<pre><code>    Missing FROM-clause entry for table ""excluded""
    LINE 1: ...tablename) VALUES (excluded.tablename...
</code></pre>

<p>And my code:</p>

<pre><code>    index_fields = list(billocity_db.get_indexes(self.table_name))
    for row in self.data:
        if 'id' in self.column_info.keys():
            del row['id']
        data = row.to_dict()
        insert_stmt = insert(self.table).values(data)
        for i in index_fields:
            if i in data:
                del data[i]
        for key in data.keys():
            data[key] = insert_stmt.excluded[key]
            print(data[key])
        print(data)
        insert_stmt = insert_stmt.on_conflict_do_update(
            #Tried both constraint and index_elements with same result
            #constraint=self.table_name,
            #None of my columns are 'id'. Could that be an issue?
            index_elements=['id'],
            set_=data
        )
        try:
            print(insert_stmt)
            self.session.execute(insert_stmt)
        except Exception as e:
            self.session.rollback()
            self.log.exception(str(e))
        finally:
            self.session.commit()
</code></pre>

<p>The error comes immediately after calling </p>

<pre><code>self.session.execute(insert_stmt)
</code></pre>

<p>And this is what insert_stmt prints as right before execute, obviously column_name and table_name is just place holder.</p>

<pre><code> INSERT INTO
 table_name (column_name, column_name, column_name, 
 column_name, column_name, column_name, column_name, 
 column_name, column_name, column_name, column_name, 
 column_name, column_name, column_name, column_name, 
 column_name) 
 VALUES
    (
 excluded.column_name, excluded.column_name, excluded.column_name, 
 excluded.column_name, excluded.column_name, excluded.column_name, 
 excluded.column_name, excluded.column_name, excluded.column_name, 
 excluded.column_name, excluded.column_name, excluded.column_name, 
 excluded.column_name, excluded.column_name, excluded.column_name, 
 excluded.column_name
 )
 ON CONFLICT (id) DO 
 UPDATE SET
 column_name= excluded.column_name, column_name= excluded.column_name, 
 column_name= excluded.column_name, column_name= excluded.column_name, 
 column_name= excluded.column_name, column_name= excluded.column_name, 
 column_name= excluded.column_name, column_name= excluded.column_name, 
 column_name= excluded.column_name, column_name= excluded.column_name, 
 column_name= excluded.column_name, column_name= excluded.column_name, 
 column_name= excluded.column_name, column_name= excluded.column_name, 
 column_name= excluded.column_name, column_name= excluded.column_name 
 RETURNING 
 table_name.id
</code></pre>

<p>I can't find many extra resources online about this issue and I have no idea what else to try. Any help would be appreciated.</p>
","945615","968244","2018-03-01 05:14:01","SQLAlchemy Upsert unable to find table ""excluded""","<python><postgresql><sqlalchemy><upsert>","1","0","3341"
"49043018","2018-03-01 05:13:35","0","","<p>As per the <em>HTML</em> you have shared to click on the button with text as <strong>OK</strong> you have to induce <em>WebDriverWait</em> for the element to be clickable and you can use the following line of code :</p>

<pre><code>WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, ""//div[@class='alert' and @id='popup_content']//div[@class='popup_panel']/input[@id='popup_ok' and @value='OK']""))).click()
</code></pre>
","7429447","7429447","2018-03-01 05:22:03","0","443","DebanjanB","2017-01-17 08:59:30","63154","13103","3455","2612","49041839","","2018-03-01 02:46:35","0","179","<p>First of all, sorry for my English. I'm from Buenos Aires, and I've started learning Python just a few weeks ago. Furthermore, I have a really basic knowledge in programming. All I was able to do so far was by getting the info from internet (no formal education in this matter-I was studying Accounting last year).</p>

<p>As of this post, I want to find an element in a web page but I can't seem to get it right. I've even tried to click on ""space"" key-the simplest thing to do in this case. </p>

<p>I want to click on ""OK"" button.</p>

<p>I have from ""Inspect element"":</p>

<pre><code>&lt;div class=""alert"" id=""popup_content""&gt;
  &lt;div id=""popup_message""&gt;No Pending Documents&lt;/div&gt;
  &lt;div id=""popup_panel""&gt;
    &lt;input id=""popup_ok"" type=""button"" value=""OK""&gt;
  &lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p><a href=""https://i.stack.imgur.com/VCRFt.jpg"" rel=""nofollow noreferrer"">print:</a>
I've tried these 5 codes:</p>

<pre class=""lang-py prettyprint-override""><code>from selenium.webdriver.common.action_chains import ActionChains
element_ok = driver.find_element_by_xpath(""//input[@id='popup_ok']"")
Action.Chains(driver).move_to_element(element_ok).perform()
element.click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_xpath("".//*[@id='popup_ok']/div/input"").click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_css_selector("".button_main[value='OK']"").click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>clear_button = driver.find_element_by_xpath(""//input[@id='popup_panel'][@type='button']"")
clear_button = driver.find_element_by_xpath(""//form[@id='popup_ok']/input[1]"")
</code></pre>

<pre class=""lang-py prettyprint-override""><code>import keyboard
keyboard.press_and_release('shift+s, space')
</code></pre>

<p>Would someone help me get through this?</p>

<p>PS: I'm using selenium (read from it in the book 'Automate the Boring Stuff with Python. Practical Programming for Total Beginners'. And chrome webdriver.</p>
","9426664","199806","2018-03-01 12:25:06","Unable to find_element in web through Python (selenium)","<python><selenium>","4","0","2058"
"49043029","2018-03-01 05:14:28","11","","<p>These logging entries are created in 3 methods of ModelAdmin: log_addition, log_change and log_deletion. So what you need to do is override them in all of your admin classes inheriting form ModelAdmin and simply return in the body of these methods.</p>

<p>If you have more than a few admin classes, you can make a mixin class that overrides these methods and inherit from it in all your admin classes. Note that you need to inherit from the mixin before <strong>admin.ModelAdmin</strong>.</p>

<p>For example:</p>

<pre><code>class DontLog:
    def log_addition(self, *args):
        return

    # Do same for log_change and log_deletion

@admin.register(Category)
class CategoryAdmin(DontLog, admin.ModelAdmin):
    pass
</code></pre>

<p>To remove history buttons, you'll want to edit the template as described in the admin docs linked to in one of the comments to your question:</p>

<p><a href=""https://docs.djangoproject.com/en/2.0/ref/contrib/admin/#overriding-vs-replacing-an-admin-template"" rel=""noreferrer"">https://docs.djangoproject.com/en/2.0/ref/contrib/admin/#overriding-vs-replacing-an-admin-template</a></p>
","2748838","548736","2018-10-17 19:15:05","0","1127","Rainy","2013-09-05 00:20:33","741","55","15","3","49024039","49043029","2018-02-28 07:24:03","4","1261","<p>to all!</p>

<p>I'm using Django 2.* and have no idea how to remove this useless for me logging features from Django Admin panel.</p>

<p><strong>I need completely stop tracking all recent actions and logging history in Django admin panel.</strong></p>

<p>Please help me find out a solution.
(i've Googled well enough before asking for help here)</p>

<p><a href=""https://i.stack.imgur.com/BIvXj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BIvXj.png"" alt=""History in Django admin""></a>
<a href=""https://i.stack.imgur.com/E0Bo4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/E0Bo4.png"" alt=""Recent actions in Django admin""></a></p>
","2891421","","","How to stop logging Recent actions and History in Django 2.* admin panel?","<python><django><python-3.x><django-admin>","1","3","678"
"49043043","2018-03-01 05:15:30","1","","<p>Your question is a little vague, but here's my attempt:</p>

<p>Running your code gives me the following response: <code>The page requested may have been relocated, renamed or removed from the Hong Kong Exchanges and Clearing Limited, or HKEX, website.</code></p>

<p>Additionally, I don't see any span ids equal to <code>lbDateTime</code>. I do however see span ids that end with <code>lbDateTime</code>. If you are not receiving such an error, you might try this instead: <code>dates = soup.findAll(""span"", {""id"": lambda L: L and L.endswith('lbDateTime')})</code></p>

<p>(source: <a href=""https://stackoverflow.com/a/14257743/942692"">https://stackoverflow.com/a/14257743/942692</a>)</p>

<p>If you are indeed getting the same response, you will need to fix your request. I'm not familiar with <code>urllib</code> so I can't help you there, but if you are able to use the <code>requests</code> library instead, here's some code that works for me: (<code>dates</code> returns a ResultSet object with 20 elements)</p>

<pre><code>import requests
from bs4 import BeautifulSoup

headers = {
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36',
    'Content-Type': 'application/x-www-form-urlencoded',
    'Accept-Encoding': 'gzip, deflate',
    'Accept-Language': 'en-GB,en;q=0.9,en-US;q=0.8,zh-TW;q=0.7,zh;q=0.6,zh-CN;q=0.5'}

session = requests.session()
response = session.get('http://www.hkexnews.hk/listedco/listconews/advancedsearch/search_active_main_c.aspx', headers={
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36'})
soup = BeautifulSoup(response.content, 'html.parser')
form_data = {
    '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'}).get('value'),
    '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'}).get('value'),
    '__VIEWSTATEENCRYPTED': soup.find('input', {'name': '__VIEWSTATEENCRYPTED'}).get('value') 
}
f = session.post('http://www.hkexnews.hk/listedco/listconews/advancedsearch/search_active_main_c.aspx', data=form_data,
                 headers=headers)
soup = BeautifulSoup(f.content, 'html.parser')
dates = soup.findAll(""span"", {""id"": lambda L: L and L.endswith('lbDateTime')})
</code></pre>
","9426920","9426920","2018-03-01 05:30:26","1","2446","Slim","2018-03-01 03:49:38","83","8","5","0","49042076","","2018-03-01 03:16:31","0","466","<p>I am trying to scrap the following website: <a href=""http://www.hkexnews.hk/listedco/listconews/advancedsearch/search_active_main_c.aspx"" rel=""nofollow noreferrer"">http://www.hkexnews.hk/listedco/listconews/advancedsearch/search_active_main_c.aspx</a></p>

<p>I'm using python2.7, Here is my code:</p>

<pre><code>import urllib
from bs4 import BeautifulSoup

headers = {
'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36',
'Content-Type': 'application/x-www-form-urlencoded',
'Accept-Encoding': 'gzip, deflate',
'Accept-Language': 'en-GB,en;q=0.9,en-US;q=0.8,zh-TW;q=0.7,zh;q=0.6,zh-CN;q=0.5',}

class MyOpener(urllib.FancyURLopener):
    version = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36'

myopener = MyOpener()
url = 'http://www.hkexnews.hk/listedco/listconews/advancedsearch/search_active_main_c.aspx'

f = myopener.open(url)
soup_dummy = BeautifulSoup(f,""html5lib"")

viewstate = soup_dummy.select(""#__VIEWSTATE"")[0]['value']
viewstategen = soup_dummy.select(""#__VIEWSTATEGENERATOR"")[0]['value']

soup_dummy.find(id=""aspnetForm"")


formData = (
    ('__VIEWSTATE', viewstate),
    ('__VIEWSTATEGENERATOR', viewstategen),
    ('ctl00$txt_stock_code', '00005')
)

encodedFields = urllib.urlencode(formData)
# second HTTP request with form data
f = myopener.open(url, encodedFields)
soup = BeautifulSoup(f,""html5lib"")
date = soup.find(""span"", id=""lbDateTime"")
print(date)
</code></pre>

<p>Nothing can be collected.
It shows ""none"" when I run this code.
If I change print(date) to print(date.text) 
Error occur: AttributeError: 'NoneType' object has no attribute 'text' </p>
","9426811","9426811","2018-03-01 03:42:35","Scraping .aspx page with python (HKEX)","<python><asp.net><web-scraping>","1","2","1846"
"49043054","2018-03-01 05:16:20","2","","<pre><code>Bodyguard= Town('Bodyguard', 'Choose someone to protect','Yes','No', 'Town Protective')
Crusader = Town('Crusader','Protect someone each night','Yes','No','Town Protective')
Town_Protectives = [Bodyguard,Crusader]
print([p.role for p in Town_Protectives if p.Type == 'Town Protective'])
</code></pre>
","8756315","","","1","312","Sunnysinh Solanki","2017-10-11 03:50:15","448","51","19","4","49042968","","2018-03-01 05:07:53","1","37","<p>So I'm looking for a way to list out all the instances of a subclass either through a regular method or a classmethod.
For example:</p>

<pre><code>class Player:

    def __init__(self,role, abilities, visiting, unique,Type)
        self.role = role
        self.abilities = abilities
        self.unique = unique
        self.visiting = visiting
        self.Type= Type

class Town(Player):
    def __init__(self,role,abilities,visiting,unique,Type):
        super().__init__(role,abilities,visiting,unique,Type)

Bodyguard= Town('Bodyguard', 'Choose someone to protect','Yes','No', 'Town Protective')
Crusader = Town('Crusader','Protect someone each night','Yes','No','Town Protective')
         .
         .
         .
</code></pre>

<p>I want to be able to group up all the <code>Type='Town Protective'</code> and print out a list of them. for example</p>

<pre><code>print(Town_Protectives)
</code></pre>

<p>Displays:</p>

<pre><code>['Bodyguard','Crusader'....]
</code></pre>

<p>This is just a little project used to help me learn Python so it's nothing serious. Thanks for all of your help! </p>
","9399165","7832176","2018-03-01 05:23:49","How do I list out all the instances of a subclass?","<python>","2","3","1108"
"49043058","2018-03-01 05:16:59","3","","<p>Example using xarray:</p>

<pre><code>import xarray as xr
import matplotlib
import matplotlib.pyplot as plt

matplotlib.use('Agg')
file_name = ""reduced_cmorph_adjusted_spi_pearson_01.nc""
with xr.open_dataset(file_name) as ds:
    for t in range(ds.time.shape[0]):
        da = ds.spi_pearson_01.isel(time=t)
        plt.figure()
        da.plot()
        plt.savefig('frame{}.png'.format(t))
</code></pre>

<p>Non-scripting method if you don't mind using a few clicks in Panoply: create a lat/lon plot and then choose File->Export Animation . You can output individual time steps as JPG or PNG.</p>
","7017006","7017006","2018-03-28 04:00:48","4","602","Robert Davy","2016-10-14 03:22:50","353","68","25","1","49035660","49043058","2018-02-28 17:47:19","2","389","<p>I would like to create plot images from a NetCDF at each time step.</p>

<p>My NetCDF files look like this:</p>

<pre><code>netcdf file:/C:/home/data/cmorph/test/reduced_cmorph_adjusted_spi_pearson_01.nc {
  dimensions:
    time = UNLIMITED;   // (240 currently)
    lat = 120;
    lon = 360;
  variables:
    float spi_pearson_01(time=240, lat=120, lon=360);
      :_FillValue = NaNf; // float
      :valid_min = -3.09; // double
      :valid_max = 3.09; // double
      :long_name = ""Standard Precipitation Index (Pearson Type III distribution), 1-month scale"";
      :_ChunkSizes = 1, 120, 360; // int

    int time(time=240);
      :units = ""days since 1800-01-01 00:00:00"";
      :_ChunkSizes = 1024; // int
      :_CoordinateAxisType = ""Time"";

    float lat(lat=120);
      :units = ""degrees_north"";
      :_CoordinateAxisType = ""Lat"";

    float lon(lon=360);
      :units = ""degrees_east"";
      :_CoordinateAxisType = ""Lon"";

  // global attributes:
  :title = ""CMORPH Version 1.0BETA Version, daily precip from 00Z-24Z"";
  :history = ""Wed Feb 28 07:30:01 2018: C:\\home\\miniconda\\Library\\bin\\ncks.exe --dmn lon,0,,4 --dmn lat,0,,4 CMORPH_V1.0_ADJ_0.25deg-DLY_00Z_1998_2017.nc cmorph_reduced_adjusted.nc"";
  :NCO = ""4.7.1"";
  :_CoordSysBuilder = ""ucar.nc2.dataset.conv.DefaultConvention"";
}
</code></pre>

<p>I like the plots produced by Panoply but I haven't worked out how to script it (I don't want to go through the GUI for this since I'll have roughly 1500 plots to create). I'm not wedded to Panoply per se, so if someone has a better idea please advise. I could hammer this out in matplotlib but it'd take me quite a while and wouldn't look as good as the Panoply plots. I'm trying to avoid doing much if any of the plotting myself, but maybe there's something out there that provides easy plotting of NetCDFs which can be called from a script (I typically use Python and bash), if so please clue me in. Thanks in advance for any suggestions or examples.</p>
","85248","","","NetCDF: How can I script plotting at each time step?","<python><plot><netcdf>","2","0","1983"
"49043107","2018-03-01 05:22:12","1","","<p>First of all let me clarify you that importing an entire module, if you are going to use a part of it, then is not a good idea. Instead of that you can use <code>from</code> to import specific function under a library/package. By doing this, you make your program efficient in terms of memory and performance. </p>

<p>To know more refer these:</p>

<ol>
<li><a href=""https://stackoverflow.com/questions/710551/import-module-or-from-module-import"">'import module' or 'from module import'</a></li>
<li><a href=""http://effbot.org/pyfaq/tutor-whats-the-difference-between-import-foo-and-from-foo-import.htm"" rel=""nofollow noreferrer"">difference between import and from</a></li>
</ol>

<p>Net let us look into the solution.</p>

<p>Before starting off with the solution, let me clarify you the use of <code>__init__.py</code> file. It just tells the python interpreter that the <strong>*.py</strong> files present there are importable which means they are modules and <em>are/maybe</em> a part of a package. </p>

<p>So, If you have N no of sub directories you have to put <code>__init__.py</code> file in all those sub directories such that they can also be imported. Inside <code>__init__.py</code> file you can also add some additional information like which path should be included, default functions,variables,scope,..etc. To know about these just google about <code>__init__.py</code> file or take some python library and go through the same <code>__init__.py</code> file to know about it. (Here lies the solution) </p>

<p>More Info:</p>

<ol>
<li><a href=""https://docs.python.org/3/tutorial/modules.html#modules"" rel=""nofollow noreferrer"">modules</a></li>
<li><a href=""http://mikegrouchy.com/blog/2012/05/be-pythonic-__init__py.html"" rel=""nofollow noreferrer"">Be pythonic</a></li>
</ol>

<p>So as stated by <a href=""https://stackoverflow.com/users/6154579/sushant-chaudhary"">@Sushant Chaudhary</a> your project structure should be like</p>

<pre><code>proj-dir
 --|--__init__.py
   --package1
     --|--__init__.py
     --|--module1.py
   --package2
     --|--__init__.py
     --|--module2.py
</code></pre>

<blockquote>
  <p>So now, If I put <code>__init__.py</code> file under my directory like above, Will
  it be importable and work fine? </p>
  
  <p><strong>yes and no</strong>.</p>
</blockquote>

<h2>Yes :</h2>

<p>If you are importing the modules within that project/package directory. 
for example in your case<br>
 you are importing package1.module1 in pakage2.module2 as <code>from package1 import module1</code>.</p>

<p>Here you have to import the <strong>base dir</strong> inside the sub modules, <strong><em>Why?</em></strong> the project will run fine if you are running the module from the same place. <em>i.e: inside package2 as python module2.py</em>, <strong><em>But</em></strong> will throw <code>ModuleNotFoundError</code> If you run the module from some other directory. <em>i.e: any other path except under package2</em> for example under proj-dir as <code>python package2/module2.py</code>. This is what happening in your case. You are running the module from project-dir. </p>

<p>So How to fix this?</p>

<p>1- You have to append basedir path to system path in module2.py as </p>

<pre><code>from sys import path
dir_path = ""/absolute/path/to/proj-dir""
sys.path.insert(0, dir_path)
</code></pre>

<p>So that module2 will be able to find package1 (and module1 inside it).</p>

<p>2- You have to add all the sub module paths in <code>__init__.py</code> file under proj-dir.</p>

<p>For example:</p>

<pre><code>#__init__.py under lxml
# this is a package

def get_include():
    """"""
    Returns a list of header include paths (for lxml itself, libxml2
    and libxslt) needed to compile C code against lxml if it was built
    with statically linked libraries.
    """"""
    import os
    lxml_path = __path__[0]
    include_path = os.path.join(lxml_path, 'includes')
    includes = [include_path, lxml_path]

    for name in os.listdir(include_path):
        path = os.path.join(include_path, name)
        if os.path.isdir(path):
            includes.append(path)

    return includes
</code></pre>

<p>This is the <code>__init__.py</code> file of <strong><em>lxml</em></strong> (a python library for parsing html,xml data). You can refer any <code>__init__.py</code> file under any python libraries having sub modules.<strong>ex (os,sys)</strong>. Here I've mentioned <strong><em>lxml</em></strong> because I thought it will be easy for you to understand. You can even check <code>__init__.py</code> file under other libraries/packages. Each will have it's own way of defining the path for submodules.</p>

<h2>No</h2>

<p>If you are trying to import modules outside the directory. Then you have to export the module path such that other modules can find them into environment variables. This can be done directly by appending absolute path of the base dir to <strong><em>PYTHONPATH</em></strong> or to <strong><em>PATH</em></strong>. </p>

<p>To know more:</p>

<ol>
<li><a href=""https://en.wikipedia.org/wiki/PATH_(variable)"" rel=""nofollow noreferrer"">PATH variables in OS</a></li>
<li><a href=""https://docs.python.org/3/using/cmdline.html#environment-variables"" rel=""nofollow noreferrer"">PYTHONPATH variable</a></li>
</ol>

<p>So to solve your problem, include the paths to all the sub modules in <code>__init__.py</code> file under <strong><em>proj-dir</em></strong> and add the <strong><em>/absolute/path/to/proj-dir</em></strong> either to <code>PYTHONPATH</code> or <code>PATH</code>.</p>

<p><strong><em>Hope the answer explains you about usage of <code>__init__.py</code> and solves your problem.</em></strong></p>
","6663095","1273751","2019-03-19 03:43:42","7","5658","Mani","2016-08-01 11:42:35","3141","286","55","23","48759465","","2018-02-13 04:28:48","10","1943","<p>I'm trying to keep a data science project well-organized so I've created a directory inside my <code>src</code> directory called <code>utils</code> that contains a file called <code>helpers.py</code>, which contains some helper functions that will be used in many scripts. What is the best practice for how I should import <code>func_name</code> from <code>src/utils/helpers.py</code> into a file in a totally different directory, such as <code>src/processing/clean_data.py</code>?</p>

<p>I see <a href=""https://stackoverflow.com/questions/4383571/importing-files-from-different-folder"">answers</a> to this question, and I've implemented a solution that works, but this feels ugly:</p>

<pre><code> sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))))
</code></pre>

<p>Am I doing this right? Do I need to add this to every script that wants to import <code>func_name</code>, like <code>train_model.py</code>?</p>

<p>My current project folder structure:</p>

<pre><code>myproject
    /notebooks
        notebook.ipynb
    /src
        /processing
            clean_data.py
        /utils
            helpers.py
        /models
            train_model.py
        __init__.py
</code></pre>

<p>Example files:</p>

<pre><code># clean_data.py

import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))))
from src.utils.helpers import func_name

func_name()


# helpers.py

def func_name():
    print('I'm a helper function.')
</code></pre>
","2569531","3154233","2018-02-13 04:38:12","Do I need to add my project directory to the system path in every script to import a function from another directory?","<python>","7","4","1542"
"49043122","2018-03-01 05:23:37","0","","<p>First you need to check out the feature names which the CountVectorizer is using.</p>

<p>Do this:</p>

<pre><code>bigram_vec.get_feature_names()
# Out:  [u'am', u'dont', u'hello', u'to', u'want']
</code></pre>

<p>You see that the word <code>""i""</code> is not present. That's because the default tokenizer uses a pattern:</p>

<blockquote>
  <p>token_pattern : string</p>

<pre><code>Regular expression denoting what constitutes a “token”, only used if 
analyzer == 'word'. The default regexp select tokens of 2 or more
alphanumeric characters (punctuation is completely ignored and always
treated as a token separator).
</code></pre>
</blockquote>

<p>And the actual output of the X should be interpreted as:</p>

<pre><code>            [u'am', u'dont', u'hello', u'to', u'want']
'hello'    [[ 0        0        1        0       0]
'i'         [ 0        0        0        0       0]
'am'        [ 1        0        0        0       0]
'hello'     [ 0        0        1        0       0]
'i'         [ 0        0        0        0       0]
'dont'      [ 0        1        0        0       0]
'want'      [ 0        0        0        0       1]
'to'        [ 0        0        0        1       0]
'i'         [ 0        0        0        0       0]
'dont'      [ 0        1        0        0       0]]
</code></pre>

<p>Now when you do <code>X.T * X</code> this should be interpreted as:</p>

<pre><code>           u'am'  u'dont'  u'hello'  u'to'  u'want'
u'am'      [[1      0         0        0       0]
u'dont'     [0      2         0        0       0]
u'hello'    [0      0         2        0       0]
u'to'       [0      0         0        1       0]
u'want'     [0      0         0        0       1]]
</code></pre>

<p>If you are expecting anything else, then you should add the details in the question.</p>
","3374996","","","2","1818","Vivek Kumar","2014-03-03 13:07:13","20443","4119","856","5581","49039015","49043122","2018-02-28 21:37:50","0","103","<p>I am trying to produce a bigram word co-occurrence matrix, indicating how many times one word follows another in a corpus.</p>

<p>As a test, I wrote the following (which I gathered from other SE questions):</p>

<pre><code>from sklearn.feature_extraction.text import CountVectorizer

test_sent = ['hello', 'i', 'am', 'hello', 'i', 'dont', 'want', 'to', 'i', 'dont']
bigram_vec = CountVectorizer(ngram_range=(1,2)) 
X = bigram_vec.fit_transform(test_sent)
Xc = (X.T * X)
print Xc
</code></pre>

<p>This should give the correct output. The matrix <code>Xc</code> is output like so:</p>

<pre><code>(0, 0)  1
(1, 1)  2
(2, 2)  2
(3, 3)  1
(4, 4)  1
</code></pre>

<p>I have no idea how to interpret this. I attempted to make it dense to help with my interpretation using <code>Xc.todense()</code>, which got this:</p>

<pre><code>[[1 0 0 0 0]
 [0 2 0 0 0]
 [0 0 2 0 0]
 [0 0 0 1 0]
 [0 0 0 0 1]]
</code></pre>

<p>Neither of these give the correct word co-occurrence matrix showing one how many times row follows column.</p>

<p>Could someone please explain how I can interpret/use the output? Why is it like that?</p>

<p><strong>Addition to question</strong></p>

<p>Here is another possible output with a different example using <code>ngram_range=(2,2)</code>:</p>

<pre><code>from sklearn.feature_extraction.text import CountVectorizer

test_sent = ['hello biggest awesome biggest biggest awesome today lively splendid awesome today']

bigram_vec = CountVectorizer(ngram_range=(2,2)) 

X = bigram_vec.fit_transform(test_sent)
print bigram_vec.get_feature_names()

Xc = (X.T * X)

print Xc
print ' '
print Xc.todense()

(4, 0)  1
(2, 0)  2
(0, 0)  1
(3, 0)  1
(1, 0)  2
(7, 0)  1
(5, 0)  1
(6, 0)  1
(4, 1)  2
(2, 1)  4
(0, 1)  2
(3, 1)  2
(1, 1)  4
(7, 1)  2
(5, 1)  2
(6, 1)  2
(4, 2)  2
(2, 2)  4
(0, 2)  2
(3, 2)  2
(1, 2)  4
(7, 2)  2
(5, 2)  2
(6, 2)  2
(4, 3)  1
:   :
(6, 4)  1
(4, 5)  1
(2, 5)  2
(0, 5)  1
(3, 5)  1
(1, 5)  2
(7, 5)  1
(5, 5)  1
(6, 5)  1
(4, 6)  1
(2, 6)  2
(0, 6)  1
(3, 6)  1
(1, 6)  2
(7, 6)  1
(5, 6)  1
(6, 6)  1
(4, 7)  1
(2, 7)  2
(0, 7)  1
(3, 7)  1
(1, 7)  2
(7, 7)  1
(5, 7)  1
(6, 7)  1

[[1 2 2 1 1 1 1 1]
 [2 4 4 2 2 2 2 2]
 [2 4 4 2 2 2 2 2]
 [1 2 2 1 1 1 1 1]
 [1 2 2 1 1 1 1 1]
 [1 2 2 1 1 1 1 1]
 [1 2 2 1 1 1 1 1]
 [1 2 2 1 1 1 1 1]]
</code></pre>

<p>This one seems to tokenize by bigrams, since calling <code>bigram_vec.get_feature_names()</code> gives </p>

<pre><code>[u'awesome biggest', u'awesome today', u'biggest awesome', u'biggest biggest', u'hello biggest', u'lively splendid', u'splendid awesome', u'today lively']
</code></pre>

<p>Some help interpretting this would be great. It's a symmetric matrix so I'm thinking it might just be number of occurrences?</p>
","7490953","7490953","2018-03-01 08:17:32","How does one interpret sklearn sparse matrix outputs?","<python><scikit-learn><sparse-matrix>","1","1","2724"
"49043172","2018-03-01 05:28:57","1","","<p>This <code>label_y</code> has continuous values. </p>

<p>But you have specified the scoring function as <code>chi2</code>. And according to the <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2"" rel=""nofollow noreferrer"">documentation of chi2</a>, this is only valid for classification tasks.</p>

<blockquote>
  <p>Compute chi-squared stats between each non-negative feature and class.</p>
</blockquote>

<p>For regression tasks, you can use the following:</p>

<ul>
<li><a href=""http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression"" rel=""nofollow noreferrer"">f_regression</a></li>
<li><a href=""http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression"" rel=""nofollow noreferrer"">mutual_info_regression</a></li>
</ul>
","3374996","","","0","971","Vivek Kumar","2014-03-03 13:07:13","20443","4119","856","5581","49025207","","2018-02-28 08:38:53","0","177","<pre><code>import pandas as pd
import numpy as np
from sklearn.feature_selection import SelectKBest ,chi2 

label_ds=pd.read_csv(""D:/intern/bll_beijing.csv"")  
array = label_ds.values

label_X  = array[:,1:]
label_y = array[:,0]

test = SelectKBest(score_func=chi2, k=4)
fit = test.fit(label_X, label_y)
</code></pre>

<p>I received this:</p>

<pre><code>Traceback (most recent call last):

    fit = test.fit(label_X, label_y)
  File ""C:\Users\TOSHIBA\AppData\Local\Programs\Python\Python35\lib\site-packages\sklearn\feature_selection\univariate_selection.py"", line 349, in fit
    score_func_ret = self.score_func(X, y)
  File ""C:\Users\TOSHIBA\AppData\Local\Programs\Python\Python35\lib\site-packages\sklearn\feature_selection\univariate_selection.py"", line 217, in chi2
    Y = LabelBinarizer().fit_transform(y)
  File ""C:\Users\TOSHIBA\AppData\Local\Programs\Python\Python35\lib\site-packages\sklearn\preprocessing\label.py"", line 307, in fit_transform
    return self.fit(y).transform(y)
  File ""C:\Users\TOSHIBA\AppData\Local\Programs\Python\Python35\lib\site-packages\sklearn\preprocessing\label.py"", line 284, in fit
    self.classes_ = unique_labels(y)
  File ""C:\Users\TOSHIBA\AppData\Local\Programs\Python\Python35\lib\site-packages\sklearn\utils\multiclass.py"", line 97, in unique_labels
    raise ValueError(""Unknown label type: %s"" % repr(ys))

ValueError: Unknown label type: (array([0.55, 0.84, 0.72, 0.54, 0.59, 0.77, 0.85, 1.03, 1.62, 3.04, 3.6 ]),)

[Finished in 3.4s]
</code></pre>

<p><code>[ 0.55, 0.84, 0.72, 0.54, 0.59, 0.77, 0.85, 1.03, 1.62, 3.04, 3.6 ]</code> is the first column of the csv document. </p>

<p>What's wrong with it?</p>
","9422768","","2018-02-28 09:18:25","SelectKBest Error: ValueError: Unknown label type: (array([ 0.55, 0.84, 0.72, 0.54, 0.59, 0.77, 0.85, 1.03, 1.62, 3.04, 3.6 ]),)","<python><scikit-learn>","1","2","1664"
"49043264","2018-03-01 05:39:40","1","","<p>I am not 100% sure but i went through one tutorial on Logistic Regression using Newton's method(<a href=""http://thelaziestprogrammer.com/sharrington/math-of-machine-learning/solving-logreg-newtons-method"" rel=""nofollow noreferrer"">http://thelaziestprogrammer.com/sharrington/math-of-machine-learning/solving-logreg-newtons-method</a>) and it's implementation of Newton's method is little different from yours.Actually there is one major difference. In Newton's method it's adding product of inv of hessian and gradient to theta whereas you are subtracting. I know about logistic regression normal way not using newton's method. Apart from that it seems that you are using loops in Cost function and Hessian which i think can be done with one statement in numpy than looping.</p>

<p>I would suggest refer to attached link which i gave as it has done all implementation in python numpy and there are no loops. Loops which you have created are impacting performance.</p>
","8756315","","","1","972","Sunnysinh Solanki","2017-10-11 03:50:15","448","51","19","4","49043061","","2018-03-01 05:17:28","0","234","<p>I am a machine learning noob attemping to implement regularized logistic regression via Newton's method.</p>

<p>The data have two features which are supposed to be expanded to 28 through finding all monomial terms of (u,v) up to degree 6  </p>

<p>My code converges to the correct solution of norm(theta)=0.9384 after around 500 or so iterations when it should only take around 15 for lambda = 10, though the exercise is based on Matlab instead of Python. Each cycle of the parameter update is also very slow with my code and I am not sure exactly why. If anyone could explain why my code takes so many iterations to converge and why each iteration is painfully slow I would be very grateful!</p>

<p>The data are taken from Andrew Ng's open course exercise 5. The problem information and data can be found here <a href=""http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&amp;doc=exercises/ex5/ex5.html"" rel=""nofollow noreferrer"">http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&amp;doc=exercises/ex5/ex5.html</a>
although I posted the data and my code below.</p>

<p>X data with two features</p>

<pre><code>0.051267,0.69956
-0.092742,0.68494
-0.21371,0.69225
-0.375,0.50219
-0.51325,0.46564
-0.52477,0.2098
-0.39804,0.034357
-0.30588,-0.19225
0.016705,-0.40424
0.13191,-0.51389
0.38537,-0.56506
0.52938,-0.5212
0.63882,-0.24342
0.73675,-0.18494
0.54666,0.48757
0.322,0.5826
0.16647,0.53874
-0.046659,0.81652
-0.17339,0.69956
-0.47869,0.63377
-0.60541,0.59722
-0.62846,0.33406
-0.59389,0.005117
-0.42108,-0.27266
-0.11578,-0.39693
0.20104,-0.60161
0.46601,-0.53582
0.67339,-0.53582
-0.13882,0.54605
-0.29435,0.77997
-0.26555,0.96272
-0.16187,0.8019
-0.17339,0.64839
-0.28283,0.47295
-0.36348,0.31213
-0.30012,0.027047
-0.23675,-0.21418
-0.06394,-0.18494
0.062788,-0.16301
0.22984,-0.41155
0.2932,-0.2288
0.48329,-0.18494
0.64459,-0.14108
0.46025,0.012427
0.6273,0.15863
0.57546,0.26827
0.72523,0.44371
0.22408,0.52412
0.44297,0.67032
0.322,0.69225
0.13767,0.57529
-0.0063364,0.39985
-0.092742,0.55336
-0.20795,0.35599
-0.20795,0.17325
-0.43836,0.21711
-0.21947,-0.016813
-0.13882,-0.27266
0.18376,0.93348
0.22408,0.77997
0.29896,0.61915
0.50634,0.75804
0.61578,0.7288
0.60426,0.59722
0.76555,0.50219
0.92684,0.3633
0.82316,0.27558
0.96141,0.085526
0.93836,0.012427
0.86348,-0.082602
0.89804,-0.20687
0.85196,-0.36769
0.82892,-0.5212
0.79435,-0.55775
0.59274,-0.7405
0.51786,-0.5943
0.46601,-0.41886
0.35081,-0.57968
0.28744,-0.76974
0.085829,-0.75512
0.14919,-0.57968
-0.13306,-0.4481
-0.40956,-0.41155
-0.39228,-0.25804
-0.74366,-0.25804
-0.69758,0.041667
-0.75518,0.2902
-0.69758,0.68494
-0.4038,0.70687
-0.38076,0.91886
-0.50749,0.90424
-0.54781,0.70687
0.10311,0.77997
0.057028,0.91886
-0.10426,0.99196
-0.081221,1.1089
0.28744,1.087
0.39689,0.82383
0.63882,0.88962
0.82316,0.66301
0.67339,0.64108
1.0709,0.10015
-0.046659,-0.57968
-0.23675,-0.63816
-0.15035,-0.36769
-0.49021,-0.3019
-0.46717,-0.13377
-0.28859,-0.060673
-0.61118,-0.067982
-0.66302,-0.21418
-0.59965,-0.41886
-0.72638,-0.082602
-0.83007,0.31213
-0.72062,0.53874
-0.59389,0.49488
-0.48445,0.99927
-0.0063364,0.99927
</code></pre>

<p>Y data</p>

<pre><code>1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
</code></pre>

<p>My code below:</p>

<pre><code>import pandas as pd
import numpy as np
import math

def sigmoid(theta, x):

    return 1/(1 + math.exp(-1*theta.T.dot(x)))


def cost_function(X, y, theta):

    s = 0
    for i in range(m):
        loss = -y[i]*np.log(sigmoid(theta, X[i])) - (1-y[i])*np.log(1-sigmoid(theta, X[i]))
        s += loss
    s /= m
    s += (lamb/(2*m))*sum(theta[j]**2 for j in range(1, 28)) 
    return s


def gradient(theta, X, y):
    # add regularization terms
    add_column = theta * (lamb/m)
    add_column[0] = 0
    a = sum((sigmoid(theta, X[i]) - y[i])*X[i] + add_column for i in range(m))/m
    return a


def hessian(theta, X, reg_matrix):

    matrix = []
    for i in range(28):
        row = []
        for j in range(28):
            cell = sum(sigmoid(theta, X[k])*(1-sigmoid(theta, X[k]))*X[k][i]*X[k][j] for k in range(m))
            row.append(cell)
        matrix.append(row)

    H = np.array(matrix)
    H = np.add(H, reg_matrix)
    return H


def newtons_method(theta, iterations):

    for i in range(iterations):
        g = gradient(theta, X, y)
        H = hessian(theta, X, reg_matrix)
        theta = theta - np.linalg.inv(H).dot(g)
        cost = cost_function(X,y,theta)
        print(cost)    
    return theta

def map_feature(u, v): # expand features according to problem instructions

    new_row = [] 
    new_row.append(1)
    new_row.append(u)
    new_row.append(v)
    new_row.append(u**2)
    new_row.append(u*v)
    new_row.append(v**2)
    new_row.append(u**3)
    new_row.append(u**2*v)
    new_row.append(u*v**2)
    new_row.append(v**3)
    new_row.append(u**4)
    new_row.append(u**3*v)
    new_row.append(u*v**3)
    new_row.append(v**4)
    new_row.append(u**2*v**2)
    new_row.append(u**5)
    new_row.append(u**4*v)
    new_row.append(u*v**4)
    new_row.append(v**5)
    new_row.append(u**2*v**3)
    new_row.append(u**3*v**2)
    new_row.append(u**6)
    new_row.append(u**5*v)
    new_row.append(u*v**5)
    new_row.append(v**6)
    new_row.append(u**4*v**2)
    new_row.append(u**2*v**4)
    new_row.append(u**3*v**3)
    return np.array(new_row)

with open('ex5Logx.dat', 'r') as f:
    array = []
    for line in f.readlines():
        array.append(line.strip().split(','))

    for a in array:

        a[0], a[1] = float(a[0]), float(a[1].strip())

    xdata= np.array(array)

with open('ex5Logy.dat', 'r') as f:
    array = []
    for line in f.readlines():
        array.append(line.strip())

    for i in range(len(array)):
        array[i] = float(array[i])
    ydata= np.array(array)


X_df = pd.DataFrame(xdata, columns=['score1', 'score2'])

y_df = pd.DataFrame(ydata, columns=['acceptence'])

m = len(y_df)

iterations = 15

ones = np.ones((m,1)) # intercept term in first column
X = np.array(X_df)
X = np.append(ones, X, axis=1)
y = np.array(y_df).flatten()

new_X = [] # prepare new array for expanded features
for i in range(m):
    new_row = map_feature(X[i][1], X[i][2])

    new_X.append(new_row)

X = np.array(new_X)

theta = np.array([0 for i in range(28)]) # initialize parameters to 0

lamb = 10 # lambda constant for regularization

reg_matrix = np.zeros((28,28),dtype=int) # n+1*n+1 regularization matrix 
np.fill_diagonal(reg_matrix, 1)
reg_matrix[0] = 0
reg_matrix = (lamb/m)*reg_matrix

theta = newtons_method(theta, iterations)
print(np.linalg.norm(theta))
</code></pre>
","8390325","","","Inefficient Regularized Logistic Regression with Numpy","<python><numpy><machine-learning><classification><regression>","1","2","6826"
"49043299","2018-03-01 05:43:13","1","","<p>This should work</p>

<p><code>matplotlib.pyplot.yticks(np.arange(start, stop+1, step))</code></p>
","5337505","","","0","102","Siladittya","2015-09-15 10:19:18","415","125","154","24","49043162","49043818","2018-03-01 05:28:11","0","37","<p>Let's say if I have <code>Height = [3, 12, 5, 18, 45]</code> and plot my graph then the yaxis will have ticks starting 0 up to 45 with an interval of 5, which means 0, 5, 10, 15, 20 and so on up to 45. Is there a way to define the interval gap (or the step). For example I want the yaxis to be 0, 15, 30, 45 for the same data set.</p>
","2497039","","","Custom Yaxis plot in matplotlib python","<python><matplotlib>","2","1","338"
"49043337","2018-03-01 05:46:52","2","","<p>There are multiple issues here:</p>

<p>1) TruncatedSVD is a <a href=""http://scikit-learn.org/stable/modules/decomposition.html#lsa"" rel=""nofollow noreferrer"">dimensionality reduction algorithm</a>. So I am not understanding how do you intend to calculate the f1_score.</p>

<p>2) <a href=""https://en.wikipedia.org/wiki/F1_score"" rel=""nofollow noreferrer"">f1_score</a> is traditionally used on classification tasks, and have a formula:</p>

<pre><code>f1 = 2*recall*precision
    --------------------
     recall + precision
</code></pre>

<p>where recall and precision are defined in terms of True Positives, True Negative, False Positive, False Negative which in turn need the true classes and predicted classes to be calculated.</p>

<p>3) cv = 1 makes no sense. In <code>cross_val_score</code>, cv denotes the number of folds. So cv = 5 denotes that in each fold, 80% data will be in training and 20% in testing. So how do you intend to test the data without the true labels of ground truth of some sort.</p>
","3374996","","","0","1016","Vivek Kumar","2014-03-03 13:07:13","20443","4119","856","5581","49037567","49043337","2018-02-28 19:56:36","0","189","<p>I am having an issue where I am trying to create a recommender system for a local newspaper (as a school project), but I am running into trouble when I am trying to use the cross_validate function from the model_selection library.</p>

<p>I am trying to use SVD and obtain the f1 score. But I am a bit confused. So this is unsupervised learning, and I do not have a test set, so I want to use KFolding for the cross validation. I believe the number of folds for this is denoted by the ""cv"" parameter in the cross_validate function. Is this correct?</p>

<p>The problem arise when I try to run the code, as I get the following stack trace: <a href=""https://hastebin.com/kidoqaquci.tex"" rel=""nofollow noreferrer"">https://hastebin.com/kidoqaquci.tex</a></p>

<p>I am not passing anything to the ""y"" parameter of the cross_validate function, but is this wrong? Is not this where the test set should go? And as I said, I do not have any test set as this is unsupervised. I have looked at the example in chapter 3.1.1.1 here:  <a href=""http://scikit-learn.org/stable/modules/cross_validation.html"" rel=""nofollow noreferrer"">http://scikit-learn.org/stable/modules/cross_validation.html</a></p>

<p>And it looks like they are passing in a ""target"" for the dataset in the cross_validate function. But why are they passing both a target set AND the cv parameter? Does not a cv value above 1 indicate that kfolding should be used and that the fold left out is to be used as the target (test) set?</p>

<p>Or am I completely misunderstanding something? Why am I getting the ""missing argument"" error in the stack trace?</p>

<p>This is the code that is failing:</p>

<pre><code>from sklearn.model_selection import cross_val_score as cv
from sklearn.decomposition.truncated_svd import TruncatedSVD
import pandas as pd

# keywords_data_filename = 'keywords_data.txt'
active_data_filename = 'active_time_data.txt'

header = ['user_id', 'item_id', 'rating']
# keywords_data = pd.read_csv(keywords_data_filename, sep='*', names=header, engine='python')
active_time_data = pd.read_csv(active_data_filename, sep='*', names=header, engine='python')


# Number of users in current set
print('Number of unique users in current data-set', active_time_data.user_id.unique().shape[0])
print('Number of unique articles in current data-set', active_time_data.item_id.unique().shape[0])

# SVD allows us to look at our input matrix as a product of three smaller matrices; U, Z and V.
# In short this will help us discover concepts from the original input matrix,
# (subsets of users that like subsets of items)
# Note that use of SVD is not strictly restricted to user-item matrices
# https://www.youtube.com/watch?v=P5mlg91as1c

algorithm = TruncatedSVD()

# Finally we run our cross validation in n folds, where n is denoted by the cv parameter.
# Verbose can be adjusted by an integer to determine level of verbosity.
# We pass in our SVD algorithm as the estimator used to fit the data.
# X is our data set that we want to fit.
# Since our estimator (The SVD algorithm), We must either define our own estimator, or we can simply define how it
# score the fitting.
# Since we currently evaluate the enjoyment of our users per article highly binary, (Please see the rate_article fn in
# the filter script), we can easily decide our precision and recall based on whether or not our prediction exactly
# matches the binary rating field in the test set.
# This, the F1 scoring metric seems an intuitive choice for measuring our success, as it provides a balanced score
# based on the two.

cv(estimator=algorithm, X=active_time_data, scoring='f1', cv=5, verbose=True)
</code></pre>
","4308554","","","Recommender System using SciKit-Learn's cross_validate, missing 1 required positional argument: 'y_true'","<python><scikit-learn>","1","0","3655"
"49043343","2018-03-01 05:47:14","2","","<p>It is not supposed to work like that, <strong>intents are triggered based on what user types</strong>. For example, you can make an intent <code>BestFootballer</code> and it will be triggered on utterance <code>who is the best footballer</code>.</p>

<p>Now, once the intent is triggered you can apply some logic to dynamically create a response.</p>

<pre><code>def build_response(message):
    return {
        ""dialogAction"":{
            ""type"":""Close"",
            ""fulfillmentState"":""Fulfilled"",
            ""message"":{
                ""contentType"":""PlainText"",
                ""content"":message
            }
        }
    }

def perform_action(intent_request):
    source = intent_request['invocationSource']
    output_session_attributes = intent_request['sessionAttributes'] if intent_request['sessionAttributes'] is not None else {}
    if source == 'FulfillmentCodeHook':
        a = 100
        if a &lt; 90:
            return build_response('Ronaldo is the best Footballer')
        else:
            return build_response('Messi is the best Footballer')

def dispatch(intent_request):
    intent_name = intent_request['currentIntent']['name']
    if intent_name == 'BestFootballer':
        return perform_action(intent_request)
    raise Exception('Intent with name ' + intent_name + ' not supported')

def lambda_handler(event, context):
    return dispatch(event)
</code></pre>

<p>Hope it helps.</p>
","3196845","3196845","2018-03-01 10:27:55","4","1424","sid8491","2014-01-15 05:56:19","4483","710","717","490","49033714","49043343","2018-02-28 16:00:41","1","503","<p>I am newbie in AWS Arena. This is my 2nd question regarding AWS Lambda function and AWS LEX. I want to write a lambda function to trigger 2 different intents based on the value of something without any user Utterance. For example </p>

<p>if a >= 90.....Intent-1 will work and say ""Messi is the best Footballer""  and
if a &lt; 90......Intent-2 will work and say ""Ronaldo is the best Footballer""</p>
","8899060","8899060","2018-03-01 10:26:26","Write a conditional AWS Lambda Function for AWS LEX","<javascript><python><amazon-web-services><aws-lambda><amazon-lex>","1","3","402"
"49043377","2018-03-01 05:50:21","3","","<p>just use <code>hist2d[0][r, g]</code>:</p>

<pre><code>import numpy as np

r, g, b = np.random.randint(0, 256, size=(3, 500, 500)).astype(np.uint8)
hist2d = np.histogram2d(r.ravel(), g.ravel(), bins=256, range=[[0, 256], [0, 256]])
hist2d[0][r, g]
</code></pre>
","772649","","","1","265","HYRY","2011-05-27 07:38:27","71257","2164","76","1","49043070","49043377","2018-03-01 05:18:52","1","298","<p>To be more specific, here is the exact requirement. I'm not sure how to word the question.
I have an image, of size say <code>(500,500)</code>. I extract only r and g channels</p>

<pre><code>r = image[:, :, 0]
g = image[:, :, 1]
</code></pre>

<p>Then, I compute the 2D histogram of r and g</p>

<pre><code>hist2d = np.histogram2d(r, g, bins=256, range=[(255,255),(255,255)])
</code></pre>

<p>Now, <code>hist2d[0].shape</code> is <code>(256, 256)</code> since It corresponds to every pair of 256x256 colors. Fine</p>

<p>The main requirement is, in an separate image, called <code>result</code> with same shape as original image i.e. <code>(500, 500)</code>, I want to populate each element of <code>result</code> with the value of 2d histogram of <code>r</code> and <code>g</code> channels</p>

<p>For example, if <code>r[200,200]</code> is 23 and <code>g[200, 200]</code> is 26, I want to place <code>result[200, 200] = hist2d[0][23, 26]</code></p>

<p>The naive method for doing this is, simple python loop.</p>

<pre><code>for i in range(r.shape[0]):
    for j in range(r.shape[1]):
        result[i, j] = hist2d[0][r[i, j], g[i, j]]
</code></pre>

<p>But for a large image, this takes a significant time to compute. Is there a numpy way of doing this?</p>

<p>Thanks</p>
","6304205","","","How to get 2D histogram map of an image?","<python><numpy><opencv><scipy>","1","0","1281"
"49043423","2018-03-01 05:54:24","2","","<p>Assuming first list is already sorted, you can do something like this to average the numbers in other lists which correspond to same numbers in list1:</p>

<pre><code>list1=[26, 26, 26, 27, 27, 27, 27, 28, 28, 100, 100, 100]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10, 90, 10,  -1]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 14, -1, -1, -1]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10, 20, 20, 20]

# Transformed Lists
list1_new = []
list2_new = []
list3_new = []
list4_new = []

def populate_new_list():
    list1_new.append(list1[start_index])
    # If using python 3, we don't need to convert int to float before division
    list2_new.append( float(sum(list2[start_index:end_index+1])) / float((end_index-start_index+1)) )
    list3_new.append( float(sum(list3[start_index:end_index+1])) / float((end_index-start_index+1)) )
    list4_new.append( float(sum(list4[start_index:end_index+1])) / float((end_index-start_index+1)) )

start_index = 0 # Start index of same number in first list
end_index = 0 # End index of same number in first list
previous_item = list1[0] # Initialize previous_item with first item in the list

# Iterate through the first list and store start and end index of duplicate numbers, then use populate_new_list to average those numbers.
for index, item in enumerate(list1):
    if previous_item == item:
        end_index = index
    else:
        populate_new_list()
        start_index = index
        end_index = index
        previous_item = list1[index]

# Call populate_new_list once more after iterating through list1 to populate lists with last same number in list1
populate_new_list()

print(list1_new) # [26, 27, 28, 100]
print(list2_new) # [2.3333333333333335, 15.5, -7.0, 33.0]
print(list3_new) # [6.666666666666667, 7.25, 13.5, -1.0]
print(list4_new) # [60.0, 45.0, 15.0, 20.0]
</code></pre>
","893039","893039","2018-03-01 06:28:56","2","1830","Harshveer Singh","2011-08-13 12:32:31","1804","221","66","4","49043153","","2018-03-01 05:27:13","1","99","<p>I have four lists with same <code>len</code></p>

<pre><code>list1=[26, 26, 26, 27, 27, 27, 27, 28, 28, ..., 100, 100, 100]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10,...., 90, 10,  -1]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 14, ..., -1, -1, -1]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10, ...., 20, 20, 20]
</code></pre>

<p>I have to average out the values in <code>list2, 3, and 4</code>, whom share the same values in <code>list1</code>. What I mean by that is that for example, for <code>list2</code>, I want <code>(-1+-2+10)/3=2.33</code> because the corresponding elements of <code>-1, -2, and 10</code> in list1 is <code>26</code>. <code>(14+13+15+20)/4=15.5 (four corresponding 27s in list1).</code> Essentially, the same idea applies to <code>list3 and list4</code> as well. For <code>list3</code>, I want <code>(11+12+-3)/3=6.67</code></p>

<p>Eventually, after transformation and averaging out, 4 lists are:</p>

<pre><code>list1=[26, 27, 28, ...., 100]
list2=[2.33, 15.5, -7, ..., 33]
list3=[6.667, 7.25, 13.5,.., -1]
list4=[60, 45, 15, ..., 20]
</code></pre>

<p>I'm thinking about something like this. There is definitely a more elegant way to do this. </p>

<pre><code>for x, y, z, q in zip(list1, list2, list3, list4):
    if x==previous x:
       #same x, add y, z, q, to separate temp lists (when new x appears, average out)
    else:
       #new x, average out y, z, q (empty temp lists)   
</code></pre>
","6000353","6000353","2018-03-01 05:56:02","python average out columns in list","<python><list><mean>","7","8","1427"
"49043424","2018-03-01 05:54:28","1","","<p>The path is incomplete at <code>&lt;Directory /home/user/mycode/mysite/&gt;</code>. It should be <code>&lt;Directory /home/user/mycode/mysite/mysite&gt;</code> (note that <code>mysite</code> should occur twice).</p>

<hr>

<p>Anyway, from an old project, here's what my apache config file looks like:</p>

<pre><code>WSGIScriptAlias / /home/user/mycode/mysite/mysite/wsgi.py

WSGIPythonPath /home/user/mycode/mysite/mysite

&lt;Directory /home/user/mycode/mysite/mysite&gt;
    &lt;Files wsgi.py&gt;
        Order deny,allow
        Require all granted
    &lt;/Files&gt;
&lt;/Directory&gt;
</code></pre>
","1925257","","","3","608","xyres","2012-11-19 15:17:30","11768","2386","1247","376","49043325","","2018-03-01 05:45:39","0","73","<p>I'm running Apache 2.4.18 on Ubuntu 16.04. I've set up a virtual server with the following settings. The virtual host has been registered with a2ensite and appears to be being accessed ok.</p>

<pre><code>&lt;VirtualHost *:80&gt;
    ServerName www.factsfromfigures.com

    WSGIScriptAlias / /home/user/mycode/mysite/mysite/wsgi.py

    &lt;Directory /home/user/mycode/mysite/&gt;
    &lt;Files wsgi.py&gt;
        Require all granted
    &lt;/Files&gt;
    &lt;/Directory&gt;

&lt;/VirtualHost&gt;
</code></pre>

<p>When it runs I get the following error in the Apache log.</p>

<pre><code>[Thu Mar 01 17:35:00.968878 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552] mod_wsgi (pid=12278): Target WSGI script '/home/user/mycode/mysite/mysite/wsgi.py' cannot be loaded as Python module.
[Thu Mar 01 17:35:00.968895 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552] mod_wsgi (pid=12278): Exception occurred processing WSGI script '/home/user/mycode/mysite/mysite/wsgi.py'.
[Thu Mar 01 17:35:00.968923 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552] Traceback (most recent call last):
[Thu Mar 01 17:35:00.968933 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]   File ""/home/user/mycode/mysite/mysite/wsgi.py"", line 18, in &lt;module&gt;
[Thu Mar 01 17:35:00.968964 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]     application = get_wsgi_application()
[Thu Mar 01 17:35:00.968971 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]   File ""/usr/lib/python2.7/dist-packages/django/core/wsgi.py"", line 14, in get_wsgi_application
[Thu Mar 01 17:35:00.968988 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]     django.setup()
[Thu Mar 01 17:35:00.968992 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]   File ""/usr/lib/python2.7/dist-packages/django/__init__.py"", line 17, in setup
[Thu Mar 01 17:35:00.969007 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]     configure_logging(settings.LOGGING_CONFIG, settings.LOGGING)
[Thu Mar 01 17:35:00.969024 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]   File ""/usr/lib/python2.7/dist-packages/django/conf/__init__.py"", line 48, in __getattr__
[Thu Mar 01 17:35:00.969057 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]     self._setup(name)
[Thu Mar 01 17:35:00.969062 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]   File ""/usr/lib/python2.7/dist-packages/django/conf/__init__.py"", line 44, in _setup
[Thu Mar 01 17:35:00.969075 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]     self._wrapped = Settings(settings_module)
[Thu Mar 01 17:35:00.969079 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]   File ""/usr/lib/python2.7/dist-packages/django/conf/__init__.py"", line 92, in __init__
[Thu Mar 01 17:35:00.969084 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]     mod = importlib.import_module(self.SETTINGS_MODULE)
[Thu Mar 01 17:35:00.969087 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]   File ""/usr/lib/python2.7/importlib/__init__.py"", line 37, in import_module
[Thu Mar 01 17:35:00.969103 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552]     __import__(name)
[Thu Mar 01 17:35:00.969113 2018] [wsgi:error] [pid 12278] [client 192.168.1.68:61552] ImportError: No module named mysite.settings
</code></pre>

<p>The mysite settings.py file is at /home/user/mycode/mysite/mysite/settings.py</p>

<p>The wsgi.py file is at /home/user/mycode/mysite/mysite/wsgi.py</p>

<p>I'm not sure what version of python the server is accessing as I get these warning messages in the log: (I've no idea why it reports 2 different version)</p>

<pre><code>[Thu Mar 01 18:32:03.219991 2018] [wsgi:warn] [pid 13753] mod_wsgi: Compiled for Python/2.7.11.
[Thu Mar 01 18:32:03.220008 2018] [wsgi:warn] [pid 13753] mod_wsgi: Runtime using Python/2.7.12.
</code></pre>

<p>My history on this is that I've taken a very good Python and Django course. I have 40 years programming experience so don't find coding a problem. I'm relatively new to Linux/Ubuntu and have spent over a week trying to get as little as a 'hello world' appearing on my browser. The documentation is not clear. For example, the official Django documentation recommends putting various settings in httpd.conf but there isn't one. I've tried just about every suggestion on SO into practice but nothing seems to work.</p>

<p>Now I guess this might be bad etiquette but I'm getting desperate and on the verge of giving up on Django. I would really like someone who knows their way around to help me out. I can reward with a suitable number of Amazon vouchers or goodies. I have RealVNC installed so you would be able to log in and have a look as there is nothing sensitive on the server yet. The truth of the matter is that I'm a developer and find the system admin/configuration side of things to be difficult. Thanks for your attention and hopefully you'll help me out.</p>
","6542742","","","Django on Apache2 (Ubuntu 16.04) reports 'No module named mysite.settings'","<python><django><apache><ubuntu>","1","3","4958"
"49043431","2018-03-01 05:55:20","0","","<p>You need to return the file.</p>

<pre><code>response = app.make_response(file)
response.headers[""Content-Disposition""] = ""attachment; filename=yourfile.csv""
return response
</code></pre>
","6809571","","","1","191","John H","2016-09-08 14:00:36","1269","236","108","12","49043362","","2018-03-01 05:49:06","-1","266","<p>How to process the file which is uploaded by giving the file path to the python script and download the processed file ?<br>
<strong>The code</strong>  </p>

<pre><code>@app.route(""/upload"", methods=['POST'])
def upload():
    target = os.path.join(APP__ROOT, 'data/')
    print(target)
    if not os.path.isdir(target):
        os.mkdir(target)
    for file in request.files.getlist(""file""):
        filename = file.filename
        print(filename)
        destination = ""/"".join([target, filename])
        print(destination)
        file.save(destination)
    return render_template(""downloads.html"")
</code></pre>
","9228173","4365969","2018-03-01 05:57:51","How to process an uploaded csv file in python script using flask","<python><flask><pycharm>","1","0","621"
"49043479","2018-03-01 05:59:55","0","","<pre><code> ""INSERT into dbo.test_tbl VALUES (3,'ITS','Paris', 10, 'Laptop', %)"" % (timestamp)
</code></pre>

<p>I think you have to add <code>s</code> after %</p>

<pre><code>""INSERT into dbo.test_tbl VALUES (3,'ITS','Paris', 10, 'Laptop', '%s')"" % (timestamp)
</code></pre>
","8572897","8572897","2018-03-01 06:12:13","11","276","Jay Shankar Gupta","2017-09-07 06:49:13","5609","610","4","15","49043373","49043479","2018-03-01 05:49:51","-3","314","<p>I am trying to insert data into a table that has already been created. The code does not throw any error but simply does not writes into the DB.</p>

<p>I think there is problem with the timestamp, may be.</p>

<p>If any of you could please have a look at the code and provide some pointers, that would be great.
TIA!!</p>

<p>Cheers</p>

<pre><code>import pyodbc
import datetime
import time

def connect_db():
    db = pyodbc.connect(""Driver={SQL Server Native Client 11.0};""
                      ""Server=xxxxx\SQLEXPRESS;""
                      ""Database=test;""
                      ""Trusted_Connection=yes;""
                      ""uid=xxx;""
                      ""password=xyz"")
    cursor = db.cursor()



    ts = time.time()
    timestamp = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')
    sql = ""INSERT into dbo.test_tbl VALUES (3,'ITS','Paris', 10, 'Laptop', %)"" % (timestamp)
    cursor.execute(sql)
    db.commit()
    cursor.close()
    db.close()
</code></pre>
","1199246","1199246","2018-03-01 05:53:09","SQL insert into MS Server DB using Python not working","<python><sql><sql-server>","1","3","999"
"49043483","2018-03-01 06:00:18","0","","<p>As per inputs from @Ami Hollander and @DeepSpace I have figured out that put request is not supported. Trying with get request, I am able to get the response     </p>

<pre><code>Code :
      ips = getipaddress()   # returns device ip:192.168.72.31
      url = ""https://%s/UDW/Command?entry=eprint.register"" % ips  
      requests.get(url=URL,verify=False)

Output :
        {
          ""state"": 200,
          ""eprint_reg_state"": ""registering""
        }
</code></pre>
","6120132","6120132","2018-03-01 06:13:59","0","472","Sum","2016-03-27 09:31:37","71","22","7","0","49028418","","2018-02-28 11:23:20","0","68","<p>I am trying to send parameterized url in put request using python.
One of my function ""getipaddress()"" is returning the device ip address as 192.168.72.31</p>

<p>Code:</p>

<pre><code>import requests
ips= getipaddress()
URL = ""https://%s/UDW/Command?entry=eprint.register"" % ips
r = requests.put(url=URL,data=data, verify=False)
print r.status_code
</code></pre>

<p>Getting error : 405 error (Method Not Allowed response status code).</p>
","6120132","1000551","2018-02-28 11:25:29","how to parametrize url in put requests using python","<python><python-2.7><rest><python-requests>","2","2","444"
"49043489","2018-03-01 06:01:11","1","","<p>Use collections.OrderedDict would be better:</p>

<pre><code>list1=[26, 26, 26, 27, 27, 27, 27, 28, 28, 100, 100, 100]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10, 90, 10,  -1]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 14, -1, -1, -1]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10, 20, 20, 20]

from collections import OrderedDict
def refine_list(lst):
    d = OrderedDict()
    for index, value in enumerate(lst):
        d.setdefault(list1[index], []).append(value)
    result = []
    for value in d.values():
        result.append(sum(value) / len(value))
    return result

print(list(set(list1)))
for lst in [list2, list3, list4]:
    print(refine_list(lst))


[100, 26, 27, 28]
[2.3333333333333335, 15.5, -7.0, 33.0]
[6.666666666666667, 7.25, 13.5, -1.0]
[60.0, 45.0, 15.0, 20.0]
</code></pre>
","6931919","","","0","796","scriptboy","2016-10-06 12:31:07","507","127","114","10","49043153","","2018-03-01 05:27:13","1","99","<p>I have four lists with same <code>len</code></p>

<pre><code>list1=[26, 26, 26, 27, 27, 27, 27, 28, 28, ..., 100, 100, 100]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10,...., 90, 10,  -1]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 14, ..., -1, -1, -1]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10, ...., 20, 20, 20]
</code></pre>

<p>I have to average out the values in <code>list2, 3, and 4</code>, whom share the same values in <code>list1</code>. What I mean by that is that for example, for <code>list2</code>, I want <code>(-1+-2+10)/3=2.33</code> because the corresponding elements of <code>-1, -2, and 10</code> in list1 is <code>26</code>. <code>(14+13+15+20)/4=15.5 (four corresponding 27s in list1).</code> Essentially, the same idea applies to <code>list3 and list4</code> as well. For <code>list3</code>, I want <code>(11+12+-3)/3=6.67</code></p>

<p>Eventually, after transformation and averaging out, 4 lists are:</p>

<pre><code>list1=[26, 27, 28, ...., 100]
list2=[2.33, 15.5, -7, ..., 33]
list3=[6.667, 7.25, 13.5,.., -1]
list4=[60, 45, 15, ..., 20]
</code></pre>

<p>I'm thinking about something like this. There is definitely a more elegant way to do this. </p>

<pre><code>for x, y, z, q in zip(list1, list2, list3, list4):
    if x==previous x:
       #same x, add y, z, q, to separate temp lists (when new x appears, average out)
    else:
       #new x, average out y, z, q (empty temp lists)   
</code></pre>
","6000353","6000353","2018-03-01 05:56:02","python average out columns in list","<python><list><mean>","7","8","1427"
"49043511","2018-03-01 06:03:20","1","","<p>This will work - </p>

<pre><code>list1=[26, 26, 26, 27, 27, 27, 27, 28, 28]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 1]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10]

a={}
b={}
c={}
for i in range(len(list1)):
    if a.get(list1[i]) is None:
        a[list1[i]] = [list2[i]]
        b[list1[i]] = [list3[i]]
        c[list1[i]] = [list4[i]]
    else:
        a[list1[i]] += [list2[i]]
        b[list1[i]] += [list3[i]]
        c[list1[i]] += [list4[i]]
a = { i: (sum(l) / len(l)) for i,l in a.items()}
b = { i: (sum(l) / len(l)) for i,l in b.items()}
c = { i: (sum(l) / len(l)) for i,l in c.items()}
list1 = list(a.keys())
list2 = list(a.values())
list3 = list(b.values())
list4 = list(c.values())
print(list1, list2, list3, list4)
</code></pre>

<p><strong>Output</strong></p>

<pre><code>[26, 27, 28] [2.3333333333333335, 15.5, -7.0] [6.666666666666667, 7.25, 7.0] [60.0, 45.0, 15.0]
</code></pre>

<p><strong>Explanation</strong></p>

<p>Let's review the sections (I will exaplain for one of the cases, rest is good old copy paste :)) - </p>

<p>Declare 3 <code>dict</code> - </p>

<pre><code>a={}
b={}
c={}
</code></pre>

<p>Here, an assumption is all lists have the same length. for every element in the list, you are creating a <code>dict</code> of values. For example, for element <code>26</code> in <code>list1</code>, the output after this operation will be <code>{26: [-1, -2, 10], 27: [14, 13, 15, 20], 28: [-4, -10]}</code></p>

<pre><code>for i in range(len(list1)):
    if a.get(list1[i]) is None:
        a[list1[i]] = [list2[i]]
    else:
        a[list1[i]] += [list2[i]]
</code></pre>

<p>Once this is complete, you just average out the list for every <code>key</code> in the <code>dict</code> - </p>

<pre><code>a = { i: (sum(l) / len(l)) for i,l in a.items()}
</code></pre>
","4098013","","","0","1837","Vivek Kalyanarangan","2014-10-01 08:30:07","5481","696","528","44","49043153","","2018-03-01 05:27:13","1","99","<p>I have four lists with same <code>len</code></p>

<pre><code>list1=[26, 26, 26, 27, 27, 27, 27, 28, 28, ..., 100, 100, 100]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10,...., 90, 10,  -1]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 14, ..., -1, -1, -1]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10, ...., 20, 20, 20]
</code></pre>

<p>I have to average out the values in <code>list2, 3, and 4</code>, whom share the same values in <code>list1</code>. What I mean by that is that for example, for <code>list2</code>, I want <code>(-1+-2+10)/3=2.33</code> because the corresponding elements of <code>-1, -2, and 10</code> in list1 is <code>26</code>. <code>(14+13+15+20)/4=15.5 (four corresponding 27s in list1).</code> Essentially, the same idea applies to <code>list3 and list4</code> as well. For <code>list3</code>, I want <code>(11+12+-3)/3=6.67</code></p>

<p>Eventually, after transformation and averaging out, 4 lists are:</p>

<pre><code>list1=[26, 27, 28, ...., 100]
list2=[2.33, 15.5, -7, ..., 33]
list3=[6.667, 7.25, 13.5,.., -1]
list4=[60, 45, 15, ..., 20]
</code></pre>

<p>I'm thinking about something like this. There is definitely a more elegant way to do this. </p>

<pre><code>for x, y, z, q in zip(list1, list2, list3, list4):
    if x==previous x:
       #same x, add y, z, q, to separate temp lists (when new x appears, average out)
    else:
       #new x, average out y, z, q (empty temp lists)   
</code></pre>
","6000353","6000353","2018-03-01 05:56:02","python average out columns in list","<python><list><mean>","7","8","1427"
"49043549","2018-03-01 06:07:01","1","","<p>You can get a unique set of all values in your list1 and iterate through them. Then you can find the values at the same index in list2-4. Get their respective mean value and append to a new temporary list.    </p>

<pre><code>from copy import deepcopy

list1=[26, 26, 26, 27, 27, 27, 27, 28, 28]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 14]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10]

temp_list2 = []
temp_list3 = []
temp_list4 = []

for val in set(list1):
    # List 2
    total = [list2[ix] for ix, i in enumerate(list1) if i == val]
    mean = sum(total) / len(total)
    temp_list2.append(mean)

    # List 3
    total = [list3[ix] for ix, i in enumerate(list1) if i == val]
    mean = sum(total) / len(total)
    temp_list3.append(mean)

    # List 4
    total = [list4[ix] for ix, i in enumerate(list1) if i == val]
    mean = sum(total) / len(total)
    temp_list4.append(mean)

list1 = list(set(list1))
list2 = deepcopy(temp_list2)
list3 = deepcopy(temp_list3)
list4 = deepcopy(temp_list4)

print(list1)
print(list2)
print(list3)
print(list4)
</code></pre>

<blockquote>
  <p>[26, 27, 28]  [2.3333333333333335, 15.5, -7.0]  [6.666666666666667,
  7.25, 13.5]  [60.0, 45.0, 15.0]</p>
</blockquote>
","1923086","","","0","1249","JahKnows","2012-12-22 05:54:50","1732","193","68","21","49043153","","2018-03-01 05:27:13","1","99","<p>I have four lists with same <code>len</code></p>

<pre><code>list1=[26, 26, 26, 27, 27, 27, 27, 28, 28, ..., 100, 100, 100]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10,...., 90, 10,  -1]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 14, ..., -1, -1, -1]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10, ...., 20, 20, 20]
</code></pre>

<p>I have to average out the values in <code>list2, 3, and 4</code>, whom share the same values in <code>list1</code>. What I mean by that is that for example, for <code>list2</code>, I want <code>(-1+-2+10)/3=2.33</code> because the corresponding elements of <code>-1, -2, and 10</code> in list1 is <code>26</code>. <code>(14+13+15+20)/4=15.5 (four corresponding 27s in list1).</code> Essentially, the same idea applies to <code>list3 and list4</code> as well. For <code>list3</code>, I want <code>(11+12+-3)/3=6.67</code></p>

<p>Eventually, after transformation and averaging out, 4 lists are:</p>

<pre><code>list1=[26, 27, 28, ...., 100]
list2=[2.33, 15.5, -7, ..., 33]
list3=[6.667, 7.25, 13.5,.., -1]
list4=[60, 45, 15, ..., 20]
</code></pre>

<p>I'm thinking about something like this. There is definitely a more elegant way to do this. </p>

<pre><code>for x, y, z, q in zip(list1, list2, list3, list4):
    if x==previous x:
       #same x, add y, z, q, to separate temp lists (when new x appears, average out)
    else:
       #new x, average out y, z, q (empty temp lists)   
</code></pre>
","6000353","6000353","2018-03-01 05:56:02","python average out columns in list","<python><list><mean>","7","8","1427"
"49043552","2018-03-01 06:07:13","1","","<p>There is one assumption in my answer that all list are of same length. But this code will work even if the list1 is shuffled.</p>

<pre><code>l1 = [26, 26, 26, 27, 27, 28, 28, 28, 29, 29, 29, 29]
l2 = [-1, -2, 10, 14, 13, 15, 20, -4, -10, 90, 10,  -1]
l3=[11, 12, -3, -4, 10, 11, 12, 13, 14, -1, -1, -1]
l4=[50, 60, 70, 90, 30, 40, 20, 20, 10, 20, 20, 20]

temp_list_2 = []
temp_list_3 = []
temp_list_4 = []
count = 0

#set() finds all unique elements
for i in set(l1):
    i_count = l1.count(i) # counts number of elements in list 1
    temp2 = l2[count:count+i_count]
    temp3 = l3[count:count+i_count]
    temp4 = l4[count:count+i_count]

    count = count + i_count
    avg2 = sum(temp2)/len(temp2)
    avg3 = sum(temp3)/len(temp3)
    avg4 = sum(temp4)/len(temp4)

    temp_list_2.append(avg2)
    temp_list_3.append(avg3)
    temp_list_4.append(avg4)

print(temp_list_2)
print(temp_list_3)
print(temp_list_4)

&gt;&gt; [2.3333333333333335, 13.5, 10.333333333333334, 22.25]
[6.666666666666667, 3.0, 12.0, 2.75]
[60.0, 60.0, 26.666666666666668, 17.5]
</code></pre>
","8727339","8727339","2018-03-01 06:18:06","0","1073","Mohit Motwani","2017-10-05 15:27:59","3347","570","1592","24","49043153","","2018-03-01 05:27:13","1","99","<p>I have four lists with same <code>len</code></p>

<pre><code>list1=[26, 26, 26, 27, 27, 27, 27, 28, 28, ..., 100, 100, 100]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10,...., 90, 10,  -1]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 14, ..., -1, -1, -1]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10, ...., 20, 20, 20]
</code></pre>

<p>I have to average out the values in <code>list2, 3, and 4</code>, whom share the same values in <code>list1</code>. What I mean by that is that for example, for <code>list2</code>, I want <code>(-1+-2+10)/3=2.33</code> because the corresponding elements of <code>-1, -2, and 10</code> in list1 is <code>26</code>. <code>(14+13+15+20)/4=15.5 (four corresponding 27s in list1).</code> Essentially, the same idea applies to <code>list3 and list4</code> as well. For <code>list3</code>, I want <code>(11+12+-3)/3=6.67</code></p>

<p>Eventually, after transformation and averaging out, 4 lists are:</p>

<pre><code>list1=[26, 27, 28, ...., 100]
list2=[2.33, 15.5, -7, ..., 33]
list3=[6.667, 7.25, 13.5,.., -1]
list4=[60, 45, 15, ..., 20]
</code></pre>

<p>I'm thinking about something like this. There is definitely a more elegant way to do this. </p>

<pre><code>for x, y, z, q in zip(list1, list2, list3, list4):
    if x==previous x:
       #same x, add y, z, q, to separate temp lists (when new x appears, average out)
    else:
       #new x, average out y, z, q (empty temp lists)   
</code></pre>
","6000353","6000353","2018-03-01 05:56:02","python average out columns in list","<python><list><mean>","7","8","1427"
"49043566","2018-03-01 06:08:23","0","","<p>See Update 3 for code that solved the issue</p>
","6169585","","","0","51","William Lombard","2016-04-07 00:27:51","67","24","5","0","49015337","49043566","2018-02-27 18:15:12","0","210","<p>This endeavour is a variation on the wonderful <a href=""https://github.com/MagerValp/MacModelShelf"" rel=""nofollow noreferrer"">Mac Model Shelf</a>. I have managed thus far to write the code myself that can read single Mac serial numbers at the command line and give back the corresponding model type, based on on the last 3 or 4 chars in the serial.</p>

<p>Write now I am trying to write a script to read-in the column data in an Excel file and return back the results for each cell in the neighbouring column. </p>

<p>The output Excel would hopefully looking something like this (with headers)...</p>

<pre><code>Serial         Model
C12PT70EG8WP   Macbook Pro 2015 15"" 2.5 Ghz i7
K12PT7EG0PW    iMac 2010 Intel Core Duo 1.6 Ghz
</code></pre>

<p>This is all based on excel file that supplies its data to a python shelve. Here is a small example of how it reads... I've called it 'pgList.xlsx' in the main code. In reality it will be hundreds of lines long.</p>

<pre><code>G8WP   Macbook Pro 2015 15"" 2.5 Ghz i7
0PW    iMac 2010 Intel Core Duo 1.6 Ghz
3RT    iPad Pro 2017
</code></pre>

<p>Main python3 code...</p>

<pre><code>import shelve
import pandas as pd

#getting the shelve/database ready from the library excel file
DBPATH = ""/Users/me/PycharmProjects/shelve/macmodelshelfNEW""
databaseOfMacs = shelve.open(DBPATH) 
excelDict = pd.read_excel('pgList.xlsx', header=None, index_col=0,squeeze=True).to_dict()
databaseOfMacs.update(excelDict)

#loading up the excel file and serial numbers I want to examine...
df = pd.read_excel('testSerials.xlsx', sheet_name='Sheet1')
listSerials = df['Serial']
listModels = df['Model']

for i in listSerials:
    inputSerial = i
    inputSerial = inputSerial.upper()

    modelCodeIsolatedFromSerial = """"   

    if len(inputSerial) == 12:
        modelCodeIsolatedFromSerial = inputSerial[-4:]
    elif len(inputSerial) == 11:
        modelCodeIsolatedFromSerial = inputSerial[-3:]


    try:
        model = databaseOfMacs[modelCodeIsolatedFromSerial]
        #printing to console to check code works
        print(model)

    except:
        print(""Result not found"")

databaseOfMacs.clear()
databaseOfMacs.close()
</code></pre>

<p>Could you guys help me out with writing of the results back to the same excel file? So example, if the serial number was in cell A2, the result (the model type) would be written to B2?</p>

<p>I have tried including this line of code before the main 'for' loop in the code but it only ever serves to wipe the Excel file empty after running the script! I just comment it out for the moment. </p>

<pre><code>writer = pd.ExcelWriter('testSerials.xlsx', engine='xlsxwriter')
</code></pre>

<p>Could you also help me handle any potential blank cells in the serials column? 
A blank will throw back this error.</p>

<pre><code>AttributeError: 'float' object has no attribute 'upper'
</code></pre>

<p>Thanks again for looking after me! </p>

<p>WL</p>

<p><strong>UPDATE</strong></p>

<p>The comments I have up to now have really helped. I think the part where am I getting stuck at is getting the output of the 'for' loop, 'model' in this case into the column for 'Models. The variable 'listModels' doesn't seem to behave like other lists in Python 3 i.e I cannot append anything to it. </p>

<p><strong>UPDATE 2</strong></p>

<p>Some more tinkering, trying to get the result of the serial-number lookup of the values in ""Serial"" column into the ""Model"" column.</p>

<p>I have tried (without any real success)</p>

<pre><code>    try:

        model = databaseOfMacs[modelCodeIsolatedFromSerial]

        print(model)

        listModels.replace(['nan'], [model], inplace=True)
</code></pre>

<p>This doesn't give me an error message but still nothing appears in the outputted excel file.</p>

<p>When I run a for loop to print the contents of 'listModels' I just back a list of ""NaN""s, suggesting nothing at all has been changed... bummer!</p>

<p>I've also tried </p>

<pre><code>try:

    model = databaseOfMacs[modelCodeIsolatedFromSerial]

    print(model)

    listModels[i] = model
</code></pre>

<p>This will spit back a console error about </p>

<pre><code>A value is trying to be set on a copy of a slice from a DataFrame
</code></pre>

<p>but at least I can see the modelname relating to a serial number in the console when I iterate through 'listModels', still nothing in the output Excel file though (along with a 'nan' for every serial number that is examined?)</p>

<p>I am sure it's something small that I am missing in the code to fix this problem. Thanks again to anybody who can help me out. </p>

<p><strong>UPDATE 3</strong></p>

<p>I've solved it on my own. Just had to use a while loop instead.</p>

<pre><code>sizeOfSerialsList = len(listSerials)

count = 0


while (count &lt; sizeOfSerialsList):
    inputSerial = listSerials.iloc[count]
    inputSerial = str(inputSerial).upper()
    modelCodeIsolatedFromSerial = """"
    model = """"


    if len(inputSerial) == 12:
        modelCodeIsolatedFromSerial = inputSerial[-4:]
    elif len(inputSerial) == 11:
        modelCodeIsolatedFromSerial = inputSerial[-3:]

    try:
        model = databaseOfMacs[modelCodeIsolatedFromSerial]
        listModels.iloc[count] = model
    except:
        listModels.iloc[count] = ""Not found""

    count = count + 1
</code></pre>
","6169585","6169585","2018-03-01 06:07:39","Reading and writing column data in Python with Pandas","<python><excel><python-3.x><pandas>","2","0","5318"
"49043575","2018-03-01 06:08:52","0","","<p>As per the <em>HTML</em> you have shared to click on the radio button beside the <code>&lt;label&gt;</code> with text as <strong>Milhas</strong> you can use the following line of code :</p>

<pre><code>chromeDriver.find_element_by_xpath(""//input[@id='booking-type-2' and @name='booking-type']"").click()
</code></pre>
","7429447","","","1","320","DebanjanB","2017-01-17 08:59:30","63154","13103","3455","2612","49041461","49043575","2018-03-01 01:55:43","0","461","<p>I am trying to click into a radio button inside a span. Trying to execute:</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.common.keys import Keys 


chromeDriver = webdriver.Chrome()
chromeDriver.get('https://www.flytap.com/pt-br/')

#Works Fine
chromeDriver.find_element_by_id('origin')
origin.click()
origin.clear()
origin.send_keys('(RIO) Rio De Janeiro -  todos os aeroportos , Brasil')
    origin.click()

#Where I got the error
milesBox = chromeDriver.find_element_by_id(""booking-type-2"").click()

#Also tried:
milesBox = chromeDriver.find_element_by_id(""booking-type-2"").send_keys(Keys.ENTER)

#And, finally:
milesBox = chromeDriver.find_element_by_id(""booking-type-2"").send_keys(Keys.SPACE)
</code></pre>

<p>Here is the error I got:</p>

<pre><code>ElementNotVisibleException: Message: element not visible
</code></pre>

<p>HTML code:</p>

<pre><code>&lt;!-- Payment Methods START --&gt;
                &lt;fieldset id=""booking-payment-drag"" class=""booking-payment""&gt;
                    &lt;div class=""toolbar-radio-wrapper""&gt;
                        &lt;legend class=""ipt-label""&gt;Reservar com:&lt;/legend&gt;
                    &lt;/div&gt;
                    &lt;div class=""toolbar-radio-wrapper""&gt;
                        &lt;div class=""radio""&gt;
                            &lt;span class=""checked""&gt;&lt;input type=""radio"" id=""booking-type-1"" name=""booking-type"" value=""1"" checked&gt;&lt;/span&gt;
                        &lt;/div&gt;
                        &lt;label for=""booking-type-1"" class=""ipt-label""&gt;Dinheiro&lt;/label&gt;
                    &lt;/div&gt;
                    &lt;div class=""toolbar-radio-wrapper js-country-not-eligible""&gt;
                        &lt;div class=""radio""&gt;
                            &lt;span class=""""&gt;&lt;input type=""radio"" id=""booking-type-2"" name=""booking-type"" value=""2""&gt;&lt;/span&gt;
                        &lt;/div&gt;
                        &lt;label for=""booking-type-2"" class=""ipt-label""&gt;Milhas&lt;/label&gt;
                    &lt;/div&gt;
                        &lt;div class=""toolbar-radio-wrapper""&gt;
                            &lt;div class=""radio is-disabled js-country-eligible""&gt;
                                &lt;span class=""""&gt;&lt;input type=""radio"" id=""booking-type-3"" name=""booking-type"" value=""3"" disabled&gt;&lt;/span&gt;
                            &lt;/div&gt;
                            &lt;label for=""booking-type-3"" class=""ipt-label""&gt;Miles&amp;Cash&lt;/label&gt;
                                                        &lt;/div&gt;
                &lt;/fieldset&gt;
</code></pre>
","6584846","10388629","2019-05-30 00:28:47","Cannot click a radio button inside a span Selenium Python","<python><selenium><selenium-webdriver><radio-button><radio>","3","1","2635"
"49043602","2018-03-01 06:10:45","0","","<p>It solved after I execute send_activation_mail by using threading <code>threading.Thread(target=self.send_activation_mail(request=request, user=user)).start()</code></p>
","6501597","","","0","173","Zulwiyoza Putra","2016-06-22 23:17:08","149","92","49","10","49042917","","2018-03-01 05:02:10","0","223","<p>So this is my last 2 lines in one of my endpoint:</p>

<pre><code>self.send_activation_mail(request, user=user)
return self.response(request, status=201, title='Created', description='Please check your email for activation', data=user_data)
</code></pre>

<p>returning self.response will be return the my rest client a response of 201. My problem is the <code>send_activation_mail</code> seems like takes time to run so the my endpoint to signup process takes so much time. I tried to find the way to execute those tasks at the same time asynchronously in Python.Does anyone has any experience with this kind of situation before and how do you solve it?</p>
","6501597","6501597","2018-03-01 05:12:48","Run Multiple Tasks Asynchronously in Python","<python><asynchronous><python-multithreading>","2","1","661"
"49043640","2018-03-01 06:13:34","0","","<p>A co-worker reminded me, that I was not using columns' indices correctly. To drop columns from multi index dataframe objects, I simply did:</p>

<pre><code>f2 = f2.drop([('accuracy','std')],axis=1).drop([('F1','std')],axis=1)
</code></pre>
","3523464","","","0","243","sdgaw erzswer","2014-04-11 11:22:10","822","134","31","5","49034807","49043666","2018-02-28 16:57:08","3","1041","<p>I've been trying to understand the multi index methodology of Pandas. I am trying to delete the ""std"" sub-column, yet in vain.</p>

<p>How can this be done?</p>

<pre><code>                                    attribute                           attribute2  \
                                        test1            std           test2   
d         count       type                                                  
r1         10          rx      0.559 (0.0)    0.559 (0.0)    0.568 (0.0)   
                     sth1      0.653 (0.004)  0.653 (0.004)  0.679 (0.002)   
                     sth2      0.584 (0.002)  0.584 (0.002)  0.586 (0.003)   
                     sth3      0.651 (0.005)  0.651 (0.005)  0.676 (0
</code></pre>

<p>I can't seem to get my head around the <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.MultiIndex.drop.html"" rel=""nofollow noreferrer"">https://pandas.pydata.org/pandas-docs/stable/generated/pandas.MultiIndex.drop.html</a> function, I believe.</p>

<p>The resulting dataframe should thus have only two mean columns, no ""std""
Thank you very much.</p>
","3523464","3523464","2018-03-01 05:53:13","Deleting a column from MultiIndex Pandas dataframe","<python><pandas>","2","0","1111"
"49043662","2018-03-01 06:15:48","1","","<p>I was getting same error. I am using windows. To solve this I added system variable in Windows 10 as follows:</p>

<p>Control Panel -> System &amp; security -> System -> Advanced system setting -> Environment Variable -> add new system variable with variable name = 'MKL_THREADING_LAYER' and variable value = 'GNU' 
and click 'OK'.</p>

<p>I think in ubuntu you should make changes in .bashrc</p>
","9388802","","","0","400","C.M","2018-02-21 03:06:23","23","25","0","0","47801775","","2017-12-13 20:41:00","3","1184","<p>When importing the theano package:</p>

<pre><code>from theano import tensor, scalar
</code></pre>

<p>I get the following error:</p>

<pre><code>To use MKL 2018 with Theano you MUST set ""MKL_THREADING_LAYER=GNU"" in your environement.
</code></pre>

<p>So I looked up the details here:
<a href=""https://pypkg.com/pypi/theano/f/theano/configdefaults.py"" rel=""nofollow noreferrer"">https://pypkg.com/pypi/theano/f/theano/configdefaults.py</a></p>

<p>And then tried to isntall the mkl-service on anaconda:</p>

<pre><code>conda install -c anaconda mkl-service
</code></pre>

<p>However, I am getting the same error.</p>

<p>Any ideas? I am on an AWS ubuntu box running python in anaconda jupyter notebook.</p>

<p>Thank you!</p>
","3604836","","","python: theano import error ""MKL_THREADING_LAYER=GNU""","<python><amazon-web-services><ubuntu><theano>","2","1","729"
"49043666","2018-03-01 06:16:10","4","","<p>I think better is for remove all columns with <code>std</code> is second level of <code>MultiIndex</code> use <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"" rel=""nofollow noreferrer""><code>drop</code></a> with parameter <code>level=1</code>:</p>

<pre><code>print (df)
              attribute          attribute2          attribute3         
                  test1      std      test2      std      test3      std
d  count type                                                           
r1 10    rx       0.559    (0.0)      0.559    (0.0)      0.568    (0.0)
         sth1     0.653  (0.004)      0.653  (0.004)      0.679  (0.002)
         sth2     0.584  (0.002)      0.584  (0.002)      0.586  (0.003)
         sth3     0.651  (0.005)      0.651  (0.005)      0.676      (0)

df = df.drop('std', axis=1, level=1)
print (df)
              attribute attribute2 attribute3
                  test1      test2      test3
d  count type                                
r1 10    rx       0.559      0.559      0.568
         sth1     0.653      0.653      0.679
         sth2     0.584      0.584      0.586
         sth3     0.651      0.651      0.676
</code></pre>
","2901002","2901002","2018-03-01 06:21:15","1","1212","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49034807","49043666","2018-02-28 16:57:08","3","1041","<p>I've been trying to understand the multi index methodology of Pandas. I am trying to delete the ""std"" sub-column, yet in vain.</p>

<p>How can this be done?</p>

<pre><code>                                    attribute                           attribute2  \
                                        test1            std           test2   
d         count       type                                                  
r1         10          rx      0.559 (0.0)    0.559 (0.0)    0.568 (0.0)   
                     sth1      0.653 (0.004)  0.653 (0.004)  0.679 (0.002)   
                     sth2      0.584 (0.002)  0.584 (0.002)  0.586 (0.003)   
                     sth3      0.651 (0.005)  0.651 (0.005)  0.676 (0
</code></pre>

<p>I can't seem to get my head around the <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.MultiIndex.drop.html"" rel=""nofollow noreferrer"">https://pandas.pydata.org/pandas-docs/stable/generated/pandas.MultiIndex.drop.html</a> function, I believe.</p>

<p>The resulting dataframe should thus have only two mean columns, no ""std""
Thank you very much.</p>
","3523464","3523464","2018-03-01 05:53:13","Deleting a column from MultiIndex Pandas dataframe","<python><pandas>","2","0","1111"
"49043737","2018-03-01 06:22:57","0","","<pre><code>def pangram(s):
alphabet = set('abcdefghijklmnopqrstuvwxyz')
s = s.replace(' ','').lower()
s= sorted(s)

count = {}

    #alphabet could be one sting within '' later sorted, but I just went straight to the point. 
    #After initializing my dictionary at null, we start the count    

for letter in s:
    if letter in count:
        count[letter] =[]
    else:
        count[letter] = 1

for letter in alphabet:
    if letter in count:
        count[letter] =[]
    else:
        count[letter] = 0
for letter in count:
    if count[letter]== 0:
        print (letter +' missing!')
print (count[letter]!= 0)
</code></pre>
","8896521","8896521","2018-03-02 23:30:59","0","633","Humphrey","2017-11-06 20:51:51","1","3","0","0","47025311","47025362","2017-10-30 22:42:54","3","308","<p>How is this working?  It checks if a string contains each character from a-z at least once?</p>

<pre><code>import string

def ispangram(str1, alphabet=string.ascii_lowercase):  
    alphaset = set(alphabet)  
    return alphaset &lt;= set(str1.lower()) 
</code></pre>

<p>This returns True for example:</p>

<pre><code>ispangram(""The quick brown fox jumps over the lazy dog"")
</code></pre>

<p>I can only assume it is something to do with lexographical ordering as stated here, but still a bit confused.</p>

<p><a href=""https://stackoverflow.com/questions/13052857/comparing-two-lists-using-the-greater-than-or-less-than-operator"">Comparing two lists using the greater than or less than operator</a></p>

<p>When I read the link in this SO question:</p>

<p><a href=""https://docs.python.org/3/tutorial/datastructures.html#comparing-sequences-and-other-types"" rel=""nofollow noreferrer"">https://docs.python.org/3/tutorial/datastructures.html#comparing-sequences-and-other-types</a></p>

<p>It says:</p>

<blockquote>
  <p>Sequence objects may be compared to other objects with the same
  sequence type. The comparison uses lexicographical ordering: first the
  first two items are compared, and if they differ this determines the
  outcome of the comparison; if they are equal, the next two items are
  compared, and so on, until either sequence is exhausted. If two items
  to be compared are themselves sequences of the same type, the
  lexicographical comparison is carried out recursively. If all items of
  two sequences compare equal, the sequences are considered equal. If
  one sequence is an initial sub-sequence of the other, the shorter
  sequence is the smaller (lesser) one. Lexicographical ordering for
  strings uses the Unicode code point number to order individual
  characters. Some examples of comparisons between sequences of the same
  type.</p>
</blockquote>

<p>But this isn't clear to me.</p>
","1754307","1754307","2017-10-30 22:48:15","Detecting if a string is a pangram in Python","<python>","3","2","1920"
"49043748","2018-03-01 06:23:26","0","","<p>To expand the row from the numpy data use <code>*</code> like:</p>

<h3>Code:</h3>

<pre><code>writer.writerow(*line)
</code></pre>

<h3>Whole Listing:</h3>

<pre><code>def write_to_csv(file_name, header, numpy_data):
    with open(file_name, ""w"", newline='') as csv_file:
        writer = csv.writer(csv_file, delimiter=',')
        writer.writerow(header)
        for line in numpy_data:
            if line is None:
                writer.writerow(line)
            else:
                writer.writerow(*line)
</code></pre>
","7311767","","","1","531","Stephen Rauch","2016-12-18 02:06:51","33601","12784","4195","3857","49043682","","2018-03-01 06:17:50","0","121","<pre><code>def write_to_csv(file_name, header, numpy_data):
    with open(file_name, ""w"", newline='') as csv_file:
        writer = csv.writer(csv_file, delimiter=',')
        header = [header]
        for line in header:
            writer.writerow(line)

        for line in numpy_data:
            if line is None:
                writer.writerow(line)
            else:
                writer.writerow(line)
</code></pre>

<p>I have cells in my excel like this after executing the above code</p>

<pre><code>['Financial Analysis', 'Finance', 'Financial Modeling']
</code></pre>

<p>What I would like is </p>

<pre><code>Financial Analysis, Finance, Financial Modeling
</code></pre>

<p>I tried to do <code>line.strip(""[]"")</code> but then nothing appears in the excel when I do this. </p>

<p>sample of <code>numpy_data</code> is :</p>

<pre><code>[['Financial Analysis', 'Finance', 'Financial Modeling']]
</code></pre>

<p>Thank you</p>
","5327707","7932273","2018-03-01 06:22:51","Strip brackets before writing to csv using writerow","<python>","4","0","942"
"49043818","2018-03-01 06:28:58","1","","<pre><code>import matplotlib.pyplot as plt
import numpy as np

plt.plot([3, 12, 5, 18, 45])
plt.yticks(np.arange(0,45+1,15))
plt.show()
</code></pre>
","1902886","","","0","150","William Feirie","2012-12-14 03:13:55","424","36","6","1","49043162","49043818","2018-03-01 05:28:11","0","37","<p>Let's say if I have <code>Height = [3, 12, 5, 18, 45]</code> and plot my graph then the yaxis will have ticks starting 0 up to 45 with an interval of 5, which means 0, 5, 10, 15, 20 and so on up to 45. Is there a way to define the interval gap (or the step). For example I want the yaxis to be 0, 15, 30, 45 for the same data set.</p>
","2497039","","","Custom Yaxis plot in matplotlib python","<python><matplotlib>","2","1","338"
"49043828","2018-03-01 06:29:28","3","","<p>I'm kind of assuming you don't want to insert 1500 figures in a report or talk and therefore the purpose of this is just to investigate the file slice by slice. If this is the case I would simply open the file using </p>

<pre><code>ncview file.nc 
</code></pre>

<p>This allows you to step through the slices, animate, pass the cursor over the slices to see the values and click on a point to see a timeseries. If you don't have it, you can install it easily with apt-get (ubuntu, mint etc) with </p>

<pre><code>sudo apt-get install ncview
</code></pre>
","6068294","","","2","559","Adrian Tompkins","2016-03-15 19:46:46","2066","531","2636","81","49035660","49043058","2018-02-28 17:47:19","2","389","<p>I would like to create plot images from a NetCDF at each time step.</p>

<p>My NetCDF files look like this:</p>

<pre><code>netcdf file:/C:/home/data/cmorph/test/reduced_cmorph_adjusted_spi_pearson_01.nc {
  dimensions:
    time = UNLIMITED;   // (240 currently)
    lat = 120;
    lon = 360;
  variables:
    float spi_pearson_01(time=240, lat=120, lon=360);
      :_FillValue = NaNf; // float
      :valid_min = -3.09; // double
      :valid_max = 3.09; // double
      :long_name = ""Standard Precipitation Index (Pearson Type III distribution), 1-month scale"";
      :_ChunkSizes = 1, 120, 360; // int

    int time(time=240);
      :units = ""days since 1800-01-01 00:00:00"";
      :_ChunkSizes = 1024; // int
      :_CoordinateAxisType = ""Time"";

    float lat(lat=120);
      :units = ""degrees_north"";
      :_CoordinateAxisType = ""Lat"";

    float lon(lon=360);
      :units = ""degrees_east"";
      :_CoordinateAxisType = ""Lon"";

  // global attributes:
  :title = ""CMORPH Version 1.0BETA Version, daily precip from 00Z-24Z"";
  :history = ""Wed Feb 28 07:30:01 2018: C:\\home\\miniconda\\Library\\bin\\ncks.exe --dmn lon,0,,4 --dmn lat,0,,4 CMORPH_V1.0_ADJ_0.25deg-DLY_00Z_1998_2017.nc cmorph_reduced_adjusted.nc"";
  :NCO = ""4.7.1"";
  :_CoordSysBuilder = ""ucar.nc2.dataset.conv.DefaultConvention"";
}
</code></pre>

<p>I like the plots produced by Panoply but I haven't worked out how to script it (I don't want to go through the GUI for this since I'll have roughly 1500 plots to create). I'm not wedded to Panoply per se, so if someone has a better idea please advise. I could hammer this out in matplotlib but it'd take me quite a while and wouldn't look as good as the Panoply plots. I'm trying to avoid doing much if any of the plotting myself, but maybe there's something out there that provides easy plotting of NetCDFs which can be called from a script (I typically use Python and bash), if so please clue me in. Thanks in advance for any suggestions or examples.</p>
","85248","","","NetCDF: How can I script plotting at each time step?","<python><plot><netcdf>","2","0","1983"
"49043848","2018-03-01 06:31:13","2","","<p>found the answer here: <a href=""https://stackoverflow.com/questions/6750251/sqlalchemy-order-by-on-relationship-for-join-table"">SQLAlchemy - order_by on relationship for join table</a></p>

<p>I just had to change the relationship in model.py</p>

<pre><code>actions = db.relationship('Action', backref='entry', order_by=""desc(Action.id)"", lazy='dynamic')
</code></pre>
","9427043","","","0","373","The Picard","2018-03-01 04:37:32","21","12","0","0","49042895","","2018-03-01 04:59:29","0","271","<p>Here are my models:  </p>

<pre><code>class Entry(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    manifest = db.Column(db.String, default=None, nullable=True)
    name = db.Column(db.String, default=None, nullable=True)
    actions = db.relationship('Action', backref='entry', lazy='dynamic')

class Action(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    action_date = db.Column(db.DateTime, default=datetime.utcnow, nullable=True)
    location = db.Column(db.String, default=None, nullable=True)
    entry_id = db.Column(db.Integer, db.ForeignKey('entry.id'))
</code></pre>

<p><code>routes.py</code>:</p>

<pre><code>@app.route('/manifests/&lt;manifest_to_view&gt;')
@login_required
def view_manifest(manifest_to_view):
    page = request.args.get('page', 1, type=int)
    entries = Entry.query.filter_by(manifest=manifest_to_view).paginate(
        page, app.config['POSTS_PER_PAGE'], False)
    next_url = url_for('view_manifest', manifest_to_view=manifest_to_view, page=entries.next_num) \
        if entries.has_next else None
    prev_url = url_for('view_manifest', manifest_to_view=manifest_to_view, page=entries.prev_num) \
        if entries.has_prev else None
    return render_template(""view_manifest.html"", title='View Manifest', manifest_to_view=manifest_to_view, entries=entries.items, next_url=next_url, prev_url=prev_url)
</code></pre>

<p>And from the template:</p>

<pre><code>{% for entry in entries %}
&lt;td&gt;{{ entry.actions.first().location }}&lt;/td&gt;
{% endfor %}
</code></pre>

<p>This page displays all rows in the Entry table that share a specific ""manifest"" (an alphanumeric identifier). So you can see my query in <code>routes.py</code> starts:</p>

<pre><code>entries = Entry.query.filter_by(manifest=manifest_to_view)...
</code></pre>

<p>For each row from the Entry table, I also need to display the most recent <code>location</code> from the related Action table, but my current line displays the wrong location:</p>

<pre><code>{{ entry.actions.first().location }}
</code></pre>

<p>Is there a way to sort locations by the Action.action_date column using <code>order_by()</code> instead of using <code>first()</code>? Or any way to print the most recent location?</p>

<p>Thanks.</p>
","9427043","6700019","2019-02-15 12:38:01","order_by() a related table with Flask-SQLAlchemy","<python><sql><flask><flask-sqlalchemy>","1","0","2259"
"49043855","2018-03-01 06:31:27","1","","<p>the on_text property does not exist so it will not help. For your case there are 2 possibilities:</p>

<ul>
<li>Assign the text using a function:</li>
</ul>

<hr>

<p><strong>*.py</strong></p>

<pre><code>import kivy
kivy.require('1.10.0')

from kivy.app import App 
from kivy.uix.boxlayout import BoxLayout
import json

class Lab(BoxLayout):   
    def  inpuut(self):
        with open('vocab_words.json') as rfile:
            data=json.load(rfile)
            return data[0]['word']

class main(App):
    def build(self):
        return Lab()

m = main()
m.run()
</code></pre>

<p><strong>*.kv</strong></p>

<pre><code>&lt;Lab&gt;:
    BoxLayout:
        Label:
            id: L
            text: root.inpuut()
        Label:
            text: ""something""
</code></pre>

<ul>
<li>Or use <code>StringProperty</code>:</li>
</ul>

<hr>

<p><strong>*.py</strong></p>

<pre><code>import kivy
kivy.require('1.10.0')

from kivy.app import App 
from kivy.properties import StringProperty
from kivy.uix.boxlayout import BoxLayout
import json

class Lab(BoxLayout): 
    the_value= StringProperty()     
    def  __init__(self, *args):
        BoxLayout.__init__(self, *args)
        with open('vocab_words.json') as rfile:
            data=json.load(rfile)
            self.the_value = data[0]['word']

class main(App):
    def build(self):
        return Lab()

m = main()
m.run()
</code></pre>

<p><strong>*.kv</strong></p>

<pre><code>&lt;Lab&gt;:
    BoxLayout:
        Label:
            id: L
            text: root.the_value
        Label:
            text: ""something""
</code></pre>
","6622587","","","1","1589","eyllanesc","2016-07-21 23:29:11","114264","27275","2584","21000","49043654","49043855","2018-03-01 06:14:57","1","130","<p>I am new to python and kivy. I am trying to make a small program in which the text of the label will be the value from vocab_words.json</p>

<p>but I am getting a blank label, and I think the inpuut() function is running even though I have made a call to it.
plz tell me what is wrong with my code and 
also how else can i change the text of the label to the value in json file.</p>

<p>heres my code:</p>

<pre><code>import kivy
kivy.require('1.10.0')

from kivy.uix.label import Label
from kivy.app import App 
from kivy.uix.widget import Widget
from kivy.properties import StringProperty
from kivy.uix.boxlayout import BoxLayout

class Lab(BoxLayout):
    the_value= StringProperty()     
    def  inpuut(self):
        with open('vocab_words.json') as rfile:
            data=json.load(rfile)

        the_value=data[0]['word']


class main(App):
    def build(self):
        return Lab()

m = main()
m.run()
</code></pre>

<p>heres the kivy code:</p>

<pre><code>&lt;Lab&gt;:

    BoxLayout:
        Label:
            id: L
            on_text:root.inpuut()
            text: root.the_value
        Label:
            text: ""something""
</code></pre>

<p>I would appreciate any help.</p>
","9355642","6622587","2018-03-01 06:31:41","change the text of label to a value from a json file, but when I run the program the label is blank","<python><kivy>","1","0","1196"
"49043856","2018-03-01 06:31:30","1","","<p>You can use itertool's <a href=""https://docs.python.org/2/library/itertools.html#itertools.groupby"" rel=""nofollow noreferrer""><code>groupby</code></a>:</p>

<pre><code>from itertools import groupby
from statistics import mean

list1=[26, 26, 26, 27, 27, 27, 27, 28, 28]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 14]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10]

def avg_from_list(list1, list_n):
    new_list = []
    for key, group in groupby(enumerate(list1), key=lambda x: x[1]):
        new_list.append(mean([list_n[i] for i, _ in group]))
    return new_list

print(sorted(list(set(list1))))
for l in (list2, list3, list4):
    print(avg_from_list(list1, l))
</code></pre>

<p>Output:</p>

<pre><code>[26, 27, 28]
[2.3333333333333335, 15.5, -7]
[6.666666666666667, 7.25, 13.5]
[60, 45, 15]
</code></pre>
","2933645","","","0","851","damores","2013-10-29 19:24:09","1618","171","1278","27","49043153","","2018-03-01 05:27:13","1","99","<p>I have four lists with same <code>len</code></p>

<pre><code>list1=[26, 26, 26, 27, 27, 27, 27, 28, 28, ..., 100, 100, 100]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10,...., 90, 10,  -1]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 14, ..., -1, -1, -1]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10, ...., 20, 20, 20]
</code></pre>

<p>I have to average out the values in <code>list2, 3, and 4</code>, whom share the same values in <code>list1</code>. What I mean by that is that for example, for <code>list2</code>, I want <code>(-1+-2+10)/3=2.33</code> because the corresponding elements of <code>-1, -2, and 10</code> in list1 is <code>26</code>. <code>(14+13+15+20)/4=15.5 (four corresponding 27s in list1).</code> Essentially, the same idea applies to <code>list3 and list4</code> as well. For <code>list3</code>, I want <code>(11+12+-3)/3=6.67</code></p>

<p>Eventually, after transformation and averaging out, 4 lists are:</p>

<pre><code>list1=[26, 27, 28, ...., 100]
list2=[2.33, 15.5, -7, ..., 33]
list3=[6.667, 7.25, 13.5,.., -1]
list4=[60, 45, 15, ..., 20]
</code></pre>

<p>I'm thinking about something like this. There is definitely a more elegant way to do this. </p>

<pre><code>for x, y, z, q in zip(list1, list2, list3, list4):
    if x==previous x:
       #same x, add y, z, q, to separate temp lists (when new x appears, average out)
    else:
       #new x, average out y, z, q (empty temp lists)   
</code></pre>
","6000353","6000353","2018-03-01 05:56:02","python average out columns in list","<python><list><mean>","7","8","1427"
"49043867","2018-03-01 06:32:32","1","","<p>Instead of parsing the html, what about downloading the excel files? This seems to download all of the events you are after.</p>

<pre><code>from selenium import webdriver
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

url = ""https://www.rankonesport.com/Calendar/?D=e8bb5c10-8d0c-4b26-b304-262397124de8""

driver = webdriver.Chrome()
driver.get(url)

weekly = driver.find_element_by_id(""cmd_Weekly"")
weekly.click()

while True:
    try:
        element = WebDriverWait(driver, 5).until(
            EC.presence_of_element_located((By.ID, ""cmd_Export_Event_Excel""))
        ).click()
    except TimeoutException:
        driver.quit()
        break
    else:
        driver.find_element_by_id('lnk_Next_Day').click()
</code></pre>

<p>Then, using <code>pandas</code> and some help from stackoverflow, you can write the results out to a csv file.</p>

<ul>
<li><a href=""https://stackoverflow.com/a/30512931/8079103"">https://stackoverflow.com/a/30512931/8079103</a></li>
<li><a href=""https://stackoverflow.com/a/24725123/8079103"">https://stackoverflow.com/a/24725123/8079103</a></li>
</ul>

<hr>

<pre><code>import os
from functools import reduce

import pandas as pd

dfs = []
dir_path = '/home/lettuce/Downloads'
for f in os.listdir(dir_path):
    if f.endswith('.xls'):
        df = pd.read_html('{}/{}'.format(dir_path, f))[0]
        dfs.append(df)

df_final = reduce(lambda left, right: pd.merge(left, right, how='outer'), dfs)
df_final.to_csv('all_events.csv', index=False, header=False)
</code></pre>

<p><a href=""https://bpaste.net/show/8cd335241716"" rel=""nofollow noreferrer"">Link to the csv output file</a></p>
","8079103","","","2","1797","G_M","2017-05-29 00:31:33","3102","440","139","287","49042607","49043867","2018-03-01 04:25:00","0","44","<pre><code>from selenium import webdriver
from selenium.webdriver.firefox.options import Options
import bs4
import datetime
import time

#options = Options()
#options.add_argument(""--headless"")
#driver = webdriver.Firefox(firefox_options=options)

driver = webdriver.Firefox()

driver.get(""https://www.rankonesport.com/Calendar/?D=e8bb5c10-8d0c-4b26-
b304-262397124de8"")

weekly = driver.find_element_by_id(""cmd_Weekly"").click()

source = driver.page_source

bs_source = bs4.BeautifulSoup(source, ""lxml"")

month = datetime.date.today().month

year_end = 5
total = 12
times = 0

if month &lt;= year_end:
    times = year_end - month

if month == year_end:
    times = 1

if month &gt;= year_end:
    value = month - year_end

    times = total - value

times *= 5

mylist = []
#{EventName:[Date, Where, Time(Start), Time(End)]}
mydict = {}

for x in range(times):


    events = bs_source.find('table', id='gv_Events')


    for tr in events.find_all('tr', class_='lightgray'):

        td = tr.find_all('td')
        mylist.append(td)

    for tr2 in events.find_all('tr', class_='white'):

        td2 = tr2.find_all('td')
        mylist.append(td2)

    next = driver.find_element_by_id('lnk_Next_Day').click()


for event in mylist:
    mydict.update({event[0].text: [event[2].text, event[1].text, 
    event[3].text, event[4].text]})

print(mylist)
print(mydict)
</code></pre>

<p>So my school has an online calendar that I am trying to scrape off of. My goal is to pull each event, that happens before the school year ends, and their corresponding properties such as time and date. </p>

<p>I have the script loop through the calendar portion that has the events by week and pull them off. The calendar is a JS based calendar so the link does not change when the script goes and clicks the next button. I store the events and their properties in a list and then throw them into a dictionary in order to easily access them by name. </p>

<p>What I want to happen is the dictionary to be full of as many events as the script loops through. Rather the dictionary only contains a select few which seem to be the first couple of events it parses through. The events have the same HTML ids and classes when the next page is pulled up so it should just rinse and repeat the code as many times as I have it.</p>

<p>If someone could point something out that I missed or lead me in the right direction that would be awesome as I have spent way to much time trying to figure this out myself.</p>

<p>Links:</p>

<p><a href=""https://www.rankonesport.com/Calendar/Daily.aspx?S=&amp;D=e8bb5c10-8d0c-4b26-b304-262397124de8&amp;Date=2/28/2018"" rel=""nofollow noreferrer"">Calendar</a><br>
<a href=""http://prntscr.com/il7hin"" rel=""nofollow noreferrer"">Calendar Outline</a></p>

<p>Dictionary Output:</p>

<pre><code>{'Sadie Ticket Sales': ['3/1/2018', 'New Cafeteria, 541 Chartres St. LaSalle, Lasalle, IL 61301', '11:00 AM', '1:00 PM'], 
 'Winter Guard Practice': ['3/3/2018', ' East Gym, 541 Chartres St. LaSalle, Lasalle, IL 61301', '5:00 PM', '8:00 PM'], 
 'Sadie Dance': ['3/3/2018', 'Sellett Gym, 541 Chartres St. LaSalle, Lasalle, IL 61301', '8:00 PM', '11:00 PM']}
</code></pre>

<p>^Should be way, way more events</p>

<p>List output:</p>

<pre><code>[[&lt;td&gt;Sadie Ticket Sales&lt;/td&gt;, &lt;td&gt;New Cafeteria, 541 Chartres St. LaSalle, Lasalle, IL 61301&lt;/td&gt;, &lt;td&gt;2/26/2018&lt;/td&gt;, &lt;td&gt;11:00 AM&lt;/td&gt;, &lt;td&gt;1:00 PM&lt;/td&gt;, &lt;td&gt;Non-Game Activity&lt;/td&gt;, &lt;td align=""center""&gt;&lt;a href=""javascript:__doPostBack('gv_Events','Outlook$0')""&gt;Sync&lt;/a&gt;&lt;/td&gt;],
 [&lt;td&gt;Winter Guard Practice&lt;/td&gt;, &lt;td&gt;North Balcony, 541 Chartres St. LaSalle, Lasalle, IL 61301&lt;/td&gt;, &lt;td&gt;2/27/2018&lt;/td&gt;, &lt;td&gt;6:30 PM&lt;/td&gt;, &lt;td&gt;9:00 PM&lt;/td&gt;, &lt;td&gt;Non-Game Activity&lt;/td&gt;, &lt;td align=""center""&gt;&lt;a href=""javascript:__doPostBack('gv_Events','Outlook$2')""&gt;Sync&lt;/a&gt;&lt;/td&gt;],
 ...]
</code></pre>

<p>It seems to repeat those events over and over in the list ^</p>

<p>Thanks.</p>

<p>Edit 1:</p>

<pre><code>mylist = []
#{EventName:[Date, Where, Time(Start), Time(End)]}
mydict = {}

for x in range(5):

    source = driver.page_source

    bs_source = bs4.BeautifulSoup(source, 'lxml')
    events = bs_source.find('table', id='gv_Events')


    for tr in events.find_all('tr', class_='lightgray'):

        td = tr.find_all('td')
        mylist.append(td)

    for tr2 in events.find_all('tr', class_='white'):

        td2 = tr2.find_all('td')
        mylist.append(td2)

    next = driver.find_element_by_id('lnk_Next_Day').click()


for event in mylist:
    mydict.update({event[0].text: [event[2].text, event[1].text, 
    event[3].text, event[4].text]})
</code></pre>
","8414357","8414357","2018-03-02 01:38:12","Trouble with updating lists and dictionaries in a for loop","<python><selenium><for-loop><beautifulsoup><html-parsing>","2","0","4797"
"49043941","2018-03-01 06:38:59","0","","<p>Try using a join statement in a list comprehension that identifies instances of lists and converts them to strings before writing the list of elements to file.</p>

<pre><code>line = [', '.join(i) if isinstance(i,list) else i for i in line]
writer.writerow(line)
</code></pre>
","6233386","6233386","2018-03-01 07:23:51","5","280","Mike Peder","2016-04-21 03:40:45","604","60","66","8","49043682","","2018-03-01 06:17:50","0","121","<pre><code>def write_to_csv(file_name, header, numpy_data):
    with open(file_name, ""w"", newline='') as csv_file:
        writer = csv.writer(csv_file, delimiter=',')
        header = [header]
        for line in header:
            writer.writerow(line)

        for line in numpy_data:
            if line is None:
                writer.writerow(line)
            else:
                writer.writerow(line)
</code></pre>

<p>I have cells in my excel like this after executing the above code</p>

<pre><code>['Financial Analysis', 'Finance', 'Financial Modeling']
</code></pre>

<p>What I would like is </p>

<pre><code>Financial Analysis, Finance, Financial Modeling
</code></pre>

<p>I tried to do <code>line.strip(""[]"")</code> but then nothing appears in the excel when I do this. </p>

<p>sample of <code>numpy_data</code> is :</p>

<pre><code>[['Financial Analysis', 'Finance', 'Financial Modeling']]
</code></pre>

<p>Thank you</p>
","5327707","7932273","2018-03-01 06:22:51","Strip brackets before writing to csv using writerow","<python>","4","0","942"
"49043984","2018-03-01 06:42:28","0","","<p><strong>intModifiedUser</strong> is an instance of AppUser. You should not set the foreign key identifier directly.</p>

<p>Use to get the object from AppUser Instance</p>

<pre><code>intModifiedUser = AppUser.objects.get(id=1) 

country_details = Country(values, intModifiedUser = intModifiedUser)
</code></pre>
","4570769","","","0","316","Jay Venkat","2015-02-16 06:39:12","162","50","72","0","49027382","49043984","2018-02-28 10:32:38","-1","358","<p>While insert into one of my table i got following error message:</p>

<p><strong>Cannot assign ""1"": ""Country.intModifiedUser"" must be a ""AppUser"" instance.</strong>   </p>

<pre><code>country_details.intModifiedUser = 1
</code></pre>

<p><em>views.py</em></p>

<pre><code>country_details = Country.objects.get(pk=pk,chrDocumentStatus='N')
country_details.intModifiedUser = 1
country_details.save()
</code></pre>

<p><em>model.py</em></p>

<pre><code>class Country(UpdateLog):
intCountryId = models.BigAutoField(primary_key = True, db_column = 'pk_bint_country_id')
strCountryName = models.CharField('Country Name', db_column = 'vchr_country', max_length = 100, null = False)
strNationality = models.CharField('Nationality', db_column = 'vchr_nationality', max_length = 100, null = True)
chrDocumentStatus = models.CharField('Document Status', db_column = 'chr_document_status', max_length = 1, null = False, default = 'N')
intModifiedUser = models.ForeignKey(AppUser,related_name='%(class)s_modified', db_column= 'fk_bint_modified_user_id', null = True)

class Meta:
    db_table='tbl_country'

class AppUser(AbstractBaseUser,ChangeLog):
   email = models.EmailField(
    verbose_name='email address',
    max_length=255,
    unique=True,
) 

chrUserType = models.CharField('User type code', db_column='chr_user_type',max_length=5,blank=True,null=True)
blnSuperUser = models.BooleanField(default=False, db_column='is_superuser')
intTravelAgencyUserId = models.ForeignKey(TravelAgencyUser,db_column='fk_travel_agency_user_id',default=None)
objects = MyUserManager()

USERNAME_FIELD = 'email'
REQUIRED_FIELDS = []
class Meta:
    db_table='tbl_user'
def is_staff(self):
    return True
def has_module_perms(self, re):
    return self.is_superuser
def has_perm(self, re):
    return self.is_superuser

def get_short_name(self):
    return self.email
</code></pre>
","9088194","9088194","2018-03-01 06:21:42","Django error. Cannot assign must be an instance while insert into table","<python><django-models><django-rest-framework>","1","1","1864"
"49044029","2018-03-01 06:46:08","0","","<p>Because there is a line break in the end of lines when you read the data from <code>.txt</code> file. So you should strip the line break in the first.</p>

<pre><code>from requests import get

def download(url, filename):
    response = get(url, stream = True)
    with open(filename, ""wb"") as file:
        for chunk in response.iter_content(chunk_size=1024):
            if chunk:
                file.write(chunk)
    print('Downloaded! ', filename)

with open('NVD_JSON_SOURCE_URLS.txt') as f:
    for line in f:
        line = line.strip()    
        filename = line.split('/')[-1]
        url = line
        download(url, filename)
</code></pre>
","8381663","","","0","656","BrianChen","2017-07-28 11:35:37","58","11","0","0","49041914","","2018-03-01 02:55:29","1","120","<p>New to python and attempting to download the NIST NVD JSON files. I have tried several methods but it only write about 324 bytes file. If I do one file that does in fact work but there are several files to download for this.</p>

<p>I did try to adjust the chunk_size but still can't get a 1 to 6mb zip file to download</p>

<pre><code>from requests import get

def download(url, filename):
    response = get(url, stream = True)
    with open(filename, ""wb"") as file:
        for chunk in response.iter_content(chunk_size=1024):
            if chunk:
                file.write(chunk)
    print('Downloaded! ', filename)

with open('NVD_JSON_SOURCE_URLS.txt') as f:
    for line in f:    
        filename = line.split('/')[-1]
        url = line
        download(url, filename)
</code></pre>

<p>The input works and it starts the downloads, just never completes them. Clearly I am missing something frustratingly simple here but after 2 days I am not getting any closer. Thanks.</p>
","9426759","8196244","2018-03-01 02:59:21","Python file downloading fails","<python><python-requests>","3","6","988"
"49044066","2018-03-01 06:48:58","0","","<p>Your  <code>''</code> is either <code>None</code> nor <code>NaN</code>:</p>

<pre><code>import math

print(None == '')
print(float('nan')=='')
print(math.isnan(float('nan')))
</code></pre>

<p>Output:</p>

<pre><code>False
False
True
</code></pre>

<p>Doku:   <a href=""https://turi.com/products/create/docs/generated/graphlab.SFrame.dropna.html#graphlab.SFrame.dropna"" rel=""nofollow noreferrer"">dropna()</a></p>

<blockquote>
  <p>Remove missing values from an SFrame. A missing value is either <code>None</code> or <code>NaN</code>.  </p>
</blockquote>

<p>Your value <code>''</code> is neither so it stays.</p>
","7505395","","","1","616","Patrick Artner","2017-02-02 10:46:51","30736","5120","3506","4713","49043922","49044066","2018-03-01 06:37:23","0","28","<p>I'm testing graphlabe create with following</p>

<pre><code>sf=gl.SFrame(['t1','t2','','t3','','t4'])
sf.dropna()
</code></pre>

<p>accoding to <a href=""https://turi.com/products/create/docs/generated/graphlab.SFrame.dropna.html#graphlab.SFrame.dropna"" rel=""nofollow noreferrer"">graphlab api</a></p>

<p>the above should remove empty values(na), but actually it does not, and no errors given either. anyone knows why? </p>
","1015633","","","graphlab create dropna does not work","<python><python-3.x><python-2.7><graphlab>","1","0","426"
"49044079","2018-03-01 06:49:42","1","","<p>Get the list of all distance from the input, then sort it</p>

<p>Tested in Python3</p>

<pre><code>from operator import itemgetter 

# Use raw_input() with Python 2
lat = float(input(""Latitude:""))
lon = float(input(""Longitude:""))

distances = (distance(v['lat'],v['lon'],lat,lon) for v in sdata)
for lat_lng, d in sorted(zip(sdata, distances), key=itemgetter(1)):
  print(lat_lng['lat'], lat_lng['lon'], d)
</code></pre>

<p>Output </p>

<pre><code>Latitude: 0.0
Longitude: 0.0

37.82 86.142 9668.762962674926
40.42 86.123 9679.445101487952
39.66 87.11 9760.193791714297
38.88 87.251 9769.623036766754
39.78 89.336 9950.802415333788
41.35 90.21 10025.072644640604
</code></pre>
","2308683","","","1","682","cricket_007","2013-04-22 19:10:38","94731","41997","1888","5481","49043009","49044079","2018-03-01 05:12:48","1","82","<p>I have a program that compares a user input of Lat/Lon against a set of Lat/Lon and displays the closest.The code is below and works fine:</p>

<pre><code>#prints out the closest lat and lon
from math import cos, asin, sqrt

#Haversine formula
def distance(lat1, lon1, lat2, lon2):
    p = 0.017453292519943295#degree to radian
    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2
    return 12742 * asin(sqrt(a))#print in km


def closest(data, v):
    return min(data, key=lambda p:   distance(v['lat'],v['lon'],p['lat'],p['lon']))

sdata = [{'lat': 37.82, 'lon': 86.142}, 
        {'lat': 38.88,  'lon': 87.251 }, 
        {'lat': 39.78, 'lon': 89.336},
        {'lat': 40.42, 'lon': 86.123}, 
        {'lat': 41.35,  'lon': 90.21 }, 
        {'lat': 39.66, 'lon': 87.11}]

lat = input(""Latitude:"")
lon = input(""Longitude:"")

cust = {'lat': lat, 'lon':lon}

print(closest(sdata,cust))
</code></pre>

<p>However  I want to display the result in a range i.e Lat/lon from closest to farthest from the list instead of a single Lat/lon output.<br>
<strong>Input</strong>  :<code>lat:40 lon:80</code> <br>
<strong>Output</strong> :<code>{'lat': 40.42, 'lon': 86.123}</code><br>
<strong>Expected Output</strong>: <code>{'lat': 40.42, 'lon': 86.123}, {'lat': 39.78, 'lon': 89.336},  {'lat': 39.66, 'lon': 87.11},{'lat': 41.35,  'lon': 90.21 },{'lat': 38.88,  'lon': 87.251 },{'lat': 37.82, 'lon': 86.142}</code></p>
","","7932273","2018-03-01 06:57:45","Compare Lat/Lon and Display Closest to Farthest in Python","<python>","2","5","1451"
"49044110","2018-03-01 06:52:19","3","","<p>I think you can use re module to search the correct count.</p>

<pre><code>import requests
import re

username_extract = 'lazada_my'

url = 'https://www.instagram.com/'+ username_extract
r = requests.get(url)
m = re.search(r'""followed_by"":\{""count"":([0-9]+)\}', str(r.content))
print(m.group(1))
</code></pre>
","1902886","1902886","2018-03-01 07:01:38","5","313","William Feirie","2012-12-14 03:13:55","424","36","6","1","49043857","49044110","2018-03-01 06:31:30","2","2916","<p>I want to parse a website's followers count with BeautifulSoup. This is what I have so far:</p>

<pre><code>username_extract = 'lazada_my'

url = 'https://www.instagram.com/'+ username_extract
r = requests.get(url)
soup = BeautifulSoup(r.content,'lxml')
f = soup.find('head', attrs={'class':'count'})
</code></pre>

<p>This is the part I want to parse:</p>

<p><a href=""https://i.stack.imgur.com/thnXz.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/thnXz.jpg"" alt=""enter image description here""></a></p>

<p>Something within my soup.find() function is wrong, but I can't wrap my head around it. When returning f, it is empty. Any idea what I am doing wrong?</p>
","9166952","9166952","2018-03-01 06:44:39","Get instagram followers","<python><beautifulsoup><instagram><screen-scraping>","5","1","685"
"49044161","2018-03-01 06:56:00","0","","<p>Try this:</p>

<pre><code>import csv, codecs, cStringIO
import threading


class UnicodeWriter:

    def __init__(self, f, dialect=csv.excel, encoding=""utf-8"", **kwds):
        # Redirect output to a queue
        self.queue = cStringIO.StringIO()
        self.writer = csv.writer(self.queue, dialect=dialect, **kwds)
        self.stream = f
        self.encoder = codecs.getincrementalencoder(encoding)()
        self.lock = threading.RLock()

    def writerow(self, row):
        self.lock.acquire()
        self.writer.writerow([s.encode(""utf-8"") for s in row])
        # Fetch UTF-8 output from the queue ...
        data = self.queue.getvalue()
        data = data.decode(""utf-8"")
        # ... and reencode it into the target encoding
        data = self.encoder.encode(data)
        # write to the target stream
        self.stream.write(data)
        # empty queue
        self.queue.truncate(0)
        self.lock.release()

    def writerows(self, rows):
        self.lock.acquire()
        for row in rows:
            self.writerow(row)
        self.stream.flush()
        self.lock.release()
</code></pre>

<p>And in your file , import this above file, like:</p>

<pre><code>def write_to_csv(file_name, header, numpy_data):
    with open(file_name, ""w"", newline='') as csv_file:
        writer = csv.writer(csv_file, delimiter=',')
        header = [header]
        for line in header:
            writer.UnicodeWriter(line)

        for line in numpy_data:
            if line is None:
                writer.UnicodeWriter(line)
            else:
                writer.UnicodeWriter(line)
</code></pre>
","7531125","","","0","1620","rahul mehra","2017-02-07 20:52:51","297","71","21","10","49043682","","2018-03-01 06:17:50","0","121","<pre><code>def write_to_csv(file_name, header, numpy_data):
    with open(file_name, ""w"", newline='') as csv_file:
        writer = csv.writer(csv_file, delimiter=',')
        header = [header]
        for line in header:
            writer.writerow(line)

        for line in numpy_data:
            if line is None:
                writer.writerow(line)
            else:
                writer.writerow(line)
</code></pre>

<p>I have cells in my excel like this after executing the above code</p>

<pre><code>['Financial Analysis', 'Finance', 'Financial Modeling']
</code></pre>

<p>What I would like is </p>

<pre><code>Financial Analysis, Finance, Financial Modeling
</code></pre>

<p>I tried to do <code>line.strip(""[]"")</code> but then nothing appears in the excel when I do this. </p>

<p>sample of <code>numpy_data</code> is :</p>

<pre><code>[['Financial Analysis', 'Finance', 'Financial Modeling']]
</code></pre>

<p>Thank you</p>
","5327707","7932273","2018-03-01 06:22:51","Strip brackets before writing to csv using writerow","<python>","4","0","942"
"49044162","2018-03-01 06:56:07","0","","<p>In general, if you want to hold something and use it later, your going to want a ""global"" variable.  These go at the start of your script and any function  will be able to utilize it or change it.  </p>

<pre><code>ans = 0

def this_changes_ans():
    ans += 0.75

def use_previous():
    If input == ""Y"":
        ans = ans
    else:
        ans = 0
</code></pre>

<p>Also ..</p>

<pre><code>Ans = print(x + y)
</code></pre>

<p>just... no </p>
","7497210","472495","2018-04-12 12:29:09","2","448","J. Wolfe","2017-01-31 20:44:44","83","46","2","0","49042957","49044162","2018-03-01 05:06:41","0","36","<pre><code>def Use_Last_Answer():
    choose_opt = input('''Do you want to use the previous answer?  (Y/N)''' )
    if choose_opt.upper() == 'Y': #Function for ANS
        x = ANS
        find_fractions_2
    elif choose_opt.upper() == 'N':
        find_fractions()
    else:
        Use_Last_Answer()

def find_fractions(): 
    x = 0 # makes x reset but not necessary
    x = Fraction(input('''Enter (1st) fraction:'''))
    find_fractions_2()

def find_fractions_2():
    operation = input('''
What do you want to do?
Add         (1) (e.g) 1/5 + 1/10 = 3/10
Enter Function number:''')
    if(operation != '1'):
        print(""You must enter a valid operation"")
    else:
        y = Fraction(input('''Enter (2nd) fraction:'''))
        if operation == '1':
            print('''Adding Fractions...''')
            print('{} + {} = '.format(x, y)) 
            ANS = print(x + y)
    Use_Last_Answer()
find_fractions()
</code></pre>

<p>(This isn't the whole code, but just cut down to fit).</p>

<p>I'm trying to make an ANS function which is usually available on calculators by making <code>ANS = (x+y)</code> &lt;- from the previous equation and making a def to see whether ANS is able to become x variable. I separated  <code>def find_functions()</code> into two parts to bypass <code>x = Fraction(input('''Enter (1st) fraction:'''))</code> and go to which operation (e.g) add, subtract etc. making the previous answer the new equations x variable.</p>

<p>But it's not working and when I separate <code>def find_fractions()</code> into the two parts and start a new equation the x variable doesn't carry through to the second part and the x+y doesn't compute. I'm in high school and this is my 5th week of computer science, so I won't know too much jargon.</p>
","9347848","472495","2018-04-12 12:25:26","Trying to insert a previous answer as an x value","<python>","1","2","1768"
"49044171","2018-03-01 06:56:38","2","","<p>Basically you get the base64 string from the odoo. You don't need to modify it just add the <code>data:image/jpeg;base64,</code> content before the base64 string. Now you have to add whole updated string in image tag as below.</p>

<pre><code>&lt;img src=""data:image/jpeg;base64,iVBORw0KGgoAAAANSUhEUgAAAAUA
AAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO
    9TXL0Y4OHwAAAABJRU5ErkJggg=="" alt=""Red dot"" /&gt;
</code></pre>

<p>Also Check this <a href=""https://jsfiddle.net/Xadvz/7883/"" rel=""nofollow noreferrer"">https://jsfiddle.net/Xadvz/7883/</a> example in which I have created image from the base64 string of demo product ""Ink Cartridge"" for further reference.</p>

<p>I hope this will help you!</p>
","5063736","","","2","721","PyMaster","2015-06-30 03:53:41","410","40","3","1","49038670","49044171","2018-02-28 21:13:57","0","426","<p>I am trying to retrieve image from XMLRPC.</p>

<p>I do:</p>

<pre class=""lang-py prettyprint-override""><code>record = api.execute_kw(db, uid, pwd, 'product.template', 'read', [[id]], {'fields': ['id', 'name', 'image']})
sub_record = dict((k, record[0][k]) for k in ('id', 'name', 'image'))
print sub_record['image']
</code></pre>

<p>If I print the image using <code>print sub_record['image']</code> then I get:</p>

<pre><code>[...]
eSYH+sOdc3UW9XB1SzWvVCtcI0PfKdoYe9Suf/3116+mMGyhLTg/yedEprt6nOI3eNOxT9t6SzMN
Cj8tT5Lp9eqmsvmu1reytnROwdFvdWvkwsLihqqJ0+49ZW8nu9tzDb+RkT2f5tWpjpf8yZaJzyYW
SPN8f22Vnp9pr+mA7KzqwltQk8QGT02ViY6bpvBdTZqJH5uafxJcHFzPp8nB6KTYUlMq4jS3mAkm
[...]
</code></pre>

<p>So basically several carriage returns are inserted in the middle of the image base64 string.</p>

<p>How can I use that string to display it in an <code>&lt;img&gt;</code> html tag?</p>

<p>Do I have to remove these carriage returns first? </p>
","5328289","","","Odoo 10 XMLRPC - Retrieve Image","<python><xml-rpc><odoo>","2","0","938"
"49044172","2018-03-01 06:56:40","0","","<p>you can save the <strong>base64</strong> data into image using code.</p>

<pre><code>rec = models.execute_kw(db, uid, password, 'product.template', 'read', [[id]], {'fields': ['id', 'name', 'image']})
img_data = rec[0]['image']
data_id = rec[0]['id']
fh = open(""/tmp/product_image-%d.png"" %(data_id), ""wb"") #you can use imghdr to identify the image type
decoded = img_data.decode('base64')
fh.write(decoded)
fh.close()
</code></pre>

<p>and after that you can write yout code to use the file path in <strong></strong> tag.</p>
","1312904","","","2","530","Atul Arvind","2012-04-04 13:00:32","11191","858","591","10","49038670","49044171","2018-02-28 21:13:57","0","426","<p>I am trying to retrieve image from XMLRPC.</p>

<p>I do:</p>

<pre class=""lang-py prettyprint-override""><code>record = api.execute_kw(db, uid, pwd, 'product.template', 'read', [[id]], {'fields': ['id', 'name', 'image']})
sub_record = dict((k, record[0][k]) for k in ('id', 'name', 'image'))
print sub_record['image']
</code></pre>

<p>If I print the image using <code>print sub_record['image']</code> then I get:</p>

<pre><code>[...]
eSYH+sOdc3UW9XB1SzWvVCtcI0PfKdoYe9Suf/3116+mMGyhLTg/yedEprt6nOI3eNOxT9t6SzMN
Cj8tT5Lp9eqmsvmu1reytnROwdFvdWvkwsLihqqJ0+49ZW8nu9tzDb+RkT2f5tWpjpf8yZaJzyYW
SPN8f22Vnp9pr+mA7KzqwltQk8QGT02ViY6bpvBdTZqJH5uafxJcHFzPp8nB6KTYUlMq4jS3mAkm
[...]
</code></pre>

<p>So basically several carriage returns are inserted in the middle of the image base64 string.</p>

<p>How can I use that string to display it in an <code>&lt;img&gt;</code> html tag?</p>

<p>Do I have to remove these carriage returns first? </p>
","5328289","","","Odoo 10 XMLRPC - Retrieve Image","<python><xml-rpc><odoo>","2","0","938"
"49044226","2018-03-01 06:59:53","0","","<p>You have to look for the <code>scripts</code>, Then look for the <code>'window._sharedData'</code> exits in it. If exits then perform the regular expression operation. </p>

<pre><code>import re

username_extract = 'lazada_my'
url = 'https://www.instagram.com/'+ username_extract
r = requests.get(url)
soup = BeautifulSoup(r.content,'lxml')
s = re.compile(r'""followed_by"":{""count"":\d*}')
for i in soup.find_all('script'):
     if 'window._sharedData' in str(i):
         print s.search(str(i.contents)).group()
</code></pre>

<p><strong>Result,</strong></p>

<pre><code>""followed_by"":{""count"":407426}
</code></pre>
","4407666","","","0","618","Rahul K P","2014-12-31 07:18:54","8206","903","675","167","49043857","49044110","2018-03-01 06:31:30","2","2916","<p>I want to parse a website's followers count with BeautifulSoup. This is what I have so far:</p>

<pre><code>username_extract = 'lazada_my'

url = 'https://www.instagram.com/'+ username_extract
r = requests.get(url)
soup = BeautifulSoup(r.content,'lxml')
f = soup.find('head', attrs={'class':'count'})
</code></pre>

<p>This is the part I want to parse:</p>

<p><a href=""https://i.stack.imgur.com/thnXz.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/thnXz.jpg"" alt=""enter image description here""></a></p>

<p>Something within my soup.find() function is wrong, but I can't wrap my head around it. When returning f, it is empty. Any idea what I am doing wrong?</p>
","9166952","9166952","2018-03-01 06:44:39","Get instagram followers","<python><beautifulsoup><instagram><screen-scraping>","5","1","685"
"49044244","2018-03-01 07:00:52","0","","<pre><code>for index, row in df_price.iterrows():
    try:        
        prod_weight= prod_data.loc[prod_data['sku'] == row['sku']]['weight'].item()
    except:
        prod_weight= prod_data.loc[prod_data['sku'] == row['sku']]['weight']
</code></pre>

<p>TRY this.</p>

<p>The error <code>ValueError: can only convert an array of size 1 to a Python scalar</code> is because .item() works only on series/dataframe datatypes. and if you try to do any scalar.item()  it will throw this error</p>
","6803114","","","0","496","Shubham","2016-09-07 05:36:45","2186","388","266","25","49042729","","2018-03-01 04:40:00","-1","122","<p>I am currently a Python self-educating beginner.  </p>

<pre><code>for index, row in df_price.iterrows():                    
    prod_weight = prod_weight = prod_data.loc[prod_data['sku'] == row['sku']]['weight'].item
</code></pre>

<p>------result --------------------------------------</p>

<pre><code>&lt;bound method IndexOpsMixin.item of 18066    0.2
Name: weight, dtype: float64&gt;
&lt;bound method IndexOpsMixin.item of 18063    0.1
Name: weight, dtype: float64&gt;
&lt;bound method IndexOpsMixin.item of 18064    0.1
Name: weight, dtype: float64&gt;
&lt;bound method IndexOpsMixin.item of Series([], Name: weight, dtype: float64)&gt;
&lt;bound method IndexOpsMixin.item of 18062    0.1
Name: weight, dtype: float64&gt;
&lt;bound method IndexOpsMixin.item of 18058    0.1
Name: weight, dtype: float64&gt;
&lt;bound method IndexOpsMixin.item of 18059    0.1

---------------------------------------------------------
</code></pre>

<p>The result I want is:</p>

<pre><code>1.0
0.2
0.1
0.1
0.1
0.1
0.1
...
0.5
0.6
0.3
</code></pre>

<p>so,I changed the code as follows.</p>

<pre><code>prod_weight = prod_data.loc[prod_data['sku'] == row['sku']]['weight'].item()
</code></pre>

<p>-------------result--------------------------------</p>

<pre><code>1.0
0.2
0.1
0.1
0.1
0.1
0.1
...
0.5
0.6
0.3
</code></pre>

<blockquote>
  <p>Traceback (most recent call last):
        File ""D:/python_project/price_reviser/price_reviser.py"", line 58, in 
          prod_weight = prod_data.loc[prod_data['sku'] == row['sku']]['weight'].item()
        File ""C:\Users\tlsdy\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\base.py"",
  line 719, in item
          return self.values.item()
      ValueError: can only convert an array of size 1 to a Python scalar</p>
</blockquote>

<p>So I changed the code again as shown below.</p>

<pre><code>prod_weight = prod_data.loc[prod_data['sku'] == row['sku']]['weight'].values

-------------result--------------------------------
[1.0]
[0.2]
[0.1]
[0.1]
[0.1]
[0.1]
[0.1]
...
[0.5]
[0.6]
[0.3]
</code></pre>

<p>So I changed the code again as shown below.</p>

<pre><code>prod_weight = re.sub('\[|''\]|''\'|', '', str(prod_data.loc[prod_data['sku'] == row['sku']]['weight'].values))
</code></pre>

<p>--------------result-------</p>

<pre><code>1.
0.2
0.1
0.1
0.1
0.1
0.1
...
0.5
0.6
0.3
</code></pre>

<p>but, </p>

<pre><code>1.0 --&gt; 1.
2.0 --&gt; 2.
</code></pre>

<p>How can I extract it properly?
How can I extract it properly?
How can I extract it properly?
How can I extract it properly?
How can I extract it properly? </p>
","9185909","4729967","2018-03-01 05:17:24","dataframe Can I extract the pure values in the list properly?","<python><pandas><dataframe><slice>","1","3","2589"
"49044250","2018-03-01 07:01:02","0","","<p>You can also do it in one line.</p>

<pre><code>cust = {'lat': 40, 'lon': 80}
out = sorted(sdata, key=lambda data: distance(data['lat'], data['lon'], cust['lat'], cust['lon']))
print(out)
</code></pre>

<p>Output:</p>

<pre><code>[{'lat': 40.42, 'lon': 86.123}, {'lat': 37.82, 'lon': 86.142}, {'lat': 39.66, 'lon': 87.11}, {'lat': 38.88, 'lon': 87.251}, {'lat': 39.78, 'lon': 89.336}, {'lat': 41.35, 'lon': 90.21}]
</code></pre>
","3494669","","","1","432","pe-pe-rry","2014-04-03 16:21:17","1824","199","871","21","49043009","49044079","2018-03-01 05:12:48","1","82","<p>I have a program that compares a user input of Lat/Lon against a set of Lat/Lon and displays the closest.The code is below and works fine:</p>

<pre><code>#prints out the closest lat and lon
from math import cos, asin, sqrt

#Haversine formula
def distance(lat1, lon1, lat2, lon2):
    p = 0.017453292519943295#degree to radian
    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2
    return 12742 * asin(sqrt(a))#print in km


def closest(data, v):
    return min(data, key=lambda p:   distance(v['lat'],v['lon'],p['lat'],p['lon']))

sdata = [{'lat': 37.82, 'lon': 86.142}, 
        {'lat': 38.88,  'lon': 87.251 }, 
        {'lat': 39.78, 'lon': 89.336},
        {'lat': 40.42, 'lon': 86.123}, 
        {'lat': 41.35,  'lon': 90.21 }, 
        {'lat': 39.66, 'lon': 87.11}]

lat = input(""Latitude:"")
lon = input(""Longitude:"")

cust = {'lat': lat, 'lon':lon}

print(closest(sdata,cust))
</code></pre>

<p>However  I want to display the result in a range i.e Lat/lon from closest to farthest from the list instead of a single Lat/lon output.<br>
<strong>Input</strong>  :<code>lat:40 lon:80</code> <br>
<strong>Output</strong> :<code>{'lat': 40.42, 'lon': 86.123}</code><br>
<strong>Expected Output</strong>: <code>{'lat': 40.42, 'lon': 86.123}, {'lat': 39.78, 'lon': 89.336},  {'lat': 39.66, 'lon': 87.11},{'lat': 41.35,  'lon': 90.21 },{'lat': 38.88,  'lon': 87.251 },{'lat': 37.82, 'lon': 86.142}</code></p>
","","7932273","2018-03-01 06:57:45","Compare Lat/Lon and Display Closest to Farthest in Python","<python>","2","5","1451"
"49044263","2018-03-01 07:02:17","0","","<p>I came across this problem too. I think you should wait for </p>

<pre><code>pexpect.expect('100%')
</code></pre>

<p>possibly with a timeout. sftp seems to have asynchronous command line interface so it returns right away to the prompt while the transfer continues. Timeout is more or less relevant here since the file is truncated because the script exits while downloads are still ongoing / pending.</p>
","6367","","","0","410","Eric","2008-09-14 21:53:42","14120","1452","1219","47","32363948","","2015-09-02 22:07:15","1","501","<p>I am currently trying to use pexpect to transfer files. It usually works fine, but recently it has been causing issues by not transferring entire files. It either truncates the file transfer or the script moves on before it is done. </p>

<p>My code is as follows:</p>

<pre><code>job_id = str(job_record['control']['id'])
self.px_ssh.sendline('cd ' + self.remotePath + job_id)
self.px_ssh.prompt()
self.px_ssh.sendline('ls')
self.px_ssh.prompt()
remote_files = self.px_ssh.before.decode('utf-8')
for cop in outfiles:
  if cop in remote_files:
    print('Transferring file _from_ remote cluster:   ' + cop)
    self.px_ftp.sendline('get ' + self.remotePath + job_id + '/' + cop + ' ' + os.getcwd())
    self.px_ftp.expect('sftp&gt;', timeout=None)
</code></pre>

<p>And the logfile:</p>

<pre><code>get path/QMCDB/Elemental/As/As_QMC_2x2x2/prop.in.o    path/Documents/Research/QMCDB/Runs/Elemental/As/As_QMC_2x2x2
Connected to taub.campuscluster.illinois.edu.
sftp&gt; get path/QMCDB/Elemental/As/As_QMC_2x2x2/prop.in.o path/Documents/Research/QMCDB/Runs/Elemental/As/As_QMC_2x2x2
Fetching path/QMCDB/Elemental/As/As_QMC_2x2x2/prop.in.o to path/Documents/Research/QMCDB/Runs/Elemental/As/As_QMC_2x2x2/prop.in.o

path/QMCDB/Elemental/As/As_   0%    0     0.0KB/s   --:-- ETA
path/QMCDB/Elemental/As/As_   0%   11MB  11.1MB/s   02:32 ETA
path/QMCDB/Elemental/As/As_   1%   22MB  11.1MB/s   02:31 ETA
</code></pre>

<p>It can be seen that it just moves on after a short time. I am not sure why it does this. Do you have any idea how to ensure the whole file is transferred before the rest of my code progresses?</p>
","5117019","","","SFTP not completing file transfer when using pexpect (python)","<python><sftp><pexpect>","1","2","1616"
"49044272","2018-03-01 07:02:43","1","","<p>Most of the content is dynamically generated with JS. That's the reason you're getting empty results.</p>

<p>But, the <code>followers</code> count is present in the page source. Only thing is, it is not directly available in the form you want. You can see it here:</p>

<pre><code>&lt;meta content=""407.4k Followers, 27 Following, 2,740 Posts - See Instagram photos and videos from Lazada Malaysia (@lazada_my)"" name=""description"" /&gt;
</code></pre>

<p>If you want to scrape the followers count without regex, you can use this:</p>

<pre><code>&gt;&gt;&gt; followers = soup.find('meta', {'name': 'description'})['content']
&gt;&gt;&gt; followers
'407.4k Followers, 27 Following, 2,740 Posts - See Instagram photos and videos from Lazada Malaysia (@lazada_my)'
&gt;&gt;&gt; followers_count = followers.split('Followers')[0]
&gt;&gt;&gt; followers_count
'407.4k '
</code></pre>
","7832176","7832176","2018-03-01 07:08:07","0","882","Keyur Potdar","2017-04-07 10:33:50","5988","1260","1872","985","49043857","49044110","2018-03-01 06:31:30","2","2916","<p>I want to parse a website's followers count with BeautifulSoup. This is what I have so far:</p>

<pre><code>username_extract = 'lazada_my'

url = 'https://www.instagram.com/'+ username_extract
r = requests.get(url)
soup = BeautifulSoup(r.content,'lxml')
f = soup.find('head', attrs={'class':'count'})
</code></pre>

<p>This is the part I want to parse:</p>

<p><a href=""https://i.stack.imgur.com/thnXz.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/thnXz.jpg"" alt=""enter image description here""></a></p>

<p>Something within my soup.find() function is wrong, but I can't wrap my head around it. When returning f, it is empty. Any idea what I am doing wrong?</p>
","9166952","9166952","2018-03-01 06:44:39","Get instagram followers","<python><beautifulsoup><instagram><screen-scraping>","5","1","685"
"49044274","2018-03-01 07:02:53","2","","<p>Create <code>MultiIndex</code> by <code>split</code> and then is possible use <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.stack.html"" rel=""nofollow noreferrer""><code>stack</code></a>:</p>

<pre><code>df.columns = df.columns.str.split('_', expand=True)
df = df.stack().reset_index(level=0, drop=True)
print (df)
   max  min
a    5    3
b    9    1
</code></pre>

<p><strong>Setup</strong>:</p>

<pre><code>original = """"""
min_a max_a min_b max_b
3 5 1 9
""""""
df = pd.read_csv(pd.compat.StringIO(original), sep=""\s+"")
print (df)
   min_a  max_a  min_b  max_b
0      3      5      1      9
1      4      6      2     10
</code></pre>
","2901002","2901002","2018-03-01 07:06:46","0","668","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49044235","49044274","2018-03-01 07:00:23","1","122","<p>I have a CSV file which contains <code>min</code> and <code>max</code> values for each variable like this:</p>

<pre><code>original = """"""
min_a max_a min_b max_b
3 5 1 9
""""""
</code></pre>

<p>The first row is sorted in variable names, so it is guaranteed that it goes from <code>min_a</code> to <code>max_z</code>. I want to reshape/melt it in chunks like so:</p>

<pre><code>goal = """"""
 min max
a 3 5
b 1 9
""""""
</code></pre>

<p>How can I do that? I feel like <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html"" rel=""nofollow noreferrer"">pandas.melt</a> or a numpy method can be used here, but couldn't figure out how. My current ""hack"" is to reshape the second row of values as follows, and copy-paste or write the result into CSV:</p>

<pre><code>orig = ""3 5 1 9""
temp = orig.split()
chopped = ["" "".join(temp[i:i+2]+[""\n""]) for i in range(0,3,2)]
# chopped: ['3', '5', '1', '9']
ready = ["" min max \n""] + ["" "".join(e) for e in zip(['a','b'],chopped)]
# ready: [' min max \n', 'a 3 5 \n', 'b 1 9 \n']
flipped = """".join(ready)
# flipped: ' min max \na 3 5 \nb 1 9 \n'
print(flipped)
# Result:
#  min max
# a 3 5 
# b 1 9 
</code></pre>

<p>Is there a proper way of doing this? Thanks!</p>
","6520041","","","How to chop and reshape/melt a table or CSV file","<python><string><pandas><csv><numpy>","1","0","1223"
"49044292","2018-03-01 07:04:20","1","","<pre><code>    if train[col].dtype == 'object':
      train[col] = train[col].fillna(train[col].mode().iloc[0])
</code></pre>

<p>You can fill this types of NaN value by replacing with the mean value in this colums. i think this will solve the error.</p>
","7205164","","","0","255","Taimur Islam","2016-11-24 12:19:06","352","149","48","0","48852824","","2018-02-18 14:36:58","0","810","<p>There are 14 columns of data and approximately 1,011,052 rows. About ten rows are skipped when reading the CSV (with the error being: Error tokenizing data. C error: Expected 14 fields in line &lt;...>, saw 15). Using <code>data.apply(LabelEncoder().fit_transform)</code> to convert strings to floats for use in <code>scikit-learn.fit(...)</code>. Use of <code>data.apply(LabelEncoder().fit_transform)</code> is suggested here (<a href=""https://stackoverflow.com/a/31939145/2178774"">https://stackoverflow.com/a/31939145/2178774</a>). (<em>Edit:</em> Note that 670 is the first value.)</p>

<pre><code>data = pd.read_csv('./dm.csv',error_bad_lines=False)

print(X.shape,y.shape)

(1011052, 13) (1011052, 1)

data.apply(LabelEncoder().fit_transform)

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-18-9734848fb589&gt; in &lt;module&gt;()
     19 # y is now: array([2, 0, 1, 3, 2, 0, 1, 3])
     20 
---&gt; 21 data.apply(LabelEncoder().fit_transform)
     22 # TypeError: (""'&gt;' not supported between instances of 'int' and 'str'"", 'occurred at index 670')
     23 

/usr/lib64/python3.6/site-packages/pandas/core/frame.py in apply(self, func, axis, broadcast, raw, reduce, args, **kwds)
   4358                         f, axis,
   4359                         reduce=reduce,
-&gt; 4360                         ignore_failures=ignore_failures)
   4361             else:
   4362                 return self._apply_broadcast(f, axis)

/usr/lib64/python3.6/site-packages/pandas/core/frame.py in _apply_standard(self, func, axis, ignore_failures, reduce)
   4454             try:
   4455                 for i, v in enumerate(series_gen):
-&gt; 4456                     results[i] = func(v)
   4457                     keys.append(v.name)
   4458             except Exception as e:

/usr/lib64/python3.6/site-packages/sklearn/preprocessing/label.py in fit_transform(self, y)
    110         """"""
    111         y = column_or_1d(y, warn=True)
--&gt; 112         self.classes_, y = np.unique(y, return_inverse=True)
    113         return y
    114 

/usr/lib64/python3.6/site-packages/numpy/lib/arraysetops.py in unique(ar, return_index, return_inverse, return_counts)
    209 
    210     if optional_indices:
--&gt; 211         perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
    212         aux = ar[perm]
    213     else:

TypeError: (""'&gt;' not supported between instances of 'int' and 'str'"", 'occurred at index 670')
</code></pre>

<p><strong>Edit:</strong>
On <code>read_csv</code> there is the following output: 
    <code>/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.</code>
    <code>interactivity=interactivity, compiler=compiler, result=result)</code></p>

<p><strong>Edit:</strong>
Added dtype={...} to read_csv, which now results in the type error: <code>TypeError: (""'&gt;' not supported between instances of 'str' and 'int'"", 'occurred at index 0')</code>.</p>

<pre><code>data = pd.read_csv('./dm.csv',error_bad_lines=False,header=None,dtype={
  0: np.dtype('u8'), # 64-bit unsigned integer
  1: np.dtype('u4'), # 32-bit unsigned integer
  2: np.dtype('U'),  # unicode
  3: np.dtype('U'),  # unicode
  4: np.dtype('U'),  # unicode
  5: np.dtype('U'),  # unicode
  6: np.dtype('u2'), # 16-bit unsigned integer
  7: np.dtype('U'),  # unicode
  8: np.dtype('U'),  # unicode
  9: np.dtype('f2'), # 16-bit floating point
  10:np.dtype('U'),  # unicode
  11:np.dtype('U'),  # unicode
  12:np.dtype('f4'), # 32-bit floating point
  13:np.dtype('U')   # unicode
})
</code></pre>

<p><strong>Edit:</strong> The type error occurs when using two rows of data. It occurs in the eighth column. Row1 Column8 is ""GHI789"". Row2 Column8 is ""NaN"".</p>

<pre><code>X = data.iloc[0:2,0:14]
print(X)
print('--------')
for col in X.columns:
    print(col)
    print(X.dtypes[col])
    if X.dtypes[col] == ""object"":
        le = LabelEncoder()
        le.fit_transform(X[col])
        X[col] = le.transform(X[col])
</code></pre>

<p>Output:</p>

<pre><code>     0      1           2   \
0  100  138.0  2017-12-31   
1  101   13.0  2017-12-31   

        3         4   \
0  Title1    ABC123   
1  Title2    ABC123

       5    6        7   \
0  User1  0.0   DEF456
1  User2  0.0   DEF456

        8    9      10  \
0  GHI789  0.0  XYZ123   
1     NaN  0.0  XYZ123

        11   12   13  
0  Title11  0.0  NaN  
1  Title22  0.0  NaN  

--------

0
object
1
float64
2
object
3
object
4
object
5
object
6
float64
7
object
8
object

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-70-c94173863fd7&gt; in &lt;module&gt;()
     29     if X.dtypes[col] == ""object"":
     30         le = LabelEncoder()
---&gt; 31         le.fit_transform(X[col])
     32         X[col] = le.transform(X[col])

/usr/lib64/python3.6/site-packages/sklearn/preprocessing/label.py in fit_transform(self, y)
    110         """"""
    111         y = column_or_1d(y, warn=True)
--&gt; 112         self.classes_, y = np.unique(y, return_inverse=True)
    113         return y
    114 

/usr/lib64/python3.6/site-packages/numpy/lib/arraysetops.py in unique(ar, return_index, return_inverse, return_counts)
    209 
    210     if optional_indices:
--&gt; 211         perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')
    212         aux = ar[perm]
    213     else:

TypeError: '&gt;' not supported between instances of 'float' and 'str'
</code></pre>

<p><strong>Edit:</strong> <em>Solution?:</em> ""NaN"" mixed with strings is an issue. Solution is then to replace ""NaN"" with an empty string. Such as: <code>data = data.replace(np.nan, '', regex=True)</code>.</p>

<p><strong>Edit:</strong> Just noticed two issues with column 9. One: About two-hundred rows were empty string, causing str to float issue. Two: Another large set were the str ""0"", which was parsed as either an int or str, again causing str to float issue. In the second case, a fix is the perform the following: <code>data[9] = data[9].replace('^0$', 0.0, regex=True)</code>.</p>
","2178774","2178774","2018-02-18 21:12:32","sklearn.preprocessing.LabelEncoder TypeError on data set","<python><pandas><scikit-learn>","2","0","6316"
"49044294","2018-03-01 07:04:30","2","","<p><code>soup.find('head', attrs={'class':'count'})</code> searches for something that looks like <code>&lt;head class=""count""&gt;</code>, which doesn't exist anywhere in the HTML. The data you're after is contained in the <code>&lt;script&gt;</code> tag that starts with <code>window._sharedData</code>:</p>

<pre><code>script = soup.find('script', text=lambda t: t.startswith('window._sharedData'))
</code></pre>

<p>From there, you can just strip off the variable assignment and the semicolon to get valid JSON:</p>

<pre><code># &lt;script&gt;window._sharedData = ...;&lt;/script&gt;
#                              ^^^
#                              JSON

page_json = script.text.split(' = ', 1)[1].rstrip(';')
</code></pre>

<p>Parse it and everything you need is contained in the object:</p>

<pre><code>import json

data = json.loads(page_json)
follower_count = data['entry_data']['ProfilePage'][0]['user']['followed_by']['count']
</code></pre>
","464744","","","0","952","Blender","2010-10-02 17:47:48","223387","26068","2924","740","49043857","49044110","2018-03-01 06:31:30","2","2916","<p>I want to parse a website's followers count with BeautifulSoup. This is what I have so far:</p>

<pre><code>username_extract = 'lazada_my'

url = 'https://www.instagram.com/'+ username_extract
r = requests.get(url)
soup = BeautifulSoup(r.content,'lxml')
f = soup.find('head', attrs={'class':'count'})
</code></pre>

<p>This is the part I want to parse:</p>

<p><a href=""https://i.stack.imgur.com/thnXz.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/thnXz.jpg"" alt=""enter image description here""></a></p>

<p>Something within my soup.find() function is wrong, but I can't wrap my head around it. When returning f, it is empty. Any idea what I am doing wrong?</p>
","9166952","9166952","2018-03-01 06:44:39","Get instagram followers","<python><beautifulsoup><instagram><screen-scraping>","5","1","685"
"49044377","2018-03-01 07:10:49","0","","<p>You can use the following command on the command prompt (<strong>cmd</strong>) on <strong>Windows</strong>:</p>

<pre><code>py -3.3 -m pip install opencv-python
</code></pre>

<p>I made a <strong>video</strong> on how to install OpenCV Python on Windows in <strong>1 minute</strong> here:</p>

<p><a href=""https://www.youtube.com/watch?v=m2-8SHk-1SM"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=m2-8SHk-1SM</a></p>

<p><em>Hope it helps!</em></p>
","4398784","","","0","464","Geraldo Neto","2014-12-27 23:29:30","2396","110","335","5","20953273","21212023","2014-01-06 15:29:14","57","111653","<p>Is OpenCV still not available for Python 3.3 and do I really have to downgrade to Python 2.7 to use it? I didn't find much about it on the internet, only some posts from 2012 that OpenCV wasn't yet ported to be used in Python 3.x. But now it's 2014 and after trying to install the latest OpenCV 2.4.x and copying the <code>cv2.pyd</code> file to <em>C:\Program Files (x86)\Python333\Lib\site-packages</em> this still yields the error in Python IDLE:</p>

<pre><code>&gt;&gt;&gt; import cv2
Traceback (most recent call last):
  File ""&lt;pyshell#0&gt;"", line 1, in &lt;module&gt;
    import cv2
ImportError: DLL load failed: %1 ist keine zulässige Win32-Anwendung.
</code></pre>
","701049","","","Install opencv for Python 3.3","<python><opencv><python-3.x>","13","4","681"
"49044440","2018-03-01 07:14:20","1","","<pre><code>try:
    import copy_reg
except:
    import copyreg as copy_reg
</code></pre>
","8756315","","","2","89","Sunnysinh Solanki","2017-10-11 03:50:15","448","51","19","4","49044133","","2018-03-01 06:54:09","1","1259","<p>I have a git submodule that has this line</p>

<pre><code>import copy_reg
</code></pre>

<p>It works for Python 2.
However, there is no module named <strong>copy_reg</strong> in Python3.
The Python3 module name is <strong>copyreg</strong>.</p>

<p>I cannot change code in the git submodule since it will break in future updates.
How to make the code work for both Python2 and Python3 without modifying module's code.</p>
","9427375","","","No module named copy_reg in python3","<python><python-3.x><git-submodules><python-2.x>","1","0","424"
"49044441","2018-03-01 07:14:23","3","","<p>Strictly speaking, <code>list</code> is not a subclass of <code>typing.List</code>. To see what <code>list</code> is actually a subclass of, you can take a look at its <a href=""https://www.python.org/download/releases/2.3/mro/"" rel=""nofollow noreferrer"">MRO</a>:</p>

<pre><code>&gt;&gt;&gt; list.__mro__
(&lt;class 'list'&gt;, &lt;class 'object'&gt;)
</code></pre>

<p>On the other hand, the MRO of <code>typing.List</code> shows that it actually is a subclass of <code>list</code>, as well as of many other classes:</p>

<pre><code>&gt;&gt;&gt; typing.List.__mro__
(typing.List, &lt;class 'list'&gt;, typing.MutableSequence, &lt;class 'collections.abc.MutableSequence'&gt;, typing.Sequence, &lt;class 'collections.abc.Sequence'&gt;, typing.Reversible, &lt;class 'collections.abc.Reversible'&gt;, typing.Collection, &lt;class 'collections.abc.Collection'&gt;, &lt;class 'collections.abc.Sized'&gt;, typing.Iterable, &lt;class 'collections.abc.Iterable'&gt;, typing.Container, &lt;class 'collections.abc.Container'&gt;, typing.Generic, &lt;class 'object'&gt;)
</code></pre>

<h2>So, why does Python say that <code>list</code> is a subclass of <code>typing.List</code>?</h2>

<p>Well, that is the whole point of <code>typing.List</code>. To pretend to be a base class of <code>list</code>.</p>

<h2>How is it done?</h2>

<p>Using <em>Abstract Base Classes</em>. See what <a href=""https://docs.python.org/3/glossary.html#term-abstract-base-class"" rel=""nofollow noreferrer"">Python doc</a> says about them:</p>

<blockquote>
  <p>ABCs introduce virtual subclasses, which are classes that don’t
  inherit from a class but are still recognized by isinstance() and
  issubclass(); see the <a href=""https://docs.python.org/3/library/abc.html#module-abc"" rel=""nofollow noreferrer"">abc</a> module documentation.</p>
</blockquote>

<p>You can see from its MRO that <code>typing.List</code> inherits from many ABC's, which list recognizes as its base classes, e.g.:</p>

<pre><code>&gt;&gt;&gt; issubclass(list, collections.abc.MutableSequence)
True
&gt;&gt;&gt; issubclass(list, collections.abc.Collection)
True
&gt;&gt;&gt; issubclass(list, collections.abc.Container)
True
</code></pre>
","389289","","","0","2180","zvone","2010-07-12 08:25:02","11303","980","601","663","49043989","49044441","2018-03-01 06:42:52","3","78","<p>I tested this simple code and find something confuses me. Run the following code in Python 3.6 and both statements returns True. Why?</p>

<pre><code>import typing
print(issubclass(list, typing.List))  # print True
print(issubclass(typing.List, list))  # print True
</code></pre>

<p>Can someone give me some explanation on this?</p>
","637902","1033581","2019-03-30 12:48:38","How come Python3 typing.List is a subclass of list and list is also a subclass of typing.List?","<python><list><typing>","1","1","337"
"49044454","2018-03-01 07:15:22","1","","<p>Try:</p>

<pre><code>def write_to_csv(file_name, header, numpy_data):
    with open(file_name, ""w"", newline='') as csv_file:
        writer = csv.writer(csv_file, delimiter=',')
        header = [header]
        for line in header:
            writer.writerow(line)

        for line in numpy_data:
            if line is None:
                writer.writerow(line)
            else:
                val = ["", "".join(line[0])] + line[1:]  #--&gt; ['Financial Analysis, Finance, Financial Modelling', '5000', 'Company A']
                writer.writerow(val)
</code></pre>
","532312","","","0","575","Rakesh","2010-12-06 13:07:54","56694","5302","758","1508","49043682","","2018-03-01 06:17:50","0","121","<pre><code>def write_to_csv(file_name, header, numpy_data):
    with open(file_name, ""w"", newline='') as csv_file:
        writer = csv.writer(csv_file, delimiter=',')
        header = [header]
        for line in header:
            writer.writerow(line)

        for line in numpy_data:
            if line is None:
                writer.writerow(line)
            else:
                writer.writerow(line)
</code></pre>

<p>I have cells in my excel like this after executing the above code</p>

<pre><code>['Financial Analysis', 'Finance', 'Financial Modeling']
</code></pre>

<p>What I would like is </p>

<pre><code>Financial Analysis, Finance, Financial Modeling
</code></pre>

<p>I tried to do <code>line.strip(""[]"")</code> but then nothing appears in the excel when I do this. </p>

<p>sample of <code>numpy_data</code> is :</p>

<pre><code>[['Financial Analysis', 'Finance', 'Financial Modeling']]
</code></pre>

<p>Thank you</p>
","5327707","7932273","2018-03-01 06:22:51","Strip brackets before writing to csv using writerow","<python>","4","0","942"
"49044499","2018-03-01 07:18:21","1","","<p>In keras use binary_crossentropy for classification problem with 2 class. use categorical_crossentropy for more than 2 classes. </p>

<p>Both are same only.If tensorflow is used as backend for keras then it uses below mentioned function to evaluate binary_crossentropy.</p>

<pre><code>tf.nn.sigmoid_cross_entropy_with_logits(labels=target,
                                                   logits=output)
</code></pre>

<p><strong>In documentation of this function below is mentions:</strong></p>

<p>For brevity, let x = logits, z = labels. The logistic loss is</p>

<p>z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))</p>
","8756315","8756315","2018-03-01 07:26:46","0","634","Sunnysinh Solanki","2017-10-11 03:50:15","448","51","19","4","49044398","","2018-03-01 07:11:50","2","648","<p>I want to use a logistic loss cost function for my deep learning model to solve a binary classification problem. I am using keras to build the model. However, keras doesn't have any pre-defined logistic <a href=""https://keras.io/losses/"" rel=""nofollow noreferrer"">loss function</a>.</p>

<p>While reading about loss functions I came across confusing statements about cross entropy loss and logistic loss.
In this wikipedia <a href=""https://en.wikipedia.org/wiki/Loss_functions_for_classification"" rel=""nofollow noreferrer"">article</a>, there is a separate section for logistic loss and cross entropy loss.</p>

<p>However in this wikipedia <a href=""https://en.wikipedia.org/wiki/Cross_entropy"" rel=""nofollow noreferrer"">article</a>, its mentioned that:</p>

<blockquote>
  <p>The logistic loss is sometimes called cross-entropy loss.</p>
</blockquote>

<p>Additionally, this sklearn <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html"" rel=""nofollow noreferrer"">page</a> starts with:</p>

<blockquote>
  <p>Log loss, aka logistic loss or cross-entropy loss.</p>
</blockquote>

<p>Any help would be appreciated.</p>
","3467353","","","Is there any difference between cross entropy loss and logistic loss?","<python><deep-learning><keras><loss-function>","1","1","1154"
"49044500","2018-03-01 07:18:28","1","","<p>Assuming that the issue you get is that flask does not see your service it looks like nothing is importing your service code once you split your code.</p>

<p>Simply modify your <em>main.py</em> file to look like this to fix it:</p>

<pre><code>from api.restplus import app

import api.endpoints.service

if __name__ == '__main__':
    app.run(host='127.0.0.1', port=8080, debug=True)
</code></pre>

<p>Hope this helps !</p>
","9407999","","","1","428","Jean-Sébastien Gélinas","2018-02-25 06:05:26","46","0","0","0","49044284","49044500","2018-03-01 07:03:43","-1","50","<p>I am trying to build some restful API's. When I try to segregate code into packages the service doesn't work and I get <em>URL not found on the server.</em> For examples:</p>

<p><strong>Scenario 1</strong> [Works fine as I have everything in main.py]</p>

<pre><code>from flask import Flask, jsonify, request

app = Flask(__name__)

@app.route('/echo', methods=['POST'])
def echo():
    message = request.get_json().get('message', '')
    return jsonify({'message': message})

if __name__ == '__main__':
    app.run(host='127.0.0.1', port=8080, debug=True)
</code></pre>

<p>Now when I try to segregate the code into different packages, it just doesn't work. For example:</p>

<p><strong>Scenario 2</strong> [Doesn't work as the code is in different packages]</p>

<p>I am initializing the app in <em>api/restful.py</em></p>

<pre><code>from flask import Flask, jsonify, request
app = Flask(__name__)
</code></pre>

<p>Then created a service in <em>api/endpoints/service.py</em></p>

<pre><code>from api.restplus import app, jsonify, request

@app.route('/echo', methods=['POST'])
def echo():
    message = request.get_json().get('message', '')
    return jsonify({'message': message})
</code></pre>

<p>Finally in <em>main.py</em></p>

<pre><code>from api.restplus import app

if __name__ == '__main__':
   app.run(host='127.0.0.1', port=8080, debug=True)
</code></pre>

<p>It seems like the service is not visible to the app when I put it in a different package. Please advise.</p>
","8323260","2308683","2018-03-01 07:10:59","python code doesn't work when I segregate into packages | works fine in same file","<python><flask>","2","4","1488"
"49044502","2018-03-01 07:18:35","2","","<p>I found the solution! The problem was that even though a document could miss any of the displayText, displayTitle, tags or displayUrl fields, still all three of UpdateExpression, ConditionExpression and ExpressionAttributeValues were considering those fields for the document. The solution is to construct them for each document separately based on the fields present in the document.</p>

<pre><code>def send_docs_to_DynamoDB(Docs):
    dynamodb = boto3.resource('dynamodb')
    table = dynamodb.Table('Compete_Dental_Incoming_Data')
    print(""Sending documents to DynamoDB..."")

    for item in Docs:
            expression_attribute_values={
                    "":time"":item[""publication_timestamp""],
                    "":ttl"":item[""time_to_live""],
                    "":p"":item[""producer""]
            }
            update_expression=""SET publication_timestamp = :time, producer = :p, time_to_live= if_not_exists(time_to_live, :ttl)""
            condition_expression= ""publication_timestamp &lt;&gt; :time OR producer &lt;&gt; :p""
            try:
                    if 'displayTitle' in item.keys():
                            update_expression+="", displayTitle= :title""
                            expression_attribute_values["":title""]=item[""displayTitle""]
                            condition_expression+="" OR displayTitle &lt;&gt; :title""
                    if 'displayText' in item.keys():
                            update_expression+="", displayText= :text""
                            expression_attribute_values["":text""]=item[""displayText""]
                            condition_expression+="" OR displayText &lt;&gt; :text""
                    if 'displayUrl' in item.keys():
                            update_expression+="", displayUrl= :url""
                            expression_attribute_values["":url""]=item[""displayUrl""]
                            condition_expression+="" OR displayUrl &lt;&gt; :url""
                    if 'tags' in item.keys():
                            update_expression+="", tags= :tags""
                            expression_attribute_values["":tags""]=item[""tags""]
                            condition_expression+="" OR tags &lt;&gt; :tags""

                    response=table.update_item(
                            Key={""computedID"":item[""computedID""]},
                            UpdateExpression=update_expression,
                            ConditionExpression= condition_expression,
                            ExpressionAttributeValues=expression_attribute_values,
                            ReturnValues=""UPDATED_NEW""
                            )
                    print(""response is: ""+str(response))
            except Exception as e:
                    print (e)
    print(""Done with sending documents to DynamoDB"")
</code></pre>
","3972035","","","1","2801","na1368","2014-08-24 04:38:36","67","11","40","0","49041524","49044502","2018-03-01 02:05:37","2","442","<p>I have a table in DynamoDB that holds a bunch of documents for me. The documents have the following fields: computedID (Primary partition key), publication_timestamp, displayTitle, displayText, displayUrl, producer and tags.</p>

<p>I'd like to do update_item on the table, so that a record gets updated only if any of the fields publication_timestamp, displayTitle, displayText, displayUrl, producer and tags has changed. If the record is totally new it will be simply inserted in the table.</p>

<p>The problem is that not all the existing documents in the table or the incoming documents have displayTitle, displayText, displayUrl and tags. They may miss any number of these fields.</p>

<p>I have tried the following:</p>

<pre><code>dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('project_Incoming_Data')
print(""Sending documents to DynamoDB..."")

for item in Docs:
    try:
        response=table.update_item(
            Key={""computedID"":item[""computedID""]},
            UpdateExpression=""SET publication_timestamp = :time, displayTitle= :title, displayText= :text, producer = :p, tags= :tags, displayUrl= :url, time_to_live= :ttl"",
            ConditionExpression= ""publication_timestamp &lt;&gt; :time OR (attribute_exists(displayTitle) AND displayTitle &lt;&gt; :title) OR (attribute_exists(displayText) AND displayText &lt;&gt; :text) OR producer &lt;&gt; :p OR (attribute_exists(tags) AND tags &lt;&gt; :tags) OR (attribute_exists(displayUrl) AND displayUrl &lt;&gt; :url)"",
            ExpressionAttributeValues={
                    "":time"":item[""publication_timestamp""],
                    "":ttl"":item[""time_to_live""],
                    "":title"":item[""displayTitle""],
                    "":text"":item[""displayText""],
                    "":p"":item[""producer""],
                    "":tags"":item[""tags""],
                    "":url"":item[""displayUrl""]
            },
            ReturnValues=""UPDATED_NEW""
            )
        print(""response is: ""+str(response))
    except Exception as e:
        print (e)
print(""Done with sending documents to DynamoDB"")
</code></pre>

<p>I still am unable to get some of my documents into DynamoDB. The error I get is 'displayText'! I am guessing that the mechanism I have in place for making sure that the field exists on the record doesn't work for documents that don't have that field.</p>

<p>Any idea how to fix this?</p>
","3972035","","","Error doing update_item in DynamoDB python boto3","<python><amazon-dynamodb><boto3>","1","0","2398"
"49044504","2018-03-01 07:18:41","0","","<p>Thank you all, I ended up using William's solution. In case anybody will have future projects, here is my complete code for scraping a bunch of URL's for their follower count:</p>

<pre><code>import requests
import csv 
import pandas as pd
import re

insta = pd.read_csv('Instagram.csv')

username = []

bad_urls = [] 

for lines in insta['Instagram'][0:250]:
    lines = lines.split(""/"")
    username.append(lines[3])

with open('insta_output.csv', 'w') as csvfile:
t = csv.writer(csvfile, delimiter=',')     #   ----&gt; COMMA Seperated
for user in username:
   try:
       url = 'https://www.instagram.com/'+ user
       r = requests.get(url)
       m = re.search(r'""followed_by"":\{""count"":([0-9]+)\}', str(r.content))
       num_followers = m.group(1)
       t.writerow([user,num_followers])    #  ----&gt; Adding Rows
   except:
       bad_urls.append(url)
</code></pre>
","9166952","","","0","879","calicationoflife","2018-01-03 07:06:30","61","34","2","0","49043857","49044110","2018-03-01 06:31:30","2","2916","<p>I want to parse a website's followers count with BeautifulSoup. This is what I have so far:</p>

<pre><code>username_extract = 'lazada_my'

url = 'https://www.instagram.com/'+ username_extract
r = requests.get(url)
soup = BeautifulSoup(r.content,'lxml')
f = soup.find('head', attrs={'class':'count'})
</code></pre>

<p>This is the part I want to parse:</p>

<p><a href=""https://i.stack.imgur.com/thnXz.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/thnXz.jpg"" alt=""enter image description here""></a></p>

<p>Something within my soup.find() function is wrong, but I can't wrap my head around it. When returning f, it is empty. Any idea what I am doing wrong?</p>
","9166952","9166952","2018-03-01 06:44:39","Get instagram followers","<python><beautifulsoup><instagram><screen-scraping>","5","1","685"
"49044573","2018-03-01 07:23:54","1","","<p>You may want to do this way Or I would suggest, if there are less routes try to have everthing in one file.</p>

<pre><code>from yourfile import app

if __name__ == '__main__':
   app.run(host='127.0.0.1', port=8080, debug=True)
</code></pre>

<p>In yourfile.py</p>

<pre><code>from flask import Flask, jsonify, request
app = Flask(__name__)

@app.route('/echo', methods=['POST'])
def echo():
    message = request.get_json().get('message', '')
    return jsonify({'message': message})
</code></pre>
","5364318","","","5","503","Reck","2015-09-22 16:28:37","903","107","41","6","49044284","49044500","2018-03-01 07:03:43","-1","50","<p>I am trying to build some restful API's. When I try to segregate code into packages the service doesn't work and I get <em>URL not found on the server.</em> For examples:</p>

<p><strong>Scenario 1</strong> [Works fine as I have everything in main.py]</p>

<pre><code>from flask import Flask, jsonify, request

app = Flask(__name__)

@app.route('/echo', methods=['POST'])
def echo():
    message = request.get_json().get('message', '')
    return jsonify({'message': message})

if __name__ == '__main__':
    app.run(host='127.0.0.1', port=8080, debug=True)
</code></pre>

<p>Now when I try to segregate the code into different packages, it just doesn't work. For example:</p>

<p><strong>Scenario 2</strong> [Doesn't work as the code is in different packages]</p>

<p>I am initializing the app in <em>api/restful.py</em></p>

<pre><code>from flask import Flask, jsonify, request
app = Flask(__name__)
</code></pre>

<p>Then created a service in <em>api/endpoints/service.py</em></p>

<pre><code>from api.restplus import app, jsonify, request

@app.route('/echo', methods=['POST'])
def echo():
    message = request.get_json().get('message', '')
    return jsonify({'message': message})
</code></pre>

<p>Finally in <em>main.py</em></p>

<pre><code>from api.restplus import app

if __name__ == '__main__':
   app.run(host='127.0.0.1', port=8080, debug=True)
</code></pre>

<p>It seems like the service is not visible to the app when I put it in a different package. Please advise.</p>
","8323260","2308683","2018-03-01 07:10:59","python code doesn't work when I segregate into packages | works fine in same file","<python><flask>","2","4","1488"
"49044608","2018-03-01 07:25:47","0","","<p>The best answer I have found so far is to enumerate and loop through the array, using the python operator for the threshold or comparison logic.</p>

<p>The key is to multiply the index element by the logical comparison.  e.g.</p>

<pre><code>a = 1.5
a_positive = a * (a&gt;0)
print(a)
</code></pre>

<p>Returns the value of 1.5 as expected, and returns 0 if a is negative.  </p>

<p>Here's the example then with the full list:</p>

<pre><code>a = [1.5, 1.3 -1.4, -1.2]
for i, element in enumerate(a):
     a[i] = element*(element&gt;0)

print(a)
[1.5, -0.0, -0.0]
</code></pre>

<p>Hope that helps someone!</p>
","1931185","","","0","615","Kelton.Temby","2012-12-27 04:08:53","524","51","26","0","49044607","49044638","2018-03-01 07:25:47","0","695","<p>I want to do an inline comparison without writing 'If statements' in Python.  If the value meets the threshold condition, it should be unchanged.  If it doesn't the value should be set to 0.</p>

<p>In Python I don't seem to be allowed to apply a boolean operator to a list directly. In Matlab, it's convenient that 'True' gives a '1' and 'False' gives a zero in array operations. This is matlab-like, but won't work in python (maybe would with numpy?). Pseudocode example:</p>

<pre><code>a = [1.5, 1.3, -1.4, -1.2]
a_test_positive = a&gt;0 # Gives [1, 1, 0, 0]
positive_a_only = a.*a&gt;0 
</code></pre>

<p>Desired result: </p>

<pre><code>positive_a_only&gt;&gt; [1.5, 1.3, 0, 0]
</code></pre>

<p>What is the best way to do this in python?</p>
","1931185","1931185","2018-03-01 07:29:41","How to threshold values in python without if statement (to zero if below threshold, same if above)","<python><arrays><operators><threshold>","3","0","752"
"49044638","2018-03-01 07:27:45","3","","<p>You need - </p>

<pre><code>a = [1.5, 1.3, -1.4, -1.2]
positive_a_only = [i if i&gt;0 else 0 for i in a]

print(positive_a_only)
</code></pre>

<p><strong>Output</strong></p>

<pre><code>[1.5, 1.3, 0, 0]
</code></pre>

<p>This is known as a <a href=""https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions"" rel=""nofollow noreferrer"">List Comprehension</a>
According to your input and expected output, this is a ""pythonic"" way to do this</p>

<blockquote>
  <p>List comprehensions provide a concise way to create lists. Common
  applications are to make new lists where each element is the result of
  some operations applied to each member of another sequence or
  iterable, or to create a subsequence of those elements that satisfy a
  certain condition.</p>
</blockquote>

<p>You use case is kind of made for this :)</p>
","4098013","","","1","845","Vivek Kalyanarangan","2014-10-01 08:30:07","5481","696","528","44","49044607","49044638","2018-03-01 07:25:47","0","695","<p>I want to do an inline comparison without writing 'If statements' in Python.  If the value meets the threshold condition, it should be unchanged.  If it doesn't the value should be set to 0.</p>

<p>In Python I don't seem to be allowed to apply a boolean operator to a list directly. In Matlab, it's convenient that 'True' gives a '1' and 'False' gives a zero in array operations. This is matlab-like, but won't work in python (maybe would with numpy?). Pseudocode example:</p>

<pre><code>a = [1.5, 1.3, -1.4, -1.2]
a_test_positive = a&gt;0 # Gives [1, 1, 0, 0]
positive_a_only = a.*a&gt;0 
</code></pre>

<p>Desired result: </p>

<pre><code>positive_a_only&gt;&gt; [1.5, 1.3, 0, 0]
</code></pre>

<p>What is the best way to do this in python?</p>
","1931185","1931185","2018-03-01 07:29:41","How to threshold values in python without if statement (to zero if below threshold, same if above)","<python><arrays><operators><threshold>","3","0","752"
"49044664","2018-03-01 07:29:20","0","","<p>The @SeanVieria answer will not work if the file is very large (more than 7mb) </p>

<p>This function will work for all cases (tested on Python version 3.4):</p>

<pre><code>def __parse64(self, path_file):
        data = bytearray()
        with open(path_file, ""rb"") as f:
            b = f.read(1)
            while b != b"""":
                data.append(int.from_bytes(b, byteorder='big'))
                b = f.read(1)
        self.encoded_string_file = base64.b64encode(data)
</code></pre>
","1612771","","","0","497","cheziHoyzer","2012-08-20 21:09:05","1798","227","231","16","5020643","5020690","2011-02-16 18:37:47","3","720","<p>i'm having some troubles to get the URI from a certain file, like .mp4/.ogg/etc..
The thing is that i need to do it in python, where the webserver is running.</p>

<p>Initially, i proceed like this:</p>

<pre><code>def __parse64(self, path_file):
    string_file = open(path_file, 'r').readlines()
    new_string_file = ''
    for line in string_file:
        striped_line = line.strip()
        separated_lines = striped_line.split('\n')
        new_line = ''
        for l in separated_lines:
            new_line += l
        new_string_file += new_line
    self.encoded_string_file = b64.b64encode(new_string_file)
</code></pre>

<p>But this way, doesn't give what i need, if you compare the result with given <a href=""http://datauri.com/"" rel=""nofollow"">here.</a></p>

<p>What a i need is a way to implement the function readAsDataURL() from FileReader class (see the code of the link above), in python.</p>

<p><strong>UPDATE:</strong>
The solution given by @SeanVieira, returns a valid data field for the URI.</p>

<pre><code>def __parse64(self, path_file):
    file_data = open(path_file, 'rb').read(-1) 
    self.encoded_string_file = b64.b64encode(file_data)
</code></pre>

<p>Now how can i complete the URI, with the previous fields?
Like <a href=""http://en.wikipedia.org/wiki/Data_URI_scheme#Format"" rel=""nofollow"">this</a>.</p>

<p>For example: data:video/mp4;base64,data</p>

<p>Thanks!</p>
","620188","620188","2011-02-16 19:51:37","python implementation of 'readAsDataURL","<python><uri><filereader>","2","2","1408"
"49044672","2018-03-01 07:29:57","0","","<p>Try this,</p>

<pre><code>def mystery(l):
    if len(l)&lt;2:
        return [1] # change here
    else:
        return (mystery(l[1:])+[l[0]])

print(mystery(ll))
# output: [1, 28, 41, 12, 17]
</code></pre>
","4407666","6622817","2018-03-01 07:31:36","2","211","Rahul K P","2014-12-31 07:18:54","8206","903","675","167","49044553","","2018-03-01 07:22:06","-8","105","<p>I don't understand how do I assign this function to an identifier? Should I make it a list or something? I need to print the return values but I am unable to do so. Please help me out.</p>

<pre><code>def mystery(l):
    if len(l)&lt;2:
        return (1)
    else:
        return (mystery(l[1:])+[l[0]])

ll= [17,12,41,28,25]
new[:]=mystery(ll)
print(ll)
</code></pre>

<p>The error:</p>

<pre><code>Traceback (most recent call last):   
File ""Test2.py"", line 8, in &lt;module&gt;
  new[:]=mystery(ll)   
  File ""Test2.py"", line 5, in mystery
    return (mystery(l[1:])+[l[0]])   
    File ""Test2.py"", line 5, in mystery
      return (mystery(l[1:])+[l[0]])   
      File ""Test2.py"", line 5, in mystery
        return (mystery(l[1:])+[l[0]]) 
TypeError: unsupported operand type(s) for +: 'int' and 'list'
</code></pre>
","9372685","9372685","2018-03-01 07:38:56","How to assign a function that returns a list to another list in python?","<python>","1","4","824"
"49044845","2018-03-01 07:42:36","1","","<p>It may worth looking at <a href=""http://www.numpy.org/"" rel=""nofollow noreferrer""><code>Numpy</code></a> if you are working with numerical arrays.</p>

<pre><code>import numpy as np

a = np.array([1.5, 1.3, -1.4, -1.2])
a[a &lt; 0] = 0
# [ 1.5  1.3  0.   0. ]
</code></pre>
","2291710","2291710","2018-03-01 07:43:34","1","277","Delgan","2013-04-17 16:32:32","10224","643","2102","181","49044607","49044638","2018-03-01 07:25:47","0","695","<p>I want to do an inline comparison without writing 'If statements' in Python.  If the value meets the threshold condition, it should be unchanged.  If it doesn't the value should be set to 0.</p>

<p>In Python I don't seem to be allowed to apply a boolean operator to a list directly. In Matlab, it's convenient that 'True' gives a '1' and 'False' gives a zero in array operations. This is matlab-like, but won't work in python (maybe would with numpy?). Pseudocode example:</p>

<pre><code>a = [1.5, 1.3, -1.4, -1.2]
a_test_positive = a&gt;0 # Gives [1, 1, 0, 0]
positive_a_only = a.*a&gt;0 
</code></pre>

<p>Desired result: </p>

<pre><code>positive_a_only&gt;&gt; [1.5, 1.3, 0, 0]
</code></pre>

<p>What is the best way to do this in python?</p>
","1931185","1931185","2018-03-01 07:29:41","How to threshold values in python without if statement (to zero if below threshold, same if above)","<python><arrays><operators><threshold>","3","0","752"
"49044972","2018-03-01 07:52:08","0","","<p>For this, you need to define some way to find similarity between a set of words. One way to do this can be Word2Vec which generates word embeddings. 
Gensim has a good implementation of word2vec, read more here :</p>

<p><a href=""https://radimrehurek.com/gensim/models/word2vec.html"" rel=""nofollow noreferrer"">https://radimrehurek.com/gensim/models/word2vec.html</a></p>

<p>For word2Vec, you need corpora to train the model and then make vector embeddings for the given set of words. Then you find the word closest to it using any distance function (e.g. cosine)</p>

<p>Here is a sample code :</p>

<pre><code>#imports
from nltk.corpus import brown
import numpy as np
from gensim.models import Word2Vec

#Using brown corpus (category news) from nltk. Replace by your corpus with suitable words/sentences
sentences =brown.sents(categories = 'news')

#initialize and train model
model = Word2Vec(min_count=1)
model.build_vocab(sentences)
model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)

# find similarity between two words
model.wv.similarity('good','well')
</code></pre>

<blockquote>
  <p>0.99978923463065106</p>
</blockquote>

<p>P.S. : Here, I'm comparing two words, you can use other methods too which give you most similar word from the corpus. Be careful about words not in corpus.</p>
","7521600","","","0","1325","Yuvraj Jaiswal","2017-02-06 06:14:41","988","86","598","24","49042409","","2018-03-01 04:00:10","-1","187","<p>I have a list </p>

<pre><code>list1 = ['good']
</code></pre>

<p>I have another list with synonyms of the word ""good""</p>

<pre><code>list2 = ['unspoilt', 'respectable', 'honorable', 'undecomposed', 'goodness', 'well', 'near', 'commodity', 'safe', 'dear', 'just', 'secure', 'in_force', 'practiced', 'trade_good', 'proficient', 'expert', 'good', 'sound', 'soundly', 'effective', 'in_effect', 'beneficial', 'dependable', 'unspoiled', 'estimable', 'salutary', 'adept', 'full', 'ripe','upright', 'skilful', 'right', 'serious', 'skillful', 'thoroughly','honest']
</code></pre>

<p>Now i wanted to list the word with maximum similarity 
Is it possible?</p>

<p>suppose if the word good has a similarity greater than 0.8 then i wanted to return those words alone in a list</p>

<p>here let me consider unspoilt has similarity around 0.9</p>

<pre><code>max_similar_list = ['unspoilt']
</code></pre>
","9395329","9395329","2018-03-01 04:04:25","How to compare two lists and return the highest similarity of words in a list","<python><similarity>","2","1","896"
"49044982","2018-03-01 07:52:43","0","","<p>This error is a result of trying to force 2 sets into venn3. You need to import venn2 from the same library.</p>

<pre><code>from matplotlib_venn import venn2

df_dataset = pd.read_csv('...path...',delimiter=',',decimal=',')
campaign_a = df_dataset[(df_dataset['CAM_A'] == 1)] 
campaign_b = df_dataset[(df_dataset['CAM_B'] == 1)]

plt.figure(figsize=(4,4))
set1 = set(campaign_a['CLI_ID'])
set2 = set(campaign_b['CLI_ID'])

venn2([set1, set2], ('Set1', 'Set2'))
plt.show()
</code></pre>
","6602477","","","0","490","Ignacio Carvajal","2016-07-18 07:59:12","83","2","39","0","37725099","37725714","2016-06-09 11:46:40","2","4896","<p>I'd like to plot venn diagrams based on my pandas data frame. I understand that <code>matplotlib_venn</code> accepts sets as input. My dataset contain client id and two other columns with information if the client was in campaign or not.</p>

<pre><code>df_dataset = pd.read_csv('...path...',delimiter=',',decimal=',')
campaign_a = df_dataset[(df_dataset['CAM_A'] == 1)] 
campaign_b = df_dataset[(df_dataset['CAM_B'] == 1)]

plt.figure(figsize=(4,4))
set1 = set(campaign_a['CLI_ID'])
set2 = set(campaign_b['CLI_ID'])

venn3([set1, set2], ('Set1', 'Set2'))
plt.show()
</code></pre>

<p>However I get an error:</p>

<blockquote>
  <p>File ""C:\Python27\Lib\site-packages\matplotlib_venn_venn3.py"", line 44, in compute_venn3_areas
      areas = np.array(np.abs(diagram_areas), float)</p>
  
  <p>TypeError: bad operand type for abs(): 'set'</p>
</blockquote>

<p><strong>UPDATE</strong></p>

<p>Based on lanS advice, it works now. But for some reasons, the diagrams are not together. But in their documentation, the same code works.</p>

<pre><code>plt.figure(figsize=(4,4))

set1 = set(campaign_a['CLI_ID'])
set2 = set(campaign_b['CLI_ID'])
set3 = set(union['CLI_ID'])

venn3([set1, set2, set3], ('A', 'B', 'union'))
plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/HydWY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HydWY.png"" alt=""enter image description here""></a></p>

<p><strong>UPDATE 2</strong> - solution</p>

<p>In the end, the simplest approach seems to be only insert size of each space, not dataset. Inspiration <a href=""http://matthiaseisen.com/pp/patterns/p0144/"" rel=""nofollow noreferrer"">here</a>.</p>
","3441597","3441597","2016-06-09 13:16:03","Plot venn diagram with pandas and matplotlib_venn","<python><pandas><matplotlib-venn>","3","4","1655"
"49045029","2018-03-01 07:55:30","2","","<p>Use:</p>

<pre><code>df['new'] = (df.index - df.index[0]).total_seconds() / 3600
</code></pre>

<p>Or:</p>

<pre><code>df['new'] = (df.index - df.index[0]) / np.timedelta64(1, 'h')
</code></pre>

<hr>

<pre><code>print (df)
                     col   new
2018-02-17 00:30:00    0   0.0
2018-02-17 07:00:00    1   6.5
2018-02-17 13:00:00    2  12.5
2018-02-17 19:00:00    3  18.5
2018-02-18 00:00:00    4  23.5
2018-02-18 07:00:00    5  30.5
2018-02-18 10:30:00    6  34.0
2018-02-18 13:00:00    7  36.5
</code></pre>
","2901002","","","2","520","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49044984","49045029","2018-03-01 07:52:52","1","50","<p>I have a dataframe like this:</p>

<pre><code>index = ['2018-02-17 00:30:00', '2018-02-17 07:00:00',
'2018-02-17 13:00:00', '2018-02-17 19:00:00',
'2018-02-18 00:00:00', '2018-02-18 07:00:00',
'2018-02-18 10:30:00', '2018-02-18 13:00:00']

df = pd.DataFrame({'col': list(range(len(index)))})
df.index = pd.to_datetime(index)

                     col
2018-02-17 00:30:00    0
2018-02-17 07:00:00    1
2018-02-17 13:00:00    2
2018-02-17 19:00:00    3
2018-02-18 00:00:00    4
2018-02-18 07:00:00    5
2018-02-18 10:30:00    6
2018-02-18 13:00:00    7
</code></pre>

<p>and would like to add a column that reflects the actual duration in hours, so my desired outcome looks like this:</p>

<pre><code>                     col  time_range
2018-02-17 00:30:00    0         0.0
2018-02-17 07:00:00    1         6.5
2018-02-17 13:00:00    2        12.5
2018-02-17 19:00:00    3        18.5
2018-02-18 00:00:00    4        23.5
2018-02-18 07:00:00    5        30.5
2018-02-18 10:30:00    6        34.0
2018-02-18 13:00:00    7        36.5
</code></pre>

<p>I currently do this as follows:</p>

<pre><code>df['time_range'] = [(ti - df.index[0]).delta / (10 ** 9 * 60 * 60) for ti in df.index]
</code></pre>

<p>Is there a smarter (i.e. vectorized/built-in) way of doing this? </p>
","1534017","1534017","2018-03-01 08:03:07","How to convert datetime series to actual duration in hours?","<python><pandas><datetime>","1","0","1276"
"49045056","2018-03-01 07:56:30","0","","<p>Vim doesn't support anything except its own Regex engine natively. You must use plugins. The ones that may fit your needs are <a href=""https://github.com/ivanov/vim-ipython"" rel=""nofollow noreferrer"">vim-ipython</a> and <a href=""https://www.vim.org/scripts/script.php?script_id=2771"" rel=""nofollow noreferrer"">Conque Shell</a>.</p>

<p>These plugins will basically allow you to execute Python code from inside of Vim, so you can work with your Python regex code from inside a Vim buffer. </p>
","797744","797744","2018-03-01 08:02:48","1","496","DBedrenko","2011-06-14 13:34:09","2738","491","2167","785","49042138","","2018-03-01 03:25:05","2","63","<p>Is there a way to change vim' regular expressions to python's regular expressions? I'd like to work with python's regular expressions in my vim. </p>
","9426846","391161","2018-03-01 03:25:35","Change vim's regular expressions","<python><regex><vim>","2","0","153"
"49045163","2018-03-01 08:04:57","4","","<p>In the Python 3.6 or above, <code>os.chdir()</code> can deal with <code>Path</code> object directly. In fact, the <code>Path</code> object can replace most <code>str</code> paths in standard libraries.</p>

<blockquote>
  <p>os.<strong>chdir</strong>(path) Change the current working directory to path.</p>
  
  <p>This function can support specifying a file descriptor. The descriptor
  must refer to an opened directory, not an open file.</p>
  
  <p>New in version 3.3: Added support for specifying path as a file
  descriptor on some platforms.</p>
  
  <p>Changed in version 3.6: Accepts a <a href=""https://docs.python.org/3/glossary.html#term-path-like-object"" rel=""nofollow noreferrer"">path-like object</a>.</p>
</blockquote>

<pre><code>import os
from pathlib import Path

path = Path('/etc')
os.chdir(path)
</code></pre>

<p>This may help in the future projects which do not have to be compatible with 3.5 or below.</p>
","5588463","","","1","932","Yan QiDong","2015-11-21 06:59:38","546","17","73","0","41742317","42441759","2017-01-19 12:55:18","15","7412","<p>What is the intended way to change directory using the Python <code>pathlib</code> <a href=""https://docs.python.org/3/library/pathlib.html"" rel=""noreferrer"">(Documentation)</a> functionality?</p>

<p>Lets assume I create a <code>Path</code> object as follows:</p>

<pre><code>from pathlib import Path
path = Path('/etc')
</code></pre>

<p>Currently I just know the following, but that seems to undermine the idea of <code>pathlib</code>.</p>

<pre><code>import os
os.chdir(str(path))
</code></pre>
","911441","","","How can I change directory with Python pathlib","<python><pathlib>","3","5","501"
"49045168","2018-03-01 08:05:14","0","","<p>Do you want to use Python in the Android Studio? That might not be possible. </p>

<p>What you can do is develop the python module/functionality in a python environment - either using an editor and executing the script from the command line, or some other IDE supporting Python.</p>

<p>Next step is to call the package in java, as you would call it in the command line:</p>

<pre><code>Runtime rt = Runtime.getRuntime();
Process pr = rt.exec(""python myPythonScript.py [arguments]"");
</code></pre>
","5010285","","","0","501","Petronella","2015-06-15 07:34:40","664","99","10","2","49044902","","2018-03-01 07:47:24","0","368","<p>I want to implement face recognition functionality in my android app. I found out that there is a library <a href=""https://pypi.python.org/pypi/face_recognition"" rel=""nofollow noreferrer"">face_recognition</a> in Python. 
I have successfully installed the library and its working fine. Now I want to use that library in the Android Studio. I don't know how to proceed and import or call the python files using Java in Android studio. Can someone guide me how to proceed?</p>
","7939665","6700019","2019-02-15 12:37:51","Using Python's Face Recognition library in Android","<java><android><python><android-studio><face-recognition>","1","0","477"
"49045171","2018-03-01 08:05:29","0","","<p>In DRF, you can add additional package for simple token-based Authentication. Add <code>rest_framework.authtoken</code> to <code>INSTALLED_APPS</code>. To make HTTP(S) request to client you pass the authorization token like this <code>Authorization: Token 9944b09199c62bcf9418ad846dd0e4bbdfc6ee4b</code></p>

<p>For testing, you can use curl</p>

<p><code>curl -X GET http://127.0.0.1:8000/api/example/ -H 'Authorization: Token 9944b09199c62bcf9418ad846dd0e4bbdfc6ee4b</code></p>

<p><a href=""http://www.django-rest-framework.org/api-guide/authentication/#tokenauthentication"" rel=""nofollow noreferrer"">Read more...</a></p>
","694682","","","1","627","webbyfox","2011-04-06 10:57:45","708","93","105","11","49043267","49045171","2018-03-01 05:40:20","0","133","<p>So, i new in django and djangorestframework. i followed their tutorial in their page. <a href=""http://www.django-rest-framework.org/tutorial/4-authentication-and-permissions/"" rel=""nofollow noreferrer"">http://www.django-rest-framework.org/tutorial/4-authentication-and-permissions/</a></p>

<p>in that tutorial, you can login as django user from djangorestframework api login page. my question is, if i want to make a CLI or GUI application and using requests module to post a content to the API, but the API must be loggged in first. how i do that?</p>
","9426966","","","Authenticate restframework User in python","<python><django><django-rest-framework>","2","4","557"
"49045202","2018-03-01 08:08:02","9","","<p>You can pass <code>df.cat_var_1+ ""_"" + df.cat_var_2</code> to argument <code>y</code> of <code>StratifiedShuffleSplit.split()</code>:</p>

<p>But here is a method that use <code>DataFrame.groupby</code>:</p>

<pre><code>import pandas as pd
import numpy as np

nrows = 10000
p1 = {'Orange': 0.6, 'Banana': 0.4}
p2 = {'Monkey': 0.2, 'Cat': 0.7, 'Dog': 0.1}

c1 = [key for key, val in p1.items() for i in range(int(nrows * val))]
c2 = [key for key, val in p2.items() for i in range(int(nrows * val))]
random.shuffle(c1)
random.shuffle(c2)

df = pd.DataFrame({""c1"":c1, ""c2"":c2, ""val"":np.random.randint(0, 100, nrows)})

index = []
for key, idx in df.groupby([""c1"", ""c2""]).groups.items():
    arr = idx.values.copy()
    np.random.shuffle(arr)
    p1 = int(0.6 * len(arr))
    p2 = int(0.8 * len(arr))
    index.append(np.split(arr, [p1, p2]))

idx_train, idx_test, idx_validate = list(map(np.concatenate, zip(*index)))
</code></pre>
","772649","","","0","932","HYRY","2011-05-27 07:38:27","71257","2164","76","1","48988182","49045202","2018-02-26 12:07:17","9","801","<p>I have a dataframe of the form, <strong>df</strong>:</p>

<pre><code>    cat_var_1    cat_var_2     num_var_1
0    Orange       Monkey         34
1    Banana        Cat           56
2    Orange        Dog           22
3    Banana       Monkey          6
..
</code></pre>

<p>Suppose the possible values of cat_var_1 in the dataset have the ratios- ['Orange': 0.6, 'Banana': 0.4] and the possible values of cat_var_2 have the ratios ['Monkey': 0.2, 'Cat': 0.7, 'Dog': 0.1].</p>

<p>How to I split the data into train, test and validation sets (60:20:20 split) such that the ratios of the categorical variables remain preserved? In practice, these variables can be of any number, not just two. Also, clearly, the exact ratios may never be achieved in practice, but we would like it to be as near as possible.</p>

<p>I have looked into the StratifiedKFold method from sklearn described here: <a href=""https://stackoverflow.com/questions/29082001/how-to-split-a-dataset-into-training-and-validation-set-keeping-ratio-between-cl"">how to split a dataset into training and validation set keeping ratio between classes?</a> but this is restricted to evaluating on the basis of one categorical variable only.</p>

<p>Additionally, I would be grateful if you could provide the complexity of the solution you achieve.</p>
","5858873","1423333","2018-02-26 12:45:49","How to achieve stratified K fold splitting for arbitrary number of categorical variables?","<python><pandas><numpy><machine-learning><scikit-learn>","1","5","1315"
"49045243","2018-03-01 08:11:06","1","","<p>The <code>RUN</code> is used only when building image. The <code>CMD</code> is the command that is started when you start container from your image. If you run migrate when building image it is wrong, migrate is building your database and you want to run it each time before runserver</p>

<pre><code># Dockerfile -- api

FROM python:3

RUN pip3 -q install -r requirements.txt
RUN echo `$DJANGO_SECRET_KEY`
CMD /bin/bash -c ""python manage.py migrate --settings=falcon.settings.dev-microservice &amp;&amp; python manage.py runserver 0.0.0.0:8001 --settings=falcon.settings.dev-microservice""
</code></pre>

<p><strong>This is the proper way how to start django in docker, because you want to run the migrations on production when starting server. Not on your PC when building image...</strong></p>
","2894123","","","0","799","Mazel Tov","2013-10-18 09:45:20","1307","219","52","132","49015773","49045243","2018-02-27 18:42:12","3","481","<p>Though my configuration looks good, my <code>python:3</code> image does not seem to have the expected <code>DJANGO_SECRET_KEY</code> set, at least at the point that the <code>Dockerfile</code> attempts to run migrations</p>

<pre><code>$ docker-compose config
services:
  api:
    build:
      context: /Users/ben/Projects/falcon/falcon-backend
      dockerfile: Dockerfile
    depends_on:
    - db
    - redis
    environment:
      DJANGO_SECRET_KEY: 'some-secret-that-works-elsewhere'
$
$ docker-compose up --build api
[...]
 Step 6/7 : RUN echo `$DJANGO_SECRET_KEY`
 ---&gt; Running in fbfb569c0191

[...]
django.core.exceptions.ImproperlyConfigured: Set the DJANGO_SECRET_KEY env variable
ERROR: Service 'api' failed to build: The command '/bin/sh -c python manage.py migrate' returned a non-zero code: 1
</code></pre>

<p>however, the final line, 
<code>CMD python manage.py runserver 0.0.0.0:8001 --settings=falcon.settings.dev-microservice</code> does start up as desired, with the necessary env vars set. </p>

<pre><code># Dockerfile -- api

FROM python:3

RUN pip3 -q install -r requirements.txt
RUN echo `$DJANGO_SECRET_KEY`
RUN python manage.py migrate --settings=falcon.settings.dev-microservice # &lt;-- why does this not work
CMD python manage.py runserver 0.0.0.0:8001 --settings=falcon.settings.dev-microservice
</code></pre>

<p>Why does the penultimate line of the <code>Dockerfile</code> fail due to an unset environment variable while the final one works as expected?</p>
","188473","","","Missing Environment Vars in docker python:3 with docker-compose","<python><django><docker><docker-compose><django-migrations>","2","2","1497"
"49045272","2018-03-01 08:12:54","3","","<p>This should help. Your return statement is inside the loop. so after the first element the value is returned. try the below snippet.</p>

<pre><code>def print_top(all_text, top = 20):
    word_d =  word_dict(all_text)
    items = sorted(word_d.items(), key=get_count, reverse=True)
    dict2 = {}  #Output Dict
    for amounts in items[:20]:
        dict2[amounts[0]] = amounts[1]
    return dict2  #-- &gt; Outside the loop
</code></pre>
","532312","","","0","442","Rakesh","2010-12-06 13:07:54","56694","5302","758","1508","49045213","49045468","2018-03-01 08:08:47","-1","57","<p>I need to return the top 20 word counts. However, I'm only able to return the no.1 word count and not the rest.</p>

<pre><code>def print_top(all_text, top = 20):
    dict2 ={}
    word_d =  word_dict(all_text)
    items = sorted(word_d.items(), key=get_count, reverse=True)
    for amounts in items[:20]:
        dict2 = (amounts[0], amounts[1])
        return dict2 
</code></pre>
","9327298","4464653","2018-03-01 10:00:40","I need to return the top 20 word counts however I'm only able to return the no.1 word count and not the rest. If someone could please assist","<python><jupyter-notebook>","3","1","386"
"49045295","2018-03-01 08:14:28","0","","<p>Use Python's <code>groupby()</code> to read <code>list1</code> in chunks with the same value. Assign an index to each element which is then used by <code>itergetter()</code> to allow you to extract the same indexes from all four lists:</p>

<pre><code>from itertools import groupby
from operator import itemgetter

list1 = [26, 26, 26, 27, 27, 27, 27, 28, 28, 100, 100, 100]
list2 = [-1, -2, 10, 14, 13, 15, 20, -4, -10, 90, 10,  -1]
list3 = [11, 12, -3, -4, 10, 11, 12, 13, 14, -1, -1, -1]
list4 = [50, 60, 70, 90, 30, 40, 20, 20, 10, 20, 20, 20]

output = [[], [], [], []]

for k, g in groupby(zip(list1, range(len(list1))), key=lambda x: x[0]):
    req_cols = itemgetter(*[i for v, i in g])

    for index, l in enumerate([list1, list2, list3, list4]):
        cols = req_cols(l)
        output[index].append(sum(cols) / float(len(cols)))

print output

# Reassign the updated lists back if needed
list1 = output[0]
list2 = output[1]
list3 = output[2]
list4 = output[3]
</code></pre>

<p>Giving you:</p>

<pre><code>[[26.0, 27.0, 28.0, 100.0], [2.3333333333333335, 15.5, -7.0, 33.0], [6.666666666666667, 7.25, 13.5, -1.0], [60.0, 45.0, 15.0, 20.0]]
</code></pre>
","4985733","4985733","2018-03-01 22:13:37","4","1169","Martin Evans","2015-06-08 09:46:30","31317","3697","2144","9","49043153","","2018-03-01 05:27:13","1","99","<p>I have four lists with same <code>len</code></p>

<pre><code>list1=[26, 26, 26, 27, 27, 27, 27, 28, 28, ..., 100, 100, 100]
list2=[-1, -2, 10, 14, 13, 15, 20, -4, -10,...., 90, 10,  -1]
list3=[11, 12, -3, -4, 10, 11, 12, 13, 14, ..., -1, -1, -1]
list4=[50, 60, 70, 90, 30, 40, 20, 20, 10, ...., 20, 20, 20]
</code></pre>

<p>I have to average out the values in <code>list2, 3, and 4</code>, whom share the same values in <code>list1</code>. What I mean by that is that for example, for <code>list2</code>, I want <code>(-1+-2+10)/3=2.33</code> because the corresponding elements of <code>-1, -2, and 10</code> in list1 is <code>26</code>. <code>(14+13+15+20)/4=15.5 (four corresponding 27s in list1).</code> Essentially, the same idea applies to <code>list3 and list4</code> as well. For <code>list3</code>, I want <code>(11+12+-3)/3=6.67</code></p>

<p>Eventually, after transformation and averaging out, 4 lists are:</p>

<pre><code>list1=[26, 27, 28, ...., 100]
list2=[2.33, 15.5, -7, ..., 33]
list3=[6.667, 7.25, 13.5,.., -1]
list4=[60, 45, 15, ..., 20]
</code></pre>

<p>I'm thinking about something like this. There is definitely a more elegant way to do this. </p>

<pre><code>for x, y, z, q in zip(list1, list2, list3, list4):
    if x==previous x:
       #same x, add y, z, q, to separate temp lists (when new x appears, average out)
    else:
       #new x, average out y, z, q (empty temp lists)   
</code></pre>
","6000353","6000353","2018-03-01 05:56:02","python average out columns in list","<python><list><mean>","7","8","1427"
"49045301","2018-03-01 08:14:54","1","","<p>One possible solution:</p>

<pre><code>a = defaultdict( list )
_ = {x['METRIC']: a[x['METRIC']].append(x) for x in frontendFrame.to_dict('records')}
a = dict(a)
</code></pre>

<hr>

<pre><code>from collections import defaultdict

a = defaultdict( list )
for x in frontendFrame.to_dict('records'):
    a[x['METRIC']].append(x)
a = dict(a)
</code></pre>

<hr>

<p>Slow:</p>

<pre><code>dataDict = frontendFrame.groupby('METRIC').apply(lambda x: x.to_dict('records')).to_dict()
</code></pre>
","2901002","2901002","2018-03-01 08:43:35","2","492","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49045203","","2018-03-01 08:08:03","0","81","<p>I am trying to iterate over a list of unique column-values to create three different keys with dictionaries inside a dictionary. This is the code I have now:</p>

<pre><code>import pandas as pd

dataDict = {}
metrics = frontendFrame['METRIC'].unique()

for metric in metrics:
    dataDict[metric] = frontendFrame[frontendFrame['METRIC'] == metric].to_dict('records')

print(dataDict)
</code></pre>

<p>This works fine for low amounts of data, but as fast as the amount of data increases this can take almost one second (!!!!).</p>

<p>I've tried with groupby in pandas which is even slower, and also with map, but I don't want to return things to a list. How can I iterate over this and create what I want in a faster way? I am using Python 3.6</p>

<p>UPDATE:</p>

<p>Input:</p>

<pre><code>    DATETIME             METRIC  ANOMALY           VALUE
0   2018-02-27 17:30:32  SCORE      2.0                    -1.0
1   2018-02-27 17:30:32  VALUE      NaN                     0.0
2   2018-02-27 17:30:32  INDEX      NaN  6.6613381477499995E-16
3   2018-02-27 17:31:30  SCORE      2.0                    -1.0
4   2018-02-27 17:31:30  VALUE      NaN                     0.0
5   2018-02-27 17:31:30  INDEX      NaN  6.6613381477499995E-16
6   2018-02-27 17:32:30  SCORE      2.0                    -1.0
7   2018-02-27 17:32:30  VALUE      NaN                     0.0
8   2018-02-27 17:32:30  INDEX      NaN  6.6613381477499995E-16
</code></pre>

<p>Output:</p>

<pre><code>{
  ""INDEX"": [
{
  ""DATETIME"": 1519759710000,
  ""METRIC"": ""INDEX"",
  ""ANOMALY"": null,
  ""VALUE"": ""6.6613381477499995E-16""
},
{
  ""DATETIME"": 1519759770000,
  ""METRIC"": ""INDEX"",
  ""ANOMALY"": null,
  ""VALUE"": ""6.6613381477499995E-16""
}],
  ""SCORE"": [
{
  ""DATETIME"": 1519759710000,
  ""METRIC"": ""SCORE"",
  ""ANOMALY"": 2,
  ""VALUE"": ""-1.0""
},
{
  ""DATETIME"": 1519759770000,
  ""METRIC"": ""SCORE"",
  ""ANOMALY"": 2,
  ""VALUE"": ""-1.0""
}],
  ""VALUE"": [
{
  ""DATETIME"": 1519759710000,
  ""METRIC"": ""VALUE"",
  ""ANOMALY"": null,
  ""VALUE"": ""0.0""
},
{
  ""DATETIME"": 1519759770000,
  ""METRIC"": ""VALUE"",
  ""ANOMALY"": null,
  ""VALUE"": ""0.0""
}]
}
</code></pre>
","8625952","8625952","2018-03-01 08:25:51","Python Pandas - Iterate over unique columns","<python><python-3.x><pandas><loops><dataframe>","1","2","2109"
"49045318","2018-03-01 08:16:45","5","","<p>I believe you need <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html"" rel=""nofollow noreferrer""><code>cut</code></a>:</p>

<pre><code>df['Age_Interval'] = pd.cut(df['Age'], bins=np.arange(0,110,10))
print (df)
  Customer  Age Age_Interval
0        A   10      (0, 10]
1        B   53     (50, 60]
2        C   20     (10, 20]
3        D    2      (0, 10]
4        E   55     (50, 60]
5        F   12     (10, 20]
</code></pre>

<hr>

<pre><code>b = np.arange(0,110,10)
l = [ ""{0}-{1}"".format(i, i + 10) for i in range(0, 100, 10)]
df['Age_Interval'] = pd.cut(df['Age'], bins=b, labels=l)
print (df)
  Customer  Age Age_Interval
0        A   10         0-10
1        B   53        50-60
2        C   20        10-20
3        D    2         0-10
4        E   55        50-60
5        F   12        10-20
</code></pre>

<p>EDIT:</p>

<pre><code>print (df)
  Customer  Age
0        A   10
1        B   53
2        C   20
3        D    2
4        E   55
5        F   12
6        G    0

b = np.arange(0,110,10)
l = [ ""{0}-{1}"".format(i, i + 10) for i in range(0, 100, 10)]
df['Age_Interval'] = pd.cut(df['Age'], bins=b, labels=l, include_lowest=True)
print (df)
  Customer  Age Age_Interval
0        A   10         0-10
1        B   53        50-60
2        C   20        10-20
3        D    2         0-10
4        E   55        50-60
5        F   12        10-20
6        G    0         0-10
</code></pre>
","2901002","2901002","2018-03-01 12:04:59","3","1435","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49045283","49045318","2018-03-01 08:13:40","2","54","<p>I've a CSV with the following data:</p>

<pre><code>Customer    Age
A           10
B           53
C           20
D            2
E           55
F           12
</code></pre>

<p>For that I'm using Pandas library to read the csv. My question is how I can group the Ages values in order to get a new column with intervals like this:</p>

<pre><code>Customer    Age   Age_Interval
A           10      [0-10]
B           53      [50-60]
C           20      [10-20]
D           2       [0-10]
E           55      [50-60]
F           12      [10-20]   
</code></pre>

<p>How can I do this?</p>

<p>Thanks!</p>
","6534180","","","Python - Group Column values into Classes","<python><pandas><dataframe><grouping>","2","0","605"
"49045332","2018-03-01 08:18:11","0","","<p>If you are facing this error ""<strong>exec x</strong>"" while installing <strong>pypdfocr</strong> then just follow some steps and you will be able to install pypdfocr.</p>

<p>Just download the whl file of <strong>evernote</strong> just replace the ""<strong>exec x</strong>"" in setup.py by ""<strong>exec(x)</strong>"" and then run setup.py.</p>

<p>After installing evernote install pypdfocr on version3.x of python. It will be installed successfully.</p>

<p>Thank you</p>
","7803648","7803648","2018-03-01 11:19:14","1","476","satyamj37","2017-04-02 05:16:10","1","3","0","0","49045299","","2018-03-01 08:14:39","-5","230","<p>How can i solve this problem, I am getting the exec x error in evernote/setup.py while installing pypdfocr in python</p>
","7803648","","","error : exec x in pypdfocr in python","<python><exec><evernote>","1","0","124"
"49045381","2018-03-01 08:21:59","13","","<p>In python 3 you may create new list by unpacking old one and adding new element:</p>

<pre><code>a = [1,2,3]
b = [*a,4] # b = [1,2,3,4] 
</code></pre>

<p>when you do:</p>

<pre><code>myList + [40]
</code></pre>

<p>You actually have 3 lists.</p>
","9305152","2602816","2019-06-14 19:50:10","1","250","Damian Paszkowski","2018-02-02 12:26:44","149","15","10","0","12902980","12903015","2012-10-15 19:52:17","56","40975","<p>I want to do something like this:</p>

<pre><code>myList = [10,20,30]
yourList = myList.append (40)
</code></pre>

<p>Unfortunately, list append does not return the modified list.</p>

<p><strong>So, how can I allow <code>append</code> to return the new list?</strong></p>
","916784","355230","2019-10-17 02:10:47","How to allow list append() method to return the new list","<python><list><append>","7","0","276"
"49045396","2018-03-01 08:22:49","1","","<p>The reason you are getting this error is because the <code>LinearRegression</code> function you are trying to use is from <code>pyspark.ml</code> not from <code>pyspark.mllib</code>. Your global variable space still recognizes <code>LinearRegression</code> is from <code>pyspark.ml</code> module after you commented out the line <code>from pyspark.ml.regression import LinearRegression</code>. Restart and run it again.</p>
","4117331","","","0","427","ashwinids","2014-10-07 13:18:45","2097","134","447","13","49043614","49045396","2018-03-01 06:11:46","0","482","<p>I tried to run linear regression with dataframe in pyspark, but after I tried functions to make fields, labels, it still gives me an error. Can someone help me to figure out how to run linear regression with dataframe?</p>

<pre><code>import pyspark.mllib
import pyspark.mllib.regression
from pyspark.mllib.regression import LabeledPoint
from pyspark.sql.functions import *
from pyspark.sql import Row
from pyspark.ml.linalg import Vectors
#from pyspark.ml.regression import LinearRegression
</code></pre>

<p>my data looks like,</p>

<pre><code>df_all_shorted.head(2)

[Row(bonica_rid=u'cand1457', party=100, vote_date=u'2001-01-03', vote_choice=6, vs_idealPoint=-0.514169271337908, vs_cuttingpoint=-0.514169271337908, vs_rcdir=1, fecyear_new=u'1992', Cand_ID_new=u'H2MA11060', state_new=u'MA', recipient_cfscore_new=-0.758, num_givers_total_new=1533, cand_gender_new=u'M', total_receipts_new=169089.0, total_indiv_contrib_new=105870.0, total_pac_contribs_new=0.0, ran_primary_new=1, ran_general_new=1, district_partisanship_new=-0.119),
 Row(bonica_rid=u'cand1457', party=100, vote_date=u'2001-01-03', vote_choice=6, vs_idealPoint=-0.514169271337908, vs_cuttingpoint=-0.514169271337908, vs_rcdir=1, fecyear_new=u'1992', Cand_ID_new=u'H2MA11060', state_new=u'MA', recipient_cfscore_new=-0.758, num_givers_total_new=1533, cand_gender_new=u'M', total_receipts_new=0.0, total_indiv_contrib_new=0.0, total_pac_contribs_new=0.0, ran_primary_new=0, ran_general_new=0, district_partisanship_new=-0.119)]
</code></pre>

<p>and</p>

<pre><code>training = df_all_shorted.rdd.map(lambda line:LabeledPoint(line[0],[line[1:]])
</code></pre>

<p>I tried this code and get an error, </p>

<pre><code>AttributeError: 'DataFrame' object has no attribute 'map'
</code></pre>

<p>so I changed to </p>

<pre><code>training = df_all_shorted.rdd.map(lambda line:LabeledPoint(line[0],[line[1:]]))

and it worked, but when I run 

lr = LinearRegression()\
.setMaxIter(10)\
.setRegParam(0.3)\
.setElasticNetParam(0.8)
lrModel = lr.fit(training)
</code></pre>

<p>Error occured,</p>

<pre><code>AttributeError: 'PipelinedRDD' object has no attribute '_jdf'
</code></pre>
","7170857","","","pyspark run linear regression with dataframe","<python><dataframe><pyspark><linear-regression>","1","0","2149"
"49045421","2018-03-01 08:24:24","0","","<p>You can set that a user must be authenticated at all times as default setting in settings.py (in your web server project):</p>

<pre><code>REST_FRAMEWORK = {
    'DEFAULT_PERMISSION_CLASSES': (
        'rest_framework.permissions.IsAuthenticated',
    ),
</code></pre>

<p>More info about that <a href=""http://www.django-rest-framework.org/api-guide/permissions/"" rel=""nofollow noreferrer"">here</a>.</p>

<p>In your web client project, like one of the comments on your questions mentions, you must add an Authentication header in the HTTP messages you send to the web server. An example (TypeScript Angular application implementation) would be:</p>

<pre><code>import {Injectable} from '@angular/core';
import {HttpClient, HttpHeaders} from '@angular/common/http';
import {Observable} from 'rxjs/Observable';
import {Spacecraft} from '../model/spacecraft';

/* Create the authentication headers for the HTTP requests to the DRF project's API.
 * Note: uses btoa(): base-64 encoding of ASCII string, see https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/btoa.
 */
const basicAuthenticationToken = btoa(environment.REST_API.username + ':' + environment.REST_API.password);
const httpOptions = {
  headers: new HttpHeaders({
    'Authorization': `Basic ${basicAuthenticationToken}`
  })
};

@Injectable()
export class APICommunicationService {

  constructor(private http: HttpClient,
              private notificationsService: NotificationsService) {
  }

  getSpacecraftInfo(url: string): Observable&lt;Spacecraft&gt; {
    return this.http.get&lt;Spacecraft&gt;(url, httpOptions)
  }
}
</code></pre>
","5433896","","","1","1629","Sander Vanden Hautte","2015-10-11 16:54:10","585","104","1662","6","49043267","49045171","2018-03-01 05:40:20","0","133","<p>So, i new in django and djangorestframework. i followed their tutorial in their page. <a href=""http://www.django-rest-framework.org/tutorial/4-authentication-and-permissions/"" rel=""nofollow noreferrer"">http://www.django-rest-framework.org/tutorial/4-authentication-and-permissions/</a></p>

<p>in that tutorial, you can login as django user from djangorestframework api login page. my question is, if i want to make a CLI or GUI application and using requests module to post a content to the API, but the API must be loggged in first. how i do that?</p>
","9426966","","","Authenticate restframework User in python","<python><django><django-rest-framework>","2","4","557"
"49045424","2018-03-01 08:24:32","0","","<p>You can try this</p>

<pre><code>df['Age_Interval'] = pd.cut(df.Age, range(10,100,10), include_lowest=True)
</code></pre>
","8580190","8580190","2018-03-01 12:34:40","1","125","grshankar","2017-09-08 13:00:41","282","22","63","2","49045283","49045318","2018-03-01 08:13:40","2","54","<p>I've a CSV with the following data:</p>

<pre><code>Customer    Age
A           10
B           53
C           20
D            2
E           55
F           12
</code></pre>

<p>For that I'm using Pandas library to read the csv. My question is how I can group the Ages values in order to get a new column with intervals like this:</p>

<pre><code>Customer    Age   Age_Interval
A           10      [0-10]
B           53      [50-60]
C           20      [10-20]
D           2       [0-10]
E           55      [50-60]
F           12      [10-20]   
</code></pre>

<p>How can I do this?</p>

<p>Thanks!</p>
","6534180","","","Python - Group Column values into Classes","<python><pandas><dataframe><grouping>","2","0","605"
"49045452","2018-03-01 08:26:28","0","","<p>Please refer to the documentation of <a href=""https://www.tensorflow.org/api_docs/python/tf/tile"" rel=""nofollow noreferrer"">tf.tile</a>. It clearly says </p>

<p><code>multiples: Length must be the same as the number of dimensions in input</code></p>

<p>In your example, rank of <code>labels</code> is <code>1</code> and <code>len([10, 1]) == 2</code> which is why you are seeing the error.</p>

<p>You could try something like</p>

<p><code>tf.tile(tf.expand_dims(labels, -1), [1, 10])</code></p>

<p>or</p>

<p><code>tf.tile(tf.reshape(a, [128, 1]), [1, 10])</code></p>
","2082009","","","0","576","Saurabh Saxena","2013-02-18 04:51:31","469","46","4","0","49044433","","2018-03-01 07:13:58","0","768","<p>I am completely new to Tensorflow. I have a tensor named ""lebels"" of shape (128,) and I want to change it to (128, 10) by using the <code>tf.tile</code> method.</p>

<p>I have tried,</p>

<pre><code>tf.tile(labels, [10, 1])
</code></pre>

<p>However this gives me the error </p>

<blockquote>
  <p>""Shape must be rank 1 but is rank 2 for 'Tile' (op: 'Tile') with input shapes: [128], [2]""</p>
</blockquote>

<p>I tried to search online but found nothing relevant. It looks like a easy thing to do but I have spent hours to try to get it working with no success. Any help would be appreciated. </p>
","4630773","4684861","2018-03-01 07:18:09","Tensorflow: how to use Tile to duplicate rows of a Tensor object?","<python><tensorflow>","1","1","601"
"49045468","2018-03-01 08:27:37","2","","<p><a href=""https://stackoverflow.com/a/49045272/7505395"">Rakeshs answer</a> shows you why yours only returns 1 result. </p>

<p>You can accomplish your task with a 1-liner using <a href=""https://docs.python.org/3/library/collections.html#collections.Counter"" rel=""nofollow noreferrer""><code>Counter</code></a> and it's <a href=""https://docs.python.org/3/library/collections.html#collections.Counter.most_common"" rel=""nofollow noreferrer""><code>most_common(n)</code> function</a>:</p>

<pre><code>dic = Counter(wordList).most_common(20)
</code></pre>

<p>Example:</p>

<pre><code>from collections import Counter
from pprint import pprint

data = """"""Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod 
tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos 
et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata 
sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing 
elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, 
sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita 
kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor 
sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore 
et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo 
dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum 
dolor sit amet.   

Duis autem vel eum iriure dolor in hendrerit in vulputate velit esse molestie consequat, 
vel illum dolore eu feugiat nulla facilisis at vero eros et accumsan et iusto odio 
dignissim qui blandit praesent luptatum zzril delenit augue duis dolore te feugait nulla 
facilisi. Lorem ipsum dolor sit amet, consectetuer adipiscing elit, sed diam nonummy 
nibh euismod tincidunt ut laoreet dolore magna aliquam erat volutpat.""""""

words = [x.strip("",.!?"") for x in data.split() if x.rstrip()]

dic = Counter(words).most_common(20)

pprint(dic)
</code></pre>

<p>Output:</p>

<pre><code>[('et', 14),
 ('dolor', 8),
 ('Lorem', 7),
 ('ipsum', 7),
 ('sit', 7),
 ('amet', 7),
 ('sed', 7),
 ('diam', 7),
 ('dolore', 6),
 ('ut', 4),
 ('magna', 4),
 ('erat', 4),
 ('vero', 4),
 ('consetetur', 3),
 ('sadipscing', 3),
 ('elitr', 3),
 ('nonumy', 3),
 ('eirmod', 3),
 ('tempor', 3),
 ('invidunt', 3)]
</code></pre>
","7505395","","","0","2448","Patrick Artner","2017-02-02 10:46:51","30736","5120","3506","4713","49045213","49045468","2018-03-01 08:08:47","-1","57","<p>I need to return the top 20 word counts. However, I'm only able to return the no.1 word count and not the rest.</p>

<pre><code>def print_top(all_text, top = 20):
    dict2 ={}
    word_d =  word_dict(all_text)
    items = sorted(word_d.items(), key=get_count, reverse=True)
    for amounts in items[:20]:
        dict2 = (amounts[0], amounts[1])
        return dict2 
</code></pre>
","9327298","4464653","2018-03-01 10:00:40","I need to return the top 20 word counts however I'm only able to return the no.1 word count and not the rest. If someone could please assist","<python><jupyter-notebook>","3","1","386"
"49045482","2018-03-01 08:28:38","0","","<p>Excel <code>.xlsx</code> files are actually zip files. In order for the unzip to work correctly, the file must be opened in binary mode, as such your need to open the file using:</p>

<pre><code>import tablib

BASE_PATH = r'c:\my folder\my_test.xlsx'
data = tablib.Dataset().load(open(BASE_PATH, 'rb').read())

print data
</code></pre>

<p>Add <code>r</code> before your string to stop Python from trying to interpret the backslash characters in your path.</p>
","4985733","4985733","2018-03-01 09:41:08","0","464","Martin Evans","2015-06-08 09:46:30","31317","3697","2144","9","49042976","","2018-03-01 05:08:56","0","155","<p>I am getting error on opening xlsx extension file in windows 8 using tablib library.</p>

<p>python version  - 2.7.14</p>

<p>error is as follows:</p>

<pre><code>python suit_simple_sheet_product.py
Traceback (most recent call last):
  File ""suit_simple_sheet_product.py"", line 19, in &lt;module&gt;
    data = tablib.Dataset().load(open(BASE_PATH).read())
  File ""C:\Python27\lib\site-packages\tablib\core.py"", line 446, in load
    format = detect_format(in_stream)
  File ""C:\Python27\lib\site-packages\tablib\core.py"", line 1157, in detect_format
    if fmt.detect(stream):
  File ""C:\Python27\lib\site-packages\tablib\formats\_xls.py"", line 25, in detect
    xlrd.open_workbook(file_contents=stream)
  File ""C:\Python27\lib\site-packages\xlrd\__init__.py"", line 120, in open_workbook
    zf = zipfile.ZipFile(timemachine.BYTES_IO(file_contents))
  File ""C:\Python27\lib\zipfile.py"", line 770, in __init__
    self._RealGetContents()
  File ""C:\Python27\lib\zipfile.py"", line 811, in _RealGetContents
    raise BadZipfile, ""File is not a zip file""
zipfile.BadZipfile: File is not a zip file
</code></pre>

<p>path location is as follows = 
BASE_PATH = 'C:\Users\anju\Downloads\automate\catalog-5090 fabric detail and price list.xlsx'</p>
","6834042","","","Tablib xlsx file badZip file issue","<python><tablib>","1","3","1245"
"49045490","2018-03-01 08:29:06","0","","<p>Run this command first:</p>

<pre><code> python manage.py collectstatic
</code></pre>
","7531125","","","0","89","rahul mehra","2017-02-07 20:52:51","297","71","21","10","49044372","","2018-03-01 07:10:22","0","37","<p>I am a beginner of python Django .i created a django administration page but it was some problem with css.<a href=""https://i.stack.imgur.com/FAQAi.png"" rel=""nofollow noreferrer"">this is the screen shot of the that page</a>.i want to be that  like this. <a href=""https://i.stack.imgur.com/1nvLz.png"" rel=""nofollow noreferrer"">this is the what i wanted page's screen shot</a>. anyone can help me?</p>
","9374243","","","about Python Django Administration page's appearance","<python><django>","2","3","402"
"49045491","2018-03-01 08:29:06","3","","<p>You can use <code>filter</code> with a quick lambda.</p>

<pre><code>def get_cs(ts):
    return filter(lambda t: t[1] == 'c', ts)
</code></pre>

<p>or, since you seem to be only returning the <em>first</em> value found:</p>

<pre><code>def get_cs(ts):
    return next(filter(lambda t: t[1] == 'c', ts), None)
</code></pre>
","3058609","3058609","2018-03-01 08:34:28","3","326","Adam Smith","2013-12-02 18:43:41","37364","3533","3752","1082","49045444","","2018-03-01 08:25:48","0","59","<p>I am trying to find tuples in a list with a certain symbol at the 2nd position. The list looks something like this:</p>

<pre><code>list = [ (0, ""a"", 1), (1, ""b"", 2), (2, ""c"", 3)]
</code></pre>

<p>I can obviously find all the tuples with e.g. a ""c"" by running the following code:</p>

<pre><code>for item in list:
    if item[1] == ""c"":
        return item
</code></pre>

<p>I was just wondering if I could combine line1 and line2 of the above given code to do something like</p>

<pre><code>for (numb1, symbol==""c"", numb2) in list:
    return (numb1, symbol, numb2)
</code></pre>

<p>Does anyone know if there is a shortcut for this?</p>

<p>Thank you!</p>
","9409605","532312","2018-03-01 08:26:36","check element of tuple at certain position - shortcut?","<python><list><indexing><tuples>","5","5","662"
"49045510","2018-03-01 08:30:03","0","","<p>If your distribution is symmetrical (which is the case of the normal distribution), then the theoretical median, has the same value as the average.</p>

<p>Otherwise, the median probability, is the one corresponding with 0.5 in CDF distribution.</p>
","9077457","","","2","253","Camion","2017-12-09 19:08:53","371","80","25","12","49045372","","2018-03-01 08:21:37","0","392","<p>I am trying to calculate the exact median of a simple standard normal PDF in Python 36. The code looks like this:</p>

<pre><code>from scipy.stats import norm
from pynverse import inversefunc

mean = 'some_number'
standard_deviation = 1

inverse_normal_pdf = inversefunc(lambda x: norm.pdf(x, mean, standard_deviation))
median = inverse_normal_pdf(norm.pdf(float('-inf'), mean, standard_deviation)+.5)
</code></pre>

<p>I use the <a href=""https://pypi.python.org/pypi/pynverse"" rel=""nofollow noreferrer"">pynverse library</a> to get the inverse of the normal PDF and use the solver for upper limit of integration from <a href=""https://math.stackexchange.com/questions/579521/solving-for-upper-limit-of-integration-given-a-lower-limit-and-integrand"">here</a> to arrive to the solution for the median. But this method works for only means in the range [-8.6:11.2], and any other mean outside this range gives me exactly the number 2.6180339603380443 for some reason. I can't figure out what's happening here? What is this number?</p>
","8622003","","","How to correctly calculate the MEDIAN of a probability function?","<python><statistics><median><probability-distribution>","1","4","1034"
"49045581","2018-03-01 08:34:12","0","","<p>Using <a href=""https://github.com/erikrose/more-itertools"" rel=""nofollow noreferrer""><code>more_itertools</code></a>, a third-party library:</p>

<p><strong>Given</strong></p>

<pre><code>import itertools as it

import more_itertools as mit


lst = [0, 0, 1, 1, 1, 1, 0, 0, 1, 1]
</code></pre>

<p><strong>Code</strong></p>

<pre><code>longest_contiguous = max([tuple(g) for _, g in it.groupby(lst)], key=len)
longest_contiguous    
# (1, 1, 1, 1)

pred = lambda w: w == longest_contiguous
next(mit.locate(mit.windowed(lst, len(longest_contiguous)), pred=pred))
# 2
</code></pre>

<p>See also the <a href=""https://more-itertools.readthedocs.io/en/latest/api.html#more_itertools.locate"" rel=""nofollow noreferrer""><code>more_itertools.locate</code></a> docstring for details on how these tools work.</p>
","4531270","4531270","2018-03-01 08:51:17","0","805","pylang","2015-02-05 03:51:05","17689","973","1382","7","38161606","38161867","2016-07-02 15:18:20","6","997","<p>I want to find the start position of the longest sequence of 1's in my array:</p>

<pre><code>a1=[0,0,1,1,1,1,0,0,1,1]
#2
</code></pre>

<p>I am following this <a href=""https://stackoverflow.com/a/16733324/4127806"">answer</a> to find the length of the longest sequence. However, I was not able to determine the position.</p>
","4127806","-1","2017-05-23 12:10:22","find the start position of the longest sequence of 1's","<python><numpy><scipy>","6","0","328"
"49045613","2018-03-01 08:36:18","1","","<pre><code>l = [item for item in list if item[1]==""c""]
</code></pre>
","9076535","","","0","69","parsa","2017-12-09 13:53:19","602","95","68","1","49045444","","2018-03-01 08:25:48","0","59","<p>I am trying to find tuples in a list with a certain symbol at the 2nd position. The list looks something like this:</p>

<pre><code>list = [ (0, ""a"", 1), (1, ""b"", 2), (2, ""c"", 3)]
</code></pre>

<p>I can obviously find all the tuples with e.g. a ""c"" by running the following code:</p>

<pre><code>for item in list:
    if item[1] == ""c"":
        return item
</code></pre>

<p>I was just wondering if I could combine line1 and line2 of the above given code to do something like</p>

<pre><code>for (numb1, symbol==""c"", numb2) in list:
    return (numb1, symbol, numb2)
</code></pre>

<p>Does anyone know if there is a shortcut for this?</p>

<p>Thank you!</p>
","9409605","532312","2018-03-01 08:26:36","check element of tuple at certain position - shortcut?","<python><list><indexing><tuples>","5","5","662"
"49045685","2018-03-01 08:40:09","0","","<p>Try this :</p>

<pre><code>print [a for a in alist if a[1]=='c']
</code></pre>

<p>output:</p>

<pre><code>[(2, 'c', 3)]
</code></pre>
","7531125","","","1","138","rahul mehra","2017-02-07 20:52:51","297","71","21","10","49045444","","2018-03-01 08:25:48","0","59","<p>I am trying to find tuples in a list with a certain symbol at the 2nd position. The list looks something like this:</p>

<pre><code>list = [ (0, ""a"", 1), (1, ""b"", 2), (2, ""c"", 3)]
</code></pre>

<p>I can obviously find all the tuples with e.g. a ""c"" by running the following code:</p>

<pre><code>for item in list:
    if item[1] == ""c"":
        return item
</code></pre>

<p>I was just wondering if I could combine line1 and line2 of the above given code to do something like</p>

<pre><code>for (numb1, symbol==""c"", numb2) in list:
    return (numb1, symbol, numb2)
</code></pre>

<p>Does anyone know if there is a shortcut for this?</p>

<p>Thank you!</p>
","9409605","532312","2018-03-01 08:26:36","check element of tuple at certain position - shortcut?","<python><list><indexing><tuples>","5","5","662"
"49045691","2018-03-01 08:40:18","1","","<p>You could use a list comprehension:</p>

<pre><code>input = [(0, ""a"", 1), (1, ""b"", 2), (2, ""c"", 3)]
output = [item for item in input if item[1] == ""c""]
</code></pre>

<p>I would advise you not to use <code>list</code> as a variable name, as it would overwrite the <code>list()</code> function</p>

<p>EDIT: I have just read that list comprehension is not an option so @adam-smith answer would do it. Performance wise, list comprehension are implemented as map-filter functions. Also, they are more readable that filter functions, imho.</p>
","4623227","4623227","2018-03-01 08:46:21","0","543","Susensio","2015-03-02 11:45:57","517","47","277","10","49045444","","2018-03-01 08:25:48","0","59","<p>I am trying to find tuples in a list with a certain symbol at the 2nd position. The list looks something like this:</p>

<pre><code>list = [ (0, ""a"", 1), (1, ""b"", 2), (2, ""c"", 3)]
</code></pre>

<p>I can obviously find all the tuples with e.g. a ""c"" by running the following code:</p>

<pre><code>for item in list:
    if item[1] == ""c"":
        return item
</code></pre>

<p>I was just wondering if I could combine line1 and line2 of the above given code to do something like</p>

<pre><code>for (numb1, symbol==""c"", numb2) in list:
    return (numb1, symbol, numb2)
</code></pre>

<p>Does anyone know if there is a shortcut for this?</p>

<p>Thank you!</p>
","9409605","532312","2018-03-01 08:26:36","check element of tuple at certain position - shortcut?","<python><list><indexing><tuples>","5","5","662"
"49045712","2018-03-01 08:41:50","1","","<p>Simply convert your image to an <code>128x128</code> numpy array with values between 0 and 1. </p>

<p>Then:</p>

<pre><code>image = Variable(torch.from_numpy(image))[None, :, :]
classification = model(image)
</code></pre>

<p><code>classification</code> is then a pytorch Variable containing probabilities of belonging to each class. </p>
","3990607","","","6","343","patapouf_ai","2014-08-29 14:54:55","8387","765","2336","19","49044980","49045712","2018-03-01 07:52:35","0","82","<p>I've been following a course online and one of the exercises was to create a simple image detection model (using MNIST data) to detect written numbers. I've been trying to load a custom image I drew in (128x128 jpg) but I can't seem to figure it out. I'm really close, but I think I'm just confused about what parameters the model takes in. Any help would be appreciated!!</p>

<p><a href=""https://gist.github.com/diericx/261391cebbbe5970e266a4ebbdc09bc6"" rel=""nofollow noreferrer"">Here is my code</a></p>
","3553597","3990607","2018-03-01 08:42:30","How could I feed a custom image into this model?","<python><neural-network><deep-learning><pytorch><mnist>","1","0","509"
"49045757","2018-03-01 08:44:14","0","","<p>Here's something interesting:</p>

<pre><code>$ gdb python 
...
(gdb) run crash.py
...
Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
0x00007ffff745338b in ?? () from /usr/lib/libpython3.6m.so.1.0
(gdb) bt
#0  0x00007ffff745338b in ?? ()
   from /usr/lib/libpython3.6m.so.1.0
#1  0x00007ffff74a245f in ?? ()
   from /usr/lib/libpython3.6m.so.1.0
#2  0x00007ffff73f0565 in PyList_Append ()
   from /usr/lib/libpython3.6m.so.1.0
#3  0x00007ffff73a2580 in ?? ()
   from /usr/lib/libpython3.6m.so.1.0
#4  0x00007ffff7404b55 in _PyCFunction_FastCallDict ()
   from /usr/lib/libpython3.6m.so.1.0
#5  0x00007ffff740e10f in _PyObject_FastCallDict ()
   from /usr/lib/libpython3.6m.so.1.0
#6  0x00007ffff73fc9d0 in PyFile_WriteObject ()
   from /usr/lib/libpython3.6m.so.1.0
#7  0x00007ffff74a3d6a in PyFile_WriteString ()
   from /usr/lib/libpython3.6m.so.1.0
#8  0x00007ffff74b2f9d in PyTraceBack_Print ()
   from /usr/lib/libpython3.6m.so.1.0
#9  0x00007ffff7491154 in ?? ()
   from /usr/lib/libpython3.6m.so.1.0
#10 0x00007ffff7327d14 in ?? ()
   from /usr/lib/libpython3.6m.so.1.0
#11 0x00007ffff749136e in PyErr_Display ()
   from /usr/lib/libpython3.6m.so.1.0
#12 0x00007ffff74c890a in ?? ()
   from /usr/lib/libpython3.6m.so.1.0
#13 0x00007ffff7404ad0 in _PyCFunction_FastCallDict ()
   from /usr/lib/libpython3.6m.so.1.0
#14 0x00007ffff740e10f in _PyObject_FastCallDict ()
   from /usr/lib/libpython3.6m.so.1.0
#15 0x00007ffff7492c5b in PyErr_PrintEx ()
  3.6m.so.1.0
#16 0x00007ffff74939d1 in PyRun_SimpleFileExFlags ()
   from /usr/lib/libpython3.6m.so.1.0
#17 0x00007ffff748970b in Py_Main ()
   from /usr/lib/libpython3.6m.so.1.0
#18 0x0000555555554c39 in main ()
</code></pre>

<p>Observe the calls to <code>PyErr_Display</code> and <code>PyTraceBack_Print</code>. It looks like Python tried to show an error, but crashed in the process. Indeed, this does not crash:</p>

<pre><code>try:
    intbitset([x for x in arr])
except Exception as ex:
    print(repr(ex))
</code></pre>

<p>Rather, it outputs the following:</p>

<pre><code>ValueError('retrieving integers from rhs is impossible: invalid index to scalar variable.')
</code></pre>

<p>This exception is raised <a href=""https://github.com/inveniosoftware/intbitset/blob/8bdb3771f125495eb32a1a7c0690d57e346dc800/intbitset/intbitset.pyx#L249"" rel=""nofollow noreferrer"">here in <code>intbitset.__cinit__</code></a>. Note that <a href=""http://docs.cython.org/en/latest/src/userguide/special_methods.html"" rel=""nofollow noreferrer""><code>__cinit__</code></a> is a special Cython function.</p>

<p>It is raised in response to another exception, coming from <a href=""https://github.com/numpy/numpy/blob/1290e7fd5d40903d69733b4797f7c30ca025e1f7/numpy/core/src/multiarray/scalartypes.c.src#L3572"" rel=""nofollow noreferrer""><code>gen_arrtype_subscript</code></a> in numpy C code. It can be triggered by indexing a scalar like this:</p>

<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; arr = np.array([1,2,3,4,5])
&gt;&gt;&gt; arr[0][0]
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
IndexError: invalid index to scalar variable.
</code></pre>

<p>The reason that <code>intbitset</code> triggers this exception is <a href=""https://github.com/inveniosoftware/intbitset/blob/8bdb3771f125495eb32a1a7c0690d57e346dc800/intbitset/intbitset.pyx#L177"" rel=""nofollow noreferrer"">this line</a>:</p>

<pre><code>  tuple_of_tuples = rhs and hasattr(rhs, '__getitem__') and hasattr(rhs[0], '__getitem__')
</code></pre>

<p>Indeed, numpy scalars (<code>numpy.int64</code> in this case) <em>do</em> have a <code>__getitem__</code>, they just don't like it if you call it. This causes <code>intbitset</code> to incorrectly assume that it's receiving a <a href=""http://intbitset.readthedocs.io/en/latest/#intbitset.intbitset"" rel=""nofollow noreferrer"">sequence made of tuples</a>, which triggers the call to the exception-raising <code>__getitem__</code>.</p>

<p>This explains why it doesn't crash if you pass a generator, <code>intbitset(x for x in arr)</code>: it doesn't have <code>__getitem__</code>, so intbitset enters a different code path. If you pass <code>intbitset(arr)</code> directly, the <code>tuple_of_tuples</code> line triggers another exception, when trying to convert <code>arr</code> to a <code>bool</code>:</p>

<pre><code>ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
</code></pre>

<p>This exception is rather un-Pythonic of numpy (inconsistent with how lists are converted to <code>bool</code>), but that's the way it works.</p>

<p>So why does the <code>invalid index to scalar</code> exception cause a segfault, even though the <code>truth value of an array</code> doesn't? In fact, if I put <code>raise ValueError()</code> after it, both end up crashing, so it's clearly Undefined Behaviour going on in both cases, and pure luck that it sometimes doesn't crash.</p>

<p>My guess is that <code>intbitset</code> does something unexpected by raising an exception from <code>__cinit__</code>. It's not explicitly forbidden in the Cython docs, so I'm not sure how or what.</p>
","14637","","","0","5156","Thomas","2008-09-17 01:40:17","121324","9675","2713","229","49029636","","2018-02-28 12:28:57","4","86","<p>The following code causes a segmentation fault to be raised. I'm not really sure why...</p>

<pre><code>import numpy as np
from intbitset import intbitset

arr = np.array([1,2,3,4,5])

# This works
intbitset(arr.tolist())
=&gt; intbitset([1, 2, 3, 4, 5])

# This throws SIGSEGV
intbitset([x for x in arr])
</code></pre>

<p><code>[x for x in arr]</code> works perfectly and returns the list as expected.</p>

<p>Does anyone have an explanation for this? Doesn't the list comprehension get evaluated to a list before entering <code>intbitset</code> ctr?</p>

<p>I've tested on both Python 3.6.3 and 2.7.13 (need to change <code>zip</code> to <code>itertools.izip</code>). Crashes on both. <code>intbitset</code> version is 2.3.0</p>
","1643257","","","intbitset __init__ causes SIGSEGV","<python>","1","3","735"
"49045830","2018-03-01 08:48:14","4","","<p>Your file is not UTF-8 encoded. Figure out what encoding is used and specificy that explicitly when opening the file:</p>

<pre><code>with open('negative-words.txt', 'r', encoding=""&lt;correct codec&gt;"") as f:
</code></pre>

<p>In Python 2, <code>str</code> is a <em>binary string</em>, containing encoded data, not Unicode text. If you were to use <code>import io</code> then <code>io.open()</code>, you'd get the same issues, or if you were to try to decode the data you read with <code>word.decode('utf8')</code>.</p>

<p>You probably want to read up on Unicode and Python.  I strongly recommend Ned Batchelder's <a href=""https://nedbatchelder.com/text/unipain.html"" rel=""nofollow noreferrer""><em>Pragmatic Unicode</em></a>.</p>
","100297","","","0","736","Martijn Pieters","2009-05-03 14:53:57","770256","252083","5762","19510","49045774","49045830","2018-03-01 08:45:15","1","536","<p>I'm reading in a text file. I've been doing it just fine with python2, but I decided to run my code with python3 instead.</p>

<p>My code for reading the text file is:</p>

<pre><code>neg_words = []
with open('negative-words.txt', 'r') as f:
    for word in f:
        neg_words.append(word)
</code></pre>

<p>When I run this code on python 3 I get the following error:</p>

<pre><code>UnicodeDecodeError                        Traceback (most recent call last)
&lt;ipython-input-14-1e2ff142b4c1&gt; in &lt;module&gt;()
      3 pos_words = []
      4 with open('negative-words.txt', 'r') as f:
----&gt; 5     for word in f:
      6         neg_words.append(word)
      7 with open('positive-words.txt', 'r') as f:

/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/codecs.py in 
decode(self, input, final)
    319         # decode input (taking the buffer into account)
    320         data = self.buffer + input
--&gt; 321         (result, consumed) = self._buffer_decode(data, self.errors, final)
    322         # keep undecoded input until the next call
    323         self.buffer = data[consumed:]

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xef in position 3988: invalid continuation byte
</code></pre>

<p>It seems to me that there is a certain form of text that python2 decodes without any issue, which python3 can't.</p>

<p>Could someone please explain what the difference is between python2 and python3 with respect to this error. Why does it occur in one version but not the other? How can I stop it?</p>
","7490953","","","Why does Python3 get a UnicodeDecodeError reading a text file where Python2 does not?","<python><python-3.x><unicode>","2","1","1545"
"49045848","2018-03-01 08:49:38","1","","<p>The answer by @khrm didn't worked for me. </p>

<p>I was able to do this with  : </p>

<pre>sudo apt install virtualenv</pre>
","7187698","","","0","129","Procrastinator","2016-11-21 05:09:44","54","7","58","0","37304836","","2016-05-18 16:06:38","8","4780","<p>I am trying to create another virtual environment (I already installed one using the typical instructions found here: <a href=""http://docs.python-guide.org/en/latest/dev/virtualenvs/"" rel=""noreferrer"">http://docs.python-guide.org/en/latest/dev/virtualenvs/</a>) so I run:</p>

<pre><code>$ virtualenv experimental
</code></pre>

<blockquote>
  <p>-> The program 'virtualenv' is currently not installed. You can install it by typing: sudo apt install virtualenv</p>
</blockquote>

<p>I checked to see if perhaps the program needed to be updated:</p>

<pre><code>$ pip install virtualenv --upgrade
</code></pre>

<blockquote>
  <p>-> Requirement already up-to-date: virtualenv in /home/uniside/.local/lib/python2.7/site-packages</p>
</blockquote>

<p>Any ideas about what is going on here?</p>
","6352028","1220355","2016-05-18 16:35:32","Ubuntu says virtualenv is not installed but pip says it is","<python><ubuntu><pip><virtualenv>","3","0","795"
"49045900","2018-03-01 08:52:17","2","","<p>In serializer you define fields as attribute of class, not inside Meta. Try this:</p>

<pre><code>class SnippetSerializer(serializers.ModelSerializer):
  owner = serializers.ReadOnlyField(source='owner.username')
  class Meta:
    model = Snippet
    fields = ('id', 'title', 'code', 'linenos', 'language', 'style', 'owner')
</code></pre>
","641249","","","1","342","neverwalkaloner","2011-03-02 13:25:37","28058","1244","1934","0","49045839","49045900","2018-03-01 08:48:45","0","187","<p>I've been following the tutorial at <a href=""http://www.django-rest-framework.org/tutorial/4-authentication-and-permissions/"" rel=""nofollow noreferrer"">http://www.django-rest-framework.org/tutorial/4-authentication-and-permissions/</a> (which is pretty good) but I've got to the end and I'm running the command </p>

<p>http -a admin:password123 POST <a href=""http://127.0.0.1:8000/snippets/"" rel=""nofollow noreferrer"">http://127.0.0.1:8000/snippets/</a> code=""print 789""</p>

<p>and it gives me an error back:</p>

<blockquote>
  <p>HTTP/1.1 400 Bad Request Allow: GET, POST, HEAD, OPTIONS
  Content-Length: 37 Content-Type: application/json Date: Wed, 28 Feb
  2018 18:29:15 GMT Server: WSGIServer/0.2 CPython/3.6.3 Vary: Accept,
  Cookie X-Frame-Options: SAMEORIGIN</p>
  
  <p>{
      ""owner"": [
          ""This field is required.""
      ] }</p>
</blockquote>

<p>The owner field is also visible on the browseable api giving options for all the users I've created. When saving it though (either browser or command line) it does save the user who made the request so that part is right.  I think its not supposed to be visible on the browseable api and not required on the api call as it figures it out from the request.</p>

<p>Here is my code:</p>

<p>views.py:</p>

<pre><code>class SnippetList(generics.ListCreateAPIView):
  queryset = Snippet.objects.all()
  serializer_class = SnippetSerializer
  permission_classes = (permissions.IsAuthenticatedOrReadOnly,)

  def perform_create(self, serializer):
    serializer.save(owner=self.request.user)
</code></pre>

<p>models.py:</p>

<pre><code>class Snippet(models.Model):
  created = models.DateTimeField(auto_now_add=True)
  title = models.CharField(max_length=100, blank=True, default='')
  code = models.TextField()
  linenos = models.BooleanField(default=False)
  language = models.CharField(choices=LANGUAGE_CHOICES, default='python', max_length=100)
  style = models.CharField(choices=STYLE_CHOICES, default='friendly', max_length=100)
  owner = models.ForeignKey('auth.User', related_name='snippets', on_delete=models.CASCADE)
  highlighted = models.TextField()

  class Meta:
    ordering = ('created',)

  def save(self, *args, **kwargs):
    lexer = get_lexer_by_name(self.language)
    linenos = self.linenos and 'table' or False
    options = self.title and {'title': self.title} or {}
    formatter = HtmlFormatter(style=self.style, linenos=linenos, full=True, **options)
    self.highlighted = highlight(self.code, lexer, formatter)
    super(Snippet, self).save(*args, **kwargs)
</code></pre>

<p>serializers.py</p>

<pre><code>class SnippetSerializer(serializers.ModelSerializer):
  class Meta:
    model = Snippet
    fields = ('id', 'title', 'code', 'linenos', 'language', 'style', 'owner')
    owner = serializers.ReadOnlyField(source='owner.username')
</code></pre>
","1584120","","","django rest framework error requiring a field","<python><django><django-rest-framework>","2","0","2845"
"49045933","2018-03-01 08:53:30","0","","<h1>Acquiring the required data:</h1>

<p>Looking at the page source, the form which submits the data (zipcode) is:</p>

<pre><code>&lt;form action=""/ecom/account/sign-in"" method=""post""&gt;
    &lt;input type=""hidden"" name=""form"" value=""ZipCode"" /&gt;
    &lt;div class=""field id-ZipCode""&gt;
        &lt;input data-val=""true"" data-val-required=""Zip Code is required."" data-val-sdcexactlength=""Zip Code must be 5 characters long."" data-val-sdcexactlength-max=""5"" data-val-sdcexactlength-min=""5"" data-val-sdcnumeric=""Zip Code must contain numeric characters only."" data-val-sdcnumeric-pattern=""^[0-9]*$"" id=""Register_ZipCode"" maxlength=""5"" name=""Register.ZipCode"" placeholder=""Enter Your Zip Code"" type=""text"" value="""" /&gt;
    &lt;/div&gt;
    &lt;div class=""btn btn-getstarted  submit btn-round "" onclick=""javascript:trackLinkZipGetStarted();""&gt;
        &lt;input class=""submit btn-round "" name=""Browse"" type=""submit"" value=""    Get Started    ""&gt;&lt;/input&gt;
    &lt;/div&gt;
&lt;/form&gt;
</code></pre>

<p>I've removed some <code>&lt;div&gt;</code> tags as they are irrelevant.</p>

<p>From this form, the information we need is:</p>

<ol>
<li><code>URL = 'https://shop.jewelosco.com/ecom/account/sign-in'</code></li>
<li><code>method=""post""</code> implies we've to use <code>requests.post()</code></li>
<li><code>data = {'form': 'ZipCode', 'Register.ZipCode': '60637', 'Browse': '    Get Started    '}</code></li>
</ol>

<p>(<strong>Note:</strong> You've to provide all the values that are included in the <code>&lt;input&gt;</code> tag in the form data using <code>name</code> as key and <code>value</code> as value.)</p>

<hr>

<h1>Sending the data:</h1>

<p>Code to send the zipcode:</p>

<pre><code>data = {'form': 'ZipCode', 'Register.ZipCode': '60637', 'Browse': '    Get Started    '}

with requests.Session() as s:
    r = s.post('https://shop.jewelosco.com/ecom/account/sign-in', data=data)
</code></pre>

<p>If you check the response history and current url, you'll see that it is getting redirected to <code>https://shop.jewelosco.com/ecom/home</code> which is url we want to fetch the data from.</p>

<pre><code>&gt;&gt;&gt; r.status_code
200
&gt;&gt;&gt; r.url
https://shop.jewelosco.com/ecom/home
&gt;&gt;&gt; r.history
[&lt;Response [302]&gt;]
</code></pre>

<p>To check whether we've successfully posted this data you can use this:</p>

<pre><code>&gt;&gt;&gt; 'Top Offers &amp;amp; Shopping Tools' in r.text
True
</code></pre>

<hr>

<h1>Searching for items:</h1>

<p>Now that we've successfully posted the zipcode, you can use this <code>Session</code> object (<code>s</code>) to search for anything you want.</p>

<p>Complete code:</p>

<pre><code>data = {'form': 'ZipCode', 'Register.ZipCode': '60637', 'Browse': '    Get Started    '}

with requests.Session() as s:
    s.post('https://shop.jewelosco.com/ecom/account/sign-in', data=data)
    r = s.get('https://shop.jewelosco.com/ecom/search?source=searchBox&amp;searchTerm=chicken')
    print('Perdue Chicken Ground Fresh - 16 Oz' in r.text)
    # prints 'True'
</code></pre>
","7832176","7832176","2018-03-01 09:06:12","6","3061","Keyur Potdar","2017-04-07 10:33:50","5988","1260","1872","985","49042064","49045933","2018-03-01 03:15:26","1","752","<p>I'm trying to create a function that goes to <a href=""https://shop.jewelosco.com/ecom/home"" rel=""nofollow noreferrer"">this website</a> and input the zip code in the field and subsequently perform itemized searches, like ""chicken"" in the search box.  I began with this.</p>

<pre><code>import requests
s = requests.session()
input_data = {""Register_ZipCode"": ""60637""}
r = s.post(""https://shop.jewelosco.com/ecom/home"", login_data)
r2 = s.get(""https://shop.jewelosco.com/ecom/home"")
</code></pre>

<p>After this, I want to somehow retain the input information above and run a search as below.</p>

<pre><code>chicken = request.get(""https://shop.jewelosco.com/ecom/search?source=searchBox&amp;searchTerm=chicken"")
</code></pre>

<p>Where I can finally begin scraping the html data.    </p>

<p>I'm stuck on checking if the zip code has been inputted correctly and how to then use that session to conduct a search while retaining session formation (location).</p>

<p>Any advice is appreciated!</p>
","9407642","7832176","2018-03-01 08:22:47","requests.session to initialize session and input search terms","<python><python-3.x><cookies><web-scraping><python-requests>","1","0","998"
"49045951","2018-03-01 08:54:30","29","","<p>You can also use <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.query.html"" rel=""noreferrer""><code>query</code></a> which is very readable in my opinion and straightforward to use:</p>

<pre><code>import pandas as pd

df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [10, 20, 50, 80], 'C': [6, 7, 8, 9]})
df = df.set_index(['A', 'B'])

      C
A B    
1 10  6
2 20  7
3 50  8
4 80  9
</code></pre>

<p>For what you had in mind you can now simply do:</p>

<pre><code>df.query('A == 1')

      C
A B    
1 10  6
</code></pre>

<p>You can also have more complex queries using <code>and</code></p>

<pre><code>df.query('A &gt;= 1 and B &gt;= 50')

      C
A B    
3 50  8
4 80  9
</code></pre>

<p>and <code>or</code></p>

<pre><code>df.query('A == 1 or B &gt;= 50')

      C
A B    
1 10  6
3 50  8
4 80  9
</code></pre>

<p>You can also <strong>query on different index levels</strong>, e.g.</p>

<pre><code>df.query('A == 1 or C &gt;= 8')
</code></pre>

<p>will return</p>

<pre><code>      C
A B    
1 10  6
3 50  8
4 80  9
</code></pre>

<p>If you want to use variables inside your query, <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.query.html"" rel=""noreferrer"">you can use <code>@</code></a>:</p>

<pre><code>b_threshold = 20
c_threshold = 8

df.query('B &gt;= @b_threshold and C &lt;= @c_threshold')

      C
A B    
2 20  7
3 50  8
</code></pre>
","1534017","1534017","2018-10-31 10:13:20","4","1418","Cleb","2012-07-18 07:51:03","13486","1563","2133","554","18835077","18835121","2013-09-16 18:45:37","76","91126","<p>I have a multi-index data frame with columns  'A' and 'B'. </p>

<p>Is there is a way to select rows by filtering on one column of the multi-index without resetting the index to a single column index? </p>

<p>For Example.</p>

<pre><code># has multi-index (A,B)
df
#can I do this? I know this doesn't work because the index is multi-index so I need to     specify a tuple

df.ix[df.A ==1]
</code></pre>
","1594352","6633337","2019-08-01 05:34:10","selecting from multi-index pandas","<python><pandas><dataframe><multi-index>","5","3","407"
"49045982","2018-03-01 08:56:12","0","","<p>replace @pics with file://@pics and enjoy.</p>
","191241","","","0","50","nav","2009-10-16 14:28:49","723","111","73","10","39672499","","2016-09-24 04:27:23","4","1003","<p>I'm emulating the Hovertool example <a href=""http://bokeh.pydata.org/en/0.11.1/docs/user_guide/tools.html"" rel=""nofollow"">here</a>, where the hovertool displays images of snakes. My own data consists of names of people, and their profile pictures. I have a local directory of all profile pics, so whenever I get a list of names, <code>names_ls</code>, I have a method <code>get_profile_pics</code> which will search that directory* for the profile picture associated with the names on that list. </p>

<p>Note how, in the snakes example (code from the example reproduced below for convenience) the images <code>imgs</code> are stored in the ColumnDataSource <code>data</code> dictionary as html urls. I want to try to display images that are stored on my local drive instead, how could I go about doing that?</p>

<p>Some pointers:</p>

<ol>
<li>Assume that I will always have a profile pic of whatever names I'm given. Many people can have the same name, but <code>get_profile_pics</code> takes care of that.</li>
<li>I'd like to run all this in a jupyter notebook.</li>
<li>The pics are .pngs, and I've also saved those profile pics as .npy files, if that helps. </li>
<li>Because of privacy issues, I don't want to host the images on the net to retrieve using a html tag.</li>
</ol>

<p><strong>Snakes Hovertool example code</strong></p>

<pre><code>source = ColumnDataSource(
        data=dict(
            x=[1, 2, 3, 4, 5],
            y=[2, 5, 8, 2, 7],
            desc=['A', 'b', 'C', 'd', 'E'],
            imgs = [
                'http://bokeh.pydata.org/static/snake.jpg',
                'http://bokeh.pydata.org/static/snake2.png',
                'http://bokeh.pydata.org/static/snake3D.png',
                'http://bokeh.pydata.org/static/snake4_TheRevenge.png',
                'http://bokeh.pydata.org/static/snakebite.jpg'
            ]
        )
    )

hover = HoverTool(
        tooltips=""""""
        &lt;div&gt;
            &lt;div&gt;
                &lt;img
                    src=""@imgs"" height=""42"" alt=""@imgs"" width=""42""
                    style=""float: left; margin: 0px 15px 15px 0px;""
                    border=""2""
                &gt;&lt;/img&gt;
            &lt;/div&gt;
        &lt;...other div tags for text&gt;
        """"""
    )
</code></pre>

<p>I've tried various formats: as PIL.Image images, as np.arrays, and as bytes. tldr: none of these work. My code, for completeness:</p>

<pre><code>list_of_pics_PIL = [...]
list_of_pics_np = [...]
list_of_pics_png = [...]
type(list_of_pics_PIL[0]) #PIL.Image.Image
type(list_of_pics_np[0]) #numpy.ndarray
type(list_of_pics_png[0]) #bytes

selected_pics_PIL = get_profile_pics(names_ls, list_of_pics_PIL)
selected_pics_np = get_profile_pics(names_ls, list_of_pics_np)
selected_pics_png = get_profile_pics(names_ls, list_of_pics_png)

source = ColumnDataSource(
        data=dict(
            names = list_of_names,
            height = person_height,
            pics = selected_pics_&lt;format&gt;
            )
       )

hover = HoverTool(
        tooltips=""""""
        &lt;div&gt;
            &lt;div&gt;
                &lt;img
                    src=""@pics"" height=""42"" alt=""@imgs"" width=""42""
                    style=""float: left; margin: 0px 15px 15px 0px;""
                    border=""2""
                &gt;&lt;/img&gt;
            &lt;/div&gt;
        &lt;...other div tags for text&gt;
        """"""
    )
</code></pre>
","6638511","6638511","2016-09-24 04:47:38","Bokeh: Displaying Images with Hovertool","<python><bokeh>","1","0","3416"
"49046025","2018-03-01 08:58:59","5","","<p>It depends on the custom search engine that you created from google console. Goto the CSE on your google console and try ""View it on the web"" option to test it in your browser and if the results match. Results should match.</p>
","3950601","","","2","231","joginder singh","2014-08-17 18:38:10","154","15","11","3","48958387","49113855","2018-02-24 01:18:15","12","788","<p>I'm trying out google customsearch api to search image and but the weird thing is my search through api returns different result than regular search through browser. for example</p>

<pre><code>from apiclient.discovery import build
import pprint
import sys
api_key='xxxxxxx'
service = build('customsearch', 'v1', developerKey=api_key)
request=service.cse()
query=request.list(cx='xxxx:xxxxx',q='dogs and cats',searchType='image',imgType='photo')
result=query.execute()
pprint.pprint(result)
for i in result.get('items',[]):
    print (i['link'])
</code></pre>

<p>running this code gives totally different result
here is result from running above code</p>

<pre><code>https://s.yimg.com/ny/api/res/1.2/tarWzt2ZXfPOEg8oQVlOWw--/YXBwaWQ9aGlnaGxhbmRlcjtzbT0xO3c9ODAw/http://media.zenfs.com/en-US/homerun/people_218/4d82a5fa19dd37247717704975fdf602
https://www.google.com/about/main/machine-learning-qa/img/cat-dog-flow-horizontal.gif
https://www.google.com/trends/2014/static/images/pets-snapshot-reveal-1920.jpg
https://www.google.com/trends/2014/static/images/pets-share.png
https://www.google.com/about/main/machine-learning-qa/img/cat-dog-flow-vertical.gif
https://s.yimg.com/uu/api/res/1.2/YQWuQgTnzQuwXjYzX.QrWg--~B/aD0xMzMzO3c9MjAwMDtzbT0xO2FwcGlkPXl0YWNoeW9u/http://media.zenfs.com/en-US/homerun/people_218/4d82a5fa19dd37247717704975fdf602
https://www.google.com/trends/2014/static/images/pets-video-1080.jpg
https://www.google.com/trends/2014/static/images/pets-video-320.jpg
https://www.google.com/maps/d/thumbnail?mid=1hO0YkGLATyy-ZI9JxX1lbv-wK1M&amp;hl=en_US
</code></pre>

<p>here is a snapshot of google search from chrome
<a href=""https://i.stack.imgur.com/hicGA.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/hicGA.jpg"" alt=""enter image description here""></a>
queries are same, anyone knows why?</p>
","1015633","4495081","2018-02-24 02:09:05","google customsearch returns different result?","<python><python-3.x><search><google-api><google-custom-search>","4","1","1827"
"49046042","2018-03-01 08:59:50","1","","<p>As already noted, you loop the <code>range</code> and then test whether those numbers are in the set, but that check does not make sense. Instead, you should just loop the elements and print them directly.</p>

<pre><code>def printSet (A):
    for i in A:
        print(set(i), end="""")
</code></pre>

<p>But this does not really print those in ""standard set notation"". For example, the surrounding <code>{...}</code> are missing, and the empty set will print as <code>set()</code>. Instead, you can use something like this:</p>

<pre><code>def printSet (A):
    print(""{"" + "", "".join(str(set(i)) if i else ""{}"" for i in A) + ""}"")
</code></pre>

<p>Output for <code>printSet(powerset(randomSet(5, 10)))</code>:</p>

<pre><code>{{8, 9, 5, 6, 0}, {8, 9, 5, 6}, {8, 9, 5, 0}, {8, 9, 5}, {8, 0, 5, 6}, {8, 5, 6}, {8, 0, 5}, {8, 5}, {8, 9, 6, 0}, {8, 9, 6}, {8, 9, 0}, {8, 9}, {8, 0, 6}, {8, 6}, {8, 0}, {8}, {0, 9, 5, 6}, {9, 5, 6}, {0, 9, 5}, {9, 5}, {0, 5, 6}, {5, 6}, {0, 5}, {5}, {0, 9, 6}, {9, 6}, {0, 9}, {9}, {0, 6}, {6}, {0}, {}}
</code></pre>

<p>For more levels of nesting, you could make a recursive function. Note that this does not <code>print</code> but <code>return</code> the result, i.e. you'd have to do <code>print(tostr(...))</code>.</p>

<pre><code>def tostr(A):
    if isinstance(A, (list, tuple, set, frozenset)):
        return ""{"" + "", "".join(map(tostr, A)) + ""}""
    else:
        return str(A)
</code></pre>
","1639625","1639625","2018-03-01 12:34:00","0","1433","tobias_k","2012-08-31 20:34:34","63214","4895","5994","655","49042486","","2018-03-01 04:11:34","2","708","<p>I have to print a set using standard set notation. I'm supposed to use recursion and there has to be a base case somewhere. the final answer should come out as a set, and I must print without adding a new line. </p>

<p>this is a function that is supposed to print out a powerset of random integers. the first function builds the random integers and the second function builds the powerset while the last function prints the set. I have the first two functions as well as the last, but when I run the code, it sometimes prints a set and other times comes up empty. I don't know what I'm doing wrong?</p>

<p>The whole things begins like this:</p>

<pre><code>from random import *

def randomSet (n, up):
    return sample(range(up), n)


def powerset (A):
    if A == []:
        return [[]]
    aoba = A[0]
    imax = powerset(A[1:])
    doggo = []
    for set in imax:
        doggo.append([aoba] + set)
    return doggo + imax


def printSet (A):
    for i in range(len(A)):
        if i in A:
          print ((set(A)),end="""")
</code></pre>

<p>There is a tester function that I didn't put here, but the point is that my code will not work right all the time. Sometimes it runs like this:</p>

<pre><code>The powerset of 
{0, 38, 58, 30, 24}
is 
#supposed to show the powerset of the set above but it is always blank
</code></pre>

<p>and other times it runs like this:</p>

<pre><code>The powerset of 
#nothing....just nothing!!!
is 
#never anything here
</code></pre>
","9372077","4985733","2018-03-01 08:36:52","Printing a 'set' using standard set notation","<python><recursion><printing><set>","3","4","1477"
"49046052","2018-03-01 09:00:39","1","","<p><code>tail -f\ actually block current thread, it never</code>return` until you terminate it.</p>

<p><a href=""https://github.com/seb-m/pyinotify"" rel=""nofollow noreferrer"">https://github.com/seb-m/pyinotify</a> or <a href=""http://pythonhosted.org/watchdog/"" rel=""nofollow noreferrer"">http://pythonhosted.org/watchdog/</a> Would be a better idea.</p>
","6931919","","","0","353","scriptboy","2016-10-06 12:31:07","507","127","114","10","49045747","","2018-03-01 08:43:32","-1","689","<p>I want to create a script with python flask or bottle module to print my <code>/var/log/messages</code> logs with <code>tail -f</code> command.</p>

<pre><code>import subprocess
from bottle import route, response, run

@route(""/"")
def file():
    response.content_type = ""text/plain""
    while True:
        return subprocess.check_output([""tail"", ""-4"", ""file""])

run(host='localhost', port=888)
</code></pre>

<p>when i try it with <code>tail -f</code> the page just hangs and loads for ever.</p>
","8428177","7832082","2018-03-01 09:17:42","How to tail -f log file with python on browser","<python><flask><subprocess><bottle>","1","2","501"
"49046068","2018-03-01 09:01:14","2","","<p>I would try a mix of a <code>cache lock</code> and a <code>task result backend</code> which stores each task's results:</p>

<ul>
<li><p>The cache lock will prevent tasks with the same arguments to get added to the queue multiple times. Celery documentation contains a nice example of cache lock implementation <a href=""http://docs.celeryproject.org/en/latest/tutorials/task-cookbook.html#ensuring-a-task-is-only-executed-one-at-a-time"" rel=""nofollow noreferrer"">here</a>, but if you don't want to create it yourself, you can use the <a href=""https://github.com/cameronmaske/celery-once"" rel=""nofollow noreferrer"">celery-once</a> module.</p></li>
<li><p>For a task result backend, we will use the recommended <a href=""http://docs.celeryproject.org/en/latest/django/first-steps-with-django.html#django-celery-results-using-the-django-orm-cache-as-a-result-backend"" rel=""nofollow noreferrer"">django-celery-results</a>, which creates a <code>TaskResult</code> table that we will query for task results.</p></li>
</ul>

<p><strong>Example:</strong></p>

<ul>
<li><p>Install and configure <a href=""http://docs.celeryproject.org/en/latest/django/first-steps-with-django.html#django-celery-results-using-the-django-orm-cache-as-a-result-backend"" rel=""nofollow noreferrer""><code>django-celery-results</code></a>:</p>

<p><code>settings.py</code>:</p>

<pre><code>INSTALLED_APPS = (
    ...,
    'django_celery_results',
)
CELERY_RESULT_BACKEND = 'django-db'  # You can also use 'django-cache'
</code></pre>

<p><code>./manage.py migrate django_celery_results</code></p></li>
<li><p>Install and configure the <a href=""https://github.com/cameronmaske/celery-once"" rel=""nofollow noreferrer""><code>celery-once</code></a> module:</p>

<p><code>tasks.py</code>:</p>

<pre><code>from celery import Celery
from celery_once import QueueOnce
from time import sleep

celery = Celery('tasks', broker='amqp://guest@localhost//')
celery.conf.ONCE = {
    'backend': 'celery_once.backends.Redis',
    'settings': {
        'url': 'redis://localhost:6379/0',
        'default_timeout': 60 * 60
     }
}

@celery.task(base=QueueOnce)
def do_stuff_for_some_time(some_id):
    e = Model.objects.get(id=some_id)
    e.domanystuff()
</code></pre>

<p>At this point, if a task with the same arguments is going to be executed,<br>
an <code>AlreadyQueued</code> exception will be raised. </p></li>
<li><p>Let's use the above:</p>

<pre><code>from django_celery_results.models import TaskResult

try:
    result = do_stuff_for_some_time(some_id)
except AlreadyQueued:
    result = TaskResult.objects.get(task_args=some_id)
</code></pre></li>
</ul>

<p><strong>Caveats:</strong></p>

<ul>
<li><p>Mind that at the time an <code>AlreadyQueued</code> exception arises, the initial task with argument=<code>some_id</code> may not be executed and therefore it will not have results in <code>TaskResult</code> table.</p></li>
<li><p>Mind everything in your code that can go wrong and hang any of the above processes (because it will do that!).</p></li>
</ul>

<p><strong>Extra Reading:</strong></p>

<ul>
<li>Another <a href=""https://github.com/celery/celery/issues/3270#issuecomment-262761230"" rel=""nofollow noreferrer"">Task with Lock DIY implementation</a></li>
<li>django-celery-result's <a href=""https://github.com/celery/django-celery-results/blob/master/django_celery_results/models.py#L17"" rel=""nofollow noreferrer""><code>TaskResult</code></a> model.</li>
</ul>
","7414939","","","0","3432","John Moutafis","2017-01-13 13:04:37","14260","961","3073","101","45107418","49125851","2017-07-14 16:10:55","10","639","<p>Say that I have this task:</p>

<pre><code>def do_stuff_for_some_time(some_id):
    e = Model.objects.get(id=some_id)
    e.domanystuff()
</code></pre>

<p>and I'm using it like so:</p>

<pre><code>do_stuff_for_some_time.apply_async(args=[some_id], queue='some_queue')
</code></pre>

<p>The problem I'm facing is that there are a lot of repetitive tasks with the same arg param and it's boggling down the queue.</p>

<p>Is it possible to apply async only if the same args and the same task is not in the queue?</p>
","1515864","7414939","2018-03-01 09:03:41","Is it possible to skip delegating a celery task if the params and the task name is already queued in the server?","<python><django><rabbitmq><celery>","3","3","518"
"49046114","2018-03-01 09:03:48","0","","<p>I have no idea why this is happening, but the following solution helped me. I do not remember where I have found it, it would be better to give that person the credit he/she deserves.</p>

<p>Rename that libstdc++.so.6 to libstdc++.so.6.bkp so that opencv uses the default file in the operating system other than conda file. It works like a charm in Ubuntu deep learning AMI. I have not tested it with Amazon AMI.</p>

<p>Command to rename is <code>mv libstdc++.so.6 libstdc++.so.6.bkp</code> while you are in the lib directory for that environment.</p>
","1595439","","","2","557","Abdallah Nasir","2012-08-13 13:05:10","357","117","118","6","48825227","49046114","2018-02-16 10:54:08","0","605","<p>I'm using <a href=""https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-conda.html"" rel=""nofollow noreferrer"">AWS Deep Learning AMI</a> and I use environnement <strong><em>tensorflow_p27</em></strong>.</p>

<p>I would like to use OpenCV lib so I install it from conda</p>

<pre><code>conda install opencv
</code></pre>

<p>but when I try to import cv2, I got the error : </p>

<blockquote>
  <p>ImportError: /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/../../libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/cv2.so)</p>
</blockquote>

<p>Note : When I try without environnement, it works perfectly, I tried to reinstall <strong>libgcc</strong> / change my <strong>LD_LIBRARY_PATH</strong> but nothing work</p>
","8450262","","","Using OpenCV with AWS Deep Learning AMI","<python><amazon-web-services><opencv>","1","0","833"
"49046121","2018-03-01 09:04:03","0","","<p>Yes, it is. You can use the <a href=""http://sumo.dlr.de/wiki/TraCI"" rel=""nofollow noreferrer"">TraCI interface</a>. When using the python client you can use the add function in the vehicle domain (but you must add a route beforehand or use a route already defined in the sumo inputs). In general it looks like this:</p>

<pre><code>traci.route.add(""myRoute"", [""edge1"", ""edge2""])
traci.vehicle.add(""myVehicle"", ""myRoute"")
</code></pre>

<p>See also <a href=""http://www.sumo.dlr.de/daily/pydoc/traci._vehicle.html#VehicleDomain-add"" rel=""nofollow noreferrer"">http://www.sumo.dlr.de/daily/pydoc/traci._vehicle.html#VehicleDomain-add</a></p>
","5731587","","","0","640","Michael","2015-12-30 17:34:13","1954","233","8","3","49045481","","2018-03-01 08:28:35","0","62","<p>SUMO simulator: is it possible to add cars to the simulation dynamically? I wanna do script for counting cars from video input in OpenCV+python</p>
","8722266","","","SUMO + OpenCV + Python = simulation in time? Is it possible","<python><opencv><dynamic><simulation><sumo>","1","1","151"
"49046152","2018-03-01 09:06:05","0","","<p>So just a single change in my code got my required answer. I gave the input file just out of the loop and it worked!</p>

<pre><code>input = pd.read_csv(file_name)
def total_calc(i,n):
     input['calc'] = 0.0
     for index, row in input.iterrows():

       # perform calculations

     input.at[index+i, 'calc'] = calc_value
     input.to_csv(file_name, index=False)

total_calc(1,2)
total_calc(2,8)
</code></pre>

<p>the above answer is useful if there are huge number of columns to be added but since mine required only three, this answer worked fine for me.</p>
","8879248","","","0","570","Jhonny","2017-11-03 08:00:37","41","28","152","0","48906155","48906228","2018-02-21 12:38:14","1","215","<p>I wrote a function that reads in a csv file, performs some calculations and writes output to the same file. To append the calculated values to a new column, I'm using <code>df.at[index, column_name] = value</code>.</p>

<p>This is my code</p>

<pre><code>def total_calc(n):
     input = pd.read_csv(file_name)
     input['calc'] = 0.0
     for index, row in input.iterrows():

       # perform calculations

     input.at[index, 'calc'] = calc_value
     input.to_csv(file_name, index=False)
</code></pre>

<p>When I use the function for multiple values of n, it is writing the values in the same column overwriting the values of previous n values in the dataframe. 
I tried using i in the function and giving <code>index+i</code>, something like this:</p>

<pre><code>def total_calc(i,n):
     input = pd.read_csv(file_name)
     input['calc'] = 0.0
     for index, row in input.iterrows():

       # perform calculations

     input.at[index+i, 'calc'] = calc_value
     input.to_csv(file_name, index=False)

total_calc(1,2)
total_calc(2,8)
</code></pre>

<p>However, the column values are still overwritten. Is there any way to write the columns for multiple values in the function to the same file without overwriting?</p>

<p>so these are my current dataset columns</p>

<pre><code>names values wickets score
</code></pre>

<p>I need this after running all required functions</p>

<pre><code>names values wickets score calc calc1 calc2
</code></pre>
","8879248","8879248","2018-02-21 12:59:05","overwriting column values when using df.at","<python><python-3.x><pandas>","2","0","1458"
"49046162","2018-03-01 09:06:57","0","","<pre><code>class Student(models.Model):
     name = models.CharField()
     surname = models.CharField()
class Group(models.Model):
     groupId = models.AutoField()
     name = models.CharField()
     students = models.ForeignKey(Student, related_name=""group"")
class Faculty(models.Model):
    facultyId = models.AutoField()
    students = models.ForeignKey(Student, ""related_name""=""faculty"")
</code></pre>

<p>you can get this data Student.objects.filter(group__isnull=False, faculty__isnull=False )</p>

<p>It will return the student who have faculty and group.</p>

<p>for Json data:</p>

<pre><code>class Student(serializer.ModelSerializer):
    class Meta:
       model = Student
       fields = ('name', 'surname' , 'group', 'faculty')
</code></pre>
","2089929","2089929","2018-03-01 09:53:33","4","757","aman kumar","2013-02-20 05:59:04","1562","197","11","2","49045943","49046457","2018-03-01 08:54:13","0","61","<p>I have 3 models using Django Framework:</p>

<pre><code>class Student(models.Model):
    name = models.CharField()
    surname = models.CharField()
class Group(models.Model):
    groupId = models.AutoField()
    name = models.CharField()
    students = models.ForeignKey(Student)
class Faculty(models.Model):
    facultyId = models.AutoField()
    students = models.ForeignKey(Student)
</code></pre>

<p>I need to get the list of all students and for each one to have the student's group and faculty.</p>
","6067222","","","Get the django object backward using foreign key","<python><django>","2","5","508"
"49046167","2018-03-01 09:07:18","1","","<p>I solved this by <code>python -m pip install scikit-learn --upgrade</code><br>
check <a href=""https://stackoverflow.com/questions/45618808/python-loading-old-version-of-sklearn"">Python loading old version of sklearn</a></p>
","2393253","","","0","227","Ziu","2013-05-17 09:14:57","189","36","187","0","41768292","41778267","2017-01-20 16:32:33","1","4273","<p>I update <em>sklearn</em> version by terminal with</p>

<pre><code>conda install scikit-learn=0.18
</code></pre>

<p>if I list with <code>conda list scikit-learn</code></p>

<pre><code># packages in environment at /Users/Claudia/anaconda:
scikit-learn              0.18.1              np111py27_1
scikit-learn              0.18.1                    &lt;pip&gt;
</code></pre>

<p>but if I run in notebook </p>

<pre><code>print('The scikit-learn version is {}.'.format(sklearn.__version__))
</code></pre>

<p>the result is</p>

<pre><code>The scikit-learn version is 0.17.1.
</code></pre>

<p>How can I solve and update also the version in Jupyter Notebook?</p>
","4677145","4677145","2017-01-21 10:02:42","old sklearn version in Jupyter Notebook","<python><python-2.7><scikit-learn><ipython-notebook><jupyter-notebook>","2","1","664"
"49046312","2018-03-01 09:15:21","7","","<p>According to my experience, np.save()&amp;np.load() is the fastest solution when trasfering data between hard disk and memory so far.
I've heavily relied my data loading on database and HDFS system before I realized this conclusion.
My tests shows that:
The database data loading(from hard disk to memory) bandwidth could be around 50 MBps(Byets/Second), but the np.load() bandwidth is almost same as my hard disk maximum bandwidth: 2GBps(Byets/Second). Both test environments use the simplest data structure.</p>

<p>And I don't think it's a problem to use several seconds to loading an array with shape: (1e3, 1e6). E.g.
Your array shape is (1000, 1000000), its data type is float128, then the pure data size is (128/8)*1000*1,000,000=16,000,000,000=16GBytes
and if it takes 4 seconds,
Then your data loading bandwidth is 16GBytes/4Seconds = 4GBps.
SATA3 maximum bandwidth is 600MBps=0.6GBps, your data loading bandwidth is already 6 times of it, your data loading performance almost could compete with <a href=""https://en.wikipedia.org/wiki/Double_data_rate"" rel=""nofollow noreferrer"">DDR's maximum bandwidth</a>,  what else do you want?</p>

<p>So my final conclusion is:</p>

<p><strong>Don't use python's Pickle, don't use any database, don't use any big data system to store your data into hard disk, if you could use np.save() and np.load(). These two functions are the fastest solution to transfer data between harddisk and memory so far.</strong></p>

<p>I've also tested the <a href=""https://www.hdfgroup.org/HDF5/"" rel=""nofollow noreferrer"">HDF5</a> , and found that it's much slower than np.load() and np.save(), so use np.save()&amp;np.load() if you've enough DDR memory in your platfrom.</p>
","2018567","2018567","2019-10-09 03:46:27","11","1710","Clock ZHONG","2013-01-28 15:03:05","418","105","101","3","30329726","30330699","2015-05-19 15:20:34","34","26293","<p>I have a script that generates two-dimensional <code>numpy</code> <code>array</code>s with <code>dtype=float</code> and shape on the order of <code>(1e3, 1e6)</code>.  Right now I'm using <code>np.save</code> and <code>np.load</code> to perform IO operations with the arrays.  However, these functions take several seconds for each array.  Are there faster methods for saving and loading the entire arrays (i.e., without making assumptions about their contents and reducing them)?  I'm open to converting the <code>array</code>s to another type before saving as long as the data are retained exactly.</p>
","2623899","2623899","2015-05-19 15:28:02","Fastest save and load options for a numpy array","<python><arrays><performance><numpy><io>","3","0","608"
"49046331","2018-03-01 09:16:32","6","","<p>Strings in Python are immutable, so you cannot do this:</p>

<pre><code>hidden_name[i] = c
</code></pre>

<p>One option which will achieve the desired effect for your game is:</p>

<pre><code>hidden_name = hidden_name[:i] + c + hidden_name[i+1:]
</code></pre>

<p>This works because you are creating a new string using concatenation, and re-assigning the result back to the variable, rather than attempting to edit the existing string.</p>
","6866811","","","0","443","thesilkworm","2016-09-22 20:17:18","3845","151","1210","248","49046241","","2018-03-01 09:11:14","0","2749","<p>I just started programming with python a couple days ago with no prior experience in programming. </p>

<p>I've been following tutorials online and decided to challenge myself by making a hangman-esque game. I'm trying to make it so that a guess replaces the position an alphabet in the hidden word but python is returning this error. Right now the word is called name and the hidden_name are just #'s in the same length.</p>

<pre><code>    name = input (""what is your name ::"")
    hidden_name = (""#"" * len(name))
    print (hidden_name)

    guess = input (""Guess a letter ::"")
    def guess_update(guess, name, hidden_name):
        right = guess in name 
        i = 0
        for c in name:
            if c == guess:
                hidden_name[i] = c
            i += 1
    if guess in name:
        guess_update(guess, name, hidden_name)
        print (""Your progess is ::"", hidden_name)
</code></pre>

<p>Thanks for helping this newbie out :)</p>
","9427974","","","Python beginner here : TypeError: 'str' object does not support item assignment","<python>","2","1","960"
"49046336","2018-03-01 09:16:55","0","","<pre><code>class SnippetList(generics.ListCreateAPIView):
    queryset = Snippet.objects.all()
    serializer_class = SnippetSerializer
    permission_classes = (permissions.IsAuthenticatedOrReadOnly,)

    def perform_create(self, serializer):
        serializer.validated_data['owner'] = self.request.user
        serializer.save()

class SnippetSerializer(serializers.ModelSerializer):
      class Meta:
      model = Snippet
      fields = ('id', 'title', 'code', 'linenos', 'language', 'style', 'owner')
      read_only_fields = ('owner',)
</code></pre>

<p>You have to assign value in serializer validated data.</p>
","2089929","","","0","622","aman kumar","2013-02-20 05:59:04","1562","197","11","2","49045839","49045900","2018-03-01 08:48:45","0","187","<p>I've been following the tutorial at <a href=""http://www.django-rest-framework.org/tutorial/4-authentication-and-permissions/"" rel=""nofollow noreferrer"">http://www.django-rest-framework.org/tutorial/4-authentication-and-permissions/</a> (which is pretty good) but I've got to the end and I'm running the command </p>

<p>http -a admin:password123 POST <a href=""http://127.0.0.1:8000/snippets/"" rel=""nofollow noreferrer"">http://127.0.0.1:8000/snippets/</a> code=""print 789""</p>

<p>and it gives me an error back:</p>

<blockquote>
  <p>HTTP/1.1 400 Bad Request Allow: GET, POST, HEAD, OPTIONS
  Content-Length: 37 Content-Type: application/json Date: Wed, 28 Feb
  2018 18:29:15 GMT Server: WSGIServer/0.2 CPython/3.6.3 Vary: Accept,
  Cookie X-Frame-Options: SAMEORIGIN</p>
  
  <p>{
      ""owner"": [
          ""This field is required.""
      ] }</p>
</blockquote>

<p>The owner field is also visible on the browseable api giving options for all the users I've created. When saving it though (either browser or command line) it does save the user who made the request so that part is right.  I think its not supposed to be visible on the browseable api and not required on the api call as it figures it out from the request.</p>

<p>Here is my code:</p>

<p>views.py:</p>

<pre><code>class SnippetList(generics.ListCreateAPIView):
  queryset = Snippet.objects.all()
  serializer_class = SnippetSerializer
  permission_classes = (permissions.IsAuthenticatedOrReadOnly,)

  def perform_create(self, serializer):
    serializer.save(owner=self.request.user)
</code></pre>

<p>models.py:</p>

<pre><code>class Snippet(models.Model):
  created = models.DateTimeField(auto_now_add=True)
  title = models.CharField(max_length=100, blank=True, default='')
  code = models.TextField()
  linenos = models.BooleanField(default=False)
  language = models.CharField(choices=LANGUAGE_CHOICES, default='python', max_length=100)
  style = models.CharField(choices=STYLE_CHOICES, default='friendly', max_length=100)
  owner = models.ForeignKey('auth.User', related_name='snippets', on_delete=models.CASCADE)
  highlighted = models.TextField()

  class Meta:
    ordering = ('created',)

  def save(self, *args, **kwargs):
    lexer = get_lexer_by_name(self.language)
    linenos = self.linenos and 'table' or False
    options = self.title and {'title': self.title} or {}
    formatter = HtmlFormatter(style=self.style, linenos=linenos, full=True, **options)
    self.highlighted = highlight(self.code, lexer, formatter)
    super(Snippet, self).save(*args, **kwargs)
</code></pre>

<p>serializers.py</p>

<pre><code>class SnippetSerializer(serializers.ModelSerializer):
  class Meta:
    model = Snippet
    fields = ('id', 'title', 'code', 'linenos', 'language', 'style', 'owner')
    owner = serializers.ReadOnlyField(source='owner.username')
</code></pre>
","1584120","","","django rest framework error requiring a field","<python><django><django-rest-framework>","2","0","2845"
"49046339","2018-03-01 09:16:58","1","","<p>Firstly you should try and improve your variable naming to be more descriptive. Don't use <code>set</code> as a variable name as it will remove Python's <code>set()</code> function.</p>

<p>The main problem is that if use Python's <code>set()</code>, an empty set would be shown as <code>set()</code> not <code>{}</code>. </p>

<p>You pass the function a list of lists. Each list contains numbers. The aim is to wrap each lists of numbers with <code>{}</code> and also the whole thing. So one approach would be to first convert each number into a string. The simplest way to do this is to use Python's <code>map()</code> function. This applies a function to each item in a list a returns the resulting list. In this case we can apply the <code>str</code> function which converts items into strings. So the result would be:</p>

<pre><code>['1', '2', '3']
</code></pre>

<p>With this you can use <code>join()</code> to create a single string:</p>

<pre><code>', '.join(['1', '2', '3'])
</code></pre>

<p>would give you a string:</p>

<pre><code>'1, 2, 3'
</code></pre>

<p>You then just need to wrap this with <code>{}</code>. Finally, the output powerset needs to be wrapped as well:</p>

<pre><code>def printSet(A):
    print('{' + ', '.join('{' + ', '.join(map(str, a_set)) + '}' for a_set in A) + '}')

r = random_set(3, 50)
printSet(powerset(r))
</code></pre>

<p>This would display something like:    </p>

<pre class=""lang-none prettyprint-override""><code>{{32, 41, 10}, {32, 41}, {32, 10}, {32}, {41, 10}, {41}, {10}, {}}
</code></pre>
","4985733","","","0","1546","Martin Evans","2015-06-08 09:46:30","31317","3697","2144","9","49042486","","2018-03-01 04:11:34","2","708","<p>I have to print a set using standard set notation. I'm supposed to use recursion and there has to be a base case somewhere. the final answer should come out as a set, and I must print without adding a new line. </p>

<p>this is a function that is supposed to print out a powerset of random integers. the first function builds the random integers and the second function builds the powerset while the last function prints the set. I have the first two functions as well as the last, but when I run the code, it sometimes prints a set and other times comes up empty. I don't know what I'm doing wrong?</p>

<p>The whole things begins like this:</p>

<pre><code>from random import *

def randomSet (n, up):
    return sample(range(up), n)


def powerset (A):
    if A == []:
        return [[]]
    aoba = A[0]
    imax = powerset(A[1:])
    doggo = []
    for set in imax:
        doggo.append([aoba] + set)
    return doggo + imax


def printSet (A):
    for i in range(len(A)):
        if i in A:
          print ((set(A)),end="""")
</code></pre>

<p>There is a tester function that I didn't put here, but the point is that my code will not work right all the time. Sometimes it runs like this:</p>

<pre><code>The powerset of 
{0, 38, 58, 30, 24}
is 
#supposed to show the powerset of the set above but it is always blank
</code></pre>

<p>and other times it runs like this:</p>

<pre><code>The powerset of 
#nothing....just nothing!!!
is 
#never anything here
</code></pre>
","9372077","4985733","2018-03-01 08:36:52","Printing a 'set' using standard set notation","<python><recursion><printing><set>","3","4","1477"
"49046347","2018-03-01 09:17:36","2","","<p>Strings in python are inmutable, so you cannot change its content.
One solution would be to split the string, change the letter and stick it back together:</p>

<pre><code>splitted = list(hidden_name)
splitted[i] = c
hidden_name = ''.join(splitted)
</code></pre>
","4623227","","","1","266","Susensio","2015-03-02 11:45:57","517","47","277","10","49046241","","2018-03-01 09:11:14","0","2749","<p>I just started programming with python a couple days ago with no prior experience in programming. </p>

<p>I've been following tutorials online and decided to challenge myself by making a hangman-esque game. I'm trying to make it so that a guess replaces the position an alphabet in the hidden word but python is returning this error. Right now the word is called name and the hidden_name are just #'s in the same length.</p>

<pre><code>    name = input (""what is your name ::"")
    hidden_name = (""#"" * len(name))
    print (hidden_name)

    guess = input (""Guess a letter ::"")
    def guess_update(guess, name, hidden_name):
        right = guess in name 
        i = 0
        for c in name:
            if c == guess:
                hidden_name[i] = c
            i += 1
    if guess in name:
        guess_update(guess, name, hidden_name)
        print (""Your progess is ::"", hidden_name)
</code></pre>

<p>Thanks for helping this newbie out :)</p>
","9427974","","","Python beginner here : TypeError: 'str' object does not support item assignment","<python>","2","1","960"
"49046361","2018-03-01 09:18:50","2","","<p>Use:</p>

<ul>
<li><a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.set_index.html"" rel=""nofollow noreferrer""><code>set_index</code></a> of columns for not reshaping</li>
<li>reshape all another columns by <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.stack.html"" rel=""nofollow noreferrer""><code>stack</code></a> - <code>NaNs</code> rows are dropped</li>
<li><a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reorder_levels.html"" rel=""nofollow noreferrer""><code>reorder_levels</code></a> for change final ordering of columns</li>
<li><a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html"" rel=""nofollow noreferrer""><code>reset_index</code></a> for columns from <code>MultiIndex</code></li>
<li>remove column by <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html"" rel=""nofollow noreferrer""><code>drop</code></a></li>
<li><code>rename</code> first column</li>
</ul>

<hr>

<pre><code>df = (df.set_index(['time','id'])
       .stack()
       .reorder_levels([2,0,1])
       .reset_index(name='a')
       .drop('a', 1)
       .rename(columns={'level_0':'type'}))
print (df)
  type  time  id
0    A  4.42   1
1    A  4.48   3
2    A  5.45   2
3    B  6.64   2
4    B  7.49   1
5    B  7.72   3
6    C  8.13   1
7    C  8.65   2
8    C  9.07   3
</code></pre>
","2901002","2901002","2018-03-01 09:25:24","0","1434","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49046317","49046361","2018-03-01 09:15:36","1","678","<p>I'm looking to combine three columns into a single column within a dataframe, using the column headers as the value for the new column. All three columns have a unique value of '1' where the other two just have NaN.</p>

<p>Originally I wanted to use pivot, but I suspect a merge operation would be easier? I'm just not sure how to go about it.</p>

<p>i.e. I need to turn</p>

<pre><code>index     A       B        C        time      id
    0     1       NaN      NaN      4.42      1
    1     1       NaN      NaN      4.48      3
    2     1       NaN      NaN      5.45      2
    3     NaN     1        NaN      6.64      2
    4     NaN     1        NaN      7.49      1
    5     NaN     1        NaN      7.72      3
    6     NaN     NaN      1        8.13      1
    7     NaN     NaN      1        8.65      2
    8     NaN     NaN      1        9.07      3
</code></pre>

<p>into...</p>

<pre><code>index     type  time    id
    0     A     4.42    1
    1     A     4.48    3
    2     A     5.45    2
    3     B     6.64    2
    4     B     7.49    1
    5     B     7.72    3
    6     C     8.13    1
    7     C     8.65    2
    8     C     9.07    3
</code></pre>
","3506260","","","Pandas pivot/merge multiple columns into single, using column headers as values","<python><pandas><dataframe><merge><pivot>","1","0","1190"
"49046375","2018-03-01 09:19:46","2","","<p>This surely is not a <a href=""https://stackoverflow.com/help/mcve"">Minimal, Complete and Verifiable example</a>, being neither minimal nor verifiable with a code that throws error messages. For your problem, you just have to extend the x axis used to calculate the regression line. I assume this is    </p>

<pre><code> x = np.linspace(12, 14, 1000)
</code></pre>

<p>But since your code produces an error message at line</p>

<pre><code>s = InterpolatedUnivariateSpline(np.log10(mx), np.log10(my), k=order)
</code></pre>

<p>I can't test it. Instead, I just show you a minimal example that achieves your desired output:</p>

<pre><code>import matplotlib.pyplot as plt
import numpy as np
import scipy.stats as stats

motl = 'motl.txt'
mx, my = np.loadtxt(motl, unpack=True)

#log-log plot of original data
plt.loglog(mx, my, marker = 'o', color = 'g', markersize = 3, linestyle = 'None')
#x values for predicted line
x_pred = np.linspace(13, 16, 1000)
#linear regression on log-log data using base 10 like for log-log graph
b1, b0, _r, _p_val, _stderr = stats.linregress(np.log10(mx), np.log10(my)) 
#corresponding y values using regression data
y_pred = b1 * x_pred + b0   
#log-log plot of linear regression curve
plt.loglog(10 ** x_pred, 10 ** y_pred, color = 'b', linestyle = ""-"")
plt.show()
</code></pre>
","8881141","","","0","1313","Mr. T","2017-11-03 14:15:15","4373","1360","1929","1654","49043622","49046375","2018-03-01 06:12:16","-1","224","<p>I am trying to extrapolate  in a loglog plot in python. I did linear regression to fit the data with the best fit curve. Now I want to extend that best fit line to see how the slope goes with an extended range.</p>

<p>My data is really big, so here is a link of my data: <a href=""https://drive.google.com/open?id=1rbURlvyWlN3R8hwdIrLzAmDw7W3bAlvs"" rel=""nofollow noreferrer"">my_data</a></p>

<p>My code looks like this:</p>

<pre><code>import numpy as np
import scipy as sp
import matplotlib.pyplot as plt

from scipy.optimize import curve_fit
import matplotlib.pyplot as plt
import numpy as np
from scipy.interpolate import InterpolatedUnivariateSpline
from scipy.optimize import curve_fit
import scipy as sp
import scipy.stats

#########################################################
motl = 'motl.txt'
mx, my = np.loadtxt(motl, unpack=True)


print mx
print my

# now do general curve fit for all data

# Regression Function
def regress(x, y):
    #Return a tuple of predicted y values and parameters for linear regression
    p = sp.stats.linregress(x, y)
    b1, b0, r, p_val, stderr = p
    y_pred = sp.polyval([b1, b0], x)
    return y_pred, p

# plotting z
allx, ally = mx, my                              # data, non-transformed
y_pred, _ = regress(np.log(allx), np.log(ally))      # change here           # transformed input             

plt.loglog(allx, ally, marker='p',color ='g', markersize=3,linestyle='None')
plt.loglog(allx, np.exp(y_pred), ""k:"")  # transformed output


#################################################


# positions to inter/extrapolate
x = np.linspace(12, 14, 1000)
# spline order: 1linear, 2 quadratic, 3 cubic ... 
order = 1
# do inter/extrapolation
s = InterpolatedUnivariateSpline(np.log10(mx), np.log10(my), k=order)
y = s(x)

plt.loglog(10**x, 10**y, 'g:')
#######################################################
plt.show()
</code></pre>

<p>With regression, the plot looks like the following:</p>

<p><a href=""https://i.stack.imgur.com/IVidW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/IVidW.png"" alt=""enter image description here""></a></p>

<p>But how do I extrapolate to extend the line from 10^12 to 10^14?
your help is appreciated.</p>
","4936409","","","Extrapolation in loglog plot in python","<python><matplotlib><regression><extrapolation><loglog>","1","1","2212"
"49046381","2018-03-01 09:20:15","1","","<p>You can use either a modern WSGI environment like <a href=""http://flask.pocoo.org/"" rel=""nofollow noreferrer"">Flask</a> or <a href=""https://www.djangoproject.com/"" rel=""nofollow noreferrer"">Django</a>, or if the utility is very small, you can take a look at <a href=""https://docs.python.org/3/library/cgi.html"" rel=""nofollow noreferrer"">Common Gateway Interface (CGI)</a>.</p>
","9427384","","","1","380","JamieO","2018-03-01 06:31:09","11","1","0","0","49046330","","2018-03-01 09:16:27","-1","1344","<p>I have a form in an HTML page that reads input from a user (string x), and I have my python script that uses this variable.</p>

<p>What is the easiest way to fetch this variable from the HTML page by the python script (.py) and return the result - which should also be a string -  to show it in the HTML page again?</p>
","9282567","6106791","2018-03-01 10:19:39","How to link HTML page with python","<python><html>","1","0","324"
"49046390","2018-03-01 09:20:43","1","","<p>You can use <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.block.html"" rel=""nofollow noreferrer"">block()</a> </p>

<pre><code>import numpy as np
M = 0
for k in range(count):
    I = np.ones((3**k, 3**k))
    M = np.block([[M, M, M],
                  [M, I, M],
                  [M, M, M]])
</code></pre>

<p>For example, for <code>count = 4</code>, you get the following output (plotted with matplotlib -- if you are interested in making such plots let me know):</p>

<p><a href=""https://i.stack.imgur.com/Vib5J.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Vib5J.png"" alt=""enter image description here""></a></p>
","2945357","2945357","2018-03-01 11:21:34","1","660","AndyK","2013-11-01 14:55:21","1747","195","574","21","49045804","","2018-03-01 08:46:27","2","102","<p>I am trying to convert a snippet of MATLAB code into python, the MATLAB code is as follows:</p>

<pre><code>M = 0;
for k=1:i
    M = [M,        M,      M;
    M, ones(3^(k-1)), M;
    M,        M,      M];
end
</code></pre>

<p>which creates a 2d array that mimics a sierpinski carpet<br>
my python implementation is as such:</p>

<pre><code>M = 0   
for x in range(1,count):
        square = np.array([[M, M, M], [M, np.ones([3**(x-1),3**(x-1)]), M], [M, M, M]])
</code></pre>

<p>I know I am missing something with the nature of how the arrays are concatenated, since my python output is coming up with more than two dimensions. How would I maintain a 2d array that creates the same output?</p>
","9427889","2945357","2018-03-01 12:28:08","Iterative array creation in matlab and python","<python><arrays><matlab><numpy><concatenation>","2","1","700"
"49046418","2018-03-01 09:22:13","7","","<p>Late in answering this question. But hope this helps someone:</p>

<p><code>python &lt;project_path&gt;/manage.py test &lt;your_project_dir&gt;</code></p>

<p><a href=""https://i.stack.imgur.com/qRJo3.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qRJo3.png"" alt=""Running Django tests from another directory""></a></p>

<p>From Django documentation:</p>

<blockquote>
  <p>You can also provide a path to a directory to discover tests below that directory:</p>

<pre><code>$ ./manage.py test animals/
</code></pre>
</blockquote>

<p>References:</p>

<ol>
<li><a href=""https://docs.djangoproject.com/en/dev/topics/testing/overview/#running-tests"" rel=""noreferrer"">https://docs.djangoproject.com/en/dev/topics/testing/overview/#running-tests</a></li>
<li><a href=""https://docs.python.org/3/library/unittest.html#test-discovery"" rel=""noreferrer"">https://docs.python.org/3/library/unittest.html#test-discovery</a></li>
</ol>
","2515377","2515377","2018-05-10 20:37:47","2","932","Kenpachi","2013-06-24 07:43:06","351","36","32","0","29661112","","2015-04-15 21:19:03","7","1760","<p>I have a pretty standard Django test case setup (I think)</p>

<pre><code>api-name
    manage.py
    api-name
        __init__.py
        settings.py
        wsgi.py
    v0
        project
            stuff.py
            tests
                test_stuff.py
</code></pre>

<p><strong>manage.py</strong></p>

<pre><code>#!/usr/bin/env python
import os
import sys

if __name__ == ""__main__"":
    os.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""api-name.settings"")

    from django.core.management import execute_from_command_line

    execute_from_command_line(sys.argv)
</code></pre>

<p><strong>wsgi.py</strong></p>

<pre><code>import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
os.environ.setdefault(""DJANGO_SETTINGS_MODULE"", ""api-name.settings"")

from django.core.wsgi import get_wsgi_application
application = get_wsgi_application()
</code></pre>

<p><strong>test_stuff.py</strong></p>

<pre><code>from django.test import TestCase
from v0.project.stuff import *


class ProjectTestCase(TestCase):
    def setUp(self):
        # set stuff up

    def test_project_stuff(self):
        # test stuff

    def test_other_stuff(self):
        # test stuff
</code></pre>

<p>Here's what happens when I execute tests:</p>

<pre><code>[cwilbur api-name]$ ./manage.py test
Creating test database for alias 'default'...
..
----------------------------------------------------------------------
Ran 2 tests in 0.014s

OK
Destroying test database for alias 'default'...
[cwilbur api-name]$ cd ..
[cwilbur source]$ ./api-name/manage.py test
Creating test database for alias 'default'...

----------------------------------------------------------------------
Ran 0 tests in 0.000s

OK
Destroying test database for alias 'default'...
</code></pre>

<p>Is this (tests run from the project's root directory, but not from elsewhere) expected behavior? Is there a way to change things so that it will work (I want to execute my tests from a pre-commit hook in a different directory)?</p>

<p>I tried adding <code>from tests import *</code> from <a href=""https://stackoverflow.com/a/12413069/99640"">this answer</a>, but it didn't help. I also tried moving the <code>sys.path.append</code> line from wsgi.py to manage.py, but that didn't help either.</p>

<p>Any other ideas out there I can try?</p>
","99640","-1","2017-05-23 10:33:45","Can I run django tests (manage.py) from a different directory?","<python><django><unit-testing>","2","3","2317"
"49046422","2018-03-01 09:22:18","0","","<p>This is because you do not match all characters.If you remove anchors you will get a match.See demo.</p>

<p><a href=""https://regex101.com/r/uRdqZj/2"" rel=""nofollow noreferrer"">https://regex101.com/r/uRdqZj/2</a></p>
","3679490","","","0","220","vks","2014-05-27 11:12:32","58221","2861","3085","1131","49046242","49046422","2018-03-01 09:11:16","0","327","<p>I use python 2.7 and i want to find the frequencies of the words in text file , 
I write a code using this following expression but there is no output : </p>

<pre><code>    import nltk
    import os
    import re
    import string
    path=""C:\Python27\Lib""
    os.chdir(path)
    frequency = {}
    document_text = open('1.txt', 'r')
    text_string = document_text.read().lower()
    match_pattern = re.findall(r'^[\u0621-\u064A\u0660-\u0669 ]+$', 
    text_string)

    for word in match_pattern:
         count = frequency.get(word,0)
         frequency[word] = count + 1

    frequency_list = frequency.keys()

    for words in frequency_list:
         print words, frequency[words]
</code></pre>
","9288931","","","Regular Expression for Arabic words in python 2.7","<python><regex><frequency><arabic><word-frequency>","1","4","706"
"49046423","2018-03-01 09:22:21","0","","<p>I also met this problem. In your case you should change your command to:</p>

<p><code>pyrcc5 D:\MyFolder\resource_file.qrc -o D:\MyFolder\resource_file.qrc_rc.py</code></p>

<p>Hope this can help you.</p>
","9089337","","","0","209","Jonasquid","2017-12-12 14:41:48","6","1","0","0","30664317","","2015-06-05 10:31:15","3","6170","<p>I'm trying to create a resource file for the GUI i'm creating with PyQt 5.</p>

<p>I've used the command line </p>

<pre><code>pyrcc5 -o image_rc.py D:\MyFolder\resource_file.qrc
</code></pre>

<p>but i get an error message : <em>No resources in resource description</em></p>

<p>This is how my resource file looks :</p>

<pre><code>&lt;!DOCTYPE RCC&gt;
&lt;RCC&gt;
    &lt;qresource prefix=""/images""&gt;
        &lt;file alias=""img""&gt;Images\mypic.png&lt;/file&gt;
    &lt;/qresource&gt;

&lt;/RCC&gt;
</code></pre>

<p>I've followed this topic : <a href=""https://stackoverflow.com/questions/30047692/python-3-how-to-put-pics-inside-my-program/30088121#30088121"">python 3 how to put pics inside my program</a> but i somehow have something wrong.</p>

<p><strong>QUESTION</strong> : if i understand, when you have a resource file, you still need to have the images in a folder somewhere. So why bother making a resource file then ? Isn't the same ? The images can still be deleted or moved no ?</p>
","4862605","-1","2017-05-23 11:58:35","Error while using pyrcc5","<python><qt><resources><pyqt><pyqt5>","3","9","1003"
"49046457","2018-03-01 09:24:40","2","","<p>Well, first you need to modify your model relationships. With your current models, each Faculty and Group will have a single student.
You can modify the model to this:</p>

<pre><code>class Group(models.Model):
    groupId = models.AutoField()
    name = models.CharField()

class Faculty(models.Model):
    facultyId = models.AutoField()

class Student(models.Model):
    name = models.CharField()
    surname = models.CharField()
    group = models.ForeignKey(Group)
    faculty = models.ForeighKey(Faculty)
</code></pre>

<p>Then to get the Group and faculty of each student you can use <code>select_related</code>.
Now your query will look like this:</p>

<pre><code>Students.objects.all().select_related('group', 'faculty')
</code></pre>
","8295443","","","11","746","Martin Mogusu","2017-07-12 11:24:28","76","24","10","0","49045943","49046457","2018-03-01 08:54:13","0","61","<p>I have 3 models using Django Framework:</p>

<pre><code>class Student(models.Model):
    name = models.CharField()
    surname = models.CharField()
class Group(models.Model):
    groupId = models.AutoField()
    name = models.CharField()
    students = models.ForeignKey(Student)
class Faculty(models.Model):
    facultyId = models.AutoField()
    students = models.ForeignKey(Student)
</code></pre>

<p>I need to get the list of all students and for each one to have the student's group and faculty.</p>
","6067222","","","Get the django object backward using foreign key","<python><django>","2","5","508"
"49046467","2018-03-01 09:25:30","0","","<p>In Python 3.6.4 you can persist sys.path across python sessions like this:</p>

<pre><code>import sys
import os

print(str(sys.path))

dir_path = os.path.dirname(os.path.realpath(__file__))
print(f""current working dir: {dir_path}"")

root_dir = dir_path.replace(""/util"", '', 1)
print(f""root dir: {root_dir}"")

sys.path.insert(0, root_dir)

print(str(sys.path))
</code></pre>

<p>I strongly suggest you use virtualenv and virtualenvwrapper otherwise you will clutter your path</p>
","1447071","","","0","482","Rubber Duck","2012-06-10 07:39:52","1977","260","405","4","3402168","3402193","2010-08-04 02:28:07","286","513854","<p>Whenever I use <code>sys.path.append</code>, the new directory will be added. However, once I close python, the list will revert to the previous (default?) values. How do I permanently add a directory to <code>PYTHONPATH</code>?</p>
","374797","355230","2018-12-03 21:45:47","Permanently add a directory to PYTHONPATH?","<python><windows><save><pythonpath><sys>","17","0","236"
"49046477","2018-03-01 09:25:56","0","","<p>Have you tried this,</p>

<p><code>Runtime.getRuntime().exec(""python helloworld.py"");</code></p>

<p>Please try and if it doesn't work leave a comment.</p>
","9392351","","","1","159","Nixel","2018-02-21 17:25:35","110","55","56","0","49033297","49046477","2018-02-28 15:39:02","0","134","<p>I've a Python program which just prints ""hello world"". I only want to get that output in a Java program and print that again, i.e. I want to consume output of Python program in a Java program. </p>

<p>I tried using <code>Runtime.getRuntime().exec(""helloworld.py"");</code> but it is giving an exception saying <code>java.lang.IOException : Cannot run program ""helloworld.py"" : CreateProcess error=193, %1 is not a valid Win32 application</code>.</p>

<p>Can anybody please explain why this exception has occurred and what is solution for it ?</p>

<p>Thanks in advance!</p>
","9176100","9176100","2018-02-28 15:45:24","Receive output of python program in java","<java><python><windows>","2","8","577"
"49046516","2018-03-01 09:28:45","1","","<pre><code>SSHException: Error reading SSH protocol banner
</code></pre>

<p>the error usually means the remote service was not a ssh service. try to make sure the service on port 135 is actually ssh. </p>

<p>And what's the OS on your server? Windows? if so you may need to setup a 3rd-part ssh server on your server. In my opinion if you need to copy files from windows to windows ftp is a much simpler solution. python has a built-in lib <code>ftplib</code>.</p>
","7687641","","","1","466","Yun Luo","2017-03-10 01:26:28","351","9","2","0","49044642","","2018-03-01 07:28:08","-2","580","<p>I want to transfer a file from a local server (that'll contain the code and file) to a remote server preferably using <code>ssh</code>. Here's the code:</p>

<pre><code>import paramiko

ssh = paramiko.SSHClient()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
ssh.connect('Servername', port = 135, username='username', password='password')
print ""connected successfully!""
sftp = ssh.open_sftp()
print sftp
sftp.put('G:\TestDocument.txt','G:\TestDocument.txt' )
sftp.close()
print ""copied successfully!""

ssh.close()
</code></pre>

<p>But I get this error: </p>

<blockquote>
  <p>No handlers could be found for logger ""paramiko.transport""</p>
  
  <p>Traceback (most recent call last):   File
  ""C:/Python27/testtransfer.py"", line 5, in 
      ssh.connect('Servername', port = 135, username='username', password='password')   File
  ""C:\Python27\lib\site-packages\paramiko\client.py"", line 392, in
  connect
      t.start_client(timeout=timeout)   File ""C:\Python27\lib\site-packages\paramiko\transport.py"", line 545, in
  start_client
      raise e SSHException: Error reading SSH protocol banner</p>
</blockquote>

<p>Can you tell me why am I receiving this error? I have purposely used port 135 because port 22 is closed on the target server and 135 (among others) is open.</p>

<p>You can even suggest some other way in which I can transfer files from one server to another using Python.</p>
","5385722","1714692","2019-02-15 11:57:02","Transfer a file from local server to another using Python library - Paramiko","<python><python-2.7><paramiko>","1","2","1410"
"49046534","2018-03-01 09:29:45","1","","<p>To get the number, you can use this:</p>

<pre><code>balance = soup.find('span', text='Balance').parent.contents[3].strip()
print(balance)
</code></pre>

<p>Output:</p>

<pre><code>9.06451275 BTC
</code></pre>

<p>Explanation:</p>

<p><code>soup.find('span', text='Balance')</code> will get you this <code>&lt;span class=""dash-label""&gt;Balance&lt;/span&gt;</code> tag.</p>

<p>Using <code>.parent.contents</code> will give the contents of its parent tag as a list. In that list, the text you want is located in the 3rd index.</p>

<pre><code>&gt;&gt;&gt; for i, content in enumerate(soup.find('span', text='Balance').parent.contents):
...     print(i, content)
...
0

1 &lt;span class=""dash-label""&gt;Balance&lt;/span&gt;
2 &lt;br/&gt;
3
            9.06451275 BTC


4 &lt;br/&gt;
5

6 &lt;span class=""dash-label""&gt;
                (-0.0500349 BTC unconfirmed)
              &lt;/span&gt;
7
</code></pre>
","7832176","7832176","2018-03-01 09:34:45","4","911","Keyur Potdar","2017-04-07 10:33:50","5988","1260","1872","985","49046234","49046534","2018-03-01 09:10:49","0","88","<p>I am trying to extract the ""Balance"" integer value from <a href=""https://live.blockcypher.com/btc/address/3CpfD1gBBdNW7orErj3YyNNSVpzndZ9aP9/"" rel=""nofollow noreferrer"">this webpage</a> but am having trouble figuring out how to isolate that list item.</p>

<p>This is the code I currently have:</p>

<pre><code>import bs4, requests

res = requests.get('https://live.blockcypher.com/btc/address/3CpfD1gBBdNW7orErj3YyNNSVpzndZ9aP9/')
res.raise_for_status()

soup = bs4.BeautifulSoup(res.text, 'html.parser')
elems = [elem for elem in soup.findAll('li') if 'Balance' in str(elem.text)]

print(elems)
</code></pre>

<p>However when I run it all I get is a [] instead of the real balance value.</p>

<p>Any ideas on where I am going wrong?</p>
","9426337","7832176","2018-03-01 09:41:58","Extracting a specific list item using Beautiful Soup 4","<python><beautifulsoup>","1","0","742"
"49046582","2018-03-01 09:32:37","0","","<p>Solved the problem by setting my spark.pyspark.python property inside the SparkConf object to python 3.5. </p>

<pre><code>spark.pyspark.python=/usr/bin/python3.5
</code></pre>
","4486329","4486329","2018-03-02 04:36:26","0","180","Ravi Kiran","2015-01-23 10:56:16","166","89","40","0","48866329","49046582","2018-02-19 12:33:39","-2","726","<p>I am using the below code. My PYSPARK_PYTHON is set to <strong>python2.7</strong> in spark-env.sh. I am changing it to <strong>python3.5</strong> in the code. Even after changing the path i get the below error. </p>

<pre><code>import os
os.environ[""PYSPARK_PYTHON""]=""/usr/bin/python3""
os.environ[""PYSPARK_DRIVER_PYTHON""]=""/usr/bin/python3""

from abc import ABCMeta
class AbstractHiveClass(metaclass=ABCMeta):

AbstractHiveClass(metaclass=^ABCMeta): Invalid syntax error 
</code></pre>

<p>Tried to run the same in a pyspark shell.Still faced the same issue.</p>

<p>Ran the code by pointing PYSPARK_PYTHON to python3.5 in spark-evn.sh and seems to work fine.</p>

<p>Is there any way to run the above code without changing any configuration in spark-env.sh.</p>
","4486329","1000551","2018-02-19 12:38:14","metaclass=ABCmeta invalid syntax","<python><python-3.x><apache-spark><pyspark>","1","1","766"
"49046596","2018-03-01 09:33:31","1","","<p>From your example it looks like you are mixing two things: defining a Frame object (which contains an image) and defining a collection of Frames (which contains multiple frames, indexed so you can access them as you prefer).</p>

<p>So it looks like a <a href=""https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem"">xy</a> problem: you probably just need to save Frame instances in a dictionary/list type of collection and then access the Frame you need.</p>

<p>Anyway, you can access the value of an attribute of an object using <a href=""https://docs.python.org/2/library/functions.html#getattr"" rel=""nofollow noreferrer"">getattr</a>.</p>

<pre><code>all_frames = []

for i in range(10):
    img = np.random.randint(0, high=255, size=(720, 1280, 3), dtype=np.uint8) # generate a random, noisy image
    all_frames.append(Frame(img, i))

frames_to_plot = [frame for frame in all_frames if getattr(frame, index) == 5]

for frame in frames_to_plot:
    plt.imshow(frame.img)
</code></pre>
","6108661","6108661","2018-03-01 09:50:47","5","1007","FLab","2016-03-24 09:37:12","3960","226","281","8","49046501","49046596","2018-03-01 09:27:25","1","278","<p>I want to find an instance of a class, where an attribute has a certain value:</p>

<pre><code>import numpy as np
import inspect
import matplotlib.pyplot as plt

class Frame():
    def __init__(self, img, idx):
        self.image = img
        self.idx = idx

for i in range(10):
    img = np.random.randint(0, high=255, size=(720, 1280, 3), dtype=np.uint8) # generate a random, noisy image
    Frame(img, i)

# Pseudo Code below:
frame = inspect.getmembers(Frame, idx=5) # find an instance of a class where the index is equal to 5
plt.imshow(frame.img)
</code></pre>
","2450597","","","Python - Find an instance of a class, based on a value of an attribute","<python><class><instance>","2","7","571"
"49046649","2018-03-01 09:36:02","0","","<p>I used textblob-de python package.
<a href=""https://pypi.python.org/pypi/textblob-de"" rel=""nofollow noreferrer"">pypi link</a></p>

<pre><code>from textblob_de.lemmatizers import PatternParserLemmatizer


def lemmatize_text(text):
    _lemmatizer = PatternParserLemmatizer()
    return [_lemmatizer.lemmatize(w)[0][0] for w in text]

removed_pd['test'] = removed_pd['filtered'].apply(lemmatize_text) 
</code></pre>
","6803114","6803114","2018-03-01 10:01:51","5","417","Shubham","2016-09-07 05:36:45","2186","388","266","25","49046342","","2018-03-01 09:17:13","1","347","<p>I am doing some Textmining and therfor I need to lemmatize my documents after tokenization. So I have written a function that uses the python nlp libary spacy to convert my tokenized text column into a lemmatized text column. Actually I supposed that it woulb be easy and straight forward but for some reason it does not work. My DataFrame looks like:</p>

<p><img src=""https://i.stack.imgur.com/nstvC.png"" alt=""my DataFrame""><a href=""https://i.stack.imgur.com/nstvC.png"" rel=""nofollow noreferrer"">1</a></p>

<p>As mentioned before I have written a function for lemmatizing lists of strings using spacy:</p>

<pre><code>de = spacy.load('de')
def lemmatizer(x):
   return [de(unicode(y))[0].lemma_ for y in x]
</code></pre>

<p>When I use it on a simple list of strings, it works fine:</p>

<p><img src=""https://i.stack.imgur.com/pT0Ce.png"" alt=""simple list of strings""><a href=""https://i.stack.imgur.com/pT0Ce.png"" rel=""nofollow noreferrer"">2</a></p>

<p>Problems are occuring when I try to use it on my filtered column using map. </p>

<pre><code>removed_pd['test'] = removed_pd['filtered'].map(lambda x : lemmatizer(x))
</code></pre>

<p><img src=""https://i.stack.imgur.com/yx1bU.png"" alt=""error message""><a href=""https://i.stack.imgur.com/yx1bU.png"" rel=""nofollow noreferrer"">3</a></p>

<p>I don't know why because my lemmatizer function operates on lists and the column 'filtered' contains lists. </p>

<p><img src=""https://i.stack.imgur.com/v50gb.png"" alt=""column type"">]<a href=""https://i.stack.imgur.com/v50gb.png"" rel=""nofollow noreferrer"">4</a></p>

<p>And using other list functions like len works fine:</p>

<pre><code>removed_pd['test'] = removed_pd['filtered'].map(lambda x : len(x))    
</code></pre>

<p><img src=""https://i.stack.imgur.com/7rEkn.png"" alt=""using len function""><a href=""https://i.stack.imgur.com/7rEkn.png"" rel=""nofollow noreferrer"">5</a></p>
","8001477","9232626","2018-03-01 10:06:21","Map on a Pandas DataFrame Column cointaining lists","<python><python-2.7><pandas><spacy>","1","4","1876"
"49046720","2018-03-01 09:40:32","1","","<p>python dictionnaries are not ordered by default. You can create an <a href=""https://docs.python.org/3.6/library/collections.html#collections.OrderedDict"" rel=""nofollow noreferrer""><code>OrderedDict</code></a> if you want to remember the order of insertions.</p>

<p>Just replace your initialization of <code>dict</code> with:</p>

<pre><code>dict = collections.OrderedDict()
</code></pre>

<p>The dictionnary will however be ordered by insertion order, not by date.</p>
","4153209","","","1","473","Thomas Francois","2014-10-17 10:33:37","709","53","413","235","49046584","49046720","2018-03-01 09:32:42","-1","50","<p>I have code that is opening a file and reading a dictionary that is inside a dictionary. I want to take all the values from the key ""time"" and all the values from the key ""close"" and join them together as a key:value pair in a separate dictionary. My code achieves this however, I need the resulting dictionary to be ordered the same way it was from the dictionary i'm pulling from since they are dates. For some reason after the 3rd iteration the dates begin to get scrambled inside the new dictionary i've created. Any way to fix this?</p>

<p>Here's the sample</p>

<pre><code>import json
import datetime

dict={}

def parsehistory():

    file = json.load(open('histoday.json')) #open file
        for i in range(len(file[""Data""])): #iterate through subdictionaries
            time  = file[""Data""][i][""time""] #get all values from key ""time""
            close = file[""Data""][i][""close""] #get all values from key ""close""
            convert = datetime.datetime.utcfromtimestamp(time).strftime('%m-%d-%Y') #convert time from unix to UTC
            dict[convert] = close #join values

            print(dict)
</code></pre>

<p>Here is a sample of the output which is clearly not ordered by date like which it came {'02-05-2018': 6937.08, '02-03-2018': 9251.27, '02-06-2018': 7701.25, '02-21-2018': 10481.66,}</p>

<p>Any help is appreciated</p>
","9428009","","","Iterating over a dictionary and creating new one inside a for loop preserving order","<python><loops><sorting><dictionary>","1","1","1350"
"49046744","2018-03-01 09:41:56","0","","<p>You need to set the M as two dimensional array first, then you can use concatenate, based on its axis.
Next, in python, range is up to count exclusive. Thus, you need to add 1.</p>

<p>Your code is modified into the following:</p>

<pre><code>import numpy as np
import matplotlib.pylab as plt

def sierpinski(count=3):
    M = np.array([[0]])   
    for x in range(1,count+1):
        M = np.concatenate((np.concatenate((M, M, M), axis=1),
            np.concatenate((M, np.ones([3**(x-1),3**(x-1)]), M), axis=1),
            np.concatenate((M, M, M), axis=1)),axis=0)
    return M

# run the code
M=sierpinski()
plt.spy(M)
plt.show()
</code></pre>

<p>When you run it produces beautiful Sierpinski Gasket:
<a href=""https://i.stack.imgur.com/P4L8t.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/P4L8t.jpg"" alt=""enter image description here""></a></p>
","8208481","","","0","873","Kardi Teknomo","2017-06-24 08:05:23","570","78","197","6","49045804","","2018-03-01 08:46:27","2","102","<p>I am trying to convert a snippet of MATLAB code into python, the MATLAB code is as follows:</p>

<pre><code>M = 0;
for k=1:i
    M = [M,        M,      M;
    M, ones(3^(k-1)), M;
    M,        M,      M];
end
</code></pre>

<p>which creates a 2d array that mimics a sierpinski carpet<br>
my python implementation is as such:</p>

<pre><code>M = 0   
for x in range(1,count):
        square = np.array([[M, M, M], [M, np.ones([3**(x-1),3**(x-1)]), M], [M, M, M]])
</code></pre>

<p>I know I am missing something with the nature of how the arrays are concatenated, since my python output is coming up with more than two dimensions. How would I maintain a 2d array that creates the same output?</p>
","9427889","2945357","2018-03-01 12:28:08","Iterative array creation in matlab and python","<python><arrays><matlab><numpy><concatenation>","2","1","700"
"49046745","2018-03-01 09:41:56","0","","<p>You can use list comprehension with <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.itertuples.html"" rel=""nofollow noreferrer""><code>itertuples</code></a> for new <code>DataFrame</code> and then get new column by <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html"" rel=""nofollow noreferrer""><code>groupby</code></a> and <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.size.html"" rel=""nofollow noreferrer""><code>size</code></a>:</p>

<pre><code>df = pd.DataFrame(index=pd.to_datetime(['2018-01-01','2018-01-05']))
df['duration'] = pd.to_timedelta([10,8], unit='D')
df['end_date'] = df.index + df['duration']
print (df)
           duration   end_date
2018-01-01  10 days 2018-01-11
2018-01-05   8 days 2018-01-13

df = df.rename_axis('start_date').reset_index()
com = [pd.Series(r.Index,pd.date_range(r.start_date, r.end_date)) for r in df.itertuples()]
df1 = pd.concat(com).reset_index()
df1.columns=['Date','Number']
df1 = df1.groupby('Date')['Number'].size().reset_index()
print (df1)
         Date  Number
0  2018-01-01       1
1  2018-01-02       1
2  2018-01-03       1
3  2018-01-04       1
4  2018-01-05       2
5  2018-01-06       2
6  2018-01-07       2
7  2018-01-08       2
8  2018-01-09       2
9  2018-01-10       2
10 2018-01-11       2
11 2018-01-12       1
12 2018-01-13       1
</code></pre>

<p>It is faster as <code>iterrows</code> solution:</p>

<pre><code>In [288]: %timeit (iterrows_sol(df))
10 loops, best of 3: 51.1 ms per loop

In [289]: %timeit (itertupl_sol(df))
100 loops, best of 3: 10.2 ms per loop
</code></pre>

<p>Sample:</p>

<pre><code>df = pd.DataFrame(index=pd.to_datetime(['2018-01-01','2018-01-05'] * 10))
df['duration'] = pd.to_timedelta([10,8,2,3,7,2,1,9,1,20,7,18,9,0,3,20,10,8,3,15] , unit='D')
df['end_date'] = df.index + df['duration']
print (df)
           duration   end_date
2018-01-01  10 days 2018-01-11
2018-01-05   8 days 2018-01-13
2018-01-01   2 days 2018-01-03
2018-01-05   3 days 2018-01-08
2018-01-01   7 days 2018-01-08
2018-01-05   2 days 2018-01-07
2018-01-01   1 days 2018-01-02
2018-01-05   9 days 2018-01-14
2018-01-01   1 days 2018-01-02
2018-01-05  20 days 2018-01-25
2018-01-01   7 days 2018-01-08
2018-01-05  18 days 2018-01-23
2018-01-01   9 days 2018-01-10
2018-01-05   0 days 2018-01-05
2018-01-01   3 days 2018-01-04
2018-01-05  20 days 2018-01-25
2018-01-01  10 days 2018-01-11
2018-01-05   8 days 2018-01-13
2018-01-01   3 days 2018-01-04
2018-01-05  15 days 2018-01-20
</code></pre>

<p>Functions:</p>

<pre><code>def iterrows_sol(df):
    active_subscribers = pd.DataFrame({
    'Date': pd.date_range(start=df.index.min(), end=df['end_date'].max()),
    'Number': 0,})

    active_subscribers.set_index('Date', inplace=True)

    for index, row in df.iterrows():
        for this_date in pd.date_range(start=index, end=row['end_date']):
            active_subscribers.loc[this_date, 'Number'] += 1
    return active_subscribers

def itertupl_sol(df):
    df = df.rename_axis('start_date').reset_index()
    com = [pd.Series(r.Index,pd.date_range(r.start_date,r.end_date)) for r in df.itertuples()]
    df1 = pd.concat(com).reset_index()
    df1.columns=['Date','Number']
    df1 = df1.groupby('Date')['Number'].size().reset_index()
    return (df1)
</code></pre>
","2901002","2901002","2018-03-01 11:22:23","0","3357","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49036206","49046745","2018-02-28 18:25:35","1","62","<p>I have a pandas dataframe <code>df</code> for which each row contains a <code>start_date</code> (which is the index too) and a <code>duration</code> (in days) for subscriptions.</p>

<pre><code>import pandas as pd    
df = pd.DataFrame({'start_date':['2018-01-01','2018-01-05']})
df['start_date'] = df['start_date'].astype('datetime64[ns]')
df['duration'] = pd.to_timedelta([10,8], unit='D')
df['end_date'] = df['start_date'] + df['duration']
</code></pre>

<p>I'd like to plot the number of subscribers over time.</p>

<p>My idea was to create another data frame <code>subscribers</code>:</p>

<pre><code>active_subscribers = pd.DataFrame({
    'Date': pd.date_range(start=df.index.min(),end=df['end_date'].max()),
    'Number': 0,
})
active_subscribers.set_index('Date', inplace=True)
</code></pre>

<p><code>Date</code>covers the entire period of time when at least one subscriber is active. Then I was thinking creating date ranges for each subscription and adding them to the <code>Number</code> column like so:</p>

<pre><code>for index, row in df.iterrows():
    for this_date in pd.date_range(start=index, end=row['end_date']):
        active_subscribers[this_date]['Number'] += 1
</code></pre>

<p>but this returns the following error:</p>

<p><code>KeyError: Timestamp('2018-01-01 00:00:00', freq='D')</code></p>

<p>What I was hoping to get is a <code>Number</code>column that looks like this:</p>

<pre><code>Date         Number
2018-01-01     1
2018-01-02     1
2018-01-03     1
2018-01-04     1
2018-01-05     2
2018-01-06     2
2018-01-07     2
2018-01-08     2
2018-01-09     2
2018-01-10     2
2018-01-11     1
2018-01-12     1
2018-01-13     1
</code></pre>

<p>Where the column <code>Number</code>contains the number of active subscribers that day.</p>

<p>Please let me know if you have any suggestion</p>
","8628656","8628656","2018-03-01 00:05:03","python pandas obtain number of active subscribers from subscription start date and duration","<python><pandas><datetime><date-range>","1","3","1829"
"49046779","2018-03-01 09:44:06","1","","<p>Assuming this <code>class</code>:</p>

<pre><code>class Frame():
    def __init__(self, img, idx):
        self.image = img
        self.idx = idx
</code></pre>

<p>and two instances:</p>

<pre><code>a = Frame('foo', 1)
b = Frame('bar', 2)
</code></pre>

<p>You can find the one with <code>idx=1</code> like so:</p>

<pre><code>import gc


def find_em(classType, attr, targ):
    return [obj.image for obj in gc.get_objects() if isinstance(obj, classType) and getattr(obj, attr)==targ]

print(find_em(Frame, 'idx', 1))  # -&gt; ['foo']
</code></pre>

<p>Note that if you have a big code with lots of objects created in memory, <code>gc.get_objects()</code> will be big and thus this approach rather slow and inefficient. The <code>gc.get_objects()</code> idea I got from <a href=""https://stackoverflow.com/a/328882/6162307"">here</a>.</p>

<p>Does this answer your question?</p>
","6162307","","","1","881","Ev. Kounis","2016-04-05 15:46:06","11755","1841","2162","212","49046501","49046596","2018-03-01 09:27:25","1","278","<p>I want to find an instance of a class, where an attribute has a certain value:</p>

<pre><code>import numpy as np
import inspect
import matplotlib.pyplot as plt

class Frame():
    def __init__(self, img, idx):
        self.image = img
        self.idx = idx

for i in range(10):
    img = np.random.randint(0, high=255, size=(720, 1280, 3), dtype=np.uint8) # generate a random, noisy image
    Frame(img, i)

# Pseudo Code below:
frame = inspect.getmembers(Frame, idx=5) # find an instance of a class where the index is equal to 5
plt.imshow(frame.img)
</code></pre>
","2450597","","","Python - Find an instance of a class, based on a value of an attribute","<python><class><instance>","2","7","571"
"49046788","2018-03-01 09:44:34","0","","<p>Here is an example with cmds.sets() to assign a shader :</p>

<pre><code>all = cmds.ls(type='mesh')
shadingEngine = 'initialShadingGroup'
cmds.sets(all, e=True, forceElement=shadingEngine)
</code></pre>

<p>as you can guess, to query meshes with the material :</p>

<pre><code>lamb1_mshs = cmds.sets(shadingEngine, q=True)
</code></pre>
","2742418","","","3","340","DrWeeny","2013-09-03 09:17:06","1952","1022","209","26","49035311","","2018-02-28 17:25:56","1","340","<p>I get all shapes assigned to baseMaterial, select the shapes and then assign the occlusionShader.</p>

<pre><code>for materialClass in materialClassList:
    select(materialClass.baseMaterial)
    hyperShade(objects="""")
    hyperShade(a=materialClass.occlusionShader)
</code></pre>

<p>works just fine, but if I use it as a pre render script:</p>

<pre><code>  Error: line 0: hyperShade command not supported in batch mode
</code></pre>

<p>What can I change the two last lines of my function to to make this work?</p>
","7302635","","","change shader on all assigned meshes, without using hyperShade()","<python><maya>","2","1","522"
"49046810","2018-03-01 09:45:32","1","","<pre><code>import sys
import os

print(str(sys.path))

dir_path = os.path.dirname(os.path.realpath(__file__))
print(""current working dir: %s"" dir_path)

sys.path.insert(0, dir_path)
</code></pre>

<p>I strongly suggest you use virtualenv and virtualenvwrapper to avoid cluttering path</p>
","1447071","1447071","2019-01-02 07:30:53","3","289","Rubber Duck","2012-06-10 07:39:52","1977","260","405","4","10738919","10739838","2012-05-24 13:57:03","94","76915","<p>I am trying to add a path to the PYTHONPATH environment variable, that would be only visible from a particular virtualenv environment. </p>

<p>I tried <code>SET PYTHONPATH=...</code> under a virtualenv command prompt, but that sets the variable for the whole environment.</p>

<p>How do I achieve that?</p>
","980059","190597","2015-03-01 18:48:42","How do I add a path to PYTHONPATH in virtualenv","<python><virtualenv>","5","0","311"
"49046813","2018-03-01 09:45:37","0","","<p>Since list comprehensions seem not to be an option and you seem only interested in the <em>first</em> matching tuple, how about a generator expression:</p>

<pre><code>next(t for t in ts if t[1] == 'c', None)
</code></pre>
","4042267","","","0","226","Graipher","2014-09-15 11:02:12","5186","486","1152","21","49045444","","2018-03-01 08:25:48","0","59","<p>I am trying to find tuples in a list with a certain symbol at the 2nd position. The list looks something like this:</p>

<pre><code>list = [ (0, ""a"", 1), (1, ""b"", 2), (2, ""c"", 3)]
</code></pre>

<p>I can obviously find all the tuples with e.g. a ""c"" by running the following code:</p>

<pre><code>for item in list:
    if item[1] == ""c"":
        return item
</code></pre>

<p>I was just wondering if I could combine line1 and line2 of the above given code to do something like</p>

<pre><code>for (numb1, symbol==""c"", numb2) in list:
    return (numb1, symbol, numb2)
</code></pre>

<p>Does anyone know if there is a shortcut for this?</p>

<p>Thank you!</p>
","9409605","532312","2018-03-01 08:26:36","check element of tuple at certain position - shortcut?","<python><list><indexing><tuples>","5","5","662"
"49046882","2018-03-01 09:49:22","2","","<p>using np.array might not work for a very large dataset with the following error</p>

<p>""ValueError: array is too big; <code>arr.size * arr.dtype.itemsize</code> is larger than the maximum possible size.""</p>

<p>CDO can be a nice tool other than NCO and for me, it is much fast.</p>

<pre><code>CDO setvals,10,2 in.nc out.nc
</code></pre>

<p>It is particularly fast when you have to replace values in more than one variables in the same nc file (e.g. replace missing values representation). 
One can use ""setrtoc"" in place of setval for specifying a range.</p>
","7298014","","","0","566","Vinod Kumar","2016-12-14 17:26:45","59","23","19","0","42301458","","2017-02-17 15:19:36","2","3438","<p>I have a large netcdf file which is three dimensional. I want to replace for the variable <code>LU_INDEX</code> in the netcdf file all the values 10 with 2. </p>

<p>I wrote this python script to do so but it does not seem to work. </p>

<pre><code>filelocation = 'D:/dataset.nc'

ncdataset = nc.Dataset(filelocation,'r')
lat           = ncdataset.variables['XLAT_M'][0,:,:]
lon           = ncdataset.variables['XLONG_M'][0,:,:]
lu_index     = ncdataset.variables['LU_INDEX'][0,:,:]
lu_index_new = lu_index
ncdataset.close()

nlat,nlon=lat.shape

for ilat in range(nlat):
    for ilon in range(lon):
        if lu_index == 10:
          lu_index_new[ilat,ilon] = 2

newfilename = 'D:/dataset.new.nc'
copyfile(ncdataset,newfilename)


newfile     = nc.Dataset(newfilename,'r+')
newfile.variables['LU_INDEX'][0,:,:]   = lu_index_new
newfile.close()
</code></pre>

<p>I get the error: </p>

<pre><code>The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
</code></pre>

<p>I am not a very experienced with python, so if there is a more easier way to do this you are very welcome to comment. </p>
","7581459","2666859","2017-02-25 06:15:48","Changing value of a netcdf file for a variable","<python><netcdf>","3","0","1135"
"49046937","2018-03-01 09:51:58","0","","<p>Well I think the issue is that inside the scope of <code>multiproc_log_result</code> the variable <code>results</code> doesn't exist. 
So what you should do is append to results directly the result of your async call.
You won't be able to track the progress though (no way to directly share a global variable for a callback function outside a class I guess)</p>

<pre><code>from multiprocessing.pool import ThreadPool

def nested_stupid_fn():
    def multiproc_log_result(retval):
        results.append(retval)

    def veggie():
        print 'carrot'
        status = True
        return status

    results = []
    pool = ThreadPool(thread_count)
    for x in range(10):
        results.append(pool.apply_async(veggie))

    pool.close()
    pool.join()

    results = [result.get() for result in results]  # get value from async result

    ...then do stuff with results
</code></pre>
","4158837","4158837","2018-03-01 10:10:56","4","894","Gabriel Samain","2014-10-19 13:01:01","389","17","14","5","49040620","","2018-03-01 00:01:11","2","311","<p>thanks for taking a look at this. I confess I have been dabbling with parallel processing in python for all of 1 week now so I apologize if there is an obvious solution I missed. I have a piece of code that I would like to run several different instances of of a mp.pool(). Those that were on the main .py file called worked fine but when I tried to add them to functions in modules I get no output from them all. The app just runs past it and continues.  I am thinking it may have something to do with this <a href=""https://stackoverflow.com/questions/46266803/multiprocessing-pool-not-working-in-nested-functions"">post</a> but it didn't give any ideas on alternative methods to accomplish what I need. The code that works in a simple example is this:</p>

<pre><code>import multiprocessing as mp
def multiproc_log_result(retval):
    results.append(retval)
    if len(results) % (10 // 10) == 0:
        print('{0}% done'.format(100 * len(results) / 10))

def meat():
    print 'beef'
    status = True
    return status
results = []
pool = mp.Pool(thread_count)
for x in range(10):
    pool.apply_async(meat, callback=multiproc_log_result)
pool.close()
pool.join()


def veggie():
    print 'carrot'
    status = True
    return status

results = []
pool = mp.Pool(thread_count)
for x in range(10):
    pool.apply_async(veggie, callback=multiproc_log_result)
pool.close()
pool.join()
</code></pre>

<p>And the code that doesn't work is:</p>

<pre><code>import multiprocessing as mp
def multiproc_log_result(retval):
    results.append(retval)
    if len(results) % (10 // 10) == 0:
        print('{0}% done'.format(100 * len(results) / 10))

def meat():
    print 'beef'
    status = True
    return status
results = []
pool = mp.Pool(thread_count)
for x in range(10):
    pool.apply_async(meat, callback=multiproc_log_result)
pool.close()
pool.join()

def nested_stupid_fn():
    def multiproc_log_result(retval):
        results.append(retval)
        if len(results) % (10 // 10) == 0:
            print('{0}% done'.format(100 * len(results) / 10))

    def veggie():
        print 'carrot'
        status = True
        return status

    results = []
    pool = mp.Pool(thread_count)
    for x in range(10):
        pool.apply_async(veggie, callback=multiproc_log_result)
    pool.close()
    pool.join()
nested_stupid_fn()
</code></pre>

<p>Ultimately I would like that example that doesn't work to be one more step removed by having it live in another function in a separate module. So that when I import the module packngo and use it as packngo.basic_packngo(inputs) and has the contents of the nest function somewhere within it they would run. Any help would be greatly appreciated. :D I am a very simple man so if you could explain as you would to a child maybe then it will sink in my head!</p>
","5390817","364696","2019-06-28 16:18:33","Is there any way to use multiprocessing.pool within a nested function or module?","<python><python-2.7><python-multiprocessing><process-pool>","2","1","2812"
"49046940","2018-03-01 09:52:11","1","","<p>To check if the <em>ng-grid</em> cell is selected or not you can use the following code block :</p>

<pre><code>divClasses = driver.find_element_by_xpath(""//div[@class='ui-grid-cell-contents ng-binding ng-scope' and contains(text(), 'Stefan')]//ancestor::div[@class='ui-grid-row ng-scope']"").get_attribute(""class"")
if ""ui-grid-row-selected"" in divClasses :
    print(""Row is selected"")
else :
    print(""Row is not selected"")
</code></pre>
","7429447","2458730","2018-03-01 12:00:41","1","443","DebanjanB","2017-01-17 08:59:30","63154","13103","3455","2612","49042698","49046940","2018-03-01 04:36:28","1","255","<p>I am trying to find the ng-grid cell from the div structure as in the screenshot below,  using the following xpath and clicking on it.</p>

<pre><code>""//div[@class='ui-grid-cell-contents ng-binding ng-scope' and contains(text(), 'Stefan')]""
</code></pre>

<p>This xpath is working, but how do I find if the row is selected before I click on it. </p>

<p><a href=""https://i.stack.imgur.com/XE8G0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XE8G0.png"" alt=""enter image description here""></a></p>

<p>There is a parent class name that says whether the row is selected or not, and I used the following Xpath's using the parent div,, but it does not seem to work.</p>

<pre><code>//div[@class='ui-grid-row ng-scope' and contains(text(), 'Stefan')]

//div[@class='ui-grid-row ng-scope ui-grid-row-selected' and contains(text(), 'Stefan')]
</code></pre>

<p>Any other way I can achieve this?</p>
","2458730","7429447","2018-03-01 09:51:25","How to find if ng-grid row is selected or not using selenium","<python><selenium><selenium-webdriver>","1","5","916"
"49046967","2018-03-01 09:54:06","0","","<p>Check the file structure/ tree of <code>dashboard_miner (the actual package)</code> it has to contain a <strong>init</strong>.py so that it can be recognized by Python as a module.</p>
","8933250","","","0","188","David Parseen Maitoyo","2017-11-13 14:10:24","26","12","0","0","48228514","49077599","2018-01-12 14:42:59","0","163","<p>We have a custom module that works perfectly on Windows 10, however, it fails on our Linux cloud instance (Debian Jessie) with ModuleNotFoundError.
The folder structure is the following:</p>

<pre><code>|-dashboard-miner (git repo)
  |-setup.py
    |-dashboard_miner (the actual package)
</code></pre>

<p>Our setup.py is the following:</p>

<pre><code>from setuptools import setup, find_packages
import dashboard_miner
import os

MODULE_BASEDIR = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'dashboard_miner')

try:
    long_description = open('README.md').read()
except IOError:
    long_description = ''

try:
    reqs = open(os.path.join(os.path.dirname(__file__), 'requirements.txt')).read()
except (IOError, OSError):
    reqs = ''

print(find_packages(where=MODULE_BASEDIR))

setup(
    name='dashboard_miner',
    version=dashboard_miner.get_version(short=True),
    description='Data mining utilities for True Cloud Dashboard',
    long_description=long_description,
    url='https://gitlabe1.ext.net.nokia.com/TCI/dashboard-miner',
    author='Hodossy, Szabolcs',
    author_email='szabolcs.hodossy@nokia.com',
    license='NOKIA Confidential',
    packages=find_packages(where=MODULE_BASEDIR),
    package_dir={'': 'dashboard_miner'},
    install_requires=reqs,
    entry_points={
        'console_scripts': [
            'miner=dashboard_miner.cli:main',
        ]
    },
    zip_safe=False
)
</code></pre>
","9209366","9209366","2018-01-15 10:58:32","ModuleNotFoundError when trying to use package","<python><module><importerror>","2","0","1436"
"49046978","2018-03-01 09:54:32","0","","<p>Found it. My HTTPS was messing up. So the fact that I had CSRF_COOKIE_SECURE = TRUE was messing up all attempts to send a cookie.</p>
","9259672","","","0","137","thrillhouse","2018-01-24 01:09:08","26","19","2","0","49042232","","2018-03-01 03:37:11","1","55","<p>I have two forms on two pages, one leads to the other. When ""Submit"" is pressed on page 1 it is supposed to take you to the form on page 2. Page 2 fails with ""CSRF verification failed. Request aborted."" With the reason being ""CSRF cookie not set.""</p>

<p>The weird part is that if I go directly to Page 2, it loads fine. If I refresh the page and resubmit the form, I get 403'd again, but if, for example, I go into the address bar and just hit ""Enter"" to re-visit the page, it loads without the error. What gives?</p>

<p>I am using the most recent version of Django, I am using render in all my views and {% csrf_token %} in all my form tags.</p>

<p>Why would revisiting the page be fixing the 403 error? No login or authentication is happening between the forms. In fact, I don't even do anything with the data submitted in page 1 (yet).</p>

<p>Relevant code is as follows:</p>

<p>Page 1 Template:</p>

<pre><code>&lt;div class=""""&gt;
    &lt;div class=""""&gt;
        &lt;h1&gt;Page 1&lt;/h1&gt;
        &lt;p&gt;What's up?&lt;/p&gt;
        &lt;form action=""{% url 'core:getPageTwo' %}"" method=""post""&gt;
            {% csrf_token %}
            {{ form }}
            &lt;input class=""yellow_button"" type=""submit"" value=""Submit""&gt;
        &lt;/form&gt;
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p>Page 2 View:</p>

<pre><code>def getPageTwo(request):
    form = SomeForm()
    context = {'form' : form}
    return render (request, 'core/page_two.html', context)
</code></pre>

<p>Page 2 Template:</p>

<pre><code>&lt;div class=""""&gt;
    &lt;div class=""""&gt;
        &lt;h1&gt;Page 2&lt;/h1&gt;
        &lt;form action=""#"" method=""post""&gt;
            {% csrf_token %}
            {{ form }}
        &lt;/form&gt;
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>
","9259672","","","Django CSRF Error fixed by just visiting page in multi-page form?","<python><django><cookies><web><csrf>","2","0","1777"
"49046986","2018-03-01 09:55:01","1","","<p>The problem is not in the traci part but in your adoID which is an array but should be a single id (a string) so you should probably just take the first element of that array.</p>
","5731587","","","4","183","Michael","2015-12-30 17:34:13","1954","233","8","3","49038658","49046986","2018-02-28 21:13:27","0","95","<h1>Objective</h1>

<p>I want to use predefined speed vectors for individual vehicles to move them in SUMO simulation.  </p>

<h1>Data and files</h1>

<p>There are 3 vehicles in the simulation. For 2 of those vehicles, I want to specify the speeds. The speed data is created in <code>Python</code> as follows:  </p>

<pre><code>import numpy as np
import pandas as pd
from pandas import Series, DataFrame

data = {'ADO_name':['car1','car1','car1','car2','car2','car2'],
        'Time_sec':[0,1,2,0,1,2],
        'Speed.kph':[50,51,52,0,0,52]}
dframe = DataFrame(data)  
</code></pre>

<p>The route, network and configuration files for this simulation are available in a folder here:  <a href=""https://1drv.ms/f/s!AsMFpkDhWcnw61EI5wR6hPaaRBJI"" rel=""nofollow noreferrer"">https://1drv.ms/f/s!AsMFpkDhWcnw61EI5wR6hPaaRBJI</a><br>
I have also put the code in a <code>Script.py</code> file in the same folder.  </p>

<h1>What I tried</h1>

<p>Following is the code that I've been trying to use, along with the error:  </p>

<pre><code>#start sumo
sumoBinary = ""C:/Users/Quinton/Desktop/Documents/Sumo/bin/sumo-gui""
sumoCmd = [sumoBinary, ""-c"", ""C:/Users/Quinton/Desktop/Example2/example2.sumocfg""]


#importing libraries
import traci
import traci.constants as tc
traci.start(sumoCmd)

#subscribing to variables that we want to be printed once the copy has run
traci.vehicle.subscribe(""car1"", (tc.VAR_SPEED, tc.VAR_ROAD_ID, tc.VAR_LANE_ID, tc.VAR_LANEPOSITION))
traci.vehicle.subscribe(""car2"", (tc.VAR_SPEED, tc.VAR_ROAD_ID, tc.VAR_LANE_ID, tc.VAR_LANEPOSITION))
traci.vehicle.subscribe(""car3"", (tc.VAR_SPEED, tc.VAR_ROAD_ID, tc.VAR_LANE_ID, tc.VAR_LANEPOSITION))

#using traci.movetoXY to position car1 and car2 on network
traci.vehicle.moveToXY(vehID=""car1"", edgeID=""highway1.1"", lane=0, x=1000, y=-3.3, keepRoute=0)
traci.vehicle.moveToXY(vehID=""car2"", edgeID=""highway1.1"", lane=1, x=700, y=3.3, keepRoute=0)

#disallows car1 and car2 from changing lanes during simulation
traci.vehicle.setLaneChangeMode(vehID=""car1"", lcm=512)
traci.vehicle.setLaneChangeMode(vehID=""car2"", lcm=512)


#importing python modules
import numpy as np
import pandas as pd
from pandas import Series, DataFrame

#creating speed data
data = {'ADO_name':['car1','car1','car1','car2','car2','car2'],
        'Time_sec':[0,1,2,0,1,2],
        'Speed.kph':[50,51,52,0,0,52]}
dframe = DataFrame(data)
#print(dframe)

step = 0

#running traci
for ado in dframe.groupby('ADO_name'):
  ado_name = ado[1][""ADO_name""]
  adoID = ado_name.unique()

  while step &lt;= 2:
    traci.simulationStep()
    traci.vehicle.setSpeed(adoID, ado[1][ado[1].Time_sec == step]['Speed.kph'])
    print (traci.vehicle.getSubscriptionResults(""car1""), traci.vehicle.getSubscriptionResults(""car2""))

  step += 1  
</code></pre>

<h1>Error:</h1>

<pre><code>Traceback (most recent call last):
  File ""C:\Users\Quinton\AppData\Local\Temp\Rtmp6jCqR4\chunk-code-16888822790.txt"", line 41, in &lt;module&gt;
    traci.vehicle.setSpeed(adoID, ado[1][ado[1].Time_sec == step]['Speed.kph'])
  File ""C:\Program Files (x86)\DLR\Sumo\tools\traci\_vehicle.py"", line 927, in setSpeed
    tc.CMD_SET_VEHICLE_VARIABLE, tc.VAR_SPEED, vehID, speed)
  File ""C:\Program Files (x86)\DLR\Sumo\tools\traci\connection.py"", line 139, in _sendDoubleCmd
    self._beginMessage(cmdID, varID, objID, 1 + 8)
  File ""C:\Program Files (x86)\DLR\Sumo\tools\traci\connection.py"", line 127, in _beginMessage
    self._packString(objID, varID)
  File ""C:\Program Files (x86)\DLR\Sumo\tools\traci\connection.py"", line 66, in _packString
    self._string += struct.pack(""!Bi"", pre, len(s)) + s.encode(""latin1"")
AttributeError: 'numpy.ndarray' object has no attribute 'encode'  
</code></pre>

<h1>Notes</h1>

<p>From my understanding, the problem is somewhere in <code>#running traci</code> section of the code. I tested this code without invoking <code>TraCI</code> and using <code>print()</code> instead of  <code>traci.vehicle.setSpeed()</code> and got no error. So, it seems that <code>Python</code> side of things are fine. Could you please help me fixing this problem</p>
","2829961","","","How to set speeds using a pandas dataframe in SUMO with TraCI?","<python><sumo>","1","0","4081"
"49047005","2018-03-01 09:56:26","0","","<p>You want to access member or the other cols ? 
just do that : </p>

<pre><code>df.select(""group_profile.group.id"", 
          ""group_profile.group.members"",
          ""group_profile.intro"",
          ""group_profile.link"",
          ""group_profile.role"",
         )
</code></pre>
","5013752","","","4","282","Steven","2015-06-16 04:27:36","4021","506","146","66","49046909","49047005","2018-03-01 09:50:24","0","32","<p>I am new in spark and pyspark.
My DataFrame is composed of several columns and Inside some columns, the is arrays or sub dataframes.</p>

<p>the printSchema of the df is in the <a href=""https://i.stack.imgur.com/x6v07.png"" rel=""nofollow noreferrer"">image below</a></p>

<p>My question is how can I access the elements such as the <a href=""https://i.stack.imgur.com/eGYPN.png"" rel=""nofollow noreferrer"">""role"" the ""member""</a>
Thank you for your help</p>
","5288995","2618461","2018-03-01 15:24:34","Access data frames elements pyspark in jupyter","<python><apache-spark><dataframe><pyspark>","1","0","457"
"49047033","2018-03-01 09:57:22","-1","","<p>In Python if we use a variable and pass it to a function then it will be Call by Value whatever changes you make to the variable it will not be reflected to the original variable.</p>

<p>But when you use a list instead of a variable then the changes that you make to the list in the functions are reflected in the original List outside the function so this is called call by reference.</p>

<p>And this is the reason for the second option does work and the first option doesn't.</p>
","9392351","","","0","487","Nixel","2018-02-21 17:25:35","110","55","56","0","49046554","49047038","2018-03-01 09:31:08","5","913","<p>I am reading <em>Hackers and Painters</em> and am confused by a problem mentioned by the author to illustrate the power of different programming languages.</p>

<p>The problem is:</p>

<blockquote>
  <p>We want to write a function that generates accumulators—a function that takes a number <em>n</em>, and returns a function that takes another number <em>i</em> and returns <em>n</em> incremented by <em>i</em>. (That’s <em>incremented</em> by, not plus. An accumulator has to accumulate.)</p>
</blockquote>

<p>The author mentions several solutions with different programming languages. For example, Common Lisp:</p>

<pre><code>(defun foo (n)
  (lambda (i) (incf n i)))
</code></pre>

<p>and JavaScript:</p>

<pre><code>function foo(n) { return function (i) { return n += i } }
</code></pre>

<p>However, when it comes to Python, the following codes do not work:</p>

<pre><code>def foo(n):
    s = n
    def bar(i):
        s += i
        return s
    return bar

f = foo(0)
f(1)  # UnboundLocalError: local variable 's' referenced before assignment
</code></pre>

<p>A simple modification will make it work:</p>

<pre><code>def foo(n):
    s = [n]
    def bar(i):
        s[0] += i
        return s[0]
    return bar
</code></pre>

<p>I am new to Python. Why doesn the first solution not work while the second one does? The author mentions lexical variables but I still don't get it.</p>
","6181069","124319","2018-03-01 19:12:07","Function that returns an accumulator in Python","<python><scope><closures><common-lisp><local-variables>","4","2","1395"
"49047034","2018-03-01 09:57:23","1","","<p>On Linux, you can just add the path to the <em>parent folder</em> of your <code>src</code> directory to <code>~/.local/lib/python3.6/site-packages/my_modules.pth</code>. See 
<a href=""https://stackoverflow.com/questions/15208615/using-pth-files#15209116"">Using .pth files</a>. You can then import modules in <code>src</code> from anywhere on your system.</p>

<p>NB1: Replace <code>python3.6</code> by any version of Python you want to use.</p>

<p>NB2: If you use Python2.7 (don't know for other versions), you will need to create <code>__init__.py</code> (empty) files in <code>src/</code> and <code>src/utils</code>.</p>

<p>NB3: Any name<code>.pth</code> file is ok for <code>my_modules.pth</code>.</p>
","9342522","","","0","710","Rémi.B","2018-02-10 13:22:09","63","13","127","0","48759465","","2018-02-13 04:28:48","10","1943","<p>I'm trying to keep a data science project well-organized so I've created a directory inside my <code>src</code> directory called <code>utils</code> that contains a file called <code>helpers.py</code>, which contains some helper functions that will be used in many scripts. What is the best practice for how I should import <code>func_name</code> from <code>src/utils/helpers.py</code> into a file in a totally different directory, such as <code>src/processing/clean_data.py</code>?</p>

<p>I see <a href=""https://stackoverflow.com/questions/4383571/importing-files-from-different-folder"">answers</a> to this question, and I've implemented a solution that works, but this feels ugly:</p>

<pre><code> sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))))
</code></pre>

<p>Am I doing this right? Do I need to add this to every script that wants to import <code>func_name</code>, like <code>train_model.py</code>?</p>

<p>My current project folder structure:</p>

<pre><code>myproject
    /notebooks
        notebook.ipynb
    /src
        /processing
            clean_data.py
        /utils
            helpers.py
        /models
            train_model.py
        __init__.py
</code></pre>

<p>Example files:</p>

<pre><code># clean_data.py

import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))))
from src.utils.helpers import func_name

func_name()


# helpers.py

def func_name():
    print('I'm a helper function.')
</code></pre>
","2569531","3154233","2018-02-13 04:38:12","Do I need to add my project directory to the system path in every script to import a function from another directory?","<python>","7","4","1542"
"49047038","2018-03-01 09:57:40","5","","<p><code>s += i</code> is just sugar for <code>s = s + i</code>.<sup>*</sup></p>

<p>This means you assign a new value to the variable <code>s</code> (instead of mutating it in place). When you assign to a variable, Python assumes it is local to the function. However, before assigning it needs to evaluate <code>s + i</code>, but <code>s</code> is local and still unassigned -> Error.</p>

<p>In the second case <code>s[0] += i</code> you never assign to <code>s</code> directly, but only ever access an item from <code>s</code>. So Python can clearly see that it is not a local variable and goes looking for it in the outer scope.</p>

<p>Finally, a nicer alternative (in Python 3) is to explicitly tell it that <code>s</code> is not a local variable:</p>

<pre><code>def foo(n):
    s = n
    def bar(i):
        nonlocal s
        s += i
        return s
    return bar
</code></pre>

<p>(There is actually no need for <code>s</code> - you could simply use <code>n</code> instead inside <code>bar</code>.)</p>

<p>*<sub><a href=""https://docs.python.org/3/library/operator.html#inplace-operators"" rel=""nofollow noreferrer"">The situation is slightly more complex</a>, but the important issue is that computation and assignment are performed in two separate steps.</sub></p>
","3005167","3005167","2018-03-01 10:46:03","5","1276","kazemakase","2013-11-18 14:49:10","14843","1250","1246","490","49046554","49047038","2018-03-01 09:31:08","5","913","<p>I am reading <em>Hackers and Painters</em> and am confused by a problem mentioned by the author to illustrate the power of different programming languages.</p>

<p>The problem is:</p>

<blockquote>
  <p>We want to write a function that generates accumulators—a function that takes a number <em>n</em>, and returns a function that takes another number <em>i</em> and returns <em>n</em> incremented by <em>i</em>. (That’s <em>incremented</em> by, not plus. An accumulator has to accumulate.)</p>
</blockquote>

<p>The author mentions several solutions with different programming languages. For example, Common Lisp:</p>

<pre><code>(defun foo (n)
  (lambda (i) (incf n i)))
</code></pre>

<p>and JavaScript:</p>

<pre><code>function foo(n) { return function (i) { return n += i } }
</code></pre>

<p>However, when it comes to Python, the following codes do not work:</p>

<pre><code>def foo(n):
    s = n
    def bar(i):
        s += i
        return s
    return bar

f = foo(0)
f(1)  # UnboundLocalError: local variable 's' referenced before assignment
</code></pre>

<p>A simple modification will make it work:</p>

<pre><code>def foo(n):
    s = [n]
    def bar(i):
        s[0] += i
        return s[0]
    return bar
</code></pre>

<p>I am new to Python. Why doesn the first solution not work while the second one does? The author mentions lexical variables but I still don't get it.</p>
","6181069","124319","2018-03-01 19:12:07","Function that returns an accumulator in Python","<python><scope><closures><common-lisp><local-variables>","4","2","1395"
"49047063","2018-03-01 09:58:43","1","","<p>While fetching row and storing in list use str(row)</p>

<pre><code>list=[('Mark Zuckerberg',), ('Bill Gates',), ('Tim Cook',), ('Wlliam Sidis',), ('Elon Musk',)]
listoutput=[i[0] for i in list]
print(listoutput)
</code></pre>

<blockquote>
  <p>Check output below</p>
</blockquote>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;iframe height=""400px"" width=""100%"" src=""https://repl.it/repls/PortlyCarefulCodegeneration?lite=true"" scrolling=""no"" frameborder=""no"" allowtransparency=""true"" allowfullscreen=""true"" sandbox=""allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals""&gt;&lt;/iframe&gt;</code></pre>
</div>
</div>
</p>
","8572897","8572897","2018-03-01 10:17:21","0","819","Jay Shankar Gupta","2017-09-07 06:49:13","5609","610","4","15","49046930","","2018-03-01 09:51:33","0","1528","<p>Trying to make list 1, into list 2 shown in the code below by removing the brackets and commas within the brackets so I can use the strings for SQLite select queries:</p>

<pre><code>[('Mark Zuckerberg',), ('Bill Gates',), ('Tim Cook',), ('Wlliam Sidis',), ('Elon Musk',)]
['Mark Zuckerberg', 'Bill Gates', 'Tim Cook', 'William Sidis', 'Elon Musk']
</code></pre>
","9420134","3001761","2018-03-01 09:56:47","Removing brackets and comma from a list of strings (python & sqlite)","<python><python-3.x><sqlite>","4","1","366"
"49047112","2018-03-01 10:01:28","3","","<p>You checked if string posArray is a digit:</p>

<pre><code>  if posArray.isdigit():
      num = posArray
</code></pre>

<p>But you did't convert it to digit, like so:</p>

<pre><code>  if posArray.isdigit():
      num = int(posArray)
</code></pre>
","9365820","","","1","251","dodd0ro","2018-02-15 16:03:49","132","10","153","0","49046972","49047141","2018-03-01 09:54:26","0","121","<p>I have a list/array <strong>str4</strong> in python, I want to access it with a variable which I strongly believe is an int because I test it with the function <strong>isdigit()</strong> and I also made a manual debug and checked that all the option come out correctly with the only number.</p>

<pre><code>temp = ""variableX""
file2 = open('file.txt','r')
for line in file2:
  if line.find(temp) =! -1:
    posArray = line.split(temp)[1][1:3]
    if "")"" in posArray:
      posArray = posArray[:-1]
    if posArray.isdigit():
      num = posArray
      print temp+""(""+num+"")""
      print num
      print str4[num]
</code></pre>

<p>The above code is used to debug, my problem is in the <strong>str4[num]</strong>, the result of the above code is:</p>

<pre><code>variableX(1)
1
""this is position 1""
Traceback (most recent call last):
  File ""orderList.py"", line34, in &lt;module&gt;
    print str4[num]
TypeError: list indices must be integers, not str
</code></pre>

<p>Why <strong>num</strong> is a digit but python tells me it is a string?
What am I doing wrong?</p>
","5106510","1029816","2018-03-01 10:32:36","Python -> TypeError: list indices must be integers, not str","<python><python-2.7><file><integer><typeerror>","4","3","1071"
"49047139","2018-03-01 10:02:32","1","","<p>An infinite generator is one implementation. You can call <code>__next__</code> on a generator instance to extract successive results iteratively.</p>

<pre><code>def incrementer(n, i):
    while True:
        n += i
        yield n

g = incrementer(2, 5)

print(g.__next__())  # 7
print(g.__next__())  # 12
print(g.__next__())  # 17
</code></pre>

<p>If you need a flexible incrementer, one possibility is an object-oriented approach:</p>

<pre><code>class Inc(object):
    def __init__(self, n=0):
        self.n = n
    def incrementer(self, i):
        self.n += i
        return self.n

g = Inc(2)

g.incrementer(5)  # 7
g.incrementer(3)  # 10
g.incrementer(7)  # 17
</code></pre>
","9209546","9209546","2018-03-01 10:43:34","4","689","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49046554","49047038","2018-03-01 09:31:08","5","913","<p>I am reading <em>Hackers and Painters</em> and am confused by a problem mentioned by the author to illustrate the power of different programming languages.</p>

<p>The problem is:</p>

<blockquote>
  <p>We want to write a function that generates accumulators—a function that takes a number <em>n</em>, and returns a function that takes another number <em>i</em> and returns <em>n</em> incremented by <em>i</em>. (That’s <em>incremented</em> by, not plus. An accumulator has to accumulate.)</p>
</blockquote>

<p>The author mentions several solutions with different programming languages. For example, Common Lisp:</p>

<pre><code>(defun foo (n)
  (lambda (i) (incf n i)))
</code></pre>

<p>and JavaScript:</p>

<pre><code>function foo(n) { return function (i) { return n += i } }
</code></pre>

<p>However, when it comes to Python, the following codes do not work:</p>

<pre><code>def foo(n):
    s = n
    def bar(i):
        s += i
        return s
    return bar

f = foo(0)
f(1)  # UnboundLocalError: local variable 's' referenced before assignment
</code></pre>

<p>A simple modification will make it work:</p>

<pre><code>def foo(n):
    s = [n]
    def bar(i):
        s[0] += i
        return s[0]
    return bar
</code></pre>

<p>I am new to Python. Why doesn the first solution not work while the second one does? The author mentions lexical variables but I still don't get it.</p>
","6181069","124319","2018-03-01 19:12:07","Function that returns an accumulator in Python","<python><scope><closures><common-lisp><local-variables>","4","2","1395"
"49047140","2018-03-01 10:02:34","2","","<p>Take a look your code with my comments below. Read it from the bottom to the top to get an idea on how you can easily debug your own code; what the thinking process is.</p>

<pre><code>temp = ""variableX""
file2 = open('file.txt','r')  # which is a file, so `line` is `string` - CASE CLOSED
for line in file2:  # and `line` is a result of looping through `file2`
  if line.find(temp) =! -1:
    posArray = line.split(temp)[1][1:3]  # and `posArray` is a part of `line`
    if "")"" in posArray:
      posArray = posArray[:-1]  # ok, `posArray` is a part of `posArray`
    if posArray.isdigit():  # `posArray` contains digits only but that doesn't help really, so does ""123""..
      num = posArray  # ok, so `num` is whatever `posArray` is
      print temp+""(""+num+"")""
      print num
      print str4[num]  # here is the Error so we start here and work backwards
</code></pre>

<p>What we show above is that ultimately, <code>num</code> will be of the same type as <code>line</code> (<code>str</code>) and as a result, cannot be used to <code>index</code> anything. It must be converted to <code>int</code> first by doing <code>int(num)</code></p>
","6162307","","","1","1147","Ev. Kounis","2016-04-05 15:46:06","11755","1841","2162","212","49046972","49047141","2018-03-01 09:54:26","0","121","<p>I have a list/array <strong>str4</strong> in python, I want to access it with a variable which I strongly believe is an int because I test it with the function <strong>isdigit()</strong> and I also made a manual debug and checked that all the option come out correctly with the only number.</p>

<pre><code>temp = ""variableX""
file2 = open('file.txt','r')
for line in file2:
  if line.find(temp) =! -1:
    posArray = line.split(temp)[1][1:3]
    if "")"" in posArray:
      posArray = posArray[:-1]
    if posArray.isdigit():
      num = posArray
      print temp+""(""+num+"")""
      print num
      print str4[num]
</code></pre>

<p>The above code is used to debug, my problem is in the <strong>str4[num]</strong>, the result of the above code is:</p>

<pre><code>variableX(1)
1
""this is position 1""
Traceback (most recent call last):
  File ""orderList.py"", line34, in &lt;module&gt;
    print str4[num]
TypeError: list indices must be integers, not str
</code></pre>

<p>Why <strong>num</strong> is a digit but python tells me it is a string?
What am I doing wrong?</p>
","5106510","1029816","2018-03-01 10:32:36","Python -> TypeError: list indices must be integers, not str","<python><python-2.7><file><integer><typeerror>","4","3","1071"
"49047141","2018-03-01 10:02:34","2","","<p>The interpretor is never wrong...</p>

<p>More seriously, you get num as a substring so it is a string. You must convert it into in int if you want to use it as a string index:</p>

<pre><code>  num = int(posArray)          # ok num is now an int
  print temp+""(""+str(num)+"")""  # must use str to concat it with strings
  print num, type(num), posArray, type(posArray) # num is int, posArray is string
  print str4[num]              # now fine
</code></pre>
","3545273","","","0","460","Serge Ballesta","2014-04-17 12:25:02","90494","5432","1346","480","49046972","49047141","2018-03-01 09:54:26","0","121","<p>I have a list/array <strong>str4</strong> in python, I want to access it with a variable which I strongly believe is an int because I test it with the function <strong>isdigit()</strong> and I also made a manual debug and checked that all the option come out correctly with the only number.</p>

<pre><code>temp = ""variableX""
file2 = open('file.txt','r')
for line in file2:
  if line.find(temp) =! -1:
    posArray = line.split(temp)[1][1:3]
    if "")"" in posArray:
      posArray = posArray[:-1]
    if posArray.isdigit():
      num = posArray
      print temp+""(""+num+"")""
      print num
      print str4[num]
</code></pre>

<p>The above code is used to debug, my problem is in the <strong>str4[num]</strong>, the result of the above code is:</p>

<pre><code>variableX(1)
1
""this is position 1""
Traceback (most recent call last):
  File ""orderList.py"", line34, in &lt;module&gt;
    print str4[num]
TypeError: list indices must be integers, not str
</code></pre>

<p>Why <strong>num</strong> is a digit but python tells me it is a string?
What am I doing wrong?</p>
","5106510","1029816","2018-03-01 10:32:36","Python -> TypeError: list indices must be integers, not str","<python><python-2.7><file><integer><typeerror>","4","3","1071"
"49047153","2018-03-01 10:03:14","0","","<p>If you just want to test your django project, check your <code>setting.py</code> file, change <code>DEBUG</code> to <code>True</code>, then run <code>manage.py runserver</code>, and you'll see what you want at <code>localhost:8000/admin</code> Admin interface.</p>

<p>If your django project is ready for deployment, run <code>python manage.py collectstatic</code> and manage.py will automatically collect static files (css, js ...) for you.</p>
","9428183","","","0","449","ewdager","2018-03-01 09:42:12","1","1","0","0","49044372","","2018-03-01 07:10:22","0","37","<p>I am a beginner of python Django .i created a django administration page but it was some problem with css.<a href=""https://i.stack.imgur.com/FAQAi.png"" rel=""nofollow noreferrer"">this is the screen shot of the that page</a>.i want to be that  like this. <a href=""https://i.stack.imgur.com/1nvLz.png"" rel=""nofollow noreferrer"">this is the what i wanted page's screen shot</a>. anyone can help me?</p>
","9374243","","","about Python Django Administration page's appearance","<python><django>","2","3","402"
"49047167","2018-03-01 10:04:04","1","","<p>Another solution is after </p>

<pre><code>num = posArray
</code></pre>

<p>do:</p>

<p><code>print str4[int(num)])</code></p>
","8807908","","","0","130","mgracer","2017-10-20 17:19:45","180","31","69","0","49046972","49047141","2018-03-01 09:54:26","0","121","<p>I have a list/array <strong>str4</strong> in python, I want to access it with a variable which I strongly believe is an int because I test it with the function <strong>isdigit()</strong> and I also made a manual debug and checked that all the option come out correctly with the only number.</p>

<pre><code>temp = ""variableX""
file2 = open('file.txt','r')
for line in file2:
  if line.find(temp) =! -1:
    posArray = line.split(temp)[1][1:3]
    if "")"" in posArray:
      posArray = posArray[:-1]
    if posArray.isdigit():
      num = posArray
      print temp+""(""+num+"")""
      print num
      print str4[num]
</code></pre>

<p>The above code is used to debug, my problem is in the <strong>str4[num]</strong>, the result of the above code is:</p>

<pre><code>variableX(1)
1
""this is position 1""
Traceback (most recent call last):
  File ""orderList.py"", line34, in &lt;module&gt;
    print str4[num]
TypeError: list indices must be integers, not str
</code></pre>

<p>Why <strong>num</strong> is a digit but python tells me it is a string?
What am I doing wrong?</p>
","5106510","1029816","2018-03-01 10:32:36","Python -> TypeError: list indices must be integers, not str","<python><python-2.7><file><integer><typeerror>","4","3","1071"
"49047190","2018-03-01 10:05:32","1","","<p>You may to compare <strong>bytecode</strong> attributes on <strong>code object</strong> using <code>method.__code__.co_code</code>. For example lets define two classes:</p>

<pre><code>&gt;&gt;&gt; class A:
...     a = 1
...     def b(self, b):
...             print(self.a + b)
... 
&gt;&gt;&gt; class B:
...     a = 1
...     def b(self, b):
...             print(self.a + b)
... 
&gt;&gt;&gt; A().b.__code__.co_code
'|\x00\x00j\x00\x00|\x01\x00\x17GHd\x00\x00S'
&gt;&gt;&gt; B().b.__code__.co_code
'|\x00\x00j\x00\x00|\x01\x00\x17GHd\x00\x00S'
&gt;&gt;&gt; A().b.__code__.co_code == B().b.__code__.co_code
True
</code></pre>

<p>and if method <code>b</code> in class <code>A</code> is changed:</p>

<pre><code>&gt;&gt;&gt; class A:
...     a = 1
...     def b(self, b):
...             print(b + self.a)
... 
&gt;&gt;&gt; A().b.__code__.co_code
'|\x01\x00|\x00\x00j\x00\x00\x17GHd\x00\x00S'
&gt;&gt;&gt; A().b.__code__.co_code == B().b.__code__.co_code
False
</code></pre>

<p>or use <strong>inspect</strong> method <a href=""https://docs.python.org/3/library/inspect.html#inspect.getsource"" rel=""nofollow noreferrer""><code>inspect.getsource(object)</code></a> that:</p>

<blockquote>
  <p>Return the text of the source code for an object. The argument may be
  a module, class, method, function, traceback, frame, or code object.
  The source code is returned as a single string.</p>
</blockquote>

<p>And if you want to know whether the code has changed in dynamic you may need to reload your class with <a href=""https://docs.python.org/3/library/importlib.html"" rel=""nofollow noreferrer""><code>importlib</code></a> and compare bytecode.</p>
","8442366","8442366","2018-03-01 12:30:47","0","1649","Eugene Lopatkin","2017-08-09 23:13:11","840","123","387","2","18134087","","2013-08-08 19:06:29","16","766","<p>If I have a reference to a function I can check it's code object <code>f.__code__</code>, get a signature, then perform later checks against this signature to see if the code changed. This is good.
But what if one of the funciton's dependencies changed? E.g.</p>

<pre><code>def foo(a, b):
    return bar(a, b)
</code></pre>

<p>Let's say <code>foo</code> remained the same, but <code>bar</code> changed. Is there a way I can check <code>foo</code>'s dependencies 'live' via the <code>foo.__code__</code> object (vs. parsing the text and using AST)?</p>
","1161523","418374","2018-03-01 12:44:19","How do I check if a python function changed (in live code)?","<python><reflection><introspection>","2","4","557"
"49047197","2018-03-01 10:05:49","2","","<p>Well you could try it with the following piece of code, usage would be: </p>

<p>compile_rst.py yourtext.rst </p>

<p>or </p>

<p>compile_rst.py yourtext.rst desiredname.html</p>

<pre><code># compile_rst.py

from __future__ import print_function
from docutils import core
from docutils.writers.html4css1 import Writer,HTMLTranslator
import sys, os

class HTMLFragmentTranslator( HTMLTranslator ):
    def __init__( self, document ):
        HTMLTranslator.__init__( self, document )
        self.head_prefix = ['','','','','']
        self.body_prefix = []
        self.body_suffix = []
        self.stylesheet = []
    def astext(self):
        return ''.join(self.body)

html_fragment_writer = Writer()
html_fragment_writer.translator_class = HTMLFragmentTranslator

def reST_to_html( s ):
    return core.publish_string( s, writer = html_fragment_writer )

if __name__ == '__main__':
    if len(sys.argv)&gt;1:
        if sys.argv[1] != """":
            rstfile = open(sys.argv[1])
            text = rstfile.read()
            rstfile.close()
            if len(sys.argv)&gt;2:
                if sys.argv[2] != """":
                    htmlfile = sys.argv[2]
            else:
                htmlfile = os.path.splitext(os.path.basename(sys.argv[1]))[0]+"".html""
            result = reST_to_html(text)
            print(result)
            output = open(htmlfile, ""wb"")
            output.write(result)
            output.close()  
    else:
        print(""Usage:\ncompile_rst.py docname.rst\nwhich results in =&gt; docname.html\ncompile_rst.py docname.rst desiredname.html\nwhich results in =&gt; desiredname.html"")
</code></pre>
","4112844","","","0","1639","bunkus","2014-10-06 10:00:16","347","55","0","0","3819917","3829526","2010-09-29 08:29:12","21","20937","<p>I have a blog written in reStructuredText which I currently have to manually convert to HTML when I make a new post.</p>

<p>I'm writing a new blog system using Google App Engine and need a simple way of converting rst to HTML.</p>

<p>I don't want to use <code>docutils</code> because it is too big and complex. Is there a simpler (ideally single python file) way I can do this?</p>
","73048","823542","2019-02-19 18:24:44","single py file for convert rst to html","<python><google-app-engine><restructuredtext>","5","0","387"
"49047214","2018-03-01 10:06:55","2","","<p>I like @bryan and @foo-stack answers. If you are working with postgresql and you are using <code>psycopg2</code> you could use some <a href=""http://initd.org/psycopg/docs/extras.html"" rel=""nofollow noreferrer"">goodies from psycopg2</a> to achieve the same by specifying the cursorfactory being a <code>DictCursor</code> when creating your cursor from the connection, like this:</p>

<p><code>cur = conn.cursor( cursor_factory=psycopg2.extras.DictCursor )</code></p>

<p>So now you can execute your sql query and you'll get a dictionary to fetch your results, without the need to map them by hand.</p>

<pre><code>cur.execute( sql_query )
results = cur.fetchall()

for row in results:
    print row['row_no']
</code></pre>

<p>Please note that you'll have to <code>import psycopg2.extras</code> for that to work.</p>
","1283512","","","0","819","matthaeus","2012-03-21 13:36:45","539","81","176","1","16519385","16523148","2013-05-13 10:02:02","53","64078","<p>How do I serialize pyodbc cursor output (from <code>.fetchone</code>, <code>.fetchmany</code> or <code>.fetchall</code>) as a Python dictionary?</p>

<p>I'm using bottlepy and need to return dict so it can return it as JSON.</p>
","2377075","366335","2014-04-08 02:28:14","Output pyodbc cursor results as python dictionary","<python><dictionary><cursor><pyodbc><pypyodbc>","8","1","232"
"49047223","2018-03-01 10:07:17","0","","<p>Suppose you have a list like this one,</p>

<pre><code>animal_raw = [('cat', ), ('dog', ), ('elephant', )]
</code></pre>

<p>And now we will convert it into the one you asked that is without commas and parenthesis.</p>

<pre><code>animal = [i[0] for i in animal_raw]
</code></pre>

<p>Now , <code>print(animal)</code>.
You should now get the output,</p>

<pre><code>['cat', 'dog', 'elephant']
</code></pre>
","9392351","","","0","410","Nixel","2018-02-21 17:25:35","110","55","56","0","49046930","","2018-03-01 09:51:33","0","1528","<p>Trying to make list 1, into list 2 shown in the code below by removing the brackets and commas within the brackets so I can use the strings for SQLite select queries:</p>

<pre><code>[('Mark Zuckerberg',), ('Bill Gates',), ('Tim Cook',), ('Wlliam Sidis',), ('Elon Musk',)]
['Mark Zuckerberg', 'Bill Gates', 'Tim Cook', 'William Sidis', 'Elon Musk']
</code></pre>
","9420134","3001761","2018-03-01 09:56:47","Removing brackets and comma from a list of strings (python & sqlite)","<python><python-3.x><sqlite>","4","1","366"
"49047226","2018-03-01 10:07:28","0","","<p>In addition to your answer @thrillhouse :</p>

<p><code>CSRF_COOKIE_SECURE=True</code> makes the csrf token only work with ssl, like the docs also say: </p>

<blockquote>
  <p>Whether to use a secure cookie for the CSRF cookie. If this is set to True, the cookie will be marked as “secure,” which means browsers may ensure that the cookie is only sent with an HTTPS connection.</p>
</blockquote>

<p>So when you switch back to <code>HTTPS</code> connection, you should turn the value back to <code>True</code>.</p>
","7707749","","","2","518","King Reload","2017-03-14 09:21:47","2864","216","95","24","49042232","","2018-03-01 03:37:11","1","55","<p>I have two forms on two pages, one leads to the other. When ""Submit"" is pressed on page 1 it is supposed to take you to the form on page 2. Page 2 fails with ""CSRF verification failed. Request aborted."" With the reason being ""CSRF cookie not set.""</p>

<p>The weird part is that if I go directly to Page 2, it loads fine. If I refresh the page and resubmit the form, I get 403'd again, but if, for example, I go into the address bar and just hit ""Enter"" to re-visit the page, it loads without the error. What gives?</p>

<p>I am using the most recent version of Django, I am using render in all my views and {% csrf_token %} in all my form tags.</p>

<p>Why would revisiting the page be fixing the 403 error? No login or authentication is happening between the forms. In fact, I don't even do anything with the data submitted in page 1 (yet).</p>

<p>Relevant code is as follows:</p>

<p>Page 1 Template:</p>

<pre><code>&lt;div class=""""&gt;
    &lt;div class=""""&gt;
        &lt;h1&gt;Page 1&lt;/h1&gt;
        &lt;p&gt;What's up?&lt;/p&gt;
        &lt;form action=""{% url 'core:getPageTwo' %}"" method=""post""&gt;
            {% csrf_token %}
            {{ form }}
            &lt;input class=""yellow_button"" type=""submit"" value=""Submit""&gt;
        &lt;/form&gt;
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p>Page 2 View:</p>

<pre><code>def getPageTwo(request):
    form = SomeForm()
    context = {'form' : form}
    return render (request, 'core/page_two.html', context)
</code></pre>

<p>Page 2 Template:</p>

<pre><code>&lt;div class=""""&gt;
    &lt;div class=""""&gt;
        &lt;h1&gt;Page 2&lt;/h1&gt;
        &lt;form action=""#"" method=""post""&gt;
            {% csrf_token %}
            {{ form }}
        &lt;/form&gt;
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>
","9259672","","","Django CSRF Error fixed by just visiting page in multi-page form?","<python><django><cookies><web><csrf>","2","0","1777"
"49047266","2018-03-01 10:09:57","1","","<p>The problem is that <code>call</code> (<code>_Call</code>) itself if a kind of mock, and overrides <code>__getattr__</code>. When hamcrest starts checking whether it has a <code>decribe_to</code> attribute, things start going wrong.</p>

<p>I think that since both modules are doing introspective things, no single one is to blame, and special cases should be implemented on either side to play well with the other (probably in hamcrest, since <code>mock</code> is a standard module).</p>

<p>A user-side workaround is to do:</p>

<pre><code>from unittest.mock import _Call
_Call.describe_to = lambda c, d: d.append(str(c))
</code></pre>
","893790","674064","2018-03-02 01:12:04","1","641","Gnurfos","2011-08-14 11:09:02","533","44","69","2","36967375","49047266","2016-05-01 13:45:02","1","245","<p>Often, I care about the exact calls the system under test makes to another part of the software (which I mock in the test), but not about the order, in which those calls happen. (E.g. because the end effect on the <em>real</em> other part replaced by the mock does not depend on the order of these calls.)</p>

<p>In other words, I want my test to</p>

<ul>
<li>fail if not all expected calls have been made</li>
<li>fail if unexpected calls have been made (so <a href=""https://docs.python.org/3/library/unittest.mock.html#unittest.mock.Mock.assert_has_calls"" rel=""nofollow noreferrer""><code>unittest.mock.Mock.assert_has_calls</code></a> does not suffice)</li>
<li><strong>not</strong> fail if only the <strong>order</strong> of the calls changed</li>
<li>fail if a call has been made less or more often than expected</li>
</ul>

<p>So, I have to inspect the <a href=""https://docs.python.org/3/library/unittest.mock.html#unittest.mock.Mock.mock_calls"" rel=""nofollow noreferrer""><code>mock_calls</code> property</a> of the mock object. I can do that in a generic and reasonably comprehensible way with PyHamcrest's <a href=""https://pyhamcrest.readthedocs.org/en/v1.8.5/sequence_matchers/#module-hamcrest.library.collection.issequence_containinginanyorder"" rel=""nofollow noreferrer""><code>contains_inanyorder</code></a>:</p>

<pre><code>#!/usr/bin/env python3
from unittest import TestCase, main
from unittest.mock import Mock, call
from hamcrest import assert_that, contains_inanyorder as contains_in_any_order

class TestMockCalls(TestCase):
    def test_multiple_calls(self):
        m = Mock()
        m('foo')
        m.bar('baz')
        m('foo')
        assert_that(
            m.mock_calls, contains_in_any_order(
                call('foo'),
                call('foo'),
                call.bar('baz'),
            )
        )

if __name__ == '__main__':
    main()
</code></pre>

<p>This works fine for passing tests, like the one above:</p>

<pre class=""lang-none prettyprint-override""><code>$&gt; ./test_mock_calls.py
.
----------------------------------------------------------------------
Ran 1 test in 0.000s

OK
</code></pre>

<p>It also fails when it should fail (as specified above, e.g. when you change one of the <code>m('foo')</code> to <code>m('F00')</code>), but the output in that case is not as useful as it could be:</p>

<pre class=""lang-none prettyprint-override""><code>$&gt; ./test_mock_calls.py
F
======================================================================
FAIL: test_multiple_calls (__main__.TestMockCalls)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""./test_mock_calls.py"", line 16, in test_multiple_calls
    call.bar('bay'),
AssertionError: 
Expected: a sequence over [, , ] in any order
     but: not matched: 


----------------------------------------------------------------------
Ran 1 test in 0.001s

FAILED (failures=1)
</code></pre>

<p>The only information (apart from which test and which assertion failed) I can gather from this, is how many calls on the mock were expected in total (by counting the commas between the square brackets), but not what calls were expected and, more importantly, what and how many calls were actually observed.</p>

<p>Is this a bug in <code>unittest.mock</code> or PyHamcrest or am I using them wrong?</p>
","674064","674064","2017-01-30 10:01:31","near-useless assertion output from hamcrest.contains_inanyorder applied to unittest.mock.Mock.mock_calls","<python><python-3.x><hamcrest><python-unittest.mock>","1","0","3366"
"49047277","2018-03-01 10:10:30","4","","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.split.html"" rel=""nofollow noreferrer""><code>split</code></a> with <code>expand=True</code> for <code>DataFrame</code> and assign to new columns in subset by double <code>[]</code>:</p>

<pre><code>df[['Front_x', 'Front_y', 'Front_z']] = df['COORDFRONT'].str.split(expand=True).astype(float)
print (df)
              COORDFRONT              COORDREAR    ID  Front_x  Front_y  \
0  787.547 238.639 0.000  803.545 230.467 0.000  3864  787.547  238.639   
1  787.141 238.847 0.000  803.139 230.675 0.000  3864  787.141  238.847   
2  786.729 239.057 0.000  802.727 230.885 0.000  3864  786.729  239.057   
3  786.310 239.271 0.000  802.309 231.099 0.000  3864  786.310  239.271   
4  785.886 239.488 0.000  801.884 231.316 0.000  3864  785.886  239.488   

   Front_z  
0      0.0  
1      0.0  
2      0.0  
3      0.0  
4      0.0  
</code></pre>

<p>If no <code>NaN</code>s values in column is possible use <code>list comprehension</code>:</p>

<pre><code>L = [x.split() for x in df['COORDFRONT'].values.tolist()]
df[['Front_x', 'Front_y', 'Front_z']] = pd.DataFrame(L).astype(float)
</code></pre>
","2901002","2901002","2018-03-01 10:27:38","2","1185","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49047244","49047277","2018-03-01 10:08:37","3","48","<p>I am processing outputs from a piece of software that provides co-ordinates as an x, y, z triple in a single column. Is there any way to split the string out into its three separate parts and convert to floats in one fell swoop? For example, I know that I can do the following:</p>

<pre><code>import pandas as pd

df = pd.DataFrame({'ID': {0: 3864, 1: 3864, 2: 3864, 3: 3864, 4: 3864},
                   'COORDFRONT': {0: '787.547 238.639 0.000', 1: '787.141 238.847 0.000', 2: '786.729 239.057 0.000', 3: '786.310 239.271 0.000', 4: '785.886 239.488 0.000'},
                   'COORDREAR': {0: '803.545 230.467 0.000', 1: '803.139 230.675 0.000', 2: '802.727 230.885 0.000', 3: '802.309 231.099 0.000', 4: '801.884 231.316 0.000'}})

df['Front_x'], df['Front_y'], df['Front_z'] = df['COORDFRONT'].str.split(' ').str
</code></pre>

<p>To separate out the three strings, but trying for example </p>

<pre><code>df['COORDFRONT'].str.split(' ').astype(float)
</code></pre>

<p>returns a <code>ValueError</code>.</p>
","5309300","","","Splitting and converting a string column in pandas","<python><pandas>","2","0","1019"
"49047280","2018-03-01 10:10:43","0","","<p>from a tuple  we can access the element by index as <code>tuple[index]</code></p>

<p>single element tuples python represent as </p>

<pre><code>(element,)
</code></pre>

<p>you have list of tuples</p>

<pre><code>a = [('Mark Zuckerberg',), ('Bill Gates',), .... ]
b=[]
for i in a :
    b.append(i[0])

print(b)
</code></pre>

<p>or  short version </p>

<pre><code>b = [i[0] for i in a]
</code></pre>
","5033630","","","0","404","Sunimal S.K Malkakulage","2015-06-21 15:48:37","435","82","17","1","49046930","","2018-03-01 09:51:33","0","1528","<p>Trying to make list 1, into list 2 shown in the code below by removing the brackets and commas within the brackets so I can use the strings for SQLite select queries:</p>

<pre><code>[('Mark Zuckerberg',), ('Bill Gates',), ('Tim Cook',), ('Wlliam Sidis',), ('Elon Musk',)]
['Mark Zuckerberg', 'Bill Gates', 'Tim Cook', 'William Sidis', 'Elon Musk']
</code></pre>
","9420134","3001761","2018-03-01 09:56:47","Removing brackets and comma from a list of strings (python & sqlite)","<python><python-3.x><sqlite>","4","1","366"
"49047282","2018-03-01 10:10:46","1","","<p>It's indeed just as simple as in JS, only with Python syntax:</p>

<pre><code>def read_file():
    xmlhttp= __new__ (XMLHttpRequest())
    xmlhttp.open('GET', 'https://github.com/QQuick/Transcrypt/blob/master/README.rst', False);
    xmlhttp.send()
    console.log(xmlhttp.responseText)
</code></pre>

<p>In your example that would be:</p>

<pre><code>XHR = __new__ (XMLHttpRequest())
XHR.open(""POST"", ""https://example.com/cors.php"")
</code></pre>

<p>Note the <code>__new__ ()</code> function. In JavaScript it would have been the <code>new</code> operator but Python syntax doesn't allow that.</p>

<p>If you want to avoid <code>__new__ ()</code> altogether you may encapsulate <code>XMLHttpRequest</code> i a true Python class (it's a JS function now), but there's no need to.</p>

<p>See</p>

<p><a href=""http://www.transcrypt.org/docs/html/special_facilities.html#creating-javascript-objects-with-new-constructor-call"" rel=""nofollow noreferrer"">http://www.transcrypt.org/docs/html/special_facilities.html#creating-javascript-objects-with-new-constructor-call</a></p>

<p>for a general explantion on using or avoiding <code>__new__ ()</code>.</p>

<p>You may also go via JQuery as in the following somewhat bigger example:</p>

<pre><code>__pragma__ ('alias', 'jq', '$')
__pragma__ ('noalias', 'clear')

# For use by eval'ed turtle applet
import turtle
import random
import math

def clear ():
    editor.setValue ('')
    turtle.reset ()
    run ()

def run ():
    def success (result):
        global random

        turtle.reset ()
        rnd = random
        eval (result)
        random = rnd

    def fail (a, b, c):
        print ('Run error:', a, b, c)

    # N.B. The request has to be explicitly encoded, but the response is already implicitly decoded
    jq.ajax ({
        'url':'http://www.transcrypt.org/compile',
        'type': 'POST',
        'data': JSON.stringify (editor.getValue ()),
        'dataType': 'json',
        'contentType': 'application/json',
        'success': success,
        'fail': fail
    })

def mail ():
    def success (result):
        print (result)

    def fail (a, b, c):
        print ('Run error:', a, b, c)

    jq.ajax ({
        'url':'http://www.transcrypt.org/mail',
        'type': 'POST',
        'data': JSON.stringify ([document.getElementById ('mail_address') .value, editor.getValue ()]),
        'dataType': 'json',
        'contentType': 'application/json',
        'success': success,
        'fail': fail
    })

def selectExample ():
    def success (result):
        editor.setValue (result [0])
        turtle.reset ()     # Using old paths
        window.terminate = True
        console.log (result [1])
        eval (result [1])   # Using new paths (so cannot clear old result)

    def fail (a, b, c):
        print ('Select example error:', a, b, c)

    selector = document.getElementById ('select_example')

    jq.ajax ({
        'url':'http://www.transcrypt.org/example',
        'type': 'POST',
        'data': JSON.stringify (selector.options [selector.selectedIndex] .value),
        'dataType': 'json',
        'contentType': 'application/json',
        'success': success,
        'fail': fail
    })

selectExample ()
</code></pre>

<p>This is the way it's done at:</p>

<p><a href=""http://www.transcrypt.org/live/turtle_site/turtle_site.html"" rel=""nofollow noreferrer"">http://www.transcrypt.org/live/turtle_site/turtle_site.html</a></p>

<p>[EDIT]</p>

<p>(in response to comment of OP)</p>

<p>Indeed any ordinary JavaScript object can instantiated this way. Note that in special cases you can always interject a piece of literal JS code, as described in:</p>

<p><a href=""http://www.transcrypt.org/docs/html/special_facilities.html#inserting-literal-javascript-pragma-js-and-include"" rel=""nofollow noreferrer"">http://www.transcrypt.org/docs/html/special_facilities.html#inserting-literal-javascript-pragma-js-and-include</a></p>

<p>As for the available libs, Transcrypt is designed to use any JS lib directly, since JS libs tend to be focused on functionality that is relevant to the client/browser.</p>

<p>Nevertheless the number of available standard libs is growing. Currently available are:</p>

<ul>
<li>cmath</li>
<li>datetime</li>
<li>inspect</li>
<li>itertools</li>
<li>logging</li>
<li>math</li>
<li>random (partially)</li>
<li>re (almost complete)</li>
<li>time</li>
<li>turtle (almost complete)</li>
<li>warnings</li>
</ul>

<p>Apart from that there's a port of a small but useful part of Numpy as described in:</p>

<p><a href=""http://www.transcrypt.org/numscrypt/docs/html/supported_constructs.html"" rel=""nofollow noreferrer"">http://www.transcrypt.org/numscrypt/docs/html/supported_constructs.html</a></p>

<p>It is available at:</p>

<p><a href=""https://github.com/QQuick/Numscrypt"" rel=""nofollow noreferrer"">https://github.com/QQuick/Numscrypt</a></p>
","1577341","1577341","2018-03-04 10:18:23","2","4864","Jacques de Hooge","2012-08-05 12:29:33","5331","924","494","41","49042487","49047282","2018-03-01 04:11:43","3","471","<p>I only have minimal JavaScript knowledge from coding a small API site entirely client-side.</p>

<p>How would I use  <code>XMLHttpRequest()</code> in Transcrypt? Or should I be using <code>URLlib</code> or something else?</p>

<p>Is it as simple as creating a new XMLHttpRequest object and then sending the data or retrieving a page as in JS?</p>

<pre><code>XHR = XMLHttpRequest()
XHR.open(""POST"", ""https://example.com/cors.php"")
</code></pre>
","8606128","8606128","2018-03-01 04:17:33","Using XMLHttpRequest() in Transcrypt","<python><xmlhttprequest><transcrypt>","1","2","448"
"49047310","2018-03-01 10:12:01","1","","<p>Using <code>filter</code> with an anonymous function:</p>

<pre><code>&gt;&gt;&gt; Numbers = [[32,3154,53,13],[44,34,25,67],[687,346,75],[57,154]]
&gt;&gt;&gt; filter(lambda x: len(x) == 4, Numbers)
[[32, 3154, 53, 13], [44, 34, 25, 67]]
&gt;&gt;&gt; len(filter(lambda x: len(x) == 4, Numbers))
2
</code></pre>
","6338725","","","0","314","Rodrigo de Azevedo","2016-05-16 01:31:23","824","426","535","4","49036501","49036926","2018-02-28 18:46:34","3","121","<p>Given the following list of lists</p>

<pre><code>arrayNumbers = [[32,3154,53,13],[44,34,25,67], [687,346,75], [57,154]]
</code></pre>

<p>how can I efficiently get the number of lists having only 4 items?</p>

<p>In this case, that would be <code>arrayNumbers_len = 2</code>. I can do this using a loop, but that is not efficient at all. Since the lengths of my real arrays are in the millions, I need a way to do this extremely fast. </p>

<p>Here is my current solution:</p>

<pre><code>batchSize = 4
counter = 0
for i in range(len(arrayNumbers)):
    if (len(arrayNumbers[i]) == batchSize):
        counter += 1
</code></pre>

<p>Any suggestions?</p>
","2480410","6338725","2018-03-01 10:42:00","Finding out the number of lists with a certain length in Python","<python>","6","9","658"
"49047311","2018-03-01 10:12:03","3","","<p>Also, you can use date_format to create any time period you wish. 
Groupby specific day: </p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>from pyspark.sql import functions as F

df.select(F.date_format('timestamp','yyyy-MM-dd').alias('day')).groupby('day').count().show()</code></pre>
</div>
</div>
</p>

<p>Groupby specific month (just change the format):</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>df.select(F.date_format('timestamp','yyyy-MM').alias('month')).groupby('month').count().show()</code></pre>
</div>
</div>
</p>
","9423111","","","0","837","Morit","2018-02-28 09:52:56","41","0","6","0","34946051","34946509","2016-01-22 11:48:53","15","16144","<p>I've loaded a DataFrame from a SQLServer table. It looks like this:</p>

<pre><code>&gt;&gt;&gt; df.show()
+--------------------+----------+
|           timestamp|    Value |
+--------------------+----------+
|2015-12-02 00:10:...|     652.8|
|2015-12-02 00:20:...|     518.4|
|2015-12-02 00:30:...|     524.6|
|2015-12-02 00:40:...|     382.9|
|2015-12-02 00:50:...|     461.6|
|2015-12-02 01:00:...|     476.6|
|2015-12-02 01:10:...|     472.6|
|2015-12-02 01:20:...|     353.0|
|2015-12-02 01:30:...|     407.9|
|2015-12-02 01:40:...|     475.9|
|2015-12-02 01:50:...|     513.2|
|2015-12-02 02:00:...|     569.0|
|2015-12-02 02:10:...|     711.4|
|2015-12-02 02:20:...|     457.6|
|2015-12-02 02:30:...|     392.0|
|2015-12-02 02:40:...|     459.5|
|2015-12-02 02:50:...|     560.2|
|2015-12-02 03:00:...|     252.9|
|2015-12-02 03:10:...|     228.7|
|2015-12-02 03:20:...|     312.2|
+--------------------+----------+
</code></pre>

<p>Now I'd like to group (and sum) values by hour (or day, or month or...), but I don't really have a clue about how can I do that.</p>

<p>That's how I load the DataFrame. I've got the feeling that this isn't the right way to do it, though:</p>

<pre><code>query = """"""
SELECT column1 AS timestamp, column2 AS value
FROM table
WHERE  blahblah
""""""

sc = SparkContext(""local"", 'test')
sqlctx = SQLContext(sc)

df = sqlctx.load(source=""jdbc"",
                 url=""jdbc:sqlserver://&lt;CONNECTION_DATA&gt;"",
                 dbtable=""(%s) AS alias"" % query)
</code></pre>

<p>Is it ok?</p>
","1212067","1560062","2016-01-22 11:50:57","Group spark dataframe by date","<python><apache-spark><pyspark><apache-spark-sql>","2","0","1528"
"49047324","2018-03-01 10:12:46","1","","<p>This is one way:</p>

<pre><code>df['Front_x'], df['Front_y'], df['Front_z'] = list(zip(*[list(map(float, i)) for i in \
                                                   df['COORDFRONT'].str.split(' ')]))
</code></pre>

<p><strong>Result</strong></p>

<pre><code>df.dtypes

# COORDFRONT     object
# COORDREAR      object
# ID              int64
# Front_x       float64
# Front_y       float64
# Front_z       float64
# dtype: object
</code></pre>

<p><strong>Explanation</strong></p>

<ul>
<li><code>map</code> each row of string values to <code>float</code> from your <code>split</code> results.</li>
<li>Apply <code>zip(*...)</code> in order to output as 3 arrays required to assign to 3 series.</li>
</ul>

<p><strong>Performance</strong></p>

<p>For better performance on large dataframes, use <a href=""https://stackoverflow.com/a/49047277/9209546"">@jezrael's solution</a>. Some benchmarking results below.</p>

<pre><code>df = pd.DataFrame({'ID': {0: 3864, 1: 3864, 2: 3864, 3: 3864, 4: 3864},
                   'COORDFRONT': {0: '787.547 238.639 0.000', 1: '787.141 238.847 0.000', 2: '786.729 239.057 0.000', 3: '786.310 239.271 0.000', 4: '785.886 239.488 0.000'},
                   'COORDREAR': {0: '803.545 230.467 0.000', 1: '803.139 230.675 0.000', 2: '802.727 230.885 0.000', 3: '802.309 231.099 0.000', 4: '801.884 231.316 0.000'}})

def jp(df):
    df['Front_x'], df['Front_y'], df['Front_z'] = list(zip(*[list(map(float, i)) for i in df['COORDFRONT'].str.split(' ')]))
    return df

def jez(df):
    df[['Front_x', 'Front_y', 'Front_z']] = df['COORDFRONT'].str.split(expand=True).astype(float)
    return df

# df = pd.concat([df]*100)
%timeit jp(df)   # 2.2ms
%timeit jez(df)  # 2.94ms

# df = pd.concat([df]*10000
%timeit jp(df)   # 154ms
%timeit jez(df)  # 127ms
</code></pre>
","9209546","9209546","2018-03-01 10:19:21","3","1805","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49047244","49047277","2018-03-01 10:08:37","3","48","<p>I am processing outputs from a piece of software that provides co-ordinates as an x, y, z triple in a single column. Is there any way to split the string out into its three separate parts and convert to floats in one fell swoop? For example, I know that I can do the following:</p>

<pre><code>import pandas as pd

df = pd.DataFrame({'ID': {0: 3864, 1: 3864, 2: 3864, 3: 3864, 4: 3864},
                   'COORDFRONT': {0: '787.547 238.639 0.000', 1: '787.141 238.847 0.000', 2: '786.729 239.057 0.000', 3: '786.310 239.271 0.000', 4: '785.886 239.488 0.000'},
                   'COORDREAR': {0: '803.545 230.467 0.000', 1: '803.139 230.675 0.000', 2: '802.727 230.885 0.000', 3: '802.309 231.099 0.000', 4: '801.884 231.316 0.000'}})

df['Front_x'], df['Front_y'], df['Front_z'] = df['COORDFRONT'].str.split(' ').str
</code></pre>

<p>To separate out the three strings, but trying for example </p>

<pre><code>df['COORDFRONT'].str.split(' ').astype(float)
</code></pre>

<p>returns a <code>ValueError</code>.</p>
","5309300","","","Splitting and converting a string column in pandas","<python><pandas>","2","0","1019"
"49047333","2018-03-01 10:13:03","1","","<p>Looks like the target <code>ul</code> has fewer classes in scrapy response compared to the source as rendered by browser :</p>

<pre><code>response.xpath('//ul[@class=""trailer_list imglist""]/li/a/@href').extract()
</code></pre>

<p>output :</p>

<pre><code>[u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189047',
 u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189050',
 u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189053',
 u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189056',
 u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189059',
 u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189062']
</code></pre>
","2998271","","","3","784","har07","2013-11-16 00:20:32","77925","3065","1864","199","49046889","49047333","2018-03-01 09:49:34","1","259","<p>I crawl this web site
<a href=""https://movies.yahoo.com.tw/movieinfo_main.html/id=7819"" rel=""nofollow noreferrer"">https://movies.yahoo.com.tw/movieinfo_main.html/id=7819</a></p>

<p>I use <code>scarpy shell 'https://movies.yahoo.com.tw/movieinfo_main.html/id=7819'</code> on my terminal</p>

<p>I want to crawl the six <code>li</code> href under the <code>ul</code>
<a href=""https://i.stack.imgur.com/0Jrbp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0Jrbp.png"" alt=""enter image description here""></a></p>

<p>When i want to get the <code>li</code> tag i type command <code>response.xpath('//ul[@class=""trailer_list imglist slick-initialized slick-slider""]/li')</code> but get a empty list <code>[]</code></p>

<p>I try to type this command <code>response.xpath('//div[@class=""l_box_inner""]/ul/li/a/@href').extract()</code>
Here is what i get:</p>

<pre><code>In [14]: response.xpath('//div[@class=""l_box_inner""]/ul/li/a/@href').extract()
Out[14]: 
[u'https://movies.yahoo.com.tw/name_main/1000',
 u'https://movies.yahoo.com.tw/name_main/2595',
 u'https://movies.yahoo.com.tw/video/%E9%81%8A%E6%88%B2%E5%A4%9C%E6%AE%BA%E5%BF%85%E6%AD%BB-%E4%B8%AD%E6%96%87%E9%A0%90%E5%91%8A-095130014.html?movie_id=7819',
 u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189047',
 u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189050',
 u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189053',
 u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189056',
 u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189059',
 u'https://movies.yahoo.com.tw/movieinfo_photos.html/id=7819?movie_photo_id=189062',
 u'https://movies.yahoo.com.tw/post/169756772517/\u5091\u68ee\u8c9d\u7279\u66fc\u6372\u9032\u5931\u63a7\u904a\u6232\u591c-\u5168\u662f\u4ed6\u60f9\u7684\u798d']
</code></pre>

<p>But i just want to get the six href they id is 189047'189050'189053'189056'189059'189062</p>

<p>What is the correct xpath command if i just want to get the <code>li</code> six href ?</p>

<p>Any help would be appreciated. Thanks in advance.</p>
","6902961","","","Scrapy use xpath crawl ul class is no working","<python><xpath><scrapy>","1","3","2166"
"49047356","2018-03-01 10:14:19","0","","<p>Try this:</p>

<pre><code>import psutil

def bytes2human(n):
    # http://code.activestate.com/recipes/578019
    # &gt;&gt;&gt; bytes2human(10000)
    # '9.8K'
    # &gt;&gt;&gt; bytes2human(100001221)
    # '95.4M'
    symbols = ('K', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y')
    prefix = {}
    for i, s in enumerate(symbols):
        prefix[s] = 1 &lt;&lt; (i + 1) * 10
    for s in reversed(symbols):
        if n &gt;= prefix[s]:
            value = float(n) / prefix[s]
            return '%.1f%s' % (value, s)
    return ""%sB"" % n

total = psutil.disk_usage('/').total
print(total)
print(bytes2human(total))
</code></pre>

<p>...prints:</p>

<pre><code>100399730688
93.5G
</code></pre>

<p>Since it's a common use case I just added the above to psutil doc:
<a href=""http://psutil.readthedocs.io/en/latest/#bytes-conversion"" rel=""nofollow noreferrer"">http://psutil.readthedocs.io/en/latest/#bytes-conversion</a></p>
","376587","","","1","920","Giampaolo Rodolà","2010-02-10 23:12:17","8603","1062","175","3","49033295","","2018-02-28 15:38:56","1","76","<p>I am trying to convert total physical memory into stick value, ie 128gb, 64gb..etc.  </p>

<p>if I take the value of total ram from my servers, example 16826298368, and run this code I get and expected output of 16gb.  Which is great. But as the memory values increases, it begins to drift.<br>
Example: 134931955712 produces 126GB where 128GB is expected. 
Example: 67519483904 produces 63GB where 64GB is expected.</p>

<p>So my question is, how can I modify to get the expected output consistently as the value changes? The memory value is provided by a few different bits of code depending on the OS. We use psutil on Solaris for example. psutil.virtual_memory().total</p>

<pre><code>def transform_memory(data):
    for x in [""bytes"", "" KB"", "" MB"", "" GB""]:
        if data &lt; 1024.0:
            return ""%3.1f%s"" % (math.ceil(data), x)
        data /= 1024.0
    return ""%3.1f%s"" % (data, "" TB"")
</code></pre>
","4297891","4297891","2018-02-28 15:55:08","Python Convert Physical Memory to Stick Value","<python><python-2.7><psutil>","1","2","920"
"49047396","2018-03-01 10:16:50","0","","<p>It looks like the problem was MYSQL only:
By default, the strict mode isn't activated and allow incorrect insert/update to make changes in the database (wtf?), the solution is to change the sql_mode, either globally: 
<a href=""https://stackoverflow.com/questions/20373532/mysql-setting-sql-mode-permanently"">MySQL: Setting sql_mode permanently</a></p>

<p>Or in SQLalchemy like explained in this blog post:
<a href=""https://www.enricozini.org/blog/2012/tips/sa-sqlmode-traditional/"" rel=""nofollow noreferrer"">https://www.enricozini.org/blog/2012/tips/sa-sqlmode-traditional/</a></p>
","9418409","","","0","586","snoker","2018-02-27 11:37:17","1","2","0","0","49010687","49047396","2018-02-27 14:10:51","0","497","<p>I'm writing some test to a REST API linked to a MySQL db with python+werkzeug+SQLalchemy, one of the test is to try to add a ""object"" with the primary key missing in the json and verify that it fails and doesn't insert anything in the DB. It used to work fine with sqlite but I switched to MySQLdb and now I get a FlushError (instead of an IntegrityError I used to catch) and when I try to rollback after the error, it doesn't throw any error but the entry is in the database with the primary key set to ''. The code looks like this:</p>

<pre><code>    session = Session()
    try:
        res = func(*args, session=session, **kwargs)
        session.commit()
    except sqlalchemy.exc.SQLAlchemyError as e:
        session.rollback()
        return abort(422)
    else:
        return res
    finally:
        session.close()
</code></pre>

<p>And here's the error that I catch during the try/except:</p>

<blockquote>
  <p>class 'sqlalchemy.orm.exc.FlushError':Instance has a NULL identity key.  If this is an auto-generated value, check that the database table allows generation of new primary key values, and that the mapped Column object is configured to expect these generated values.  Ensure also that this flush() is not occurring at an inappropriate time, such as within a load() event.</p>
</blockquote>

<p>I just read the documentation about the SQLalchemy session and rollback feature but don't understand why the rollback doesn't work for me as this is almost textbook example from the documentation.</p>

<p>I use Python 2.7.13, werkzeug '0.12.2', sqlalchemy '1.1.13' and MySQLdb '1.2.3' and mysql  Ver 14.14 Distrib 5.1.73 !</p>

<p>Thanks for your help</p>
","9418409","","","SQLAlchemy not rolling back after FlushError","<python><mysql><orm><sqlalchemy><werkzeug>","1","0","1678"
"49047443","2018-03-01 10:19:01","2","","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing"" rel=""nofollow noreferrer""><code>boolean indexing</code></a> with <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html"" rel=""nofollow noreferrer""><code>loc</code></a> for select column <code>a</code> and last convert to <code>list</code>:</p>

<pre><code>L = df.loc[df['d'] == df['d'].min(), 'a'].tolist()
print (L)
['x', 't']
</code></pre>

<p><strong>Detail</strong>:</p>

<pre><code>print (df['d'] == df['d'].min())
0     True
1    False
2    False
3     True
4    False
Name: d, dtype: bool
</code></pre>
","2901002","","","0","636","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49047409","49047443","2018-03-01 10:17:27","1","41","<p>I have a dataframe sample looks like below. first row is header.</p>

<pre><code>a  b   c   d   e
x  1   10  4   asd
y  3   12  5   aqe
z  4   14  6   rty
t  6   12  4   abd
v  7   4   8   yul
</code></pre>

<p>I would like the find a column members by filtering d column by its minimum value. I tried the sort it and select the 0. element but column may have 2 minimum values like in the sample.</p>

<p>Output should be ""x"" and ""t"" </p>

<p>Any suggestions?</p>
","9299331","","","Filtering in pandas by condition","<python><pandas><filter><conditional-statements><minimum>","1","0","467"
"49047520","2018-03-01 10:23:37","1","","<p>Using <code>xonsh</code> I did</p>

<pre><code>$ xonsh
$ animal=""Cat""
$ age=""2""
$ weight=""3.8""
$ name=""Kitty""
$ history &gt; Cat
$ exit
$ xonsh
$ source Cat
</code></pre>

<p>Huh! Finally, I avoided <code>jupyter notebook</code>.</p>
","1114498","","","0","237","Necktwi","2011-12-24 11:03:48","918","345","175","2","48944382","","2018-02-23 09:03:43","1","56","<p>Let's say I have created some variables in the python shell. I want to do something like this:</p>

<pre><code>&gt;&gt;&gt; animal=""Cat""
&gt;&gt;&gt; age=""2""
&gt;&gt;&gt; weight=""3.8""
&gt;&gt;&gt; name=""Kitty""
&gt;&gt;&gt; env.saveTo(""./Cat.json"")
&gt;&gt;&gt; env.clear()
&gt;&gt;&gt; env.loadFrom(""./Cat.json"")
</code></pre>

<p>Is it possible? I am using <code>xonsh</code>.</p>
","1114498","10388629","2019-04-12 16:48:31","How to write all variables to a JSON file in the python shell","<python><python-3.x><shell><xonsh>","1","2","385"
"49047535","2018-03-01 10:24:18","0","","<p>You can dynamically create a class at run time inside a function:</p>

<pre><code>def Wrapper(x):
    class _wrap(x):
        def __init__(self):
            pass
        def new_method(self):
            return 1
    return _wrap
</code></pre>

<p>You can they use it normally:</p>

<pre><code>W1 = Wrapper(BaseClass1)
W2 = Wrapper(BaseClass2)
w1 = W1()
w2 = W2()
</code></pre>
","3545273","","","0","382","Serge Ballesta","2014-04-17 12:25:02","90494","5432","1346","480","49020632","49047535","2018-02-28 01:32:43","0","244","<p>How to parametrize initialisation of a class. For example, to wrap <code>BaseClass1</code> and <code>BaseClass2</code> it's possible to:</p>

<pre><code>class BaseClass1:
    pass

class BaseClass2:
    pass

class Wrapper(BaseClass1):

    def __init__(self):
        pass

    def new_method(self):
        return 1

w = Wrapper()
</code></pre>

<p>How to parametrize it so that the base class can be chosen upon initialization? </p>

<p>For example, how to initialize the <code>Wrapper</code> class using:</p>

<pre><code>w1 = Wrapper('BaseClass1')
w2 = Wrapper('BaseClass2')
</code></pre>

<p>or:</p>

<pre><code>b1 = BaseClass1
w1 = Wrapper(b1)
b2 = BaseClass2
w2 = Wrapper(b2)
</code></pre>

<p>or:</p>

<pre><code>w1 = Wrapper(BaseClass1)
w2 = Wrapper(BaseClass2)
</code></pre>

<p>Where the base class is a parameter?</p>

<p>The objective is to override/add additional methods to class instances.</p>

<p><strong>Update</strong></p>

<p>Thanks @Serge Ballesta for posting an answer, how to extend the answer so that the new methods have access to the base class attributes? For example:</p>

<pre><code>class Base:
    def __init__(self):
        self.id = 1

def Wrapper(x):
    class _wrap(x):
        def __init__(self):
            pass
        def new_method(self):
            return self.id
    return _wrap
</code></pre>

<p>Where <code>instance.new_method()</code> will return 1 in the below code:</p>

<pre><code>instance = Wrapper(Base)()
instance.new_method()
</code></pre>
","4605629","4605629","2018-03-13 06:05:13","How to initialize a wrapper class using a parametrized base class?","<python><class><inheritance><methods>","2","0","1498"
"49047537","2018-03-01 10:24:25","0","","<p>The following will work:</p>

<pre><code>def foo(n):
    s = n
    def bar(i):
        s_ = s + i
        return s_
    return bar
</code></pre>

<p>The inner function <code>bar</code> looks to find <code>s</code> locally inside its scope, and if it fails to find it, it goes to look one level up in the enclosing scope where it finds <code>s</code> which is a local variable of <code>foo</code>. But if you say <code>s = s + 1</code>, you declare <code>s</code> as a new local variable in the scope of the <code>bar</code> (""the assignment statement creates variables in the local scope""), which leads to an error because you haven't assigned a value to <code>s</code> before adding something to it (referencing to it). </p>

<p>On the other example, saying <code>s[0] = s[0] + 1</code> is different because you do not declare a new local variable inside the bar, you access the first element of <code>s</code> which is found in the enclosing scope of bar.</p>
","2945357","","","1","965","AndyK","2013-11-01 14:55:21","1747","195","574","21","49046554","49047038","2018-03-01 09:31:08","5","913","<p>I am reading <em>Hackers and Painters</em> and am confused by a problem mentioned by the author to illustrate the power of different programming languages.</p>

<p>The problem is:</p>

<blockquote>
  <p>We want to write a function that generates accumulators—a function that takes a number <em>n</em>, and returns a function that takes another number <em>i</em> and returns <em>n</em> incremented by <em>i</em>. (That’s <em>incremented</em> by, not plus. An accumulator has to accumulate.)</p>
</blockquote>

<p>The author mentions several solutions with different programming languages. For example, Common Lisp:</p>

<pre><code>(defun foo (n)
  (lambda (i) (incf n i)))
</code></pre>

<p>and JavaScript:</p>

<pre><code>function foo(n) { return function (i) { return n += i } }
</code></pre>

<p>However, when it comes to Python, the following codes do not work:</p>

<pre><code>def foo(n):
    s = n
    def bar(i):
        s += i
        return s
    return bar

f = foo(0)
f(1)  # UnboundLocalError: local variable 's' referenced before assignment
</code></pre>

<p>A simple modification will make it work:</p>

<pre><code>def foo(n):
    s = [n]
    def bar(i):
        s[0] += i
        return s[0]
    return bar
</code></pre>

<p>I am new to Python. Why doesn the first solution not work while the second one does? The author mentions lexical variables but I still don't get it.</p>
","6181069","124319","2018-03-01 19:12:07","Function that returns an accumulator in Python","<python><scope><closures><common-lisp><local-variables>","4","2","1395"
"49047682","2018-03-01 10:30:58","0","","<p>OK here's my outlook on this. You're on the right track and there <strong>is</strong> a way to update the element without the need to re-draw the page in this instance. What's happening is that you are returning data from your <code>get_selected_values()</code> method but not doing anything with it once it's returned to your AJAX request.</p>

<p>So firstly, I'm going to draw your attention to your AJAX request:</p>

<pre><code>$.ajax({
  type: 'POST',
  url: '/get_selected_values',
  success: function(response) {
    alert('Ok');
    draw();
  },
  error: function() {
    alert('Error');
  }
});
</code></pre>

<p>When you're getting a successful response from this, you're seeing your ""OK"" alert in the UI, right? However nothing updates in the UI despite you calling on the <code>draw()</code> method?</p>

<p>You won't want to return a <code>render_template</code> from your Flask function in this case. You were already on the right track with returning JSON from your function:</p>

<pre><code>if data:
  # return jsonify({'result': True, 'data': data}) # does not work this way
</code></pre>

<p>When you return your JSON data, it will be stored in the <code>response</code> variable in your <code>success</code> function. If you're unsure of exactly what's going into that <code>response</code> variable then output its contents with something like <code>alert(JSON.stringify(response))</code> in the <code>success</code> function of your AJAX request. From here you will see your data returned to your method.</p>

<p>Now you need to decide how you want to use that data to update your <code>&lt;div id=""data""&gt;</code> element in your UI. You can do this just using JavaScript with a series of <code>document.getElementById('element_id').innerHTML</code> statements or such-like so that your element is populated with all of the updated data from your response.</p>

<p>This will auto-update the data you wish to have displayed without the need to refresh the page.</p>

<p>Now that you've done that, invoke your <code>draw()</code> function again and it should now use the updated data.</p>

<p>I hope this helps set you down the right path with this one!</p>

<p><strong>AFTER EDIT 1</strong></p>

<p>When you're originally populating <code>&lt;div id=""data""&gt;</code> you are using a loop to populate a series of <code>&lt;li&gt;</code> tags in the element with your data.</p>

<p>When you are updating this element with your new data, you are just using <code>.innerHTML</code> to re-populate the parent <code>&lt;ul&gt;</code> element.</p>

<p>Your <code>draw()</code> method is looking to the data stored in the <code>&lt;li&gt;</code> elements.</p>

<p>Are you absolutely certain that, after you perform your update, your <code>&lt;div id=""data""&gt;</code> element is in exactly the same (ie. expected) format to work with your <code>draw()</code> method? In that it's still in the structure:</p>

<pre><code>&lt;div id=""data""&gt;
  &lt;ul id=""consumed_values""&gt;
    &lt;li&gt;Your updated data here...&lt;/li&gt;
    &lt;li&gt;More updated data...&lt;/li&gt;
  &lt;/ul&gt;
&lt;/div&gt;
</code></pre>

<p>This is the element structure that your <code>draw()</code> method is expecting to find. It's pulling its data in from each individual <code>&lt;li&gt;</code> element in the list. So these are the elements which need to store your updated values.</p>
","4285273","4285273","2018-03-01 13:10:51","2","3387","AJC24","2014-11-23 20:48:35","1711","75","158","35","49045755","","2018-03-01 08:44:00","1","935","<p>The data has to be refreshed without page reload. Originally data is appeared on html with jinja2.</p>

<pre><code>@app.route('/personal_account', methods=['POST'])
def welcome():
    login =  request.form['login']
    data = get_default_user_data(login)
    # ... processing
    return render_sidebar_template(""personal_account.html"", data=data)
</code></pre>

<p>According to these data graph is building with chartist.js.</p>

<p>personal_account.html</p>

<pre><code>&lt;div id=""data""&gt;
    &lt;ul id=""consumed_values""&gt;
        {% set count = 0 %}
        {% for i in data.consumed_values %}
            &lt;li&gt;{{  data.consumed_values[count] }}&lt;/li&gt;
        {% set count = count + 1 %}
        {% endfor %}
    &lt;/ul&gt;

&lt;/div&gt;
&lt;canvas width=""800"" height=""600"" id=""canvas""&gt;&lt;/canvas&gt;
&lt;button id=""button""&gt;Update&lt;/button&gt;
</code></pre>

<p>I need to update data. I am using ajax.
The function ""request"" make a post request to the server  to the function get_selected_values in Python.
This function gives new data. But new data doesn't display in jinja2 on page. The data is still old.</p>

<p>personal_account.js</p>

<pre><code>window.onload = draw(); 
function draw() {
    var consumed_values = document.querySelectorAll('ul#consumed_values li');
    var values = new Array();
    for (var i = 0; i &lt; consumed_values.length; i++) {
        console.log(consumed_values[i].innerHTML);  
        values[i] = consumed_values[i].innerHTML;
    }


    var numbers = new Array();
    for(var i=0; i&lt;consumed_values.length; i++)
    {
        numbers[i]=i+1;  
        console.log(numbers[i]);
    }

    var ctx = document.getElementById('canvas').getContext('2d');
            var grapf = {
                labels : numbers,
                datasets : [
                    {
                        strokeColor : ""#6181B4"",
                        data : values
                    }
                ]
            }
        new Chart(ctx).Line(grapf);

}

document.getElementById('button').onclick=function () {
        request();
}

function reques() { 
    var first = selected[0];
    var second = selected[1];
    first.month = first.month+1;
    second.month = second.month+1;
    $.ajax({
        type: 'POST',
        url: '/get_selected_values',
        success: function(response) {
            alert('Ok');
            draw();
        },
        error: function() {
            alert('Error');
        }
    });
}
</code></pre>

<p>Function get_selected_values()</p>

<pre><code>@app.route('/get_selected_values', methods=['POST'])
def get_selected_values():
    # ... 
    data = fetch_selected_date(start_date=start_date, end_date=end_date, login=current_user.get_id())
    if data:
        # return jsonify({'result': True, 'data': data}) # does not work this way
    # return  jsonify({'result': False, 'data': []})
    return render_sidebar_template(""personal_account.html"", data=data, result=1)
</code></pre>

<p>How to succeed in data's update and graph's rebuild?</p>

<p><strong>EDIT 1</strong></p>

<p>I am using the first version of get_selected_values function.</p>

<p>The request function look like this:</p>

<pre><code>...
 success: function(response) {
            alert('Успешно получен ответ:!'+ response.data);
            document.getElementById('consumed_values').innerHTML = response.data;
            draw();
        },
...
</code></pre>

<p>Data is updating successfully, but graph looks the same. How to fix?</p>
","","","2018-03-01 11:39:28","Data update without page reload jinja2","<javascript><python><ajax><flask><jinja2>","1","0","3507"
"49047693","2018-03-01 10:31:23","0","","<p>As stack trace says - problem is with this call:</p>

<pre><code>super(Model, self).__init__()
</code></pre>

<p>Model class takes at least 2 arguments + <code>self</code> as default - which gives number 3 of arguments mentioned above. Please look <a href=""https://github.com/tensorflow/models/blob/master/samples/core/get_started/custom_estimator.py"" rel=""nofollow noreferrer"">here</a> - there is sample custom classifier. Problem is that <code>params</code> that you are passing is taken by <code>**kwargs</code>, and describes arguments taken by constructor - you need 2 values there, or more. At least that is, what I can tell without seeing your code.</p>
","6103001","","","3","664","Michał Zaborowski","2016-03-23 08:08:55","3218","400","151","15","49047205","","2018-03-01 10:06:25","0","251","<p>I am now learning tensorflow 1.5.0 with python 2.7.5. I tried the mnist.py code in models/official/mnist I get the following error message. What is wrong ?</p>

<pre><code>bash-4.2$ cd models/official/mnist
bash-4.2$ python mnist.py
INFO:tensorflow:Using default config.
INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x4993e90&gt;, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/mnist_model', '_save_summary_steps': 100}
Traceback (most recent call last):
  File ""mnist.py"", line 270, in &lt;module&gt;
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""mnist.py"", line 202, in main
    mnist_classifier.train(input_fn=train_input_fn, hooks=[logging_hook])
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 314, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 743, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 725, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""mnist.py"", line 89, in model_fn
    model = Model(params['data_format'])
  File ""mnist.py"", line 48, in __init__
    super(Model, self).__init__()
TypeError: __init__() takes at least 3 arguments (1 given)
</code></pre>
","9427880","","","Error with tensorflow mnist.py code","<python><tensorflow><mnist>","1","2","1934"
"49047710","2018-03-01 10:32:21","0","","<p>Ok, since you want to learn some python, let me propose you a way to do it this. First you need a template engine -like <a href=""http://jinja.pocoo.org/"" rel=""nofollow noreferrer"">jinja2</a> (there are many others)-, a data source in our example a .csv file, -could be other like a db- and finally some code that reads the csv line by line and mix the content with the template.</p>

<p><strong>Sample CSV file</strong>:</p>

<pre class=""lang-csv prettyprint-override""><code>1;sample
2;dandelion
3;just for fun
</code></pre>

<p><strong>Sample template</strong>:</p>

<pre class=""lang-txt prettyprint-override""><code>**Full Scientific Name:   **[[|]]**[syn]**
**Common Name(s): *{{name}}*
=====  =====
USDA PLANTS entry for Code: *{{symbol}}*
---
</code></pre>

<p><strong>Sample code</strong>:</p>

<pre class=""lang-python prettyprint-override""><code>#!/usr/bin/env/python
#
# Using the file system load
#
# We now assume we have a file in the same dir as this one called
# test_template.ziim
#

from jinja2 import Environment, FileSystemLoader
import os
import csv

# Capture our current directory
THIS_DIR = os.path.dirname(os.path.abspath(__file__))


def print_zim_doc():
    # Create the jinja2 environment.
    # Notice the use of trim_blocks, which greatly helps control whitespace.
    j2_env = Environment(loader=FileSystemLoader(THIS_DIR),
                         trim_blocks=True)

    template = j2_env.get_template('test_template.zim')
    with open('example.csv') as File:
        reader = csv.reader(File, delimiter=';')
        for row in reader:
            result = template.render(
                symbol=row[0]
                , name=row[1]
            )
            # to save the results
            with open(row[0]+"".txt"", ""wt"") as fh:
                fh.write(result)
            fh.close()


if __name__ == '__main__':
    print_zim_doc()
</code></pre>

<p>The code is pretty simple, reads the template located in the same folder as the python code, opens the csv file (also located in the same place), iterates over each line of the csv and renders the template using the values of the csv columns to fill the {{var_name}} in the template, finally saves the rendered result in a new file named as one of the csv column values. This sample will generate 3 files (1.txt, 2.txt, 3.txt). From here you can extend and improve the code to get your desired results.</p>
","1320809","","","0","2394","Nickmancol","2012-04-08 21:11:13","956","78","33","4","49019088","","2018-02-27 22:36:16","0","118","<p>I am using the application Zim Wiki(cross-platform, FOSS), which I am using to keep a personal wiki with lots of data coming from tables, copy and pasting, my own writing, and downloading and attaching .png and .html files for viewing and offline access.  </p>

<p>The data that is not written or pasted can be stored in tables in the form of names, url addresses, and the names and locations of images and other attachments.  </p>

<p>To insert into zim, I can use the front end with WSIWYG, or to make the skeleton of each entry, I could modify a template text entry.  If I do this, nothing matters except for the location and identity of each character in each line.  </p>

<p>By supplying the text in this image:<br>
<a href=""https://postimg.org/image/fobdpwfvf/"" rel=""nofollow noreferrer"">DandelionDemo source text</a>,</p>

<p>--I can make this entry for Dandelion:<br>
<a href=""https://postimg.org/image/q9v91zm7v/"" rel=""nofollow noreferrer"">DandelionDemo Wiki</a>.</p>

<p>So, I can generate and name the Wiki entry in Zim, which creates the .txt file for me, and inserts the time stamp and title, so, the template for this type of entry without the pasted fields would be: </p>

<pre><code>**Full Scientific Name:   **[[|]]**[syn]**
**Common Name(s): **
=====  =====
**USDA PLANTS entry for Code:** [[https://plants.usda.gov/core/profile?symbol=|]]   **-   CalPhotos available images for:** [[https://calphotos.berkeley.edu/cgi/img_query?query_src=photos_index&amp;where-taxon=|]]
**---**
**From - Wikipedia **[[wp?]]   **-   **[[/Docs/Plants/]] 
{{/Docs/Plants/?height=364}}{{/Docs/Plants/?height=364}}
**()** //,// [[|(source)]]
**()** //// [[|(source)]]
**Wikipedia Intro:  **////
---
</code></pre>

<p>So the first line with content, after the 31st character(which is a tab), you paste ""http... {etc}. Then the procedure would insert ""Taraxacum officinale... {etc}"" after the ""|"", or what was the 32nd character, and so on.  This data could be from ""table1"" and ""table2"", or combining the tables to make an un-normalized ""table1table2"", where each row could be converted to text or a .csv or I don't know, what do you think?</p>

<p>Is there a way, in LibreOffice to do this?  I have used LibreOffice Base to generate a ""book"" form that populated fields, but it was much less complex data, without wiki liking and drag-and-drop pasting of images and attachments.  So maybe the answer is to go simpler?  The tables are not currently part of a registered database, but I could do that, once I have decided on the method of doing this.  </p>

<p>I am ultimately looking for a ""way"", hopefully an ""easy"" way.  However, that may not be in LibreOffice.  If not, I know that I could do this in Python, but I haven't learned much about Python yet.  If it involves a language, that is the first and only one I don't know that I will invest in learning for this project.  If you know a ""way"" to do this in Python, let me know, and my first project and way of framing my study process will be in learning the methods that you share.  </p>

<p>If you know of some other Linux GUI, I am definitely interested, but only in active free and open source builds that involve minimal/no compiling.  I know the basics of SQL and DBMS's.  In the past, have gotten Microsoft SQL server lite to work, but not DBeaver, yet.  If you know of a CLI way also let me know, but I am a self-taught outdoors-loving Linux newb and mostly know about how to tweak little settings in programs, how to use moderately easy programs like ImageMagick, and I have built a few Lamp stacks for Drupal and Wordpress (no BASH etc...).  </p>

<p>Thank you very much!</p>
","8548776","9264702","2018-04-20 07:44:47","LibreOffice/other method of filling template .txt file for import into Zim Wiki","<python><linux><database><wiki><libreoffice>","1","0","3641"
"49047748","2018-03-01 10:34:16","1","","<pre><code>section_id  = [5, 6, 8, 14]
scores  = [4, 11, 13, 7]
sorted_reverse_scores =[]
sorted_section_id =[]
for i in sorted(zip(scores,section_id),reverse=True):
  sorted_reverse_scores.append(i[0])
  sorted_section_id.append(i[1])
print(sorted_reverse_scores)
print(sorted_section_id)
</code></pre>

<blockquote>
  <p>output</p>
  
  <p>[13, 11, 7, 4]
  [8, 6, 14, 5]</p>
</blockquote>
","8572897","8572897","2018-03-01 10:42:19","3","391","Jay Shankar Gupta","2017-09-07 06:49:13","5609","610","4","15","49047681","49047748","2018-03-01 10:30:53","0","29","<p>I have two lists and I want to sort the one of them (<code>scores</code>) in reverse order and get the corresponding indexes in order to sort the second one (<code>section_id</code>).</p>

<p>For example:</p>

<pre><code>section_id = [5, 6, 8, 14]
scores = [4, 11, 13, 7]
</code></pre>

<p>The new lists will be:</p>

<pre><code>sorted_reverse_scores = [13, 11, 7, 4]
sorted_section_id = [8, 6, 14, 5]
</code></pre>

<p>Do you know how to achieve this?</p>

<p>Currently the only thing I do is:</p>

<pre><code>sorted_reverse_scores = section_id.sort(reverse=True)
</code></pre>
","1395874","","","Sort a list based on the sort indexes of another list","<python><python-3.x>","1","0","582"
"49047758","2018-03-01 10:34:38","0","","<p>This may help you. Here you go do_something() is called every 100ms.</p>

<p>This code also proves itself that the method is executed 10 times in a second. i.e. it is executed every 100ms. See the Result.</p>

<pre><code>import threading
from time import time

def quit(delta):
    print(delta)
    return int(delta) == 1

def do_something(*args):
    then = args[0]
    now = time()
    if quit(now - then):
        threading.Timer(0.1, do_something, [then, quit]).cancel()
    else:
        threading.Timer(0.1, do_something, [then, quit]).start()

do_something(time())
</code></pre>

<p>Result:</p>

<pre><code>0.10426497459411621
0.2058699131011963
0.3096139430999756
0.4199540615081787
0.525109052658081
0.6257798671722412
0.7308750152587891
0.8337719440460205
0.9371669292449951
1.041382074356079
</code></pre>
","5364318","5364318","2018-03-01 15:52:15","5","820","Reck","2015-09-22 16:28:37","903","107","41","6","49047631","49047758","2018-03-01 10:28:33","0","40","<p>I am using Python on Windows platform and I need to periodically execute a piece of code every 100ms or lower. For an example:</p>

<pre><code>while (packetNumber &lt; 30000):
    sock.sendto(bytes(MESSAGE, ""utf-8""), (SERVER_IP, SERVER_PORT))
    packetNumber = packetNumber + 1
    print(""Sent the"", packetNumber, ""th packet"")
</code></pre>

<p>I only care about calling time of this line:</p>

<pre><code>sock.sendto(bytes(MESSAGE, ""utf-8""), (SERVER_IP, SERVER_PORT))
</code></pre>

<p>and it needs to be called every 100ms (or as accurate as possible), in periods like:</p>

<p>11:24:07.00000</p>

<p>11:24:07.10000</p>

<p>11:24:07.20000</p>

<p>11:24:07.30000</p>

<p>etc.</p>

<p>What is the most accurate method of achieving this?</p>
","8458455","","","Very precise periodic function calls in Python","<python><python-3.x><udp>","1","0","745"
"49047773","2018-03-01 10:35:45","1","","<p>If I'm correct, req2.headers shows the response headers. You are setting the Content-Type of your request header, showing that the content you are sending is encoded in UTF-16. I don't think the response must have the same encoding as the request, it is up to the server to decide.</p>
","5985209","","","0","289","Aleksandar Jovanovic","2016-02-26 09:27:24","751","238","72","2","49047497","49047773","2018-03-01 10:22:07","0","115","<pre><code>req2 = requests.put(url, json = json_data, headers= header)
print(req2.status_code)
print(req2.headers)
</code></pre>

<p>Where <code>json_data = req1.json()</code></p>

<pre><code>url = 'some url'
</code></pre>

<p>and </p>

<pre><code>header = {'Content-Type': 'application/data;charset=UTF-16'}
</code></pre>

<p>In above code req1 gets a response from a server.  <br/><code>req1</code> json is passed with <code>url</code> to fetch response <code>req2</code>. I want to make <code>req2</code> using PUT() with <code>charset = utf-16</code>. When I am trying to do this by setting headers of req2 (1st line of code) it doesn't do anything as still the statement <code>print(req2.headers)</code> prints </p>

<pre><code>{'Date': 'Thu, 01 Mar 2018 09:51:00 GMT', 'Transfer-Encoding': 'chunked', 'Content-Type': 'application/json;charset=UTF-8'}
</code></pre>
","5852891","4869129","2018-03-01 10:26:40","header data in python requests.put() does not change","<python><python-requests><put>","2","0","871"
"49047777","2018-03-01 10:35:55","1","","<p>It might be a bit late to answer but just in case someone is still looking for something similar:</p>

<p>There's <a href=""https://pypi.python.org/pypi/inflect"" rel=""nofollow noreferrer"">inflect</a> (also available in <a href=""https://github.com/pwdyson/inflect.py"" rel=""nofollow noreferrer"">github</a>) which support python 2.x and 3.x.
You can find the singular or plural form of a given word:</p>

<pre><code>import inflect
p = inflect.engine()

words = ""cat dog child goose pants""
print([p.plural(word) for word in words.split(' ')])
# ['cats', 'dogs', 'children', 'geese', 'pant']
</code></pre>

<p>Is worth noticing that <code>p.plural</code> of a plural will give you the singular 
  form.
  In addition, you can provide a POS (Part Of Speech) tag or to provide a number and the lib determines if it needs to be plural or singular:</p>

<pre><code>p.plural('cat', 4)   # cats
p.plural('cat', 1)   # cat
# but also...
p.plural('cat', 0)   # cats
</code></pre>
","1522304","","","2","969","jose.marcos.rf","2012-07-13 00:24:00","121","12","469","0","32404666","","2015-09-04 18:43:29","11","8671","<p>How could I use NLTK module to write both the noun's singular and plural form, or tell it not to differentiate between singular and plural when searching a txt file for a word? Can I use NLTK to make the program case insensitive?</p>
","5301912","2664670","2015-09-08 17:04:28","Python - Generating the plural noun of a singular noun","<python><nlp>","4","0","237"
"49047800","2018-03-01 10:36:59","2","","<p>Few websites block based on language or location. Following code with additional header works </p>

<pre><code>In [11]: def downloadFile(url, fileName):
         headers = {'Accept-Language': 'en-US,en;q=0.9,te;q=0.8'}
         r = requests.get(url, allow_redirects=True, stream=True, headers=headers)
        with open(fileName, ""wb"") as pdf:             
           for chunk in r.iter_content(chunk_size=1024):
               if chunk:
                    pdf.write(chunk)

In [12]: downloadFile(""http://pubs.vmware.com/vsphere-55/topic/com.vmware.ICbase/PDF/vsphere-esxi-vcenter-server-552-storage-guide.pdf"", ""vsphere-esxi-vcenter-server-552-storage-guide.pdf"")
</code></pre>
","9222784","","","0","684","Neha Ummareddy","2018-01-16 06:49:11","66","14","9","0","49042628","49047800","2018-03-01 04:27:52","1","187","<p>I am trying to download a <a href=""http://pubs.vmware.com/vsphere-55/topic/com.vmware.ICbase/PDF/vsphere-esxi-vcenter-server-552-storage-guide.pdf"" rel=""nofollow noreferrer"">pdf</a> file with below Python function. I was able to open that <a href=""http://pubs.vmware.com/vsphere-55/topic/com.vmware.ICbase/PDF/vsphere-esxi-vcenter-server-552-storage-guide.pdf"" rel=""nofollow noreferrer"">URL</a>(redirect to another URL) in the browser. But the code is getting 404 error. </p>

<pre><code>import requests
 def downloadFile(url, fileName):
        r = requests.get(url, allow_redirects=True, stream=True)
        with open(fileName, ""wb"") as pdf:             
            for chunk in r.iter_content(chunk_size=1024):
                if chunk:
                    pdf.write(chunk)


downloadFile(""http://pubs.vmware.com/vsphere-55/topic/com.vmware.ICbase/PDF/vsphere-esxi-vcenter-server-552-storage-guide.pdf"", ""vsphere-esxi-vcenter-server-552-storage-guide.pdf"")
</code></pre>
","1554241","","","Error in Downloading live pdf file from URL in python","<python><python-requests>","1","3","979"
"49047825","2018-03-01 10:38:08","2","","<p>May not be the most efficient, requires an extra pass to remove duplicates. </p>

<p>Functional implementation : </p>

<pre><code>arr = np.array(['a','a','b','b','b','c'])
print(set(map(lambda x  : (x , list(arr).count(x)) , arr)))
</code></pre>

<p>returns : </p>

<pre><code>{('c', 1), ('b', 3), ('a', 2)}
</code></pre>

<p>or return as <code>dict</code> :</p>

<pre><code>print(dict(map(lambda x  : (x , list(arr).count(x)) , arr)))
</code></pre>

<p>returns : </p>

<pre><code>{'b': 3, 'c': 1, 'a': 2}
</code></pre>
","470184","","","0","523","blue-sky","2010-10-08 11:33:36","19981","4264","1299","13","2600191","2600208","2010-04-08 13:30:00","1397","1483192","<p>Given an item, how can I count its occurrences in a list in Python?</p>
","222893","2357112","2018-12-20 20:38:50","How can I count the occurrences of a list item?","<python><list><count>","22","0","75"
"49047833","2018-03-01 10:38:37","-2","","<p>The problem was that my script was called bz2.py so the import at the start was causing it to import itself, which caused it to run once when it was imported, then again when the rest of it ran.</p>
","830431","830431","2018-03-01 11:58:47","0","202","Grezzo","2011-07-05 16:16:11","1572","175","125","11","49047133","49047833","2018-03-01 10:02:05","-1","96","<p>I'm trying to read a binary file bit by bit because it may be large. My code is:</p>

<pre><code>import bz2

read_buffer_size = 10000

with open(r'C:\Python27\python.exe', 'rb') as f:
    data = f.read(read_buffer_size)
    while data:
        print len(data)
        data = f.read(read_buffer_size)
</code></pre>

<p>and it gives me output of:
100</p>

<pre><code>10000
10000
8160
10000
10000
8160
</code></pre>

<p>In this case the file is 28160 bytes, so I was expecting to see:</p>

<pre><code>10000
10000
8160
</code></pre>

<p>Why is python reading my file twice?</p>
","830431","830431","2018-03-01 11:57:32","Why does python read my file twice?","<python>","1","6","577"
"49047834","2018-03-01 10:38:47","0","","<p>The errors are due probably to legacy commands in the scripts. The first exemple works substituting the first instructions with</p>

<pre><code>splash:set_viewport_size(800, 600)
splash:set_user_agent('Splash bot')
</code></pre>

<p>The second isn't working simply because of unsure javascript evaluation with <code>splash:evaljs</code> not permitted under the site policy.</p>
","7674438","","","0","381","Lore","2017-03-07 19:34:01","185","178","1193","127","49026524","49047834","2018-02-28 09:52:01","-2","63","<p>I've splash on windows running with Docker toolbox.</p>

<p>I am in Splash UI running a <em>built-in</em> example:</p>

<p><a href=""https://i.stack.imgur.com/klhTk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/klhTk.png"" alt=""Splash UI""></a></p>

<p>It seems correct but... it doesn't work!</p>

<p><a href=""https://i.stack.imgur.com/zisd1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zisd1.png"" alt=""Error message""></a></p>

<p>Seem strange to me. Do you figure out why?</p>

<p>EDIT: same thing with
<a href=""https://i.stack.imgur.com/L30V7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/L30V7.png"" alt=""Splash example 2""></a></p>

<p>output</p>

<p><a href=""https://i.stack.imgur.com/PNxFi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PNxFi.png"" alt=""enter image description here""></a></p>
","7674438","7674438","2019-09-18 11:21:34","Splash UI examples running in Docker","<python><docker><scrapy-splash><splash-js-render>","1","7","881"
"49047853","2018-03-01 10:40:04","0","","<p>If your system is having <a href=""https://github.com/pciutils/pciutils"" rel=""nofollow noreferrer"">pciutils</a> library then you can use <a href=""https://pypi.python.org/pypi/libpci"" rel=""nofollow noreferrer"">libpci</a> python librarie API's for accessing PCI through python, Where ""python libpci"" uses ctype libraries to access 'pciutils libpci' shared library. The 'pciutils libpci' uses os dependent interfaces to access PCI memory region, For example in Linux it uses either procfs or sysfs to read or write memory.</p>
","2813237","","","0","526","BasavarajaMS","2013-09-25 00:39:45","56","10","42","0","26400340","","2014-10-16 09:04:10","0","3375","<p>We have a board which can be connected on the PCI bus of the motherboard. We can read the base address and whatever raleted information through the customized software of the board. reading and writting through the board is done without any problem which means that there shouldnt be any problem at the operating system level. We need to access the data though the Python interface. Is there any library or piece of code which i can send the data to that address? The board is alraedy supported for C++ and VB libraries. What i need in fact is an interface of PCI bus in python.</p>
","1571737","","","PCI bus interface in Python","<python><pci>","1","3","586"
"49047866","2018-03-01 10:41:02","0","","<p>Your problem can be perfectly solved using OpenCV and keypoint matching algorithms such as SURF or ORB. You don't really need a classifier. To my experience, such solution using unmodified openCv can scale up to recognize around 10.000 images.</p>

<p>What I would do is:
Offline: Loop over your book images to generate a database of keypoint descriptors matching each descriptor to the id of the book in which it comes from.
Online: Compute the keypoints of the query image and try to match (using  BF, FLANN, or LSH) each of them to a keypoint of the pre-computed database.
Vote for the database book cover which has matched with the most query keypoints.
Try to compute an homography matrix between selected db book cover and query image to validate match.</p>

<p>ORB, BRISK, SURF, SIFT feature descriptors are all usable for this task, and rotation invariant. ORB and BRISK are faster and a bit less performant.</p>

<p>See this link for simple example:
<a href=""https://docs.opencv.org/3.3.0/dc/dc3/tutorial_py_matcher.html"" rel=""nofollow noreferrer"">https://docs.opencv.org/3.3.0/dc/dc3/tutorial_py_matcher.html</a></p>
","9428221","","","0","1130","Xun Victor","2018-03-01 09:49:37","1","3","0","0","48673104","","2018-02-07 20:57:41","0","1677","<p>I have been training OpenCV classifier for recognition of books.The requirement is recognize book from an image. I have used 1000+ images and OpenCV is able to detect books with no rotation. However, when I try to detect books with rotations it does not work properly.So I am wondering if their anyway to detect objects with rotations in images using OpenCV? </p>
","8024510","","","How to detect rotated object from image using OpenCV?","<c#><python><c++><opencv><object-detection>","3","0","367"
"49047893","2018-03-01 10:42:27","3","","<p>Can be too late, but i'm going to help. I had the same problem, i've created my conda env and installed everything i'll need, but when i've tryed to import cv2, i've received a message 'no module named cv2'. I've tryed install again and i've done the Linda's tips and haven't worked. So, i've seen that my conda env haven't had the cv2 installed. If it happened you, you just copy your cv2 folder to ""miniconda'X'/envs/yourEnv/lib/python'X.X'/site-packages/"" that will work. At least have worked to me</p>
","9385077","9385077","2018-03-03 00:26:41","1","509","Paulo Ricardo","2018-02-20 10:27:16","31","0","0","0","39977808","40016776","2016-10-11 12:58:24","11","30054","<p>I have anaconda (version: conda 4.2.9, python3) installed and am trying to do <code>import cv2</code> when I get the following error:</p>

<p><code>ImportError: No module named 'cv2'</code></p>

<p>With <code>conda search cv2</code> I get this:</p>

<blockquote>
  <p>opencv                     2.4.2                np15py26_0  defaults<br>
                               2.4.2                np15py27_0  defaults<br>
                               2.4.2                np16py26_0  defaults<br>
                               2.4.2                np16py27_0  defaults<br>
                               2.4.2                np17py26_0  defaults<br>
                               2.4.2                np17py27_0  defaults<br>
                               2.4.2                np15py26_1  defaults<br>
                               2.4.2                np15py27_1  defaults<br>
                               2.4.2                np16py26_1  defaults<br>
                               2.4.2                np16py27_1  defaults<br>
                               2.4.2                np17py26_1  defaults<br>
                               2.4.2                np17py27_1  defaults<br>
                               2.4.6                np16py26_0  defaults<br>
                               2.4.6                np16py27_0  defaults<br>
                               2.4.6                np17py26_0  defaults<br>
                               2.4.6                np17py27_0  defaults<br>
                               2.4.6                np18py26_0  defaults<br>
                               2.4.6                np18py27_0  defaults<br>
                               2.4.9                np18py27_0  defaults<br>
                               2.4.10               np19py26_0  defaults<br>
                               2.4.10               np19py27_0  defaults<br>
                               2.4.10              np110py27_1  defaults<br>
                               2.4.10               np19py26_1  defaults<br>
                               2.4.10               np19py27_1  defaults        </p>
</blockquote>

<p>What do I need to do to be able to import the cv2 module? Thanks!</p>

<p>PS: I am using Ubuntu 16.04</p>
","4795786","4795786","2018-05-30 14:32:10","Anaconda: cannot import cv2 even though opencv is installed (how to install opencv3 for python3)","<python><python-3.x><opencv><anaconda><opencv3.0>","4","1","2247"
"49047957","2018-03-01 10:46:28","3","","<p><code>user = User.objects.filter(pk=pk)</code> return queryset. When yoy try later <code>Images.objects.filter(user_id=user.id)</code> it raise error. You need to get first object in queryset with <a href=""https://docs.djangoproject.com/en/2.0/ref/models/querysets/#first"" rel=""nofollow noreferrer""><code>first()</code></a> method:</p>

<pre><code>user = User.objects.filter(pk=pk).first()
</code></pre>

<p>Or use <a href=""https://docs.djangoproject.com/en/2.0/ref/models/querysets/#get"" rel=""nofollow noreferrer""><code>get</code></a> instead:</p>

<pre><code>user = User.objects.get(pk=pk)
</code></pre>

<p>but second option will raise <code>DoesNotExist</code> error if user with provided id does not exist. To handle this error you can use <a href=""https://docs.djangoproject.com/en/2.0/topics/http/shortcuts/#get-object-or-404"" rel=""nofollow noreferrer""><code>get_object_or_404</code></a>, which return page not found in case of wrong id:</p>

<pre><code>from django.shortcuts import get_object_or_404
user = get_object_or_404(User, pk=1)
</code></pre>
","641249","641249","2018-03-01 11:00:13","7","1062","neverwalkaloner","2011-03-02 13:25:37","28058","1244","1934","0","49047914","49047957","2018-03-01 10:43:34","1","296","<p>I'm trying to make my dashboard show a list of users in your area. This so far works but I can not get the user's fist image to show. The current error message I am getting is ""'QuerySet' object has no attribute 'id'""</p>

<p>models.py</p>

<pre><code>class Images(models.Model):
    image = models.ImageField(upload_to='profile_image', null=True, default='profile_image/none/no-img.png')
    user = models.ForeignKey(User, on_delete=models.CASCADE,  null=False)
</code></pre>

<p>views.py</p>

<pre><code>class DashboardView(TemplateView):

    template_name = 've/cp/dashboard.html'

    @method_decorator(login_required)
    def dispatch(self, *args, **kwargs):
        return super(DashboardView, self).dispatch(*args, **kwargs)


    def get(self, request, pk=None):
        users = User.objects.exclude(id=request.user.id)
        user = User.objects.filter(pk=pk)
        try:
            favorite = Favorite.objects.get(current_user=request.user)
            favorites = favorite.users.all()
        except Favorite.DoesNotExist:
            favorites = None

        args = {
            'users': users, 'favorites':favorites, 'images': Images.objects.filter(user_id=user.id)
        }

        return render(request, self.template_name, args)
</code></pre>

<p>dashboard.html</p>

<pre><code>        &lt;h2&gt;People near you&lt;/h2&gt;
        {% for user in users %}
            &lt;a href=""{% url 've:view_profile_with_pk' pk=user.pk %}""&gt;
                &lt;h4&gt;{{ user.username }}&lt;/h4&gt;
                &lt;p&gt;{{ user.images }}&lt;/p&gt;

            {% if images %}

                {% for img in images %}
                &lt;a href=""{{ img.image.url }}"" target=""_blank""&gt;
                &lt;img src=""{{ img.image.url }}"" class="""" style=""max-width: 300px""&gt;
                &lt;/a&gt;
                {% endfor %}
            {% else %}

            &lt;p&gt;No images&lt;/p&gt;
            {% endif %}

            &lt;/a&gt;

            {% if not user in favorites %}
            &lt;a href=""{% url 've:change_favorites' operation='add' pk=user.pk %}""&gt;
            &lt;button type=""button"" class=""btn btn-success""&gt;Add Favorite&lt;/button&gt;
            &lt;/a&gt;
            {% endif %}
        {% endfor %}
</code></pre>
","8315752","","","Django Foreign Key in View - get first image to show for each user in list","<python><django><foreign-keys>","1","0","2270"
"49047960","2018-03-01 10:46:30","3","","<p>Here is one more concise way (if the order is not important):</p>

<pre><code>In [56]: np.indices(a.shape).T.reshape(a.size, 2)
Out[56]: 
array([[0, 0],
       [1, 0],
       [2, 0],
       [0, 1],
       [1, 1],
       [2, 1],
       [0, 2],
       [1, 2],
       [2, 2]])
</code></pre>

<p>If you want it in your intended order you can use <code>dstack</code>:</p>

<pre><code>In [46]: np.dstack(np.indices(a.shape)).reshape(a.size, 2)
Out[46]: 
array([[0, 0],
       [0, 1],
       [0, 2],
       [1, 0],
       [1, 1],
       [1, 2],
       [2, 0],
       [2, 1],
       [2, 2]])
</code></pre>

<p>For the first approach if you don't want to use <code>reshape</code> another way is concatenation along the first axis using <code>np.concatenate()</code>.</p>

<pre><code>np.concatenate(np.indices(a.shape).T)
</code></pre>
","2867928","2867928","2018-03-01 11:42:25","6","829","Kasramvd","2013-10-10 16:10:31","83554","6938","4534","1304","49047610","49047960","2018-03-01 10:27:39","3","48","<p>If I have a multidimensional array like this:</p>

<pre><code>a = np.array([[9,9,9],[9,0,9],[9,9,9]])
</code></pre>

<p>I'd like to get an array of each index in that array, like so:</p>

<pre><code>i = np.array([[0,0],[0,1],[0,2],[1,0],[1,1],...])
</code></pre>

<p>One way of doing this that I've found is like this, using <code>np.indices</code>:</p>

<pre><code>i = np.transpose(np.indices(a.shape)).reshape(a.shape[0] * a.shape[1], 2)
</code></pre>

<p>But that seems somewhat clumsy, especially given the presence of <code>np.nonzero</code> which <em>almost</em> does what I want.</p>

<p>Is there a built-in numpy function that will produce an array of the indices of every item in a 2D numpy array?</p>
","2422432","","","Get array of indices for array","<python><arrays><numpy><multidimensional-array>","1","1","714"
"49048002","2018-03-01 10:48:52","0","","<p>It seems like you're accessing properties of some variables without checking whether they exist or not. For example in this line: (that gave the Exception you're experiencing; but also in other lines in your code...)</p>

<pre class=""lang-python prettyprint-override""><code>brand = containers.div.div.a[""title""]
</code></pre>

<p>I suggest a much more careful approach. For example, this naive code:</p>

<pre><code>if (containers is not None) and (containers.div is not None) and (containers.div.div is not None) and (containers.div.div.a is not None):
  brand = containers.div.div.a[""title""]
else:
  brand = """"
</code></pre>

<p>If you'd like to further debug the problem in the specific HTML you got, try nested conditions:</p>

<pre><code>if containers is not None:
  if containers.div is not None:
    # ... more conditions here ...
  else:
    print ""ERROR 2: containers.div was None! :(""
else:
  print ""ERROR 1: containers was None! :(""
</code></pre>
","3605610","","","2","961","Yaniv","2014-05-05 19:29:04","394","23","1","1","49047840","","2018-03-01 10:39:14","0","42","<p>This is my first webscraping application type. </p>

<p>Here's my code: </p>

<pre><code>import bs4
from urllib.request import urlopen as uReq
from bs4 import BeautifulSoup as soup

my_url= 'https://www.newegg.com/Video-Cards-Video-Devices/Category/ID-38?Tpk=graphics%20card'

#opening up connection, grabbing page
uClient = uReq(my_url)
#makes it a variablepage_html = uClient.read()

page_html = uClient.read()
#will close it
uClient.close()

#html parsing
page_soup = soup(page_html, ""html.parser"")

#grabs each container in HTML
containers = page_soup.find(""div"",{""class"":""item-container""})

filename = ""Products.csv""
f = open(filename, ""w"")

headers = ""brand, product_name, shipping\n""

f.write(headers)

for container in containers:
    brand = containers.div.div.a[""title""]

    title_container = containers.find(""a"", {""class"": ""item-title""})
    product_name = title_container[0].txt

    shipping_container = container.find(""li"", {""class"": ""price-ship""})
    shipping = shipping_container[0].txt.strip()

    print(""brand: "" + brand)
    print(""product_name: "" + product_name)
    print(""shipping: "" + shipping)

    f.write(brand + "","" + product_name.replace("","", ""|"") + "","" + shipping + ""\n"")
f.close()
</code></pre>

<p>Here's the error: </p>

<pre><code>Traceback (most recent call last):

  File ""&lt;ipython-input-23-b9aa37e3923c&gt;"", line 1, in &lt;module&gt;
    runfile('/Users/Mohit/Documents/Python/webscrape.py', wdir='/Users/Mohit/Documents/Python')

  File ""/anaconda3/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py"", line 705, in runfile
    execfile(filename, namespace)

  File ""/anaconda3/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""/Users/Mohit/Documents/Python/webscrape.py"", line 38, in &lt;module&gt;
    brand = containers.div.div.a[""title""]

TypeError: 'NoneType' object is not subscriptable
</code></pre>

<p>Basically, what I want it to do is grab the brand, product name, and shipping price of all the graphics cards on the page and format them into a CSV. </p>

<p>I think the program can't locate the image or where the data should be imported from. This is my first webscraping project and I was using <code>https://www.youtube.com/watch?v=XQgXKtPSzUI&amp;t=800s</code> as a tutorial </p>
","9428333","7832176","2018-03-03 10:52:45","Webscrape app not finding correct HTML container","<python><beautifulsoup>","1","0","2357"
"49048039","2018-03-01 10:50:38","1","","<p>As <a href=""https://github.com/apple/coremltools/issues/70"" rel=""nofollow noreferrer"">identified by G-mel</a> It appears that this bug happens because the input is length 2. CoreMLtools then assumes your input has shape <code>[Seq, D]</code>. You can get around this buy adding a reshape layer:</p>

<pre><code>inputlayer = Input(shape=(126 * 12,))

model = Reshape((126,12))(inputlayer)
model = BatchNormalization()(model)
model = Conv1D(16, 25, activation='relu')(model)
model = Flatten()(model)
model = Dense(output_size, activation='sigmoid')(model)

model = Model(inputs=inputlayer, outputs=model)
</code></pre>

<p>Your app then has to flatten the input. This is not ideal however because it is not very efficient on the GPU. Hopefully the problem will soon be fixed.</p>
","592235","592235","2018-03-01 14:30:33","2","781","Mike Vella","2011-01-27 13:20:04","4735","960","744","47","47557591","49048039","2017-11-29 16:36:56","0","511","<p>I have keras model like that:</p>

<pre><code>inputlayer = Input(shape=(126,12))

model = BatchNormalization()(inputlayer)
model = Conv1D(16, 25, activation='relu')(model)
model = Flatten()(model)
model = Dense(output_size, activation='sigmoid')(model)

model = Model(inputs=inputlayer, outputs=model)
</code></pre>

<p>Which I convert to <code>coreml</code>:</p>

<pre><code>coreml_model = coremltools.converters.keras.convert(model,
                                                    class_labels=classes)
coreml_model.save('speech_model.mlmodel')
</code></pre>

<p>So, I expect to see <code>MultiArray (Double 126x12)</code>, but I see <code>MultiArray (Double 12)</code></p>

<p><a href=""https://i.stack.imgur.com/AH5rV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AH5rV.png"" alt=""enter image description here""></a></p>

<p>Could you help to say what I'm doing wrong?</p>
","5114112","2097240","2017-11-29 18:55:14","Incorrect input shape in coreml after converting keras model","<python><ios><keras><coreml><coremltools>","1","3","902"
"49048040","2018-03-01 10:50:38","1","","<p>If you really need to protect this key, then you need to treat it as a password.</p>

<p>There are various ways of doing this:</p>

<p><a href=""https://stackoverflow.com/questions/12042724/securely-storing-passwords-for-use-in-python-script"">Securely storing passwords for use in python script</a> has 3 answers:</p>

<ul>
<li>use <code>bcrypt</code></li>
<li>use <code>pbkdf2</code></li>
<li>and some homebrew method</li>
</ul>

<p><a href=""https://stackoverflow.com/questions/7014953/i-need-to-securely-store-a-username-and-password-in-python-what-are-my-options"">I need to securely store a username and password in Python, what are my options?</a> has 7 answers:</p>

<ul>
<li>homebrew RAM only method</li>
<li>use <code>keyring</code></li>
<li>use <code>cryptography</code></li>
<li>use <code>pbkdf2</code></li>
<li>and 3 more homebrew methods</li>
</ul>
","5851593","","","0","862","Edwin van Mierlo","2016-01-28 10:55:47","2089","278","287","27","49046616","","2018-03-01 09:34:28","-3","43","<p>If I was to give a python script to someone to run, they would have to run it with an API key to allow access to the server. Is there any way I can prevent them from seeing the key but still be able to use it.</p>
","9428110","","","How would I securely prevent a user from getting a string in my script?","<python><python-3.x>","1","3","217"
"49048074","2018-03-01 10:51:57","2","","<p>It sounds like you are trying to do what is known as <a href=""https://en.wikipedia.org/wiki/Symbolic_regression"" rel=""nofollow noreferrer"">symbolic regression</a>. This problem is often solved via some variation on genetic algorithms which encode the functional relationships in the genes and then optimise based on a fitness function which includes the prediction error as well as a term which penalises more complicated relationships.</p>

<p>Here are two libraries which solve this problem for you:</p>

<ul>
<li><a href=""http://gplearn.readthedocs.io/en/stable/intro.html#intro"" rel=""nofollow noreferrer"">GPLearn</a></li>
<li><a href=""http://darioizzo.github.io/d-CGP/"" rel=""nofollow noreferrer"">dcgpy</a></li>
</ul>

<p>The following classes provide a rudimentary way of composing functions and keeping track of the number of arguments each one requires, which appears to be the main problem you have:</p>

<pre><code>class Wrapper:
    def __init__(self, f):
        self.f = f
        self.n = f.__code__.co_argcount

    def __call__(self, x):
        return self.f(*x)

    def __add__(self, other):
        return Add(self, other)

    def __mul__(self, other):
        return Mul(self, other)

class Operator:
    def __init__(self, left, right):
        self.left = left
        self.right = right
        self.n = left.n + right.n

class Mul(Operator):
    def __call__(self, x):
        return self.left(x[:self.left.n]) * self.right(x[self.left.n:])

class Add(Operator):
    def __call__(self, x):
        return self.left(x[:self.left.n]) + self.right(x[self.left.n:])
</code></pre>

<p>To use them, you first create wrappers for each of your functions:</p>

<pre><code>w1 = Wrapper(fun1)
w2 = Wrapper(fun2)
w3 = Wrapper(fun3)
</code></pre>

<p>Then you can add and multiply the wrappers to get a new function-like object:</p>

<pre><code>(w1 + w2*w3)([1, 2, 3, 4, 5, 6])
</code></pre>
","1648033","1648033","2018-03-02 04:44:08","2","1906","chthonicdaemon","2012-09-05 05:58:09","13629","968","404","103","49047684","49048074","2018-03-01 10:31:04","2","97","<p>I am facing a challenging issue in order to make my Python3 code more elegant.</p>

<p>Suppose I have a number function with variable number of different inputs, for example something like this:</p>

<pre><code>def fun1(a,b):
    return a+b

def fun2(c,d,e):
    return c*d + e

def fun3(x):
    return x*x
</code></pre>

<p>These functions needs to be agglomerated in a single function that needs to be used as the optimization function of a numerical solver.</p>

<p>However I need to create different combinations of various operations with these functions, like for example multiplying the output of the first two functions and summing by the third.</p>

<p>The manual solution is to create a specific lambda function:</p>

<pre><code>fun = lambda x : fun1(x[0],x[1])*fun2(x[2],x[3],x[4]) + fun3(x[4])
</code></pre>

<p>but the number of functions I have is large and I need to produce all the possibile combinations of them.
I would like to systematically be able to compose these functions and always knowing the mapping from the arguments of higher level function  <code>fun</code> to the lower level arguments of each single function.
In this case I manually specified that <code>x[0]</code> corresponds to the argument <code>a</code> of <code>fun1</code>, <code>x[1]</code> corresponds to argument <code>b</code> of <code>fun1</code> etcetera.</p>

<p>Any idea?</p>
","914693","","","Producing combinations of lambda functions compositions","<python><design-patterns><lambda><functional-programming>","2","1","1378"
"49048080","2018-03-01 10:52:16","2","","<p>Open any file</p>

<pre><code>import os
os.startfile(&lt;filepath&gt;)
</code></pre>
","2110245","","","0","88","Singhak","2013-02-26 07:42:01","5877","330","59","0","16387069","","2013-05-05 17:21:05","7","97023","<p>Im creating a text based labryinth game, but I figured it needed some pictures to illustrate whats going on. For some reason it just dies when I try to go to a2(Where the picture should pop up). I am a beginner so dont judge my code so much ^^</p>

<pre><code>import Image
a1 = (""a1 Go to the start of the Labyrinth"", ""You're at the start of the labyrinth"") #Start
a2 = (""a2 Go Left"", ""You've chosen to go left, unfortunatly it leads to nothing."") #Fail route
a3 = (""a3 Go Right"", ""You've chosen to go right."") #Right route
a4 = (""a4 Go Left"", ""You've chosen to go left"") #Fail route
a5 = (""a5 Go Right"", ""You've chosen to go right"") #Right route
a6 = (""a6 Go Right"", ""You've chosen to go right"") #Fail route; end
a7 = (""a7 Go Left"", ""You've chosen to go left"") #Fail route
a8 = (""a8 Go Left"", ""You've chosen to go left"") #Fail route; end
a9 = (""a9 Go Right"", ""You've chosen to go right"") #Fail route; end
a10 = (""a10 Go Forwards"", ""You've chosen to go forwards"") #Right route
a11 = (""a11 Go left"", ""You've chosen to go left; Congratulations, you won! You may restart"") #Right route; end; victory
fail = (""fail End game"", ""You lost!"") #End game
b1 = (""b1 Go Left"", ""You've chosen to go left"")
b2 = (""b2 Go Right"", ""You've chosen to go right"")
b3 = (""b3 Go Left"", ""You've chosen to go left"")

transitions = {
    a1: (a2, a3),
    a2: (fail, a1),
    a3: (b1,),
    b1: (a4, a5,),
    a4: (b2,),
    b2: (a7, a6,),
    a5: (b3,),
    b3: (a9, a10,),
    a6: (fail, a1),
    a7: (a8,),
    a8: (fail, a1),
    a9: (fail, a1),
    a10: (a11,),
    a11: (a1,)
}

location = a1

while True:
    print location[1]
    print (""Here you can: "")

    for (i, t) in enumerate(transitions[location]):
        print i + 1, t[0]

    choice = int(raw_input(""Choose one ""))
    location = transitions[location][choice - 1]

    if location == a2:
        Image.open(picture.jpg)
        Img.show
</code></pre>
","2352377","10746224","2019-06-11 03:27:25","Open images? Python","<python><image><python-2.7>","3","0","1899"
"49048095","2018-03-01 10:53:21","1","","<p>driver.window_handles returns a list of all opened windows. Just tried switch_to.window() and it raised error because it needs only one name and not a list.</p>

<ol>
<li><p>If jquery generates actual browser window you can switch to the popup window by its name/title if it has one:</p>

<p>driver.switch_to.window(""Alert popup!"")</p></li>
</ol>

<p>In the situation when the current and popup windows have equal titles I use something like this:</p>

<pre><code>current_window = driver.current_window_handle
_handles = driver.window_handles
&lt;popup opening button&gt;.click()
WebDriverWait(driver, timeout).until(
    expected_conditions.new_window_is_opened(_handles))
try:
    #find new window handle
    popup_window = (h for h in
            driver.window_handles if h != current_window).next()
except StopIteration:
    raise Exception(""No popup!"")
</code></pre>

<ol start=""2"">
<li>If jquery generates some popup-styled &lt;div&gt; (not browser window), so you just locate it like any other element on the page with driver.find_element_by_&lt;...></li>
</ol>
","9424384","9424384","2018-03-01 15:36:19","0","1072","Alexey Dolgopolov","2018-02-28 15:24:30","471","35","2","1","49036162","49048095","2018-02-28 18:22:44","0","92","<p>I am trying to click ""OK"" on my localhost for a popup window that is generated with Jquery. I tried switching to the window that didn't work</p>

<pre><code>handleName = driver.window_handles
driver.switch_to.window(handleName)
</code></pre>

<p>then I also tried doing a javascript popup but its a Jquery so it wouldn't work </p>

<pre><code>alert = browser.switch_to_alert()
alert.accept()
browser.close()
</code></pre>

<p>what are my other options?</p>
","7406018","","","Selenium/Python Jquery popup","<javascript><python><jquery><selenium>","1","0","460"
"49048096","2018-03-01 10:53:23","0","","<p>As you don't have enough data to train a deep convolutional network, I suggest you to take a look at this Python/OpenCV tutorial on a very similar dataset to yours (MNIST): <a href=""https://www.learnopencv.com/handwritten-digits-classification-an-opencv-c-python-tutorial/"" rel=""nofollow noreferrer"">https://www.learnopencv.com/handwritten-digits-classification-an-opencv-c-python-tutorial/</a></p>
","9428221","","","0","402","Xun Victor","2018-03-01 09:49:37","1","3","0","0","49002383","","2018-02-27 06:24:01","0","592","<p>I want to write a python code for Persian letter recognition. I have a dataset of  Farsi alphabet that has 15 instances from each class. There are 19 classes.
Actually I don't have much experience in python. I almost know what are the steps theoretically but I dont know the coding.
Fisrt I want to convert images to feature vectors, but I don't know how to do this:/ I've searched a lot but I couldn't find anything useful.</p>

<p>Any help would be highly appreciated.
<a href=""https://i.stack.imgur.com/AESY0.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AESY0.jpg"" alt=""Here is one of the images""></a></p>
","5113137","5113137","2018-03-01 07:34:13","Converting images of alphabet to feature vector","<python><ocr><feature-extraction>","1","2","634"
"49048103","2018-03-01 10:53:46","1","","<p>There are two solutions for now:</p>

<p>One:
Use Python2.7, solved this error for me.</p>

<p>Two:
For python 3</p>

<pre><code>def method_waraper(self, record):
    def filter(self, record):
        if record.args:
            arg = record.args[0]
            if isinstance(arg, suds.transport.Request):
                new_arg = suds.transport.Request(arg.url)
                sanitized_headers = arg.headers.copy()
                if self._AUTHORIZATION_HEADER in sanitized_headers:
                    sanitized_headers[self._AUTHORIZATION_HEADER] = self._REDACTED
                new_arg.headers = sanitized_headers
                msg = arg.message
                if sys.version_info.major &lt; 3:
                    msg = msg.decode('utf-8')
                new_arg.message = self._DEVELOPER_TOKEN_SUB.sub(
                    self._REDACTED, str(msg, encoding='utf-8'))
                record.args = (new_arg,)
    return filter(self, record)
googleads.util._SudsTransportFilter.filter = method_waraper
</code></pre>

<p>This solution changes code provided by google and add utf encoding for the binary string, which solves our problem.</p>
","2783841","2783841","2018-03-05 04:49:44","0","1155","Karioki","2013-09-16 12:04:36","515","145","102","3","49030383","49048103","2018-02-28 13:09:46","2","481","<p>I try to make connection with the <a href=""https://developers.google.com/adwords/api/docs/guides/start"" rel=""nofollow noreferrer"">Google Adwords API</a> using Python 3.6. I managed to install the libraries, got a <code>developer token</code>, <code>client_customer_id</code>, <code>user_agent</code>, <code>client_id</code>, <code>client_secret</code> and requested succesfully a <code>refresh_token</code>.</p>

<p>My googleads.yaml file looks like this:</p>

<pre><code>adwords:
  developer_token: hta...
  client_customer_id: 235-...-....
  user_agent: mycompany
  client_id: 25785...apps.googleusercontent.com
  client_secret: J9Da...
  refresh_token: 1/ckhGH6...
</code></pre>

<p>When running the first python script <code>get_campaigns.py</code>, I get the very generic response <code>TypeError: cannot use a string pattern on a bytes-like object</code> in <code>...\Anaconda3\lib\site-packages\googleads-10.0.0-py3.6.egg\googleads\util.py"", line 302, in filter</code></p>

<p>Other functions like <code>traffic_estimator_service.get(selector)</code> produce the same error. Furthermore, when starting the Python script <code>get_campaigns.py</code>, I get the following warning, which might explains something:</p>

<pre><code>WARNING:googleads.common:Your default encoding, cp1252, is not UTF-8. Please run this script with UTF-8 encoding to avoid errors.
INFO:oauth2client.client:Refreshing access_token
INFO:googleads.common:Request summary - {'methodName': get, 'clientCustomerId': xxx-xxx-xxxx}
</code></pre>

<p>I tried many things, but still can't find what causes my error. My settings seem to be right, and I use the examples as provided <a href=""https://github.com/googleads/googleads-python-lib"" rel=""nofollow noreferrer"">here</a>. Help is highly appreciated!</p>
","2353914","2353914","2018-02-28 13:24:49","Python 3.6 Googleads TypeError: cannot use a string pattern on a bytes-like object","<python><google-adwords>","1","4","1786"
"49048125","2018-03-01 10:55:11","2","","<p>I finally solved it using MultilabelBinarizer, as @VivekKumar suggested: </p>

<pre><code>headings = dct['alcohol'] + dct['tobacco'] + dct['onset']

#print('my headings:'+ str(headings))

l1 = ['Heavy drinking, Low consumption, Former Smoker, Gradual', 'Low consumption, No consumption, Current on-and-off smoker, Sudden', 'Heavy drinking, Current on-and-off smoker']


mlb = MultiLabelBinarizer()  # pass sparse_output=True if you'd like
dataMatrix = mlb.fit_transform(headings.split(', ') for headings in l1)

print(""My Classes: "")
print(mlb.classes_)
print(dataMatrix)
</code></pre>
","4685779","","","0","589","Javiss","2015-03-18 14:34:17","324","79","21","1","49035107","49048125","2018-02-28 17:14:08","0","402","<p>I am pretty new with scikitlearn and right now I am struggling with the preprocessing stage. </p>

<p>I have the following categorical features (I parsed a JSON file and place it in a dictionary) so: </p>

<pre><code>dct['alcohol'] = [""Binge drinking"",
  ""Heavy drinking"",
  ""Moderate consumption"",
  ""Low consumption"",
  ""No consumption""]


dct['tobacco']= [""Current daily smoker - heavy"",
  ""Current daily smoker"",
  ""Current on-and-off smoker"",
  ""Former Smoker"",
  ""Never Smoked"",
  ""Snuff User""]

dct['onset'] = ""Gradual"",
  ""Sudden""]
</code></pre>

<p>My first approach is to convert it first to integers with label enconder and then to the one-hot-coding method: </p>

<pre><code>OH_enc = sklearn.preprocessing.OneHotEncoder(n_values=[len(dct['alcohol']),len(dct['tobacco']),len(dct['onset'])])
le_alc = sklearn.preprocessing.LabelEncoder()
le_tobacco = sklearn.preprocessing.LabelEncoder()
le_onset = sklearn.preprocessing.LabelEncoder()

le_alc.fit(dct['alcohol'])
le_tobacco.fit(dct['tobacco'])
le_onset.fit(dct['onset'])


list_patient = []
list_patient.append(list(le_alc.transform(['Low consumption'])))
list_patient.append(list(le_tobacco.transform(['Former Smoker'])))
list_patient.append(list(le_onset.transform(['Sudden'])))

list1 = []
list1.append(np.array(list_patient).T[0][:])
list1.append([1,2,0])

OH_enc.fit(list1)
print(OH_enc.transform([[4,2,0]]).toarray())
</code></pre>

<p>So eventually if you OHE (4,2,0) you get : </p>

<pre><code>[[0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]]
</code></pre>

<p>Which is what I want since the first 5 columns refers to the ""alcohol"" feature, the 6 next columns refers to tobacco, and the last 2 columns refers to the onset feature. </p>

<p>However, let's assume that one example could have more than one value in one feature. Let's say one example gets ""Binge drinking"" and ""Heavy drinking"" from the alcohol feature. Then, if you OHE ([0,1],2,0) you would get:</p>

<pre><code>[[1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]]
</code></pre>

<p>This last step I do not know how to code it with sklearn.preprocessing.OneHotEncoder. I mean, how can I code 2 values in one feature per example?</p>

<p>I know that there might be a better way to code ""alcohol"", ""tobacco"", and ""onset"" because they are ordinal values (and then each value in each feature correlates to the other value in the same feature. Thus I could just label them and then normalize it.But let's assume those are categorical variables with independent relationship. </p>
","4685779","4685779","2018-02-28 20:17:22","one-hot encoding more than 1 value in each feature categorical data","<python><machine-learning><scikit-learn><data-science><categorical-data>","1","2","2496"
"49048153","2018-03-01 10:56:44","2","","<p>I'll be damned... There is a simple hack to solve that problem:</p>

<pre><code>from docx.oxml.text.paragraph import CT_P
from docx.text.paragraph import Paragraph

def insert_paragraph_before(item, text, style=None):
    """"""
    Return a newly created paragraph, inserted directly before this
    item (Table, etc.).
    """"""
    p = CT_P.add_p_before(item._element)
    p2 = Paragraph(p, item._parent)
    p2.text = text
    p2.style = style
    return p2
</code></pre>

<p>The idea is that the method <code>CT_P.add_p_before</code> is agnostic: it does not really care whether the item is really a paragraph. It will work just as well on a <code>CT_Tbl</code> (table) element.</p>

<p>Basically, this hack consists in using a method written for a sibling class, which happens to work just as well on a instance of this one. </p>
","4334041","4334041","2018-04-17 06:02:38","4","834","fralau","2014-12-07 11:03:45","1062","90","45","2","49025038","","2018-02-28 08:28:22","1","852","<p>In python-docx there is a <a href=""http://python-docx.readthedocs.io/en/latest/api/text.html#paragraph-objects"" rel=""nofollow noreferrer"">Paragraph method</a> for inserting a paragraph before another one:</p>

<pre><code>p2 = p.insert_paragraph_before(""hello"", style='Normal')
</code></pre>

<p>Supposing the case we already have a saved docx document with a table in it, and we want <strong>to insert a paragraph before the table</strong>, e.g. an explanation. It is fairly easy to find tables with:</p>

<pre><code>for table in document.tables:
    ...
</code></pre>

<p>Unfortunately, a <code>Table</code> object does not have an <code>insert_paragraph_before</code> method. How could one implement that?</p>
","4334041","4334041","2018-02-28 09:04:22","python-docx: Inserting a paragraph before a table","<python><python-docx>","1","0","715"
"49048156","2018-03-01 10:56:54","2","","<p>The initial code is partialy correct. You must set browser.download.folderList value as 2 :  </p>

<pre><code>fp = webdriver.FirefoxProfile()
fp.set_preference(""browser.download.folderList"", 2) # 0 means to download to the desktop, 1 means to download to the default ""Downloads"" directory, 2 means to use the directory 
fp.set_preference(""browser.helperApps.alwaysAsk.force"", False) fp.set_preference(""browser.download.manager.showWhenStarting"",False) fp.set_preference(""browser.download.dir"", ""H:\Downloads"") 

binary = FirefoxBinary(r'C:\Program Files (x86)\Mozilla Firefox\Firefox.exe')

firefox_capabilities = DesiredCapabilities.FIREFOX
firefox_capabilities['marionette'] = True

driver = webdriver.Firefox(capabilities=firefox_capabilities,firefox_binary=binary, firefox_profile = fp)
</code></pre>
","9428531","1993001","2018-03-01 11:37:47","1","808","Rony Rozas","2018-03-01 10:56:42","21","0","0","0","41644381","41683377","2017-01-13 22:23:32","8","16592","<p>I use Selenium Marrionette and GeckoDriver to pull web data. I use the following to set my Firefox profile preferences:</p>

<pre><code>fp = webdriver.FirefoxProfile()
fp.set_preference(""browser.download.folderList"", 1)
fp.set_preference(""browser.helperApps.alwaysAsk.force"", False)
fp.set_preference(""browser.download.manager.showWhenStarting"",False)
fp.set_preference(""browser.download.dir"", ""H:\Downloads"")
fp.set_preference(""browser.download.downloadDir"",""H:\Downloads"")
fp.set_preference(""browser.download.defaultFolder"",""H:\Downloads"")

binary = FirefoxBinary(r'C:\Program Files (x86)\Mozilla Firefox\Firefox.exe')

firefox_capabilities = DesiredCapabilities.FIREFOX
firefox_capabilities['marionette'] = True

driver = webdriver.Firefox(capabilities=firefox_capabilities, firefox_binary=binary, firefox_profile = fp)
</code></pre>

<p>From what I understand after reading <a href=""https://github.com/mozilla/geckodriver/issues/236"" rel=""nofollow noreferrer"">Unable to set firefox profile preferences</a> and <a href=""https://github.com/SeleniumHQ/selenium/issues/2572"" rel=""nofollow noreferrer"">FirefoxProfile passed to FirefoxDriver</a>, it seems that nothing is being done when using <code>firefox_profile</code> now. So I need to implement the new updates to <code>firefox_capabilities</code>, but I'm not sure how to exactly do that. Any ideas?</p>
","3737798","1621041","2019-01-03 15:12:30","Python Set Firefox Preferences for Selenium--Download Location","<python><selenium><web-scraping><geckodriver><firefox-marionette>","4","0","1362"
"49048185","2018-03-01 10:58:48","0","","<p>Have you tried to look at the satellite image recognition Kaggle competitions? There are a lot of discussions as well as available scripts for tasks similar to yours:
Links: <a href=""https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection"" rel=""nofollow noreferrer"">https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection</a>
Example script: <a href=""https://www.kaggle.com/arpandhatt/satellite-image-classification"" rel=""nofollow noreferrer"">https://www.kaggle.com/arpandhatt/satellite-image-classification</a></p>
","9428221","","","0","539","Xun Victor","2018-03-01 09:49:37","1","3","0","0","48848031","","2018-02-18 02:58:25","-1","70","<p>I am building a app to see the progress of deforestation. Over time i would like to take a satellite image from a location and see what percentage of that image contains forest.</p>

<p>I have attempted google's vision API, it does not have this functionality.</p>

<p>Is this something that can be done in OpenCV or must I do this from scratch with semantic segmentation or something similar?</p>
","4313927","","","Computer Vision: How to obtain what percentage of image contains a specific texture?","<python><computer-vision><google-cloud-platform><vision>","2","0","401"
"49048223","2018-03-01 11:01:03","3","","<p>First calculate frame per second like this</p>

<pre><code>fps = cap.get(cv2.cv.CV_CAP_PROP_FPS)
</code></pre>

<p>Then duration can be calculated as (number of frames) / (frames per second)</p>

<pre><code> duration = float(num_frames) / float(fps) # in seconds
</code></pre>
","5825953","","","1","280","Mitiku","2016-01-22 11:13:29","2958","310","37","6","49048111","49048421","2018-03-01 10:54:35","11","11599","<p>I can only get the number of frames <code>CAP_PROP_FRAME_COUNT</code> using CV2.</p>

<p>However, I cannot find the parameter to get the duration of the video using cv2. </p>

<p>How to do that? </p>

<p>Thank you very much.</p>
","7819796","","","How to get the duration of video using cv2","<python><video><cv2>","3","1","232"
"49048252","2018-03-01 11:02:30","0","","<pre><code>bigArr = [[1,2],[1,3],[1,4],[1,5],[5,6],[5,7],[5,8],[9,10],[9,11],[9,12],[9,13]] ## Your list of pairs of values
molArr = []
for pair in bigArr:
    flag = False
    for molecule in molArr:
        if pair[0] in molecule or pair[1] in molecule: ## Add both values if any of them are in the molecules list
            molecule.append(pair[0])
            molecule.append(pair[1])
            flag = True ## The values have been added to an existing list

    if not flag: ## The values weren't in an existing list so add them both
        molArr.append(pair)

i = 0
for i in range(len(molArr)): ## Remove duplicates in one loop
    molArr[i] = list(set(molArr[i]))
</code></pre>
","7908770","7908770","2018-03-01 11:09:51","0","689","Adi219","2017-04-23 09:50:18","3109","540","642","43","49048044","","2018-03-01 10:50:47","1","62","<p>I have a number of pairs of values (pairs of bonded atoms) for a file containing different molecules. If two pairs have a common member, it means that they are part of the same molecule. I am trying to find an efficient way in python to group the atoms depending on which molecule they belong to.</p>

<p><strong>As an example, ethane and methane would be:</strong></p>

<p><code>1,5</code> and <code>9</code> would be carbon, the rest hydrogen</p>

<pre><code>[[1,2],[1,3],[1,4],[1,5],[5,6],[5,7],[5,8],[9,10],[9,11],[9,12],[9,13]]
</code></pre>

<p>And I would like to get a list/array in which I have:</p>

<pre><code>[[1,2,3,4,5,6,7,8],[9,10,11,12,13]]
</code></pre>

<p>I have tried several things but they are really ineficient for files with a large number of atoms. There should be a smart way of doing it but I can't find it. Any ideas?</p>

<p>Thanks,
Joan</p>
","3091644","8572897","2018-03-01 11:37:35","How to combine arrays only if they have a common value?","<python>","3","2","874"
"49048310","2018-03-01 11:05:06","1","","<p>I think you misunderstood 3D cuboid. In 3D, you need to have three inputs, not 2 inputs. The corrected code is the following:</p>

<pre><code>import math

dimension = input(""What dimension: "")

if dimension == (""3D"") or dimension == (""3d"") or dimension == (""3""):
    a = int(input(""a = ""))
    b = int(input(""b = ""))
    c = int(input(""c = ""))

    z = math.sqrt(a**2 + b**2 + c**2) 
    rounded_z = round(z, 4)

    print(rounded_z,'cm')
else:
    a = int(input(""a = ""))
    b = int(input(""b = ""))

    c = (math.sqrt((a**2) + (b**2)))
    rounded_c = round(c, 2)

    print(rounded_c,'cm')
</code></pre>

<p>Test it based on your Source:
a=2, b=3, c=6 produce 7 as you expect.</p>
","8208481","","","0","686","Kardi Teknomo","2017-06-24 08:05:23","570","78","197","6","49047909","49048310","2018-03-01 10:43:21","-2","71","<p>So I want to calculate the distance from the two furthest points in a cuboid. The mathematical equation for this is z^2 = a^2 + b^2 + c^2 but when I do that it doesn't return correctly. </p>

<pre><code>from math import *

dimension = input(""What dimension: "")

if dimension == (""3D"") or dimension == (""3d"") or dimension == (""3""):
    a = int(input(""a = ""))
    b = int(input(""b = ""))
    c = (sqrt((a**2) + (b**2)))

    z = (sqrt((a**2) + (b**2) + (c))) 
    rounded_z = round(z, 4)

    print(rounded_z,'cm')
else:
    a = int(input(""a = ""))
    b = int(input(""b = ""))

    c = (sqrt((a**2) + (b**2)))
    rounded_c = round(c, 2)

    print(rounded_c,'cm')
</code></pre>

<p>For example:</p>

<p>if a = 6</p>

<p>and b = 2</p>

<p>It should be 7 cm <a href=""http://www.bbc.co.uk/schools/gcsebitesize/maths/geometry/pythagoras3drev1.shtml"" rel=""nofollow noreferrer"">Source</a>. But it returns 6.8062!! Why? please help.</p>
","8573441","","","3D Pythagoras program not returning correct results","<python><math><algebra><pythagorean>","2","3","929"
"49048338","2018-03-01 11:07:04","0","","<p>Don't know what you exactly want but if you want to loop over the image files in that directory and print their path, you can simply do something like this:</p>

<pre><code>import os

image_directory = ""C:\Users\siva\Downloads\ASL-Finger-Spelling-Recognition-master\asl_dataset\""
image_list = os.listdir(image_directory)

# Loop over images in directory
for image_name in image_list:
    image_path = os.path.join(image_directory, image_name)
    print image_path
</code></pre>
","9428221","","","0","481","Xun Victor","2018-03-01 09:49:37","1","3","0","0","48971762","","2018-02-25 08:42:41","-5","119","<pre><code>C:\Users\siva\Downloads\ASL-Finger-Spelling-Recognition-master\asl_dataset\1
</code></pre>

<p>like the above path there will be several images 0-9 and a-z hence there are 36 classes. In the above path the last one indicates the number 1. In the below program i have to find that one by traversing it  but it ended up with </p>

<blockquote>
  <p>ASL-Finger-Spelling-Recognition-master producing a key error  at  y_train.append(classes[fullpath[n + 1:t]])
  because classes[ASL-Finger-Spelling-Recognition-master] does not exists.
      def load_data_set():
      for path in paths:
          for root, directories, filenames in os.walk(path):
              for filename in filenames:
                  if filename.endswith("".jpeg""):
                      fullpath = os.path.join(root, filename)
                      img = load_img(fullpath)
                      img = img_to_array(img)
                      print fullpath
                      x_train.append(img)
                      t = fullpath.rindex(""/"")
                      fullpath = fullpath[0:t]
                      n = fullpath.rindex(""/"")
                      #print fullpath[n + 1:t]
                      y_train.append(classes[fullpath[n + 1:t]])</p>
</blockquote>
","7646545","5094664","2018-02-25 12:16:50","finding the complete path of an image","<python>","1","2","1250"
"49048342","2018-03-01 11:07:19","0","","<p>Try uncomment <code>dbms.connectors.default_listen_address=0.0.0.0</code> And check this </p>

<pre><code># Bolt connector
dbms.connector.bolt.enabled=true
dbms.connector.bolt.tls_level=OPTIONAL
dbms.connector.bolt.listen_address=:7687
# HTTP Connector. There must be exactly one HTTP connector.
dbms.connector.http.enabled=true
dbms.connector.http.listen_address=:7474    
# HTTPS Connector. There can be zero or one HTTPS connectors.
dbms.connector.https.enabled=true
dbms.connector.https.listen_address=:7473
</code></pre>
","9233431","","","3","529","Miosotaa","2018-01-18 07:03:38","21","41","130","0","49038781","","2018-02-28 21:22:24","1","650","<p>I am trying to connect to my Neo4j graph database server from a new machine.  I can successfully connect from an older machine but do not wish to use the older one anymore. </p>

<p>I have reduced the problem to a simple script that returns an exception:</p>

<pre><code>from neo4j.v1 import GraphDatabase, basic_auth

auth = basic_auth(""username"",""password"")
session = GraphDatabase.driver(""bolt://remote.server:7687"",auth=auth).session()

statement = """"""MATCH (a:Protein)
WHERE a.name={name}
RETURN a.Accession""""""

tx = session.begin_transaction()
record = tx.run(statement,{'name':""ARCH_HUMAN""}).single()
print record['a.Accession']

session.close()
</code></pre>

<p>And the error message is:</p>

<pre><code>File ""Test.py"", line 10, in &lt;module&gt;
    tx = session.begin_transaction()
File ""/home/username/anaconda2/lib/python2.7/site-packages/neo4j/v1/api.py"", line 432, in begin_transaction
    self._connect()
  File ""/home/username/anaconda2/lib/python2.7/site-packages/neo4j/v1/api.py"", line 269, in _connect
self._connection = self._acquirer(access_mode)
  File ""/home/username/anaconda2/lib/python2.7/site-packages/neo4j/v1/direct.py"", line 52, in acquire
raise ServiceUnavailable(""Cannot acquire connection to {!r}"".format(self.address))
neo4j.exceptions.ServiceUnavailable: Cannot acquire connection to Address(host='remote.server', port=7687)
</code></pre>

<p>Port 7687 is open (confirmed via <code>netstat -tulpn</code> and <code>iptables -L</code>), and neo4j is configured to listen to 0.0.0.0:7687. In addition, <code>.neo4j/known_hosts</code> contains an entry for host 0.0.0.0</p>

<p>What's strange is that I get a different error message (neo4j.exceptions.AuthError) if I break the authentication by using an incorrect password. So the connection <em>is</em> being made to check the password, but still I cannot connect with the correct auth.  </p>

<p>What's going on?</p>
","3727550","3727550","2018-02-28 21:27:37","Cannot acquire connection to Neo4j database","<python><neo4j>","2","3","1904"
"49048384","2018-03-01 11:09:40","0","","<p>Take C as third array. Store every value of A in C. 
like </p>

<p><code>C[0] &lt;- value of A at current time</code></p>

<p>after your interval</p>

<p><code>C[1] &lt;- value of A at current time</code></p>

<p>after your interval</p>

<p><code>C[2] &lt;- value of A at current time</code></p>

<p>In general, add loop that iterates after your specific time and store current value of A at each iteration.</p>

<pre><code> int indexCounter = 0;
 for(i=1; i&lt;=10; i++){
    C[indexCounter] &lt;- A   # A denotes current value of your A variable. 
    indexCounter++
    sleep(1000)     # assuming your A variable refreshes every 1000 miliseconds.
 }
</code></pre>

<p>Now you have array C which have set of values. Do minimum value calculation on all items of C.
PS. I am not good at python. This is just logic to match your requirement.</p>
","3591690","","","0","848","Savan S","2014-05-01 04:36:05","257","76","41","0","49044595","49048384","2018-03-01 07:25:18","-1","33","<p>Using Python 3.x, I have two variables <code>a</code> and <code>b</code> in the code below.<br>
<code>a</code> is a <em>dictionary</em> and  <code>b</code> stores the <code>""last_price""</code> key's value from <code>a</code>.</p>

<p>My problem is that <code>a</code> changes with time, and so does the value of ""b"".  </p>

<p>I need to store each and every value of <code>b</code> in some variables and at any moment in time, I want to get the immediate lower value than the highest value from those all values. </p>

<p>Please help me.</p>

<pre><code>a=    {
  'status': 'success',
  'data': {
    'last_price': 1160.15,
    'volume': 2007611,
    'sell_quantity': 368654,
    'open_interest': 0,
    'last_quantity': 3,
    'change': -12.45,
    'ohlc': {
      'high': 1169.6,
      'close': 1172.6,
      'open': 1169.6,
      'low': 1156.05
    },
    'last_time': '2018-03-01 12:43:16',
    'change_percent': -1.06,
    'depth': {
      'sell': [
        {
          'price': 1160.15,
          'orders': 2,
          'quantity': 2
        },
        {
          'price': 1160.2,
          'orders': 1,
          'quantity': 1
        },
        {
          'price': 1160.25,
          'orders': 1,
          'quantity': 1
        },
        {
          'price': 1160.6,
          'orders': 1,
          'quantity': 10
        },
        {
          'price': 1160.65,
          'orders': 1,
          'quantity': 200
        }
      ],
      'buy': [
        {
          'price': 1160,
          'orders': 8,
          'quantity': 352
        },
        {
          'price': 1159.9,
          'orders': 1,
          'quantity': 1
        },
        {
          'price': 1159.85,
          'orders': 3,
          'quantity': 5
        },
        {
          'price': 1159.8,
          'orders': 2,
          'quantity': 335
        },
        {
          'price': 1159.75,
          'orders': 3,
          'quantity': 644
        }
      ]
    },
    'buy_quantity': 255199
  }
} 

b=a[""data""][""last_price""]
</code></pre>
","9337404","364696","2018-03-01 11:16:26","store value of variables whose value changes with time","<python><python-3.x>","1","0","2032"
"49048385","2018-03-01 11:09:43","0","","<p>Focusing on your specific question (and ignoring some issues in your posted code), you can achieve what you want by simply splitting the input strings and maintaining frequency counts for those split tokens.</p>

<p>For example, using <a href=""https://docs.python.org/2/library/collections.html#collections.Counter"" rel=""nofollow noreferrer""><code>Counter</code></a>:</p>



<pre><code>from collections import Counter

data = [""i am donald trump"",""i am donald duck""]
c = Counter()
for seq in data:
    c += Counter(seq.split(' '))

print c  # Counter({'i': 2, 'donald': 2, 'am': 2, 'trump': 1, 'duck': 1})
</code></pre>

<p>p.s. And then you probably won't be interested in the <a href=""https://docs.python.org/2/library/collections.html#collections.Counter.most_common"" rel=""nofollow noreferrer""><code>most_common</code></a> values, but in those that surpassed a certain threshold, like:</p>

<pre><code>print {(k,v) for k,v in c.iteritems() if v &gt;= 2}  # {('am', 2), ('donald', 2), ('i', 2)}
</code></pre>
","3605610","","","3","1014","Yaniv","2014-05-05 19:29:04","394","23","1","1","49048059","","2018-03-01 10:51:23","0","42","<p>I have implemented Apriori to find the repeating sequence of letters but what i want to do is find the repeating words. My output gives me all the letters count. But, i want the word count;</p>

<p>i/p
    data = [""i am donald trump"",""i am donald duck""]</p>

<p>o/p
    --> {'d ': 3, ' d': 3, 'on': 3, 'ld': 3, 'am': 3, 'do': 3, 'al': 3, 'na'} </p>

<p>-->what i wanted ->
 i: 2</p>

<p>am: 2</p>

<p>trump: 2</p>

<p>donald: 3</p>

<p>i am: 2</p>

<p>am donald: 2</p>

<p>donald trump: 1</p>

<p>i am donald: 2</p>

<pre><code>import re
import unittest
from collections import defaultdict
import itertools

class Apriori(dict):

    def __init__(self, listOfSequences, support):

        Args:
            listOfSequences (list): A list of strings, each letter representing a specific event.
            support (int): The minimum percentage of sequences a pattern must match.
        """"""

        super(Apriori, self).__init__()
        self.data = listOfSequences
        self.thres = (support * len(self.data)) / 100.0
        self.primitives = self.getPrimitives()
        self.apriori()
        del self.data

    def apriori(self):
        candidates = self.getNewCandidates(self.primitives)
        while len(candidates) &gt; 0:
            res = self.getPatternsCount(candidates)
            self.update(res)
            candidates = self.getNewCandidates(res.keys())

    def getPrimitives(self):
        primitives = set()
        for seq in self.data:
            for event in seq:
                primitives.add(event)
        return primitives

    def getNewCandidates(self, candidates):
        newCandidates = set()
        for seq in self.data:
            for can in candidates:
                for subs in re.findall(can + ""."", seq):
                    newCandidates.add(subs)
        return newCandidates

    def getPatternsCount(self, candidates):
        patternsCount = defaultdict(int)
        for seq in self.data:
            for can in candidates:
                if can in seq:
                    patternsCount[can] += 1
        return {k: v for k, v in patternsCount.items() if v &gt; self.thres}


    if __name__ == '__main__':
        pass
</code></pre>

<p>Run:</p>

<pre><code>import csv
from ne import *

#print(t)
data = [""i am donald trump"",""i am donald duck""]
#print(data.type())

patterns= Apriori(data,15)

print(patterns)
</code></pre>
","9371612","9371612","2018-03-01 12:12:34","Word sequence using apriori","<python><apriori>","1","0","2384"
"49048405","2018-03-01 11:10:45","0","","<p>Here's another approach:</p>

<pre><code>a = [[1,2],[1,3],[1,4],[1,5],[5,6],[5,7],[5,8],[9,10],[9,11],[9,12],[9,13]]

result = []

for sub in a:
    join = False
    for i, r in enumerate(result):
        if any([x in r for x in sub]):
            join = True
            index = i
    if join:
        result[index] += [y for y in sub if y not in result[index]]
    else:
        result.append(sub)

result
#[[1,2,3,4,5,6,7,8],[9,10,11,12,13]]
</code></pre>
","5811078","","","0","462","zipa","2016-01-19 14:52:58","19592","990","923","278","49048044","","2018-03-01 10:50:47","1","62","<p>I have a number of pairs of values (pairs of bonded atoms) for a file containing different molecules. If two pairs have a common member, it means that they are part of the same molecule. I am trying to find an efficient way in python to group the atoms depending on which molecule they belong to.</p>

<p><strong>As an example, ethane and methane would be:</strong></p>

<p><code>1,5</code> and <code>9</code> would be carbon, the rest hydrogen</p>

<pre><code>[[1,2],[1,3],[1,4],[1,5],[5,6],[5,7],[5,8],[9,10],[9,11],[9,12],[9,13]]
</code></pre>

<p>And I would like to get a list/array in which I have:</p>

<pre><code>[[1,2,3,4,5,6,7,8],[9,10,11,12,13]]
</code></pre>

<p>I have tried several things but they are really ineficient for files with a large number of atoms. There should be a smart way of doing it but I can't find it. Any ideas?</p>

<p>Thanks,
Joan</p>
","3091644","8572897","2018-03-01 11:37:35","How to combine arrays only if they have a common value?","<python>","3","2","874"
"49048421","2018-03-01 11:11:37","14","","<p><code>cv2</code> is not designed to explore video metadata, so <a href=""https://docs.opencv.org/3.4.1/d8/dfe/classcv_1_1VideoCapture.html"" rel=""noreferrer""><code>VideoCapture</code></a> doesn't have API to retrieve it directly.</p>

<p>You can instead ""measure"" the length of the stream: seek to the end, then get the timestamp:</p>

<pre><code>&gt;&gt;&gt; v=cv2.VideoCapture('sample.avi')
&gt;&gt;&gt; v.set(cv2.CAP_PROP_POS_AVI_RATIO,1)
True
&gt;&gt;&gt; v.get(cv2.CAP_PROP_POS_MSEC)
213400.0
</code></pre>

<p>Checking shows that this sets the point after the last frame (not before it), so the timestamp is indeed the exact total length of the stream:</p>

<pre><code>&gt;&gt;&gt; v.get(cv2.CAP_PROP_POS_FRAMES)
5335.0
&gt;&gt;&gt;&gt; v.get(cv2.CAP_PROP_FRAME_COUNT)
5335.0

&gt;&gt;&gt; v.set(cv2.CAP_PROP_POS_AVI_RATIO,0)
&gt;&gt;&gt; v.get(cv2.CAP_PROP_POS_FRAMES)
0.0        # the 1st frame is frame 0, not 1, so ""5335"" means after the last frame
</code></pre>
","648265","648265","2018-03-01 11:29:21","0","974","ivan_pozdeev","2011-03-07 14:00:35","22423","3704","2164","1285","49048111","49048421","2018-03-01 10:54:35","11","11599","<p>I can only get the number of frames <code>CAP_PROP_FRAME_COUNT</code> using CV2.</p>

<p>However, I cannot find the parameter to get the duration of the video using cv2. </p>

<p>How to do that? </p>

<p>Thank you very much.</p>
","7819796","","","How to get the duration of video using cv2","<python><video><cv2>","3","1","232"
"49048441","2018-03-01 11:12:31","1","","<p>This is somewhat system dependent, so it would help if you mentioned your target platform(s).</p>

<p>Because PyQt5 is just a wrapper around Qt5, I think <a href=""https://doc.qt.io/qt-5/highdpi.html"" rel=""nofollow noreferrer"">High DPI Displays</a> from the Qt manual applies. Citing the relevant bit (but you should read the whole thing):</p>

<blockquote>
  <p>In order to get an application designed for low DPI values running on a high resolution monitors quickly, consider one of the scaling options (let the application run as DPI Unaware on Windows or set the environment variable QT_AUTO_SCREEN_SCALE_FACTOR to ""1"". These options may incur some scaling or painting artifacts, though.</p>
  
  <p>In the longer term, the application should be adapted to run unmodified:</p>
  
  <ul>
  <li>Always use the qreal versions of the QPainter drawing API.</li>
  <li>Size windows and dialogs in relation to the screen size.</li>
  <li>Replace hard-coded sizes in layouts and drawing code by values calculated from font metrics or screen size.</li>
  </ul>
</blockquote>

<p>In a shell, you would do something like:</p>

<pre><code>$ export QT_AUTO_SCREEN_SCALE_FACTOR=1
$ python my_application.py
</code></pre>
","14637","","","6","1213","Thomas","2008-09-17 01:40:17","121324","9675","2713","229","49048294","49048441","2018-03-01 11:04:30","1","536","<p>I am using PyQt5 and Python 3.6.4 to design a ui for a program. It was made on a 720p monitor however now using the same code on a 4k monitor, everything is tiny apart from the text. How would I go about resizing the whole app to look the same on all monitors: (720p, 1080p, 4k, etc.)
The program is to be run on windows through an executable created through compiling the python code.
Cheers</p>
","8587804","8587804","2018-03-01 11:15:47","PyQt5 Resize app for different displays","<python><resize><pyqt5><qapplication>","2","0","400"
"49048453","2018-03-01 11:13:19","1","","<p>This might help</p>

<pre><code>path = '/mypath'

for filename in glob.glob(os.path.join(path, '*.txt')):
    with open(filename) as infp:
        data = infp.read()    #Just Read the content
        searchlist = [""term1"", ""term2"", ""term3""]
        for i in searchlist:
            if i in data:  #Check if search term in content. 
                print('found')
            else: 
                print('not found')
</code></pre>
","532312","","","0","434","Rakesh","2010-12-06 13:07:54","56694","5302","758","1508","49047902","49048453","2018-03-01 10:42:51","0","23","<p>I am having problems with my script. I want to find some terms in different files, defined in a searchlist. However - it won't find those terms, even if they are definitely included in those files. I checked it.</p>

<p>Am I missing something?</p>

<pre class=""lang-html prettyprint-override""><code>path = '/mypath'

for filename in glob.glob(os.path.join(path, '*.txt')):
    with open(filename) as infp:
        mylist = infp.read().splitlines() 
        for word in mylist:
            searchlist = [""term1"", ""term2"", ""term3""]
            for i in searchlist:
                if i in word:
                    print ('found')
                else: 
                    print ('not found')
</code></pre>


","8359429","","","Search for terms in file","<python><file><search>","1","2","711"
"49048455","2018-03-01 11:13:28","0","","<p>eventually I was able to solve the issue. The issue was due to a problem inside the data frame. I open the orginial csv file and manually I clean the problematic rows. Then I re-import the new file and I was able to carry out the join.
Regards,
Andrea</p>
","9067215","","","1","259","user9067215","2017-12-07 11:57:07","1","1","0","0","47695075","","2017-12-07 12:22:07","0","109","<p>I am brand new within the community, so I hope you pay patience a little bit.
I am trying to merge two datasets by using an inner join on the fields ""Postal Code"" and ""Date"".
The orgininal code would be like this:</p>

<pre><code>Datapump = pd.merge(hack, health, how='inner', left_on=['Date', 'CP'], right_on=['Creation', 'cp'])
</code></pre>

<p>But the point is that I get an empty dataset whenever I tried to perform an head and worst an error in case to perform a sample:
So I have put as indexes the field 'Date' for hack and the field 'Creation' for health. Then I go for the join.</p>

<pre><code>Datapump = pd.merge(hack, health, how='inner', left_index=True, right_index=True)
</code></pre>

<p>Unfortunately I need as well the field postal code. So I do another join at the following point
<code>Datapump = pd.merge(hack, health, how='inner', left_on=['CP'], right_on=['cp'])</code></p>

<p>Now I can get the sample and the head, but anything is going weird according to me, especially once I see the number of entries of the new dataset:</p>

<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
</code></pre>

<p>Int64Index: 803206 entries, 0 to 803205
Data columns (total 15 columns):
CP                   803206 non-null object
Tipo Contaminante    803206 non-null int64
Valor                803206 non-null float64
Verified             803206 non-null object
nombre               803206 non-null object
edad                 801296 non-null object
cp                   803206 non-null object
patologia            802387 non-null object
created              803206 non-null datetime64[ns]
Edad_Cat             786829 non-null category
Duration             772661 non-null timedelta64[ns]
Duration_Seconds     772661 non-null float64
weekdays_created     803206 non-null int64
month                803206 non-null float64
cat_month            803206 non-null int64
dtypes: category(1), datetime64ns, float64(3), int64(3), object(6), timedelta64ns
memory usage: 92.7+ MB</p>

<p>Actually before health had roughly 9000 entries and hack roughly 6000 entries.
It cannot be that I get a dataset of 803.206 entries, by performing an inner join.</p>

<p>How can I do this inner join in a way that it can provide a meaningful and reasonable result?</p>

<p>Thank a lot for the patience.</p>

<p>Andrea</p>
","9067215","","","Python Merge Pandas Datasets via inner join with two fields","<python><join><inner-join>","1","1","2317"
"49048500","2018-03-01 11:15:33","1","","<p>You could try this</p>

<pre><code>INSTALLED_APPS = [
    .
    'app',

if not DEBUG:
    # Add the package into installed app only if debug is false otherwise use installed apps without package `storages`.
    INSTALLED_APPS += ('storages', )
</code></pre>
","6699447","6699447","2018-03-01 11:21:14","0","261","Abdul Niyas P M","2016-08-10 09:05:34","2281","443","435","117","49048357","49048500","2018-03-01 11:08:16","0","48","<p>If <code>DEBUG=True</code>, I want to exclude the package <code>storages</code>. How would I do this?</p>

<p>my settings.py:</p>

<pre><code>if DEBUG:
    storages = ''

INSTALLED_APPS = [
    ...
    'app',
    storages,
    ...
]
</code></pre>
","6733153","612124","2018-03-01 11:18:23","Exclude a package if DEBUG=True","<python><django>","2","0","250"
"49048501","2018-03-01 11:15:34","0","","<p>If <code>c</code> is a <code>global</code> variable, and <code>g()</code> is making the same <code>c</code> to be the value of <code>5</code>, meaning that this is <code>unspecified behaviour</code>.</p>

<p>Note, Python interpreters evaluate expressions from left to right, meaning that the <code>c</code> would be 5 when it's added to <code>f() + g()</code>.</p>
","7908770","7908770","2018-03-01 12:18:21","9","368","Adi219","2017-04-23 09:50:18","3109","540","642","43","49048370","49049400","2018-03-01 11:09:02","4","527","<p>In <strong>C</strong> or <strong>C++</strong> I know that there is something called </p>

<blockquote>
  <p>undefined behaviour</p>
</blockquote>

<p>In expression evaluation when some of the the expressions have side-effects. let's say I want to calculate the following:</p>

<pre><code>c = 10
f() + g() + c
</code></pre>

<p>but at some point g makes c = 5.(c is a glob variable)</p>

<p>What would be the behavior in python? Would it be undefined as <strong>C</strong>?</p>
","9004008","667266","2018-03-01 12:06:08","Undefined Behaviour in Python","<python><c++><c>","3","9","480"
"49048510","2018-03-01 11:15:53","1","","<p>It seems to me that you want to <code>print</code> your df without the index column.</p>

<p>To do so use:</p>

<pre><code>print testdf.to_string(index=False)
</code></pre>
","5811078","","","0","176","zipa","2016-01-19 14:52:58","19592","990","923","278","49048189","49048510","2018-03-01 10:58:56","0","52","<p>Using groupby I stucked at the moment to print my testdf without the indexes.</p>

<p>Is there any option to avoid indexes when storing testdf?</p>

<pre><code>g = df2.groupby('genome')['accession'].apply(list).reset_index()

testdf = g.join(pd.get_dummies(g['accession'].apply(pd.Series).stack()).sum(level=0)).drop('accession', 1)

print testdf

             genome  VFG000475  VFG000477  VFG000478  VFG000670  VFG000926
0   GCA_000367685.2          0          1          1          0          0   
1   GCF_000026185.1          0          1          1          0          0   
2   GCF_000026985.1          0          0          0          0          0 
</code></pre>

<p>Because to save it as .csv doing testdf.to_csv it works: </p>

<pre><code>testdf.to_csv(outName, sep='\t', header=True, index=False)
</code></pre>

<p>And it is saved without indexes:</p>

<pre><code>         genome VFG000475   VFG000477
GCA_000367685.2     0           1
GCF_000026185.1     0           1
</code></pre>
","5775504","","","Store or print df.groupby without index","<python><matrix><pandas-groupby>","1","0","996"
"49048514","2018-03-01 11:16:06","1","","<p>From the <a href=""http://docs.cython.org/en/latest/src/userguide/language_basics.html"" rel=""nofollow noreferrer"">Cython docs</a>:</p>

<blockquote>
  <p>Note that Cython uses array access for pointer dereferencing, as <code>*x</code> is not valid Python syntax, whereas <code>x[0]</code> is.</p>
</blockquote>

<p>So this should work:</p>

<pre><code>cdef myFunc(int n, int *nnz):
    for i in range(0, n):
        nnz[0] += n
</code></pre>

<p>Not sure what you're trying to achieve by adding <code>n</code> to the pointed-to value <code>n</code> times; why not simply add <code>n*n</code> to it once?</p>
","14637","","","0","610","Thomas","2008-09-17 01:40:17","121324","9675","2713","229","49048239","49048514","2018-03-01 11:01:52","0","29","<p>Say I have a simple function that takes as input a pointer to an integer. How do I change the originating integer value?</p>

<p>My idea was as follows:</p>

<pre><code>cdef myFunc(int n, int *nnz):

    nnz_int = &lt;uintptr_t&gt;nnz
    nnz_int = 0
    for i in range(0, n):
        nnz_int += n
</code></pre>

<p>but upon reflection, I think I only initially cast the value of <em>nnz</em> onto nnz_int, and then change nnz_int, without changing the original nnz. How do I achieve that?</p>
","1082349","","","Cython: Change integer with reference","<python><cython>","1","0","497"
"49048522","2018-03-01 11:16:33","0","","<p>I have written a code and it works exactly how I wanted.please check</p>

<pre><code>def reverse(word):
    x = ''
    for i in range(len(word)):
        x += word[len(word)-1-i]
        return x

word = input('give me a word:\n')
x = reverse(word)
if x == word:
    print('This is a Palindrome')
else:
    print('This is NOT a Palindrome')
</code></pre>
","7738644","","","0","358","Madhusudhan R","2017-03-20 08:20:13","179","48","21","0","29446433","29446524","2015-04-04 12:30:48","1","1609","<p>Is the code below code good for checking whether a string is palindrome or not?
What is its time complexity? I guess it's, <code>O(1)</code> am I right? Because we are just accessing the same string with different indexes and so accessing index <code>O(1)</code> is an operation. Please correct me if I'm wrong. Please provide a better solution, if possible.</p>

<pre><code>s1 = 'abccba'
s2 = s1[::-1]
if s1==s2:
    print 'Palindrome'
else:
    print 'Not Palindrome'
</code></pre>
","3713695","2406269","2015-04-04 12:59:36","Reversing a string and palindrom time complexity in Python","<python><string><list><palindrome>","3","2","487"
"49048557","2018-03-01 11:18:08","0","","<p>Thanks to @Pop I managed to find a solution.<br>
First, I declared a generic options method:</p>

<pre class=""lang-py prettyprint-override""><code>class DescriptiveMethodView(views.MethodView):
    name = description = uri = doc_uri = None

    def options(self, id=None):
        """"""Base Options View.
        ---
        description: retrieve options available for this resource.
        responses:
            200:
                name: description
                type: object
        """"""
        d = spec.to_dict()

        info = {'name': self.name,
                'description': self.description % {'id': id or 'model'}}

        return jsonify(info=info,
                       definitions=d['definitions'],
                       actions=d['paths'][self.doc_uri])
</code></pre>

<p>Then I just inherit from it and override those class attributes:</p>

<pre class=""lang-py prettyprint-override""><code>class FooView(DescriptiveMethodView):
    name = 'Foos'
    description = 'all Foos in the dataset'
    doc_uri = uri = '/foo'


class BarView(DescriptiveMethodView):
    name = 'Bar'
    description = 'A bar in the dataset in the dataset'
    uri = '/bar/&lt;id&gt;'
    doc_uri = '/bar/{id}'
</code></pre>
","2429640","","","0","1220","ldavid","2013-05-28 17:44:18","1940","200","3112","8","49011911","49048557","2018-02-27 15:09:29","0","231","<p>I'm trying to implement a route in my flask application to serve the OPTIONS method of a given resource and return a description of the marshmallow schema associated to said resource. Something similar to what django does:</p>

<pre><code>{
    ""name"": ""Dataset List"",
    ""description"": """",
    ""renders"": [
        ""application/json"",
        ""text/html""
    ],
    ""parses"": [
        ""application/json"",
        ""application/x-www-form-urlencoded"",
        ""multipart/form-data""
    ],
    ""actions"": {
        ""POST"": {
            ""id"": {
                ""type"": ""integer"",
                ""required"": false,
                ""read_only"": true,
                ""label"": ""ID""
            },
            ""url"": {
                ""type"": ""field"",
                ""required"": false,
                ""read_only"": true,
                ""label"": ""Url""
            },
            ""name"": {
                ""type"": ""string"",
                ""required"": true,
                ""read_only"": false,
                ""label"": ""Name"",
                ""help_text"": ""The dataset name."",
                ""max_length"": 256
            }
        }
    }
}
</code></pre>

<p>I can't seem to find any method in <code>Schema</code> or in the docs that returns this description, and <code>AlbumSchema.opts.fields</code> is empty. Is it possible to iterate throughout the fields and build the description I need? Something in the line of:</p>

<pre class=""lang-py prettyprint-override""><code>desc = {f: {""required"": f.required,
            ""type"": f.__class__.__name__,
            ...}
        for f in AlbumSchema.fields}
</code></pre>
","2429640","","","Displaying a description of a marshmallow Schema in OPTIONS method","<python><rest><flask><marshmallow>","1","1","1620"
"49048562","2018-03-01 11:18:24","2","","<p>You are reopening the same file, truncating it (removing all the contents), and writing a single line into the now empty file, for each step in your loop.</p>

<p>You need to either open the file in append mode (""a"" instead of ""w"") so that each time you append the line to the currently existing contents.</p>

<p>Or, much better, open it once only, outside your loop, and write all the lines you need to it:</p>

<pre><code>def change_strings():
with open (""file1.txt"") as file1:
    with open(""file2.txt"", ""w"") as file2:
        strings = file1.readlines()
        for string in strings:
            if not string.startswith(""As""):
                file2.write(string)
</code></pre>
","1737957","","","1","687","jwg","2012-10-11 11:38:58","3791","938","1858","404","49048508","49048562","2018-03-01 11:15:53","0","51","<p>I have a file with the following text:</p>

<pre><code>  Oh, speak again, bright angel, for thou art
  As glorious to this night, being o'er my head
  As is a winged messenger of heaven
  Unto the white-upturned wondering eyes
  Of mortals that fall back to gaze on him
  When he bestrides the lazy-puffing clouds
  And sales upon the bosom in the air
</code></pre>

<p>The task is: I have to replace the lines that begin with ""As"" with an empty line and then save the output into a new file. So far, I've figured out how to replace the words. 
Here's my last code:</p>

<pre><code>    def change_strings():
      with open (""file1.txt"") as file1:
          strings = file1.readlines()
          for string in strings:
              if not string.startswith(""As""):
                  with open(""file2.txt"", ""w"") as file2:
                      file2.write(string)
</code></pre>

<p>However, I only get the last line saved into a new file. What am I doing wrong?</p>
","9397534","235055","2018-03-01 11:47:34","How to replace a string with an empty one (in a file)","<python>","2","2","968"
"49048569","2018-03-01 11:18:51","0","","<p>For your script to work in Tableau, you need to use the python command <code>return something</code> where something is a list containing the appropriate return type. Otherwise the values may exist in python but Tableau can't see them.</p>

<p>In you case you would need to build a list using code something like this:</p>

<pre><code>ReturnValues=[]
for row in cur.fetchall():
   ReturnValues.append(row)
return ReturnValues
</code></pre>

<p>Then the complete list of rows will be sent back to Tableau. You might still have problems, though, as Tableau will be expecting a list of a particular size that matches the input list sent to python. You don't have such an input which may cause problems.</p>
","1047635","","","1","707","matt_black","2011-11-15 13:27:23","949","221","360","6","49018461","49048569","2018-02-27 21:46:36","1","168","<p>I have just started to work with TabPy on 10.13.2. I used the conda pymysql packages (pymysql and PyMySQL-0.8.0-py2.7.egg-info) and placed them in the site-packages for anaconda, so that Tableau would be able to connect to the db, retrieve the dataset and hold in a calculated field.</p>

<p>I originally tried mysql.connector, as I do within PyCharm and the CLI, but TabPy uses anaconda, which does not have a site-package for mysql.</p>

<p>Anyways, it initially connects to the TabPy server, which returns:</p>

<pre><code>An error occurred while communicating with the Predictive Service.
</code></pre>

<p>However, this is soon followed by the next two lines:</p>

<pre><code>Error processing script
TypeError : %d format: a number is required, not str
</code></pre>

<p>I have done some digging for the aforementioned error and everything that I have tried has produced the same error. I found the solution, but I have another error at the end.</p>

<pre><code>SCRIPT_REAL(""
import pymysql

db = pymysql.connect(
                     host='localhost',
                     port='9999',
                     user='usern',
                     passwd='passw',
                     db='someDb'
                     )

cur = db.cursor()

t1 = int(0)

t2 = datetime.datetime(2018, 2, 1)

sqlStr = 'select distinct APPL_ID, APPL_SUBMIT_DT from APPL_APP where APPL_ACTIVE_FLAG &gt; %d and APPL_SUBMIT_DT &gt;= %d' % (t1, t2)

cur.execute()

for row in cur.fetchall():
    print row

db.close()
"",
COUNT([Appl Id])
)
</code></pre>

<p>I do not understand why the script would be returning such an error, until I ran it in PyCharm. It was my port number that needed to be a number instead of a string.</p>

<pre><code>import pymysql

db = pymysql.connect(
                     host='localhost',
                     port=9999,
                     user='usern',
                     passwd='passw',
                     db='someDb'
                     )

cur = db.cursor()

t1 = int(0)

t2 = (2018-02-01)

sqlStr = 'select distinct APPL_ID, APPL_SUBMIT_DT from APPL_APP where APPL_ACTIVE_FLAG &gt; %d and APPL_SUBMIT_DT &gt;= %d' % (t1, t2)

cur.execute(sqlStr)

for row in cur.fetchall():
    print row

db.close()
</code></pre>

<p>Of course, while I could see all the data being returned in my terminal via the TabPy server, but it finished with the following:</p>

<pre><code>(3957423, datetime.datetime(2018, 2, 27, 15, 30, 16))
(3957424, datetime.datetime(2018, 2, 27, 15, 31))
(3957425, datetime.datetime(2018, 2, 27, 15, 31, 4))
(3957426, datetime.datetime(2018, 2, 27, 15, 31, 55))
(3957428, datetime.datetime(2018, 2, 27, 15, 32, 17))
(3957429, datetime.datetime(2018, 2, 27, 15, 32, 18))
None
ERROR:__main__:{""info"": null, ""ERROR"": ""Error running script. No return value""}
</code></pre>

<p>How is that possible? There is clearly data there.</p>
","881083","472495","2018-03-01 11:03:18","TabPy TypeError %d format a number is required, not str, followed by no return value","<python><tableau><tabpy>","1","0","2858"
"49048576","2018-03-01 11:19:10","0","","<p>simply add this line of code in <code>settings.py</code><br></p>

<pre><code>if not DEBUG:
    INSTALLED_APPS += ['storages']
</code></pre>
","8283848","","","0","143","JPG","2017-07-10 12:56:09","1","2613","916","164","49048357","49048500","2018-03-01 11:08:16","0","48","<p>If <code>DEBUG=True</code>, I want to exclude the package <code>storages</code>. How would I do this?</p>

<p>my settings.py:</p>

<pre><code>if DEBUG:
    storages = ''

INSTALLED_APPS = [
    ...
    'app',
    storages,
    ...
]
</code></pre>
","6733153","612124","2018-03-01 11:18:23","Exclude a package if DEBUG=True","<python><django>","2","0","250"
"49048587","2018-03-01 11:20:05","0","","<p>When we pass a word it checks if it can be reversed,If it can be reversed it prints ""This is a Palindrome"". or ""This is NOT a Palindrome""</p>

<pre><code>def reverse(word):
    x = ''
    for i in range(len(word)):
        x += word[len(word)-1-i]
        return x

word = input('give me a word:\n')
x = reverse(word)
if x == word:
    print('This is a Palindrome')
else:
    print('This is NOT a Palindrome')
</code></pre>
","7738644","7738644","2018-03-01 11:51:44","1","427","Madhusudhan R","2017-03-20 08:20:13","179","48","21","0","34637002","34637619","2016-01-06 15:39:45","5","805","<p>[Edit: as someone pointed out I have used improperly the palindrom concept, now I have edited with the correct functions. I have done also some optimizations in the first and third example, in which the for statement goes until it reach half of the string] </p>

<p>I have coded three different versions for a method which checks if a string is a palindrome. The method are implemented as extensions for the class ""str""</p>

<p>The methods also convert the string to lowercase, and delete all the punctual and spaces. Which one is the better (faster, pythonic)?</p>

<p>Here are the methods:</p>

<p>1) This one is the first solution that I thought of:</p>

<pre><code>    def palindrom(self):
        lowerself = re.sub(""[ ,.;:?!]"", """", self.lower())
        n = len(lowerself)
        for i in range(n//2):
            if lowerself[i] != lowerself[n-(i+1)]:
               return False
        return True
</code></pre>

<p>I think that this one is the more faster because there aren't transformations or reversing of the string, and the for statement breaks at the first different element, but I don't think it's an elegant and pythonic way to do so</p>

<p>2) In the second version I do a transformation with the solution founded here on stackoverflow (using advanced slicing string[::-1])</p>

<pre><code># more compact
def pythonicPalindrom(self):
    lowerself = re.sub(""[ ,.;:?!]"", """", self.lower())
    lowerReversed = lowerself[::-1]
    if lowerself == lowerReversed:
        return True
    else:
        return False
</code></pre>

<p>But I think that the slicing and the comparision between the strings make this solution slower.</p>

<p>3) The thirds solution that I thought of, use an iterator:</p>

<pre><code># with iterator
def iteratorPalindrom(self):
    lowerself = re.sub(""[ ,.;:?!]"", """", self.lower())
    iteratorReverse = reversed(lowerself)
    for char in lowerself[0:len(lowerself)//2]:
        if next(iteratorReverse) != char:
            return False
    return True
</code></pre>

<p>which I think is way more elegant of the first solution, and more efficient of the second solution</p>
","3653343","3653343","2016-01-06 16:37:42","Fast and pythonic way to find out if a string is a palindrome","<python><string><optimization><time-complexity>","6","7","2123"
"49048589","2018-03-01 11:20:12","1","","<p>this is what i meant in my comment - instead of re-opening and overwriting your output-file open it once only.</p>

<p>also note that there is no need for <code>.readlines()</code>; that will read your whole file in memory which may not be what you want if your file is really big.</p>

<pre><code>from io import StringIO

text = '''Oh, speak again, bright angel, for thou art
As glorious to this night, being o'er my head
As is a winged messenger of heaven
Unto the white-upturned wondering eyes
Of mortals that fall back to gaze on him
When he bestrides the lazy-puffing clouds
And sales upon the bosom in the air
'''

with StringIO(text) as infile, open('out.txt', 'w') as outfile:
    for line in infile:
        if not line.startswith(""As""):
            outfile.write(line)
</code></pre>

<p>...of course you need to replace <code>StringIO(text)</code> with <code>open('file1.txt', 'r')</code>. this was just to make my example self-containing.</p>
","4954037","4954037","2018-03-01 11:23:52","2","957","hiro protagonist","2015-05-29 16:36:58","27723","2011","1612","552","49048508","49048562","2018-03-01 11:15:53","0","51","<p>I have a file with the following text:</p>

<pre><code>  Oh, speak again, bright angel, for thou art
  As glorious to this night, being o'er my head
  As is a winged messenger of heaven
  Unto the white-upturned wondering eyes
  Of mortals that fall back to gaze on him
  When he bestrides the lazy-puffing clouds
  And sales upon the bosom in the air
</code></pre>

<p>The task is: I have to replace the lines that begin with ""As"" with an empty line and then save the output into a new file. So far, I've figured out how to replace the words. 
Here's my last code:</p>

<pre><code>    def change_strings():
      with open (""file1.txt"") as file1:
          strings = file1.readlines()
          for string in strings:
              if not string.startswith(""As""):
                  with open(""file2.txt"", ""w"") as file2:
                      file2.write(string)
</code></pre>

<p>However, I only get the last line saved into a new file. What am I doing wrong?</p>
","9397534","235055","2018-03-01 11:47:34","How to replace a string with an empty one (in a file)","<python>","2","2","968"
"49048648","2018-03-01 11:23:33","1","","<p>In the 2d case, you're calculating <img src=""https://chart.googleapis.com/chart?cht=tx&amp;chl=c=%5Csqrt%7Ba%5E2%2Bb%5E%5E2%7D"" alt=""c=\sqrt{a^2+b^2}""> which looks correct to me for a triangle.  But the answer isn't 7.  And it isn't a cuboid.</p>

<p>In the 3d case, you're calculating <img src=""https://chart.googleapis.com/chart?cht=tx&amp;chl=z=%5Csqrt%7Ba%5E2%2Bb%5E%5E2%2Bc%7D"" alt=""z=\sqrt{a^2+b^2+c}""> which looks all kinds of wrong.</p>

<p>Why don't you explain what you want to calculate, and whether you want to look at the 2d case or the 3d case?  If you're interested in a cuboid, why are you asking for the number of dimensions?</p>
","9423368","","","0","650","user9423368","2018-02-28 10:57:42","145","12","0","0","49047909","49048310","2018-03-01 10:43:21","-2","71","<p>So I want to calculate the distance from the two furthest points in a cuboid. The mathematical equation for this is z^2 = a^2 + b^2 + c^2 but when I do that it doesn't return correctly. </p>

<pre><code>from math import *

dimension = input(""What dimension: "")

if dimension == (""3D"") or dimension == (""3d"") or dimension == (""3""):
    a = int(input(""a = ""))
    b = int(input(""b = ""))
    c = (sqrt((a**2) + (b**2)))

    z = (sqrt((a**2) + (b**2) + (c))) 
    rounded_z = round(z, 4)

    print(rounded_z,'cm')
else:
    a = int(input(""a = ""))
    b = int(input(""b = ""))

    c = (sqrt((a**2) + (b**2)))
    rounded_c = round(c, 2)

    print(rounded_c,'cm')
</code></pre>

<p>For example:</p>

<p>if a = 6</p>

<p>and b = 2</p>

<p>It should be 7 cm <a href=""http://www.bbc.co.uk/schools/gcsebitesize/maths/geometry/pythagoras3drev1.shtml"" rel=""nofollow noreferrer"">Source</a>. But it returns 6.8062!! Why? please help.</p>
","8573441","","","3D Pythagoras program not returning correct results","<python><math><algebra><pythagorean>","2","3","929"
"49048662","2018-03-01 11:24:30","2","","<p>You're returning <code>question</code> rather then the dic <code>question_dict</code> in here:</p>

<pre><code>return render(request, 'fragen/detail.html', question)
</code></pre>

<p>it should be</p>

<pre><code>return render(request, 'fragen/detail.html', question_dict)
</code></pre>
","7765139","","","2","290","Levi Moreira","2017-03-25 04:14:29","9201","1136","990","34","49048494","49048662","2018-03-01 11:15:23","1","1937","<p>this is my first Post on this Site. I am learning Django and Python right now and trying to create a Quiztool. I have hughe problems with creating my views and its hard for me to understand how to refine the data in a Queryset. In my Detail View I am raising this error:</p>

<blockquote>
  <p>TypeError at /1/</p>
  
  <p>context must be a dict rather than QuerySet.</p>
  
  <p>Request Method:   GET Request URL:    <a href=""http://192.168.188.146:8080/1/"" rel=""nofollow noreferrer"">http://192.168.188.146:8080/1/</a>
  Django Version:   2.0.1 Exception Type:   TypeError Exception Value:  </p>
  
  <p>context must be a dict rather than QuerySet.</p>
  
  <p>Exception Location:
    /home/flo/Django2.0/lib/python3.5/site-packages/django/template/context.py
  in make_context, line 274 Python Executable:
    /home/flo/Django2.0/bin/python Python Version:  3.5.3 Python Path:  </p>
  
  <p>['/home/flo/Django2.0/quiztool', 
  '/home/flo/Django2.0/lib/python35.zip', 
  '/home/flo/Django2.0/lib/python3.5', 
  '/home/flo/Django2.0/lib/python3.5/plat-x86_64-linux-gnu', 
  '/home/flo/Django2.0/lib/python3.5/lib-dynload', 
  '/usr/lib/python3.5',  '/usr/lib/python3.5/plat-x86_64-linux-gnu', 
  '/home/flo/Django2.0/lib/python3.5/site-packages']</p>
  
  <p>Server time:  Thu, 1 Mar 2018 11:00:35 +0000</p>
</blockquote>

<p>I know I have to put the Queryset into a Dictonary but i dont know how to do this. </p>

<p>Here is my views.py:</p>

<pre><code>def index(request):
    latest_survey_list = Survey.objects.order_by('survey_id')[:5]

    context = {
        'latest_survey_list': latest_survey_list
    }
    return render(request, 'fragen/index.html', context)

def detail(request, survey_id):

    question = Survey.objects.get(pk=survey_id).question.all().values()
    question_dict = {
        'question': question
    }

    return render(request, 'fragen/detail.html', question)
</code></pre>

<p>And here the detail.html:</p>

<pre><code>{% if question %}
    &lt;ul&gt;
    {% for x in question %}
    &lt;li&gt;{{ x.question_text }}&lt;/li&gt;
    {% endfor %}
    &lt;/ul&gt;
{% else %}
    &lt;p&gt;No questions are available.&lt;/p&gt;
{% endif %} 
</code></pre>

<p>If u need further informations to help me just ask.</p>

<p>Many thanks in advance and my
Regards flotzen</p>
","9428533","","","Django: TypeError at /1/ context must be a dict rather than QuerySet","<python><django><django-queryset>","2","0","2300"
"49048670","2018-03-01 11:25:01","3","","<p>I was missing a crucial part that actually signaled to release the GIL:</p>

<pre><code>def estimate_forces(self, query_point):
    ...
    cdef np.float64_t[:, :] forces

    forces = np.zeros_like(query_point, dtype=np.float64)
    # HERE
    cdef DTYPE_t[:, :] query_points = query_point.data
    with nogil:
        estimate_forces_multiple(self.root, query_points, forces, self.theta)

    return np.array(forces, dtype=np.float64)
</code></pre>

<p>I've also found that the UNIX <code>time</code> command doesn't do what I wanted for multithreaded programs and reported the same numbers (I guess it reported the CPU time?). Using pythons <code>timeit</code> provided expected results:</p>

<pre><code>max_workers=1: 91.2366s
max_workers=2: 36.7975s
max_workers=4: 30.1390s
max_workers=8: 24.0240s
</code></pre>
","1627234","","","0","820","Pavlin","2012-08-27 09:04:03","2964","157","410","46","49047255","49048670","2018-03-01 10:09:21","4","267","<p>I was under the assumption that if I write my code in Cython using the <code>nogil</code> directive, that would indeed bypass the gil and I could use a <code>ThreadPoolExecutor</code> to use multiple cores. Or, more likely, I messed up something in the implementation, but I can't seem to figure out what.</p>

<p>I've written a simple n-body simulation using the Barnes-Hut algorithm, and would like to do the lookup in parallel:</p>

<pre><code># cython: boundscheck=False
# cython: wraparound=False
...

def estimate_forces(self, query_point):
    ...
    cdef np.float64_t[:, :] forces

    forces = np.zeros_like(query_point, dtype=np.float64)
    estimate_forces_multiple(self.root, query_point.data, forces, self.theta)

    return np.array(forces, dtype=np.float64)


cdef void estimate_forces_multiple(...) nogil:
    for i in range(len(query_points)):
        ...
        estimate_forces(cell, query_point, forces, theta)
</code></pre>

<p>And I call the code like this:</p>

<pre><code>data = np.random.uniform(0, 100, (1000000, 2))

executor = ThreadPoolExecutor(max_workers=max_workers)

quad_tree = QuadTree(data)

chunks = np.array_split(data, max_workers)
forces = executor.map(quad_tree.estimate_forces, chunks)
forces = np.vstack(list(forces))
</code></pre>

<p>I've omitted lots of code in order to make the code in question clearer. It is my understanding that increasing <code>max_workers</code> should use multiple cores and provide a substantial speedup, however, this does not seem to be the case:</p>

<pre><code>&gt; time python barnes_hut.py --max-workers 1
python barnes_hut.py  9.35s user 0.61s system 106% cpu 9.332 total

&gt; time python barnes_hut.py --max-workers 2
python barnes_hut.py  9.05s user 0.64s system 107% cpu 9.048 total

&gt; time python barnes_hut.py --max-workers 4
python barnes_hut.py  9.08s user 0.64s system 107% cpu 9.035 total

&gt; time python barnes_hut.py --max-workers 8
python barnes_hut.py  9.12s user 0.71s system 108% cpu 9.098 total
</code></pre>

<p>Building the quad tree takes less than 1s, so the majority of the time is spent on <code>estimate_forces_multiple</code>, but clearly, I get no speed up using multiple threads. Looking at <code>top</code>, it doesn't appear to use multiple cores either.</p>

<p>My guess is that I must have missed something quite crucial, but I can't really figure out what.</p>
","1627234","","","Cython nogil with ThreadPoolExecutor not giving speedups","<python><multithreading><cython>","1","0","2381"
"49048692","2018-03-01 11:26:13","0","","<p>Put everything you need to be in your template in your ""question_dict"" dict
and then via render like this:</p>

<pre><code>return render(request, 'fragen/detail.html', context=question_dict)
</code></pre>
","6161581","","","0","208","Andrei Todo","2016-04-05 13:23:28","39","2","12","0","49048494","49048662","2018-03-01 11:15:23","1","1937","<p>this is my first Post on this Site. I am learning Django and Python right now and trying to create a Quiztool. I have hughe problems with creating my views and its hard for me to understand how to refine the data in a Queryset. In my Detail View I am raising this error:</p>

<blockquote>
  <p>TypeError at /1/</p>
  
  <p>context must be a dict rather than QuerySet.</p>
  
  <p>Request Method:   GET Request URL:    <a href=""http://192.168.188.146:8080/1/"" rel=""nofollow noreferrer"">http://192.168.188.146:8080/1/</a>
  Django Version:   2.0.1 Exception Type:   TypeError Exception Value:  </p>
  
  <p>context must be a dict rather than QuerySet.</p>
  
  <p>Exception Location:
    /home/flo/Django2.0/lib/python3.5/site-packages/django/template/context.py
  in make_context, line 274 Python Executable:
    /home/flo/Django2.0/bin/python Python Version:  3.5.3 Python Path:  </p>
  
  <p>['/home/flo/Django2.0/quiztool', 
  '/home/flo/Django2.0/lib/python35.zip', 
  '/home/flo/Django2.0/lib/python3.5', 
  '/home/flo/Django2.0/lib/python3.5/plat-x86_64-linux-gnu', 
  '/home/flo/Django2.0/lib/python3.5/lib-dynload', 
  '/usr/lib/python3.5',  '/usr/lib/python3.5/plat-x86_64-linux-gnu', 
  '/home/flo/Django2.0/lib/python3.5/site-packages']</p>
  
  <p>Server time:  Thu, 1 Mar 2018 11:00:35 +0000</p>
</blockquote>

<p>I know I have to put the Queryset into a Dictonary but i dont know how to do this. </p>

<p>Here is my views.py:</p>

<pre><code>def index(request):
    latest_survey_list = Survey.objects.order_by('survey_id')[:5]

    context = {
        'latest_survey_list': latest_survey_list
    }
    return render(request, 'fragen/index.html', context)

def detail(request, survey_id):

    question = Survey.objects.get(pk=survey_id).question.all().values()
    question_dict = {
        'question': question
    }

    return render(request, 'fragen/detail.html', question)
</code></pre>

<p>And here the detail.html:</p>

<pre><code>{% if question %}
    &lt;ul&gt;
    {% for x in question %}
    &lt;li&gt;{{ x.question_text }}&lt;/li&gt;
    {% endfor %}
    &lt;/ul&gt;
{% else %}
    &lt;p&gt;No questions are available.&lt;/p&gt;
{% endif %} 
</code></pre>

<p>If u need further informations to help me just ask.</p>

<p>Many thanks in advance and my
Regards flotzen</p>
","9428533","","","Django: TypeError at /1/ context must be a dict rather than QuerySet","<python><django><django-queryset>","2","0","2300"
"49048707","2018-03-01 11:26:50","2","","<p>You can (ab-)use <code>numpy.frompyfunc</code>:</p>

<pre><code>&gt;&gt;&gt; F = np.arange(9).reshape(3, 3)
&gt;&gt;&gt; np.frompyfunc(F.__getitem__, 1, 1)(range(3))
array([array([0, 1, 2]), array([3, 4, 5]), array([6, 7, 8])], dtype=object)
</code></pre>
","7207392","","","3","259","Paul Panzer","2016-11-24 23:39:00","37645","7185","734","1","49047468","49048707","2018-03-01 10:20:08","2","44","<p>I'd like to create a numpy ndarray with entries of type ndarray itself. I was able to wrap ndarrays into another type to get it work but I want to do this without wrapping. With wrapping a ndarray <code>x</code> into e.g. the dictionary <code>{1:x}</code> I can do</p>

<pre><code>F = np.vectorize(lambda x: {1:np.repeat(x,3)})
F(np.arange(9).reshape(3,3))
</code></pre>

<p>and get (3,3) ndarray with entries <code>{1:[0,0,0]}</code> ... <code>{1:[8,8,8]}</code> (with ndarrays). When change <code>F</code> to <code>F = np.vectorize(lambda x: np.repeat(x,3))</code> numpy complains <code>ValueError: setting an array element with a sequence</code>. I guess it detects that the entries as arrays themselves and doesn't threat them as objects anymore.</p>

<p>How can I avoid this and do the same thing without wrapping the entries from ndarray into something different?</p>

<p>Thanks a lot in advance for hints :)</p>
","3541888","","","Numpy array with numpy arrays as objects","<python><numpy><numpy-ndarray>","1","1","922"
"49048736","2018-03-01 11:28:12","0","","<p>The best way to read messages without polling is to use DataStream. You can find the proper documentation here:</p>

<p><a href=""https://rest-api.symphony.com/docs/create-messagesevents-stream-v4"" rel=""nofollow noreferrer"">https://rest-api.symphony.com/docs/create-messagesevents-stream-v4</a>
<a href=""https://YOUR_POD_SUBDOMAIN.symphony.com/agent/v4/datafeed/:id/read"" rel=""nofollow noreferrer"">https://YOUR_POD_SUBDOMAIN.symphony.com/agent/v4/datafeed/:id/read</a></p>

<p>Note that every datastream created has a 30sec timeout if no message arrives. You need therefore to implement a recursive function to re-create the datastream every time you hit the timeout.</p>

<p>Hope this helps.</p>

<p><a href=""/questions/tagged/symphony-chat"" class=""post-tag"" title=""show questions tagged &#39;symphony-chat&#39;"" rel=""tag"">symphony-chat</a></p>
","9428510","","","0","848","Olivier Poupeney","2018-03-01 10:53:04","1","17","0","0","48144118","","2018-01-08 04:09:41","0","638","<p>I am working on a chatbot that is to be implemented in the Symphony messaging environment: <a href=""https://rest-api.symphony.com"" rel=""nofollow noreferrer"">https://rest-api.symphony.com</a></p>

<p>I have already implemented the methods I need to post and read messages. However, I am stuck at the implementation of the bot ""listener"", as it seems there is no obvious way to do that in Symphony. Ideally I would have them call my API when a ""new message"" event happens, so I can process it immediately.</p>

<p>For now my solution is to call their API every X seconds and check if there is any new message. This is obviously not very efficient.... <strong>Anybody has an idea how to improve this process?</strong></p>

<p>Thanks :)</p>
","7093694","","","Message listener on Symphony","<python><chatbot>","1","0","740"
"49048742","2018-03-01 11:28:29","1","","<p>You should use the <code>Accept-Charset</code> header to say what content type you wish to receive:</p>

<pre><code>Accept-Charset: utf-8
</code></pre>

<p>The server can still ignore you. Usually it's not a problem as Requests will decode the response for you if you use the <code>response.text</code> field.</p>
","1554386","","","0","317","Alastair McCormack","2012-07-26 10:57:59","18316","1493","576","796","49047497","49047773","2018-03-01 10:22:07","0","115","<pre><code>req2 = requests.put(url, json = json_data, headers= header)
print(req2.status_code)
print(req2.headers)
</code></pre>

<p>Where <code>json_data = req1.json()</code></p>

<pre><code>url = 'some url'
</code></pre>

<p>and </p>

<pre><code>header = {'Content-Type': 'application/data;charset=UTF-16'}
</code></pre>

<p>In above code req1 gets a response from a server.  <br/><code>req1</code> json is passed with <code>url</code> to fetch response <code>req2</code>. I want to make <code>req2</code> using PUT() with <code>charset = utf-16</code>. When I am trying to do this by setting headers of req2 (1st line of code) it doesn't do anything as still the statement <code>print(req2.headers)</code> prints </p>

<pre><code>{'Date': 'Thu, 01 Mar 2018 09:51:00 GMT', 'Transfer-Encoding': 'chunked', 'Content-Type': 'application/json;charset=UTF-8'}
</code></pre>
","5852891","4869129","2018-03-01 10:26:40","header data in python requests.put() does not change","<python><python-requests><put>","2","0","871"
"49048765","2018-03-01 11:29:17","1","","<p>You need to set the seed every time that you draw random numbers if you want to ensure consistency. The following small example will illustrate:</p>

<pre><code>np.random.seed(123)
np.random.randn(4, 1)
np.random.randn(4, 1)
</code></pre>

<p>Outputs are different:</p>

<pre><code>array([[-1.0856306 ],
       [ 0.99734545],
       [ 0.2829785 ],
       [-1.50629471]])

array([[-0.57860025],
       [ 1.65143654],
       [-2.42667924],
       [-0.42891263]])
</code></pre>

<p>Then try:</p>

<pre><code>np.random.seed(123)
np.random.randn(4, 1)
np.random.seed(123)
np.random.randn(4, 1)
</code></pre>

<p>Outputs are the same:</p>

<pre><code>array([[-1.0856306 ],
       [ 0.99734545],
       [ 0.2829785 ],
       [-1.50629471]])

array([[-1.0856306 ],
       [ 0.99734545],
       [ 0.2829785 ],
       [-1.50629471]])
</code></pre>

<p>So in your case, you could simply set the seed inside your function before each call to <code>np.random.randn</code>.</p>
","6866811","","","1","967","thesilkworm","2016-09-22 20:17:18","3845","151","1210","248","49048537","49048765","2018-03-01 11:17:18","1","37","<p>I have:</p>

<pre><code>np.random.seed(123)
var_v = 0.007 ** 2
T = 100
rho   = 0.9

def v_t(var_v, T):
    v_t_ = np.zeros([T,1])
    v_t_[1:T] = (var_v ** 0.5) * np.random.randn(len(v_t_) - 1, 1)
    return v_t_

def s_t(rho, T):
    v_t_ = v_t(var_v, T)
    s_t_ = np.zeros([T,1])
    s_t_[0] = 0
    for t in range(1,T):
        s_t_[t] = rho *s_t_[t-1] + v_t_[t]
    return s_t_
</code></pre>

<p>However every time I call one of the values, i.e.</p>

<p><code>s_t(rho, T)</code>       ""or""         <code>v_t(var_v, T)</code></p>

<p>the right value is shown. But directly afterwards, when I call the other value, the value is wrong. After I clear my namespace, when I call the functions in the mirrored sequence, the same holds true. </p>

<p>I suspect that this is because new values are drawn by <code>np.random.randn</code>.
How can I easily fix the drawn values s.t. I get the right values calling <code>s_t</code> and <code>v_t</code>?</p>
","9408531","4729967","2018-03-01 11:19:50","Python: How can I fix my drawn ""random"" values s.t. function calls are consistent?","<python><function><numpy><random>","1","0","953"
"49048777","2018-03-01 11:30:22","0","","<p><strong>TLDR</strong> (a) use neato, not dot to draw (b) pos attrs should be of the form ""100,200!"" in the dot file. Don't double-quote it, and add an ! mark.</p>

<p>Firstly, not all of the graphviz tools support positions. See <a href=""https://www.graphviz.org/doc/info/attrs.html#d:pos"" rel=""nofollow noreferrer"">docs</a>:</p>

<blockquote>
  <p>In neato and fdp, pos can be used to set the initial position of a node</p>
</blockquote>

<p>Secondly, once you are using a tool that reads the <code>pos</code> attribute, you'll see some errors in the output.  To understand problems with an external tool, it makes more sense to test it in isolation, so let's do that to file:</p>

<pre><code>nx.drawing.write_dot(graph, ""test.dot"")
</code></pre>

<p>And then run <code>neato</code>:</p>

<pre><code>&gt; neato -Tpng test.dot &gt;test1.png 
Error: node 1, position ""100,100"", expected two doubles
Error: node 2, position ""100,200"", expected two doubles
Error: node 3, position ""200,100"", expected two doubles
Error: node 4, position ""200,200"", expected two doubles
</code></pre>

<p>You'll now see that the format isn't right.  And so neato proceeds to layout the graph as if <code>pos</code> wasn't specified.</p>

<p><a href=""https://i.stack.imgur.com/tcj5k.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tcj5k.png"" alt=""automatic layout, ignoring pos attr""></a></p>

<pre><code>for n in graph:
    graph.node[n]['pos'] = ""{},{}!"".format(
        graph.node[n]['x'], graph.node[n]['y'])
</code></pre>

<p>Now try again:</p>

<pre><code>nx.drawing.write_dot(graph, ""test_fix.dot"")

# note: the -n flag causes neato to use points rather than inches. 
# see docs, and/or experiment with -s setting as well
&gt; neato -n -Tpng test_fix.dot &gt;test2.png 
</code></pre>

<p>And positions are now respected:</p>

<p><a href=""https://i.stack.imgur.com/JMYS4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JMYS4.png"" alt=""format of pos argument correct""></a></p>

<h2>Edge labels and image size</h2>

<p>The dot manual and this site both have info on how to draw edge labels (e.g. <a href=""https://stackoverflow.com/questions/1806870/how-to-add-edge-labels-in-graphviz"">How to add edge labels in Graphviz?</a> or <a href=""https://stackoverflow.com/questions/18515529/graphviz-place-edge-label-on-the-other-side-ii"">Graphviz: Place edge label on the other side (II)</a>), and obviously you need to add some property to your graph (see ""associate data to edges using keywords"": <a href=""https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.DiGraph.add_edge.html"" rel=""nofollow noreferrer"">https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.DiGraph.add_edge.html</a> )</p>

<p>It isn't clear what you mean by ""plt.figure command does not really work"" but this is quite far from the networkx issues here so I think it would be better to post a new question that isolates the problem and explains it fully.</p>
","1643946","","","2","3008","Bonlenfum","2012-09-03 14:01:36","13009","490","752","15","49040633","","2018-03-01 00:02:35","0","570","<p>I am having trouble visualizing a multidirectional graph with parallel edges in networkx so I have resorted to using pydot, but I am having two issues</p>

<p>1) I  cant seem to understand why the node positions are not being fixed I would like to plot them at the x and y specified coordinates
2) How do I set the size of the figure being plotted the plt.figure command does not really work
3) How do I add edge labels (if I had them)</p>

<p>many thanks</p>

<pre><code>import networkx as nx  
from io import StringIO
from io import BytesIO

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import networkx as nx


graph= nx.MultiGraph()                                                                                    

#add 4 nodes in the vertexs of a square. X and Y are the coordinates                                      
graph.add_node(1,x=100,y=100)                                                                             
graph.add_node(2,x=100,y=200)                                                                             
graph.add_node(3,x=200,y=100)                                                                             
graph.add_node(4,x=200,y=200)                                                                             
graph.add_edge(1,2)                                                                                       
graph.add_edge(2,1)   
graph.add_edge(3,1)
graph.add_edge(3,4)                                                                                       
graph.add_edge(4,1)                                                                                       
                                                                                                         # assign positions                                                                                        
for n in graph:                                                                                           
    graph.node[n]['pos'] = '""%d,%d""'%(graph.node[n]['x'], graph.node[n]['y'])                             
p = nx.drawing.nx_pydot.to_pydot(graph)                                                                                    

# render pydot by calling dot, no file saved to disk
png_str = p.create_png(prog='C:\\Anaconda3\\Library\\bin\\graphviz\\dot.exe')

# treat the dot output string as an image file
sio = BytesIO()
sio.write(png_str)
sio.seek(0)
img = mpimg.imread(sio)





plt.figure(figsize = (10,10))
imgplot = plt.imshow(img)
</code></pre>
","2661763","2531045","2018-03-05 01:16:04","converting network graph to graphviz","<python><networkx><graphviz><pydot>","1","0","2519"
"49048804","2018-03-01 11:31:32","0","","<p>In your views.py, import operator; in your context dictionary instead of putting the original dictionary, put the srtd. </p>

<pre><code>import operator
original_dictionary = {}
srtd = sorted(original_dictionary.items(), key=operator.itemgetter(1))
</code></pre>

<p>And finally in your html you can simply do</p>

<pre><code>{% for key, value in srtd %}
{{k}}{{v}}
</code></pre>
","8291840","","","1","383","Işık Kaplan","2017-07-11 19:57:28","1547","224","20","23","49048536","","2018-03-01 11:17:17","0","162","<p><strong>Demo.html</strong> </p>

<p>I need output with sorted value of Coverage attribute. </p>

<pre><code>&lt;table&gt;
&lt;tr &gt;
            &lt;th&gt;Test Case&lt;/th&gt;
            &lt;th&gt;File Name&lt;/th&gt;
            &lt;th&gt;Coverage&lt;/th&gt;
        &lt;/tr&gt;
           {% for key, value in d.items %}
           &lt;tr&gt;
               &lt;td&gt;{{ key }}&lt;/td&gt;
           &lt;/tr&gt;

                   {% for k,v in value.items|dictsortreversed:""0.lower"" %}
              &lt;tr&gt;
                        &lt;td&gt;   &lt;/td&gt;
                       &lt;td&gt;{{ k }}&lt;/td&gt;
                       &lt;td&gt;{{ v }}&lt;/td&gt;
            &lt;/tr&gt;
             {% endfor %}
           {% endfor %}

&lt;/table&gt;
</code></pre>

<p>I need to sort dictionary based on Coverage attribute i'm trying to do by using <strong>dictsort:""0.lower""</strong> but its sorting based on file name attribute but if i use <strong>dictsort:""1.lower""</strong> value is not printing.I need sorting on value (Coverage).</p>

<p>Please do help me out.</p>
","8433522","","","Rendering ordered reversed dictionary value in Django template","<python><django><django-templates>","1","0","1084"
"49048869","2018-03-01 11:34:55","13","","<p>By default, <code>now()</code> function returns output in the <code>YYYY-MM-DD HH:MM:SS:MS</code> format. Use the below sample script to get the current date and time in a Python script and print results on the screen. Create file <code>getDateTime1.py</code> with the below content.</p>

<pre><code>import datetime

currentDT = datetime.datetime.now()
print (str(currentDT))
</code></pre>

<p>The output looks like below:</p>

<pre><code>2018-03-01 17:03:46.759624
</code></pre>
","7738644","63550","2018-06-06 23:03:42","0","483","Madhusudhan R","2017-03-20 08:20:13","179","48","21","0","415511","415519","2009-01-06 04:54:23","2585","3026055","<p>What is the module/method used to get the current time?</p>
","46646","63550","2018-06-06 22:40:49","How to get the current time in Python","<python><datetime><time>","36","0","63"
"49048876","2018-03-01 11:35:18","23","","<p>The some as mentioned <a href=""https://stackoverflow.com/a/41640852/7127519"">here</a> by  <a href=""https://stackoverflow.com/users/1916588/kurt-bourbaki"">Kurt Bourbaki</a> but in the command line:</p>

<pre><code>python -m nltk.downloader stopwords
</code></pre>
","7127519","7127519","2018-03-21 09:02:41","0","266","Rafael Valero","2016-11-07 16:42:26","711","95","88","0","41610543","","2017-01-12 10:19:22","34","43117","<p>I trying to import the nltk package in python 2.7</p>

<pre><code>  import nltk
  stopwords = nltk.corpus.stopwords.words('english')
  print(stopwords[:10])
</code></pre>

<p>Running this gives me the following error:</p>

<pre><code>LookupError: 
**********************************************************************
Resource 'corpora/stopwords' not found.  Please use the NLTK
Downloader to obtain the resource:  &gt;&gt;&gt; nltk.download()
</code></pre>

<p>So therefore I open my python termin and did the following:</p>

<pre><code>import nltk  
nltk.download()
</code></pre>

<p>Which gives me:</p>

<pre><code>showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml
</code></pre>

<p>However this does not seem to stop. And running it again still gives me the same error. Any thoughts where this goes wrong?</p>
","6039787","","","Corpora/stopwords not found when import nltk library","<python><nltk>","8","0","849"
"49048893","2018-03-01 11:35:53","0","","<p>First of all we are not translators..</p>

<p>If you want to translate java code to python you have to translate it manually. It looks like there are some tools out e.g. <a href=""https://pypi.python.org/pypi/java2python"" rel=""nofollow noreferrer"">java2python</a> but the author states</p>

<blockquote>
  <p>The generated Python code is not guaranteed to run, nor is guaranteed
  to be syntactically valid Python.</p>
</blockquote>

<p>If you simply want to use a java library in a application that you want to write in python you could give <a href=""http://www.jython.org/"" rel=""nofollow noreferrer"">jython</a> a try.</p>

<p>But as per your question and requirement to give you example/sample or a hint..</p>

<p>First find all elements of list according to your condition by!</p>

<pre><code>from selenium import webdriver

browser = webdriver.Chrome()
browser.get(url)
# here find method will have to modified according to your condition of getting webElements
list = browser.find()
</code></pre>

<p>Then as per your requirement of method try something like this:</p>

<pre><code>def clickElementFromList(list_object, strname):
    for name in list_object:
        text = name.text
        if text is not None:
            if text == strname:
                name.click()
                break
</code></pre>

<p>Then call function:</p>

<pre><code>clickElementFromList(your list here, strname here)
</code></pre>

<p>Hope this will help you! :)</p>
","9400024","9400024","2018-03-01 11:51:38","3","1457","Abdullah Ahmed Ghaznavi","2018-02-23 05:56:43","989","186","218","610","49048339","","2018-03-01 11:07:12","0","73","<p><strong>Here is my code in Java that I want to convert in Python:</strong></p>

<pre><code>public static void clickElementFromList(String ListObject, String strname) 
{
    List&lt;WebElement&gt; wbeElement;

    wbeElement = Util.findElements(ListObject);

    for (int cnt = 0; cnt &lt; wbeElement.size(); cnt++) 
    {
        if (wbeElement.get(cnt).getText().trim().contentEquals(strname)) 
        {
            wbeElement.get(cnt).click();
            break;
        }
    }

}
</code></pre>

<p>//listobj is the web element.
//strname is the displayed text in the application</p>
","7061512","9400024","2018-03-01 11:34:42","Generic code for clicking web element from a list in Python:","<python><selenium><automation>","1","1","591"
"49048904","2018-03-01 11:36:51","2","","<p>Download the source from <a href=""https://pypi.python.org/pypi/selenium"" rel=""nofollow noreferrer"">https://pypi.python.org/pypi/selenium</a>
and install:</p>

<pre><code>python setup.py install
</code></pre>
","9063000","","","0","211","suit","2017-12-06 16:41:24","496","17","5","1","49047938","","2018-03-01 10:45:04","0","177","<p>I am trying to perform headless testing. I performed those with Casperjs, but I am not allowed to code in it. I need to find a way to integrate selenium webdriver, but <code>pip install</code> or even <code>conda install</code> won't work. Is there a way out?</p>
","9428457","9112450","2018-03-01 20:14:00","How is it possible to link libraries like Selenium without using pip or conda install?","<python><selenium><phantomjs>","1","1","267"
"49048946","2018-03-01 11:39:58","1","","<p>Use <code>int</code> function to convert it to integer and initialize MaxSlots variable with a value.</p>

<pre><code>FlightType=int(input(""Which flight would you like to fly? Type '2 Seater', '4   Seater', or 'Historic'.""))

FlightLen=int(input(""Would you like to book the '30' minutes flight or the '60'""))

MaxSlots = 0

if (FlightLen==30):
    MaxSlots=(600/FlightLen)

elif (FlightLen==60):
    MaxSlots=(600//FlightLen)

print (MaxSlots)
</code></pre>
","803316","","","0","461","Adriano Silva","2011-06-17 13:38:00","1963","105","158","6","49048874","49048954","2018-03-01 11:35:10","-1","178","<pre><code>FlightType=input(""Which flight would you like to fly? Type '2 Seater', '4   Seater', or 'Historic'."")
# No validation included for the input

FlightLen=input(""Would you like to book the '30' minutes flight or the '60'"")
# No validation included for the input

if (FlightLen==30):
    MaxSlots=(600/FlightLen)

elif (FlightLen==60):
    MaxSlots=(600//FlightLen)

print (MaxSlots)
</code></pre>

<p>When I run the code, why does the following error message appear?</p>

<blockquote>
  <p>NameError: name 'MaxSlots' is not defined</p>
</blockquote>
","9305138","8372104","2018-03-01 12:03:10","Variable not defined (Python)","<python>","2","2","558"
"49048954","2018-03-01 11:40:23","1","","<p><code>input()</code> is always returned as a string and thus never equal to an integer.  </p>

<blockquote>
  <p>The function then reads a line from input, converts it to a string (stripping a trailing newline)</p>
</blockquote>

<p>See the <a href=""https://docs.python.org/3/library/functions.html#input"" rel=""nofollow noreferrer"">documentation</a></p>

<p>Your <code>if</code> or <code>elif</code> is never true since an integer is not a string in the Python world (if you used an <code>else</code> it would always return that) so you never define the new variable (since it is never run).  What you need to do is to convert each <code>input()</code> to an integer.  This can be done using <a href=""https://docs.python.org/3/library/functions.html#int"" rel=""nofollow noreferrer""><code>int()</code></a> function:</p>

<pre><code>FlightLen=int(input(""Would you like to book the '30' minutes flight or the '60'""))
</code></pre>

<p>Here <code>FlightLen</code> has been converted to an integer once an input value has been given.</p>

<hr>

<p>You do not need the <code>()</code> in the <code>if</code> <code>elif</code> statements if you are using Python 3 either:</p>

<pre><code>if FlightLen==30:
elif FlightLen==60:
</code></pre>

<p>If you are using Python 2 <code>print</code> does not take an <code>()</code></p>

<hr>

<p>You might also want to add an <code>else</code> to make sure <code>FlightLen</code> is always defined, ensuring you do not get this error.</p>
","8372104","8372104","2018-03-01 11:46:14","0","1474","Simon","2017-07-26 19:03:27","6383","1766","5398","222","49048874","49048954","2018-03-01 11:35:10","-1","178","<pre><code>FlightType=input(""Which flight would you like to fly? Type '2 Seater', '4   Seater', or 'Historic'."")
# No validation included for the input

FlightLen=input(""Would you like to book the '30' minutes flight or the '60'"")
# No validation included for the input

if (FlightLen==30):
    MaxSlots=(600/FlightLen)

elif (FlightLen==60):
    MaxSlots=(600//FlightLen)

print (MaxSlots)
</code></pre>

<p>When I run the code, why does the following error message appear?</p>

<blockquote>
  <p>NameError: name 'MaxSlots' is not defined</p>
</blockquote>
","9305138","8372104","2018-03-01 12:03:10","Variable not defined (Python)","<python>","2","2","558"
"49048965","2018-03-01 11:40:49","2","","<p>This can be done directly with pandas using the <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_html.html#pandas-read-html"" rel=""nofollow noreferrer""><code>read_html()</code></a> function:</p>

<pre><code>import pandas as pd 
import string

df = pd.DataFrame()

for i in string.ascii_uppercase[:1]:#[:27]:
    url = ""https://myanimelist.net/anime.php?letter={}"".format(i)
    print url
    tables = pd.read_html(url, header=0)

    if df.empty:
        df = tables[2]
    else:
        df = pd.concat([df, tables[2]])

print df    
</code></pre>

<p>This returns a list of ALL tables found at a given URL. In your case, you only need the second table. This would give you a dataframe starting:</p>

<pre class=""lang-none prettyprint-override""><code>    Unnamed: 0                                              Title     Type  Eps.  Score
0          NaN  A Kite add  Sawa is a school girl, an orphan, ...      OVA     2   6.67
1          NaN  A Piece of Phantasmagoria add  A collection of...      OVA    15   6.25
2          NaN  A Play add  Music Video for the group ALT, mad...    Music     1   4.62
3          NaN  A Smart Experiment add  Bonus short included o...  Special     1   4.95
4          NaN  A-Channel add  Tooru and Run have been best fr...       TV    12   7.04
</code></pre>

<hr>

<p>To do this using BeautifulSoup, you could use the following approach:</p>

<pre><code>from bs4 import BeautifulSoup
import pandas as pd 
import string
import requests

columns = [u'Title', u'Type', u'Eps.', u'Score']
df = pd.DataFrame()

for i in string.ascii_uppercase[:27]:
    url = ""https://myanimelist.net/anime.php?letter={}"".format(i)

    r = requests.get(url)
    soup = BeautifulSoup(r.text, 'html.parser')    
    table = soup.find_all('table')[2]

    for tr in table.find_all('tr')[1:]:
        row = [td.get_text(strip=True) for td in tr.find_all('td')[1:5]]
        url_sub = tr.find('a')['href']
        print url_sub

        r_sub = requests.get(url_sub)
        soup_sub = BeautifulSoup(r_sub.text, 'html.parser')

        all_scores = []     # each title has multiple lists of scores

        # Select all of the user assigned score tables
        for div in soup_sub.select('div.spaceit.textReadability.word-break.pt8.mt8'):
            scores = []     # scores for one block

            for tr_sub in div.div.table.find_all('tr'):
                scores.append([td_sub.text for td_sub in tr_sub.find_all('td')])
            all_scores.append(scores)

        print all_scores    # These probably need adding to the row. Not all have scores.

        df_row = pd.DataFrame([row], columns=columns)

        if df.empty:
            df = df_row
        else:
            df = pd.concat([df, df_row])

print df
</code></pre>

<p>For each film, a list of all the scores found is created and appended to <code>all_scores</code> although it is not clear how you would this added to your main dataframe.</p>

<p>For example, scores could look like:</p>

<pre class=""lang-none prettyprint-override""><code>https://myanimelist.net/anime/320/A_Kite
[[[u'Overall', u'8'], [u'Story', u'8'], [u'Animation', u'7'], [u'Sound', u'7'], [u'Character', u'7'], [u'Enjoyment', u'8']], [[u'Overall', u'8'], [u'Story', u'8'], [u'Animation', u'10'], [u'Sound', u'0'], [u'Character', u'7'], [u'Enjoyment', u'10']], [[u'Overall', u'7'], [u'Story', u'7'], [u'Animation', u'8'], [u'Sound', u'6'], [u'Character', u'7'], [u'Enjoyment', u'8']], [[u'Overall', u'2'], [u'Story', u'2'], [u'Animation', u'2'], [u'Sound', u'2'], [u'Character', u'2'], [u'Enjoyment', u'2']]]
</code></pre>
","4985733","4985733","2018-03-03 15:07:38","5","3605","Martin Evans","2015-06-08 09:46:30","31317","3697","2144","9","49046887","49048965","2018-03-01 09:49:33","0","142","<p>I create my soup with : </p>

<pre><code>import pandas as pd 
import requests
from bs4 import BeautifulSoup
import os
import string

for i in string.ascii_uppercase[:27]:
    url = ""https://myanimelist.net/anime.php?letter={}"".format(i)
    r = requests.get(url)
    soup = BeautifulSoup(r.text, 'html.parser')
</code></pre>

<p>I'm trying to create a dataframe from web scrapping this site ""<a href=""https://myanimelist.net"" rel=""nofollow noreferrer"">https://myanimelist.net</a>"" et and i would like to get in a first step anime title, eps, type </p>

<p>and secondly in detail of each anime (page like that : <a href=""https://myanimelist.net/anime/2928/hack__GU_Returner"" rel=""nofollow noreferrer"">https://myanimelist.net/anime/2928/hack__GU_Returner</a>) i would like to gather the score that user assigned contains in (for example :  </p>

<pre><code>&lt;a href=""https://myanimelist.net/profile/Tii__""&gt;Tii__&lt;/a&gt;
</code></pre>

<p>and</p>

<pre><code>&lt;table border=""0"" width=""105"" cellpadding=""0"" cellspacing=""0"" class=""borderClass"" style=""border-width: 1px;""&gt;
        &lt;tbody&gt;&lt;tr&gt;
          &lt;td class=""borderClass bgColor1""&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt;
          &lt;td class=""borderClass bgColor1""&gt;&lt;strong&gt;10&lt;/strong&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td class=""borderClass"" align=""left""&gt;Story&lt;/td&gt;
          &lt;td class=""borderClass""&gt;10&lt;/td&gt;
        &lt;/tr&gt;
                  &lt;tr&gt;
            &lt;td class=""borderClass"" align=""left""&gt;Animation&lt;/td&gt;
            &lt;td class=""borderClass""&gt;9&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td class=""borderClass"" align=""left""&gt;Sound&lt;/td&gt;
            &lt;td class=""borderClass""&gt;9&lt;/td&gt;
          &lt;/tr&gt;
                &lt;tr&gt;
          &lt;td class=""borderClass"" align=""left""&gt;Character&lt;/td&gt;
          &lt;td class=""borderClass""&gt;9&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td class=""borderClass"" style=""border-width: 0;"" align=""left""&gt;Enjoyment&lt;/td&gt;
          &lt;td class=""borderClass"" style=""border-width: 0;""&gt;10&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;&lt;/table&gt;
</code></pre>

<p>can you help to gather all that information ? </p>

<p>if my request it's not clear, tell me.</p>
","9176398","9176398","2018-03-01 09:55:26","Web scrapping python (beautifull soup) multiple page and subpage","<python><pandas><web-scraping><beautifulsoup>","1","0","2380"
"49049003","2018-03-01 11:42:22","10","","<p>I have solved this,it seems that MKL 2018 has some serious problems</p>

<pre><code>conda uninstall mkl=2018
conda install mkl=2017
</code></pre>
","4723732","","","6","149","Richard Rublev","2015-03-28 11:06:19","2386","493","1623","0","49048734","49049003","2018-03-01 11:28:08","3","4533","<p>I have installed theano with </p>

<pre><code>conda install theano
</code></pre>

<p>on Ubuntu 16.04.
Now I have import problems</p>

<pre><code>import theano
Traceback (most recent call last):
  File ""/home/milenko/miniconda3/lib/python3.6/configparser.py"", line 1138, in _unify_values
    sectiondict = self._sections[section]
KeyError: 'blas'
  File ""/home/milenko/miniconda3/lib/python3.6/site-packages/theano/configdefaults.py"", line 1252, in check_mkl_openmp
    raise RuntimeError('To use MKL 2018 with Theano you MUST set ""MKL_THREADING_LAYER=GNU"" in your environement.')
RuntimeError: To use MKL 2018 with Theano you MUST set ""MKL_THREADING_LAYER=GNU"" in your environement.
</code></pre>

<p>What does this mean?How to check if everything if BLAS is properly installed?</p>
","4723732","","","RuntimeError: To use MKL 2018 with Theano you MUST set ""MKL_THREADING_LAYER=GNU""","<python><theano>","3","0","786"
"49049004","2018-03-01 11:42:24","3","","<pre><code>datetime.timedelta()
</code></pre>

<p>should take plural <code>days</code> as argument, instead of singular <code>day</code>. See <a href=""https://docs.python.org/3/library/datetime.html#datetime.timedelta"" rel=""nofollow noreferrer"">the documentation</a>.</p>

<p>This results in:</p>

<pre><code>sorted_sections_id_timestamp = [datetime.datetime(2018, 2, 20, 0, 0, tzinfo=&lt;UTC&gt;), datetime.datetime(2018, 2, 23, 0, 0, tzinfo=&lt;UTC&gt;)]

for index in range(0,len(sorted_sections_id_timestamp)):
   redo_timestamp = sorted_sections_id_timestamp[index] + datetime.timedelta(days=10)
</code></pre>
","6735980","","","0","615","Dennis Soemers","2016-08-19 17:30:31","5427","446","1354","36","49048853","49049004","2018-03-01 11:33:56","2","30","<p>I'm using python and I have a datetime value in the format: <code>2018-02-20 00:00:00+00:00</code> and I want to add 10 days in this datetime.</p>

<p>How can I suppose to achieve this?</p>

<p>My current code is the following but it's not working:</p>

<pre><code>sorted_sections_id_timestamp = [datetime.datetime(2018, 2, 20, 0, 0, tzinfo=&lt;UTC&gt;), datetime.datetime(2018, 2, 23, 0, 0, tzinfo=&lt;UTC&gt;)]

for index in range(0,len(sorted_sections_id_timestamp)):
   redo_timestamp = sorted_sections_id_timestamp[index] + datetime.timedelta(day=10)
</code></pre>

<p>In case I <code>print (sorted_sections_id_timestamp[index])</code> I get the value <code>2018-02-20 00:00:00+00:00</code>.</p>
","1395874","1395874","2018-03-01 11:40:35","Add a specific number of days in a datetime. How to specify the format?","<python><datetime>","1","4","704"
"49049037","2018-03-01 11:45:17","0","","<p>Maybe you should just check if a string with that declaration value (  ) can be found in your XML file: </p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>    def matchLine(path, line_number, text):
        """"""
        path = used for defining the file to be checked
        line_number = used to identify the line that  will be checked
        text = string containing the text to match
        """"""
        file = open(path)
        line_file = file.readline()
        line_file = line_file.rstrip()
        line_no = 1
        while line_file != """":
            if line_no == line_number:
                if line_file == text:
                    return True
                else:
                    return False
            line_no = line_no+1
            line_file = file.readline()
            line_file = line_file.rstrip()</code></pre>
</div>
</div>
</p>
","8895027","","","0","1036","Robert","2017-11-06 15:26:39","10","19","0","0","48803562","48803743","2018-02-15 09:15:12","1","339","<p>I use <code>lxml</code> to parse XML document
How can I get declaration string?</p>

<pre><code> &lt;?xml version=""1.0"" encoding=""utf-8"" ?&gt; 
</code></pre>

<p>I want to check if it is present, what encoding it has and what xml version.</p>
","5079255","","","How can I get XML declaration string with lxml","<python><xml><lxml>","2","0","246"
"49049064","2018-03-01 11:46:45","1","","<p>In your <code>DisplayPage</code> class you are overwriting the <code>__init__</code> method, so you need to call the <code>__init__</code> method of the parent (<code>Screen</code> class). With <code>BoxLayout.__ init __ (self, * args)</code> you just call the constructor of  <code>BoxLayout</code>but not the constructor of <code>Screen</code>. I don't understand why you try to do a multiple subclassing here, you can simply inherit from <code>Screen</code> and call its constructor (preferably using <code>super</code>).</p>

<p><code>Screen</code> is a <code>RelativeLayout</code>, if you need to use another layout in your screen simply add it as any widget (being careful with certain <a href=""https://kivy.org/docs/api-kivy.uix.relativelayout.html#kivy-uix-relativelayout-common-pitfalls"" rel=""nofollow noreferrer"">peculiarities</a>):</p>

<pre><code>&lt;MenuPage&gt;:
    BoxLayout:
        # Rest of screen's content here
</code></pre>

<p>You can do something like:</p>

<p><strong>main.py:</strong></p>

<pre><code>import kivy

kivy.require('1.10.0')

from kivy.app import App
from kivy.uix.screenmanager import ScreenManager, Screen
from kivy.lang.builder import Builder

import json



Builder.load_file('VocabularyJournal.kv')


class MenuPage(Screen):
    pass


class DisplayPage(Screen):
    def __init__(self, **kwargs):
        # Call __init__ method of parent class (Screen)
        super(DisplayPage, self).__init__(**kwargs)  
        with open('vocab_words.json') as rfile:
            data = json.load(rfile)


class WordInsertPage(Screen):
    pass


class NewWordPage(Screen):
    pass


class FlashCard(Screen):
    pass


class WordGroups(Screen):
    pass


class Manager(ScreenManager):
    pass


class VocabularyJournalApp(App):
    def build(self):
        return Manager()

if __name__ == ""__main__"":
    object = VocabularyJournalApp()
    object.run()
</code></pre>

<p><strong>VocabularyJournal.kv:</strong> </p>

<pre><code>&lt;Manager&gt;:
    MenuPage:
        name: 'menu'
    WordInsertPage:
        name: 'insertword'
    NewWordPage:
        name: 'newword'
    FlashCard:
        name: 'flashcard'
    WordGroups:
        name: 'wordgroup'
    DisplayPage:
        name: 'display'


&lt;MenuPage&gt;:
    # Your code here


&lt;WordInsertPage&gt;:
    FloatLayout:
        Button:
            text: ""New Word""
            on_press: root.manager.current='newword'
            font_size: 30
            color: 0,0,0,1
            size_hint: .2, .1
            pos_hint: {""center_x"": .5, ""center_y"": 0.3}
        Button:
            text: ""search word""
            on_press: root.manager.current='display'

            font_size: 30
            color: 0,0,0,1
            size_hint: .2, .1
            pos_hint: {""center_x"": .5, ""center_y"": 0.5}
        Button:
            text: 'Flash Cards'
            on_press: root.manager.current=""flashcard""
            font_size: 30
            color: 0,0,0,1
            size_hint: .2, .1
            pos_hint: {""center_x"": .5, ""center_y"": 0.7}



&lt;NewWordPage&gt;:
    # Your code here

&lt;FlashCard&gt;:
    # Your code here

&lt;WordGroups&gt;:
    # Your code here

&lt;DisplayPage&gt;:
    # Your code here
</code></pre>

<blockquote>
  <p><strong>Note:</strong> if you rename your kv as <code>vocabularyjournal.kv</code> you do not need to use <code>Builder.load_file</code>: <a href=""https://kivy.org/docs/guide/lang.html#how-to-load-kv"" rel=""nofollow noreferrer"">https://kivy.org/docs/guide/lang.html#how-to-load-kv</a></p>
</blockquote>
","7131499","7131499","2018-03-01 11:59:26","2","3539","FJSevilla","2016-11-08 11:59:44","2628","190","117","0","49047655","49049064","2018-03-01 10:29:39","1","488","<p>I am making an application using Screen Manager in kivy and I am stuck here. I am new to kivy and python. as far as I know I am doing everything correctly.</p>

<p>error says- </p>

<blockquote>
  <p>kivy.uix.screenmanager.ScreenManagerException: No Screen with name
  ""display""</p>
</blockquote>

<p>Note: this is only a part of my code for the sake of simplicity I am only showing the lines where the error is occuring.</p>

<pre><code>    import kivy
    kivy.require('1.10.0')

    from kivy.uix.stacklayout import StackLayout
    from kivy.uix.floatlayout import FloatLayout
    from kivy.uix.boxlayout import BoxLayout
    from kivy.uix.label import Label 
    from kivy.app import App
    from kivy.uix.popup import Popup  
    from kivy.uix.screenmanager import ScreenManager, Screen 
    from kivy.lang import Builder 
    from kivy.properties import ObjectProperty
    from kivy.uix.textinput import TextInput
    from kivy.properties import StringProperty


    import json

    Builder.load_file('VocabularyJournal.kv')

    class MenuPage(Screen, StackLayout):
        pass

    class DisplayPage(Screen, BoxLayout):



        def __init__(self, *args):# the error occured after I wrote these line before that every other screens were working properly.
            BoxLayout.__init__(self,*args)
            with open('vocab_words.json') as rfile:
                data=json.load(rfile)

            #some codes here

    class WordInsertPage(Screen,FloatLayout):
        pass


    class NewWordPage(Screen,StackLayout):
        pass

    class FlashCard(Screen):
        pass

    class WordGroups(Screen):
        pass

    sm=ScreenManager()
    sm.add_widget(MenuPage(name='menu'))
    sm.add_widget(WordInsertPage(name='insertword'))
    sm.add_widget(NewWordPage(name='newword'))
    sm.add_widget(FlashCard(name='flashcard'))
    sm.add_widget(WordGroups(name='wordgroup'))
    sm.add_widget(DisplayPage(name='display'))

    class VocabularyJournalApp(App):
        def build(self):
            return sm

    object = VocabularyJournalApp()
    object.run()
</code></pre>

<p>heres the part of kv file where the error is occuring:</p>

<pre><code>    # the part of the code where the error is occuring

    &lt;WordInsertPage&gt;:

        FloatLayout:

            Button: 
                text: ""New Word""
                on_press: root.manager.current='newword'# this is working very well
                font_size: 30
                color: 0,0,0,1
                size_hint: .2, .1
                pos_hint: {""center_x"": .5, ""center_y"": 0.3}
                background_down: 'darkgrey.png'
            Button:
                text: ""search word""
                on_press: root.manager.current='display' # here the error says kivy.uix.screenmanager.ScreenManagerException: No Screen with name ""display"".

                font_size: 30
                color: 0,0,0,1
                size_hint: .2, .1
                pos_hint: {""center_x"": .5, ""center_y"": 0.5}
                background_down: 'darkgrey.png'
            Button:
                text: 'Flash Cards'
                on_press: root.manager.current=""flashcard""
                font_size: 30
                color: 0,0,0,1
                size_hint: .2, .1
                pos_hint: {""center_x"": .5, ""center_y"": 0.7}
                background_down: 'darkgrey.png'
</code></pre>

<p>here is the traceback:</p>

<pre><code>    [INFO   ] [Logger      ] Record log in C:\Users\HP\.kivy\logs\kivy_18-03-01_31.txt
    [INFO   ] [Kivy        ] v1.10.0
    [INFO   ] [Python      ] v3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)]
    [INFO   ] [Factory     ] 194 symbols loaded
    [INFO   ] [Image       ] Providers: img_tex, img_dds, img_sdl2, img_gif (img_pil, img_ffpyplayer ignored)
    [INFO   ] [Text        ] Provider: sdl2
    [INFO   ] [OSC         ] using &lt;thread&gt; for socket
    [INFO   ] [Window      ] Provider: sdl2
    [INFO   ] [GL          ] Using the ""OpenGL"" graphics system
    [INFO   ] [GL          ] GLEW initialization succeeded
    [INFO   ] [GL          ] Backend used &lt;glew&gt;
    [INFO   ] [GL          ] OpenGL version &lt;b'4.4.0 - Build 21.20.16.4627'&gt;
    [INFO   ] [GL          ] OpenGL vendor &lt;b'Intel'&gt;
    [INFO   ] [GL          ] OpenGL renderer &lt;b'Intel(R) HD Graphics 520'&gt;
    [INFO   ] [GL          ] OpenGL parsed version: 4, 4
    [INFO   ] [GL          ] Shading version &lt;b'4.40 - Build 21.20.16.4627'&gt;
    [INFO   ] [GL          ] Texture max size &lt;16384&gt;
    [INFO   ] [GL          ] Texture max units &lt;32&gt;
    [INFO   ] [Shader      ] fragment shader: &lt;b""WARNING: 0:7: '' :  #version directive missing""&gt;
    [INFO   ] [Shader      ] vertex shader: &lt;b""WARNING: 0:7: '' :  #version directive missing""&gt;
    [INFO   ] [Window      ] auto add sdl2 input provider
    [INFO   ] [Window      ] virtual keyboard not allowed, single mode, not docked
    [INFO   ] [GL          ] NPOT texture support is available
    [INFO   ] [Base        ] Start application main loop
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [WARNING] [Accordion   ] not enough space for displaying all children
    [WARNING] [Accordion   ] need 176px, got 100px
    [WARNING] [Accordion   ] layout aborted.
    [INFO   ] [Base        ] Leaving application in progress...
     Traceback (most recent call last):
       File ""E:\SharanyaPy\desktop vocabulary journal\vocabJournal.py"", line 92, in &lt;module&gt;
         object.run()
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\app.py"", line 828, in run
         runTouchApp()
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\base.py"", line 504, in runTouchApp
         EventLoop.window.mainloop()
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\core\window\window_sdl2.py"", line 663, in mainloop
         self._mainloop()
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\core\window\window_sdl2.py"", line 405, in _mainloop
         EventLoop.idle()
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\base.py"", line 342, in idle
         self.dispatch_input()
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\base.py"", line 327, in dispatch_input
         post_dispatch_input(*pop(0))
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\base.py"", line 233, in post_dispatch_input
         listener.dispatch('on_motion', etype, me)
       File ""kivy\_event.pyx"", line 718, in kivy._event.EventDispatcher.dispatch (kivy\_event.c:8191)
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\core\window\__init__.py"", line 1188, in on_motion
         self.dispatch('on_touch_down', me)
       File ""kivy\_event.pyx"", line 718, in kivy._event.EventDispatcher.dispatch (kivy\_event.c:8191)
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\core\window\__init__.py"", line 1204, in on_touch_down
         if w.dispatch('on_touch_down', touch):
       File ""kivy\_event.pyx"", line 718, in kivy._event.EventDispatcher.dispatch (kivy\_event.c:8191)
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\uix\screenmanager.py"", line 1189, in on_touch_down
         return super(ScreenManager, self).on_touch_down(touch)
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\uix\widget.py"", line 457, in on_touch_down
         if child.dispatch('on_touch_down', touch):
       File ""kivy\_event.pyx"", line 718, in kivy._event.EventDispatcher.dispatch (kivy\_event.c:8191)
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\uix\relativelayout.py"", line 288, in on_touch_down
         ret = super(RelativeLayout, self).on_touch_down(touch)
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\uix\widget.py"", line 457, in on_touch_down
         if child.dispatch('on_touch_down', touch):
       File ""kivy\_event.pyx"", line 718, in kivy._event.EventDispatcher.dispatch (kivy\_event.c:8191)
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\uix\widget.py"", line 457, in on_touch_down
         if child.dispatch('on_touch_down', touch):
       File ""kivy\_event.pyx"", line 718, in kivy._event.EventDispatcher.dispatch (kivy\_event.c:8191)
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\uix\behaviors\button.py"", line 151, in on_touch_down
         self.dispatch('on_press')
       File ""kivy\_event.pyx"", line 714, in kivy._event.EventDispatcher.dispatch (kivy\_event.c:8146)
       File ""kivy\_event.pyx"", line 1225, in kivy._event.EventObservers.dispatch (kivy\_event.c:14035)
       File ""kivy\_event.pyx"", line 1109, in kivy._event.EventObservers._dispatch (kivy\_event.c:12816)
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\lang\builder.py"", line 64, in custom_callback
         exec(__kvlang__.co_value, idmap)
       File ""E:\SharanyaPy\desktop vocabulary journal\VocabularyJournal.kv"", line 51, in &lt;module&gt;
         on_press: root.manager.current='display'
       File ""kivy\properties.pyx"", line 478, in kivy.properties.Property.__set__ (kivy\properties.c:5572)
       File ""kivy\properties.pyx"", line 516, in kivy.properties.Property.set (kivy\properties.c:6405)
       File ""kivy\properties.pyx"", line 571, in kivy.properties.Property.dispatch (kivy\properties.c:7105)
       File ""kivy\_event.pyx"", line 1225, in kivy._event.EventObservers.dispatch (kivy\_event.c:14035)
       File ""kivy\_event.pyx"", line 1131, in kivy._event.EventObservers._dispatch (kivy\_event.c:13193)
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\uix\screenmanager.py"", line 1037, in on_current
         screen = self.get_screen(value)
       File ""C:\Users\HP\AppData\Local\Programs\Python\Python36-32\lib\site-packages\kivy\uix\screenmanager.py"", line 1063, in get_screen
         raise ScreenManagerException('No Screen with name ""%s"".' % name)
     kivy.uix.screenmanager.ScreenManagerException: No Screen with name ""display"".
</code></pre>
","9355642","4729967","2018-03-01 10:38:40","I am getting this error when I am using Screen Manager: kivy.uix.screenmanager.ScreenManagerException: No Screen with name ""display""","<python><kivy>","1","0","13957"
"49049072","2018-03-01 11:46:59","4","","<p>Assuming the largest 32-bit integer is <a href=""https://en.wikipedia.org/wiki/2,147,483,647"" rel=""nofollow noreferrer""><code>0xffffffff</code></a>,</p>

<p>Then, we need to check if our number is larger than this value:</p>

<pre><code>abs(n) &lt;= 0xffffffff
</code></pre>

<p>Wrapping an <code>abs()</code> around the number will take care of negative cases, too.</p>
","8516606","","","0","373","Anton Shpigunov","2017-08-25 12:19:11","46","9","8","0","11928669","","2012-08-13 05:37:32","1","9661","<p>In my program I'm looking at a string and I want to know if it represents a 32-bit integer.</p>

<p>Currently I first check if it is a digit at all using <code>isdigit()</code>, then I check if it exceeds the value of 2^32  (assuming I don't care about unsigned values).</p>

<p>What's the best way to check that my input string contains a valid 32-bit integer?</p>
","1020069","344286","2012-08-13 13:06:03","How do I check if a number is a 32-bit integer using Python?","<python><int>","4","6","369"
"49049100","2018-03-01 11:48:42","1","","<p>The <code>ab</code> in the lambda definition is defined in the surrounding scope, thus changes with every iteration. Only the <code>ab</code> values of the last iteration are reflected into all the lambda funtions.</p>

<p>One possible solution is to use a factory method for the creation of the lambda function:</p>

<pre><code>import numpy as np
import matplotlib.pylab as pl

def lambda_factory(ab):
    return lambda x:x*ab[0]+ab[1]

def broken_line(x, x0, y0):
    cl = []
    fl = []
    for i in range(len(x0)-1):
        ab = np.polyfit(x0[i:i+2], y0[i:i+2], 1)
        # Compute and append a ""condition"" interval
        cl.append(np.logical_and(x &gt;= x0[i], x &lt;= x0[i+1]))
        # Create a line function for the interval
        fl.append(lambda_factory(ab))
    return(np.piecewise(x, condlist=cl, funclist=fl))

x0 = np.array([1, 3, 5, 10])
y0 = np.array([2, 1, 5, 7])

x = np.linspace(1, 10, 30)

pl.plot(x, broken_line(x, x0, y0))
pl.plot(x0, y0)
pl.show()
</code></pre>

<p>Another solution is to save <code>ab</code> in a variable local to the lambda, thus using</p>

<pre><code>fl.append(lambda x, ab=ab:x*ab[0]+ab[1])
</code></pre>

<p>within the loop. Here you create a local variable <code>ab</code> of the outer scope variable <code>ab</code>.</p>

<p>In both cases the result looks like this:</p>

<p><a href=""https://i.stack.imgur.com/0fCPP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0fCPP.png"" alt=""Resulting piecewise fit""></a></p>

<p>For further reference see the <a href=""https://docs.python.org/3/faq/programming.html#why-do-lambdas-defined-in-a-loop-with-different-values-all-return-the-same-result"" rel=""nofollow noreferrer"">python faq</a></p>
","8914303","","","1","1709","datasailor","2017-11-09 14:44:21","1222","45","106","38","49047279","49049100","2018-03-01 10:10:39","1","816","<p>I am trying to use the data from two <code>x0</code> and <code>y0</code> coordinate arrays to create a function that uses the provided <code>x0</code> and <code>y0</code> to compute a piecewise series of segments.</p>

<p>For doing that, I create a function
</p>

<pre><code>import numpy as np
import matplotlib.pylab as pl

def broken_line(x, x0, y0):
    cl = []
    fl = []
    for i in range(len(x0)-1):
        ab = np.polyfit(x0[i:i+2], y0[i:i+2], 1)
        # Compute and append a ""condition"" interval
        cl.append(np.logical_and(x &gt;= x0[i], x &lt;= x0[i+1]))
        # Create a line function for the interval
        fl.append(lambda x: x*ab[0] + ab[1])
    return(np.piecewise(x, condlist=cl, funclist=fl))
</code></pre>

<p>and then to test it I plot the results of</p>

<pre class=""lang-py prettyprint-override""><code>x0 = np.array([1, 3, 5, 10])
y0 = np.array([2, 1, 5, 7])

x = np.linspace(1, 10, 30)

pl.plot(x, broken_line(x, x0, y0))
pl.plot(x0, y0)
pl.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/ML8lq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ML8lq.png"" alt=""enter image description here""></a></p>

<p>However, the results is not as I would expect.
I had a look at other posts on the topic, including <a href=""https://stackoverflow.com/questions/16574966/python-confused-by-numpys-piecewise-function"">this</a> and <a href=""https://stackoverflow.com/questions/47358953/matplotlib-plot-piecewise-linear-function-with-three-parts"">this other</a>, together with the <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.piecewise.html"" rel=""nofollow noreferrer"">numpy.piecewise</a> documentation.
However, I was not able to figure out why the code is not working as expected. It looks like only the last definition of <code>lambda</code> is considered.
Suggestions are all welcome.</p>
","2388462","2388462","2018-03-01 10:20:58","piecewise linear function with numpy.piecewise","<python><numpy><piecewise>","1","0","1866"
"49049108","2018-03-01 11:49:10","1","","<p>I prefer to avoid <code>apply</code> where <code>numpy</code> operations are possible.</p>

<p>In this case, there are at least a couple of alternatives. Below are examples with benchmarking. As you can see, the closer you move to <code>numpy</code>, the better the results.</p>

<pre><code>import pandas as pd, numpy as np

foo = pd.DataFrame([[1,2],[3,4]],columns=['a','b'])

foo = pd.concat([foo]*10000, ignore_index=True)

def dark(df):
    return df.apply(lambda x: tuple([np.min(x)/2,np.max(x)/2]), axis=1)

def jp1(df):
    return [tuple([np.min(x)/2,np.max(x)/2]) for x in foo[['a', 'b']].values]

def jp2(df):
    arr = foo[['a', 'b']].values
    return list(zip(*(np.min(arr, axis=1)/2, np.max(arr, axis=1)/2)))

%timeit dark(foo)  # 4.95s
%timeit jp1(foo)   # 298ms
%timeit jp2(foo)   # 4.68ms
</code></pre>

<p>Of course, <code>dark()</code> returns a <code>pd.Series</code>, but <code>pandas</code> lets you assign via a list.</p>
","9209546","9209546","2018-03-01 12:07:11","0","947","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","46158930","49049108","2017-09-11 15:09:03","2","781","<p>Have questions concerning the output of <code>apply()</code> method in python <code>pandas.DataFrame</code> </p>

<h3>Q1 -</h3>

<p>Why does this function returns a <code>pandas.DataFrame</code> <strong>with the same format</strong> as the input (<code>pandas.DataFrame</code>) when <code>apply</code> function returns an <code>array</code> with the same shape as input?.  </p>

<p>For instance  </p>

<pre><code>foo = pd.DataFrame([[1,2],[3,4]],columns=['a','b'])
foo.apply(lambda x: [np.min(x)/2,np.max(x)/2], axis='index') 
</code></pre>

<p>code will return:  </p>

<pre><code>       a        b   
0   min(a)/2   min(b)/2  
1   max(a)/2   max(b)/2 
</code></pre>

<h3>Q2 -</h3>

<p>For some reason I would like to output a <code>pandaq.Series</code> of arrays instead:</p>

<pre><code>0   [min(a)/2, max(a)/2]  
1   [min(b)/2, max(b)/2]
...
</code></pre>

<p>I have tried <code>reduce=True</code> without success. 
Then, <strong>How should I do?</strong></p>

<p>Thank you in advance.</p>
","3941704","3941704","2018-03-01 11:29:56","Pandas DataFrame.Apply output format","<python><pandas><dataframe><apply>","2","0","996"
"49049109","2018-03-01 11:49:13","2","","<p>The strings <code>\xbb</code>, <code>\x02</code> ecc are <strong>single</strong> character strings. What you are seeing is the hex escape representation of them, since the ASCII character with code <code>2</code> is not a printable character.</p>

<p>It seems like you actually want the base-16 representation of the number represented by this characters, without the <code>x</code> prefix, hence you can us e<code>ord</code> to obtain the ASCII value and then <code>hex</code> to convert it into its hexadecimal representation:</p>

<pre><code>&gt;&gt;&gt; ord('\x02')
2
&gt;&gt;&gt; ord('\xbb')
187
&gt;&gt;&gt; hex(2)
'0x2'
&gt;&gt;&gt; hex(187)
'0xbb'
</code></pre>

<p>If you don't want the <code>0x</code> prefix oyu can just use slicing to remove that part:</p>

<pre><code>result = [hex(ord(x))[2:] for x in list_input]
</code></pre>
","8718773","","","0","845","Giacomo Alzetta","2017-10-04 08:17:23","1777","443","113","75","49047517","49049109","2018-03-01 10:23:26","-1","343","<p>I have some data from <strong>Serial Port</strong> as follows</p>

<pre><code>list_input =[ '\xbb', '\x02', '\x00', '\x11', '\xbe', '\x04', '\x00', '\x0', '\x08', '\x3', '\xb2', '\xdd', '\xd9', '\x01', '\x00', '\x00', '\x00', '\x00', '\xc4', '\x1e'] 
</code></pre>

<p>I want to remove '\x' from each element and get output like, </p>

<pre><code>list_output=[bb,02,00,22,be,04,00,08,dd]
</code></pre>

<p>if i do this <code>list_input =''.join(map(str, list_input))</code> 
i get this output "" �"" �4 3���@    �"" i.e garbage value.</p>

<p>Please suggest any suitable solution.</p>
","5981326","","","How to remove '\x' from list =[ '\xbb', '\x02', '\x00', '\x11', '\xbe']","<python><serial-port>","1","4","585"
"49049127","2018-03-01 11:50:12","0","","<p>Update with the latest chromedriver and chrome. This is working without having a popup come out for headless browser when running this step by send-keys in selenium.</p>

<p>Firefox still has this issue with geckodriver.</p>
","9427479","","","0","228","tester1","2018-03-01 06:52:00","1","2","0","0","49044610","","2018-03-01 07:25:55","0","403","<p>The component which needs to be automated is antd - upload. </p>

<pre><code>https://ant.design/components/upload/ --&gt; Can be found here
</code></pre>

<p>The button for the upload is visible, but the input ""tag"" is not visible:</p>

<p>Component view: <a href=""https://i.stack.imgur.com/NDeRE.png"" rel=""nofollow noreferrer"">This is the button how it is seen on the screen</a></p>

<p>HTML view: <a href=""https://i.stack.imgur.com/QF8q3.png"" rel=""nofollow noreferrer"">This is the view of the inspection of the component</a></p>

<p>As you see the ""input"" is not visible.</p>

<p>To have selenium interact with the input (to use the sendkeys) I need to have the input element visible on the screen.</p>

<p>I make an execute script as follows:</p>

<pre><code>file_input = self.driver.find_element_by_xpath(xpath)
self.driver.execute_script('arguments[0].style.display = ""block""; ', file_input)
</code></pre>

<p>After this I get the following view of the component: <a href=""https://i.stack.imgur.com/F4aLK.png"" rel=""nofollow noreferrer"">component ui view</a></p>

<p>And the html view: <a href=""https://i.stack.imgur.com/kfvh5.png"" rel=""nofollow noreferrer"">HTML view</a></p>

<p>After this I interact with the component by sending keys to the element:</p>

<pre><code>file_input.send_keys(fpath)
</code></pre>

<p>At this step I have 2 things happening: 
1. <strong>the file selector popup is shown</strong> 
2. <strong>the file is uploaded by the send_keys.</strong></p>

<p>This causes an issue when I try to run the scripts in headless browser. The message that is shown: </p>

<pre><code>SessionNotCreatedException: Message: Tried to run command without establishing a connection headless browser
</code></pre>

<p>This is only due to running in headless browser mode. When the browser is displayed, the scripts are kept going. I have also tried using on both displayed and headless browser the module pyautogui:</p>

<pre><code>pyautogui.keyDown('esc')
pyautogui.keyUp('esc')
</code></pre>

<p>This helps only on the displayed browser, so the popup is closed. But for headless browser this doesn't help.</p>

<p>I am running the scripts on MacOS Sierra, Firefox (58.0.2) in headless browser options, python 2.7, selenium 3.8</p>

<p>Would be very grateful if someone knows how to work around this.</p>

<p>Thank you</p>
","9427479","","","Upload file by sendkeys in python opens a file selector popup","<python><selenium><firefox><sendkeys><headless>","1","4","2333"
"49049131","2018-03-01 11:50:25","0","","<p>i got it to work with:</p>

<pre><code>for materialClass in materialClassList:
    sets(materialClass.occlusionShadingGroup, e = True, forceElement = materialClass.meshList)
</code></pre>

<p>I collect the meshes when I create the materialClass now, which makes much more sense then selecting them for each renderlayer.</p>
","7302635","7302635","2018-03-01 12:08:36","0","327","mechaniac","2016-12-15 14:50:09","13","12","0","0","49035311","","2018-02-28 17:25:56","1","340","<p>I get all shapes assigned to baseMaterial, select the shapes and then assign the occlusionShader.</p>

<pre><code>for materialClass in materialClassList:
    select(materialClass.baseMaterial)
    hyperShade(objects="""")
    hyperShade(a=materialClass.occlusionShader)
</code></pre>

<p>works just fine, but if I use it as a pre render script:</p>

<pre><code>  Error: line 0: hyperShade command not supported in batch mode
</code></pre>

<p>What can I change the two last lines of my function to to make this work?</p>
","7302635","","","change shader on all assigned meshes, without using hyperShade()","<python><maya>","2","1","522"
"49049169","2018-03-01 11:52:19","0","","<p>One solution with list comprehension</p>

<pre><code>[(a,b,c) for a in range(10) for b in range(10) for c in range(10) if a+b+c ==17]
</code></pre>

<p>Then just convert this to strings or whatever you want.</p>
","8324480","","","1","215","Mathieu","2017-07-18 09:44:48","2187","365","396","149","49049114","49049169","2018-03-01 11:49:28","-5","50","<p>How can I generate a list of 3-digit numbers for which the sum of their digits equal 17?
for example: <strong>0</strong>98, 197, 188, etc..</p>
","9355410","","","how to generate a list of 3-digit numbers the sum of their digits equal 17?","<python>","1","7","147"
"49049194","2018-03-01 11:53:57","2","","<p>I have fixed the problem, however still don't know the root cause. </p>

<p>My solution was:</p>

<blockquote>
  <p>1) Install Redis windows build <a href=""https://github.com/rgl/redis/downloads"" rel=""nofollow noreferrer"">https://github.com/rgl/redis/downloads</a></p>
  
  <p>2) Reboot PC</p>
  
  <p>3) pip install pypiwin32</p>
  
  <p>4) run project</p>
</blockquote>

<p>Even works after turning on all firewalls</p>
","3091149","","","0","425","Tomasz","2013-12-11 12:47:01","1057","30","21","1","49049193","49049194","2018-03-01 11:53:57","0","801","<p>There is a problem when using Django Channels In some Windows 10 machines. 
Basically i can not connect to the Socket [Error 10061]  and python gives me out an error </p>

<pre><code>ERROR - server - Exception inside application: Multiple exceptions: [Errno 10061] Connect call failed ('::1', 6379), [Errno 10061] Connect call failed ('127. 0.0.1', 6379)
</code></pre>

<p>I know it's Windows/OS level problem.
I have already turned off all firewalls etc. Still cant connect to the socket</p>

<p>Example repo: <a href=""https://github.com/andrewgodwin/channels-examples"" rel=""nofollow noreferrer"">https://github.com/andrewgodwin/channels-examples</a></p>
","3091149","","","Windows Error 10061 - Django Channels","<python><django><redis><chat><channels>","1","0","658"
"49049204","2018-03-01 11:54:23","5","","<p>Even though, it has been quite a while since this question has been asked,
I still hope that my answer helps.</p>

<p>The solution is to derive a class from pyqtgraph.GraphicsWindow and then define a keypress signal.</p>

<pre><code>from pyqtgraph.Qt import QtCore
import pyqtgraph as pg

class KeyPressWindow(pg.GraphicsWindow):
    sigKeyPress = QtCore.pyqtSignal(object)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    def keyPressEvent(self, ev):
        self.scene().keyPressEvent(ev)
        self.sigKeyPress.emit(ev)


def keyPressed(evt):
    print(""Key pressed"")


app = pg.mkQApp()
win = KeyPressWindow()
win.sigKeyPress.connect(keyPressed)
pl = win.addPlot()
pl.plot([x*x for x in range(-10,11)])


app.exec_()
</code></pre>
","1513370","1513370","2018-03-01 13:02:43","0","780","user1513370","2012-07-10 00:15:06","51","1","0","0","40423999","","2016-11-04 13:33:16","5","1041","<p>The following example shows how to connect an arbitrary python callable to mouse motion events in a <code>GraphicsWindow</code>. How would you do the same for key press events?</p>

<pre><code>from pyqtgraph.Qt import QtGui, QtCore
import pyqtgraph as pg

app = pg.mkQApp()
win = pg.GraphicsWindow()
pl = win.addPlot()
pl.plot([x*x for x in range(-10,11)])

def mouseMoved(evt):
    print(""Mouse moved event: {}"".format(evt))

pl.scene().sigMouseMoved.connect(mouseMoved)

def keyPressed(evt):
    print(""Key pressed"")

# The scene doesn't have an equivalent signal for key presses
# pl.scene().sigKeyPressed.connect(keyPress)

app.exec_()
</code></pre>
","4122880","6622587","2018-03-01 14:57:16","Pyqtgraph: where to find signal for key preses?","<python><pyqtgraph>","1","0","657"
"49049218","2018-03-01 11:54:59","1","","<p>The python-decouple <a href=""https://github.com/henriquebastos/python-decouple/blob/master/README.rst#understanding-the-cast-argument"" rel=""nofollow noreferrer"">readme</a> suggests thay you have to cast the <code>ALLOWED_HOSTS</code> to a list. The example it gives is:</p>

<pre><code>os.environ['ALLOWED_HOSTS'] = '.localhost, .herokuapp.com'
config('ALLOWED_HOSTS', cast=lambda v: [s.strip() for s in v.split(',')])
</code></pre>

<p>You appear to be doing <code>config('ALLOWED_HOSTS')</code>, so perhaps your <code>ALLOWED_HOSTS</code> is being evaluated as a string <code>'[]'</code> instead of an empty list <code>[]</code>.</p>
","113962","","","1","639","Alasdair","2009-05-28 20:26:55","203443","9896","5891","530","49049026","","2018-03-01 11:44:04","2","370","<p>When my <code>settings.py</code> has <code>ALLOWED_HOSTS = []</code> - the server works fine. But When I do <code>ALLOWED_HOSTS = config('ALLOWED_HOSTS')</code> - it gives the error:</p>

<pre><code>DisallowedHost at /admin/login/
Invalid HTTP_HOST header: '127.0.0.1:8000'. You may need to add '127.0.0.1' to ALLOWED_HOSTS.
</code></pre>

<p>However when I go into python shell I'm successfully able to import <code>ALLOWED_HOSTS</code> - and it prints <code>[]</code> which is the correct value.</p>

<p>Any reason why I still get the error?</p>

<p>PS: The <code>config</code> is a feature of the <code>python-decouple</code> package - used to store sensitive values.</p>
","6733153","113962","2018-03-01 11:56:05","Invalid HTTP_HOST header: '127.0.0.1:8000' error when using python-decouple to set ALLOWED_HOSTS","<python><django>","2","2","678"
"49049245","2018-03-01 11:56:44","0","","<p>Simple 1 line fix for any who need </p>

<p><code>os.environ[""QT_AUTO_SCREEN_SCALE_FACTOR""] = ""1""</code></p>
","8587804","8587804","2018-03-01 16:11:57","0","112","Kermit","2017-09-10 14:01:02","114","30","28","0","49048294","49048441","2018-03-01 11:04:30","1","536","<p>I am using PyQt5 and Python 3.6.4 to design a ui for a program. It was made on a 720p monitor however now using the same code on a 4k monitor, everything is tiny apart from the text. How would I go about resizing the whole app to look the same on all monitors: (720p, 1080p, 4k, etc.)
The program is to be run on windows through an executable created through compiling the python code.
Cheers</p>
","8587804","8587804","2018-03-01 11:15:47","PyQt5 Resize app for different displays","<python><resize><pyqt5><qapplication>","2","0","400"
"49049279","2018-03-01 11:58:29","1","","<p>Here is an idea which you could try. Query CloudTrail data for ""RunInstance
"", ""StopInstance"" and ""StartInstance"" calculate the total running time of the instance.</p>

<p>Here is the script I have created.
<a href=""https://gist.github.com/sudharsans/990dbb67f397d79556dbc02e5835e5ec"" rel=""nofollow noreferrer"">https://gist.github.com/sudharsans/990dbb67f397d79556dbc02e5835e5ec</a></p>

<p>Sample output:</p>

<pre><code>i-0xxxxxfcd40ebd6a1 user 0:09:21.263278
i-xxxxxx502450c96aa yser 84 days, 15:13:37.651975
i-xxxxxxfcdf27ec894 yser 6 days, 15:43:52.191147
i-xxxxx386c630af322 user 13 days, 14:08:49.429469
i-xxxxxxxd41bf975eb test 21:37:59.67100
</code></pre>
","2244717","","","3","668","Sudharsan Sivasankaran","2013-04-04 11:53:45","3443","304","13","0","49041205","49122320","2018-03-01 01:16:52","0","896","<p>I'm trying to find the number of minutes an instance has been up using the python boto3 library for aws. I'm not able to find a direct way to do this. I can get the status of a machine using:</p>

<pre><code>ec2 = boto3.resource('ec2')
instance = ec2.Instance(instance_id)

status = instance.state['Name']
print(status)
</code></pre>

<p>But what I'm looking for is a simple metric: The number of minutes an instance has been running. Note that this is not the uptime of an instance as it gets reset whenever it is stopped.</p>
","1787599","","","AWS Python Boto3 - Getting an instance running time by id","<python><amazon-web-services><amazon-ec2><aws-sdk><boto3>","2","2","531"
"49049356","2018-03-01 12:02:45","1","","<p>I'd look directly for an <code>onchange</code> method which is bound to be modifying your field. Look in your Python code for <code>SampleType</code> string. I think there must be an <code>onchange</code> method being executed which is modifying its value just after the form view is opened.</p>
","2886640","2886640","2018-03-01 12:11:13","0","299","forvas","2013-10-16 13:41:29","6455","621","459","9","49048086","49049356","2018-03-01 10:52:24","0","29","<p>Here is my code. The field default_SampleType's value is shown for 2 seconds or so and then get lost.Question is why the value is not being preserved?</p>

<p>The declaration the field as follows</p>

<pre><code>fields.Many2one(string='SampleType',
                    comodel_name='olims.sample_type',
                    required=True

),
fields.Many2one(string='SampleType1',
                    comodel_name='olims.sample_type',
                    required=False

),
fields.Many2one(string='SampleType2',
                    comodel_name='olims.sample_type',
                    required=False

),
fields.Many2one(string='SampleType3',
                    comodel_name='olims.sample_type',
                    required=False

),
</code></pre>

<p>When I replace sampleType with SampleType1 in context, then this value is shown and it does not get lost. I dont know what is the problem with SampleType field.</p>

<pre><code>result = {
                    'name': 'Analysis Request',
                    'view_type': 'form',
                    'res_model': 'olims.analysis_request',
                    'view_id': sample_record,
                    'context': {'default_SampleType': sample_type.id , 'default_Client': client.id, 'default_Sample_id': sample_id,
                                'default_SamplingDate': sampling_date,
                                'default_ClientReference': client_reference, 'default_ClientSampleID': client_sample_ID,
                                'default_SamplePoint': sample_point.id,'default_StorageLocation': storage_location.id,
                                'default_SamplingDeviation': sampling_deviation.id, 'default_SampleCondition': sample_condition.id,
                                'default_LotID': lot_id},
                    'type': 'ir.actions.act_window',
                    'view_mode': 'form',
                }
        return result
</code></pre>
","9319989","2886640","2018-03-01 12:28:46","Why some of the field are being lost when launching ir.actions.act.window from python code in odoo 9?","<python><python-2.7><odoo><odoo-9>","1","6","1918"
"49049400","2018-03-01 12:05:39","6","","<p>From 6.15 of <a href=""/questions/tagged/python"" class=""post-tag"" title=""show questions tagged &#39;python&#39;"" rel=""tag"">python</a> documentation</p>

<blockquote>
  <p>Python evaluates expressions from left to right. Notice that while evaluating an assignment, the right-hand side is evaluated before the left-hand side.</p>
  
  <p>In the following lines, expressions will be evaluated in the arithmetic order of their suffixes:</p>
</blockquote>

<pre><code>expr1, expr2, expr3, expr4
(expr1, expr2, expr3, expr4)
{expr1: expr2, expr3: expr4}
expr1 + expr2 * (expr3 - expr4)   &lt;----- This is of importance to us.
expr1(expr2, expr3, *expr4, **expr5)
expr3, expr4 = expr1, expr2
</code></pre>

<p>So here the functions will be called in order from left to right. So any of the changes you will see will be due to the functions called from left to right.</p>

<p>And yes in <a href=""/questions/tagged/python"" class=""post-tag"" title=""show questions tagged &#39;python&#39;"" rel=""tag"">python</a> function calls are expressions.</p>
","3796113","","","0","1038","user2736738","2014-07-02 03:54:10","27652","2503","356","65","49048370","49049400","2018-03-01 11:09:02","4","527","<p>In <strong>C</strong> or <strong>C++</strong> I know that there is something called </p>

<blockquote>
  <p>undefined behaviour</p>
</blockquote>

<p>In expression evaluation when some of the the expressions have side-effects. let's say I want to calculate the following:</p>

<pre><code>c = 10
f() + g() + c
</code></pre>

<p>but at some point g makes c = 5.(c is a glob variable)</p>

<p>What would be the behavior in python? Would it be undefined as <strong>C</strong>?</p>
","9004008","667266","2018-03-01 12:06:08","Undefined Behaviour in Python","<python><c++><c>","3","9","480"
"49049470","2018-03-01 12:09:52","1","","<p>If I understand correctly, what you're trying to do is to identify connected components of the graph, where each node is an atom and each edge is a bond (hence, one connected component is a molecule). There is an efficient implementation for this in <a href=""https://docs.scipy.org/doc/scipy/reference/sparse.csgraph.html"" rel=""nofollow noreferrer""><code>scipy.sparse.csgraph</code></a>.</p>

<p>So first let's set up the graph as a sparse matrix:</p>

<pre><code>import scipy.sparse as sps

# Input as provided
edges = [[1,2],[1,3],[1,4],[1,5],[5,6],[5,7],[5,8],[9,10],[9,11],[9,12],[9,13]]
# Modify the input by adding, for each [x,y], also [y,x].
# Also transform it to a set and then again to a list
# to assure that we don't duplicate anything.
edges = list({(x[0],x[1]) for x in edges}.union({(x[1],x[0]) for x in edges}))
# Create it as a matrix. The weights of all edges are set to 1,
# as they don't matter anyway.
graph = sps.csr_matrix(([1]*len(edges), np.array(edges).T))
</code></pre>

<p>At this point, it's just a matter of calling <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csgraph.connected_components.html#scipy.sparse.csgraph.connected_components"" rel=""nofollow noreferrer""><code>scipy.sparse.csgraph.connected_components</code></a>, but the output has a slightly different format by default:</p>

<blockquote>
  <p>(3, array([0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]))</p>
</blockquote>

<p>So let's modify it a bit:</p>

<pre><code>from scipy.sparse import csgraph
connected_components = csgraph.connected_components(graph)
result = []

for u in range(1, connected_components[0]):
    result.append(np.where(connected_components[1]==u)[0])

result
</code></pre>

<blockquote>
  <p>[array([1, 2, 3, 4, 5, 6, 7, 8], dtype=int64),</p>
  
  <p>array([ 9, 10, 11, 12, 13], dtype=int64)]</p>
</blockquote>

<p>Also remark that in <code>range</code> I've started from 1, because Python standard counts from 0 and this would be found as an isolated node since you start from 1. If the numbering of the atoms is non-continuous, the one needs to skip the isolated nodes, for example by doing:</p>

<pre><code>result = [r for r in result if len(r) &gt; 1]
</code></pre>
","4305277","","","0","2216","Marco Spinaci","2014-11-29 00:21:12","1028","71","49","1","49048044","","2018-03-01 10:50:47","1","62","<p>I have a number of pairs of values (pairs of bonded atoms) for a file containing different molecules. If two pairs have a common member, it means that they are part of the same molecule. I am trying to find an efficient way in python to group the atoms depending on which molecule they belong to.</p>

<p><strong>As an example, ethane and methane would be:</strong></p>

<p><code>1,5</code> and <code>9</code> would be carbon, the rest hydrogen</p>

<pre><code>[[1,2],[1,3],[1,4],[1,5],[5,6],[5,7],[5,8],[9,10],[9,11],[9,12],[9,13]]
</code></pre>

<p>And I would like to get a list/array in which I have:</p>

<pre><code>[[1,2,3,4,5,6,7,8],[9,10,11,12,13]]
</code></pre>

<p>I have tried several things but they are really ineficient for files with a large number of atoms. There should be a smart way of doing it but I can't find it. Any ideas?</p>

<p>Thanks,
Joan</p>
","3091644","8572897","2018-03-01 11:37:35","How to combine arrays only if they have a common value?","<python>","3","2","874"
"49049501","2018-03-01 12:12:00","1","","<p>If you want to be able to alter the ylim of one particular plot in the <code>FacetGrid</code> you have to explicitly create it with <code>g = sns.lmplot(..., sharey=False)</code></p>

<p>example:</p>

<pre><code>tips = sns.load_dataset(""tips"")
g = sns.lmplot(x=""total_bill"", y=""tip"", col=""day"", hue=""day"", data=tips, col_wrap=2, size=3, 
               sharey=False)
g.axes[0].set_ylim((0,100))
</code></pre>

<p><a href=""https://i.stack.imgur.com/rcxS1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rcxS1.png"" alt=""enter image description here""></a></p>
","1356000","","","2","579","Diziet Asahi","2012-04-25 11:14:14","12866","545","51","30","49035671","49049501","2018-02-28 17:47:50","0","1133","<p>I've made a lmplot column plot (subplot) using the following commands: </p>

<pre><code>g = sns.lmplot(x=COX, y='dX', data=tidy_data, hue='hue', col='comp', 
col_wrap=8, fit_reg=True, scatter=True, aspect=1.5,
            legend_out=True, truncate=True, scatter_kws={""s"": 200})
</code></pre>

<p><a href=""https://i.stack.imgur.com/BxDbB.png"" rel=""nofollow noreferrer"">figure of the plotted lmplot FacetGrid</a></p>

<p>The FacetGrid seems to set the ylim of all subplots to the maximum value in all of the data. I would like to set the ylim individually for each subplot. I first looked to the answer of this question:</p>

<p><a href=""https://stackoverflow.com/questions/25212986/how-to-set-some-xlim-and-ylim-in-seaborn-lmplot-facetgrid"">How to set some xlim and ylim in Seaborn lmplot facetgrid</a></p>

<p>I tested:</p>

<pre><code>g.axes.shape
&gt;&gt;&gt; (23, )

g.axes[0]
&gt;&gt;&gt; AxesSubplot(0.0189366,0.704381;0.116079x0.258196)

g.axes[0].set_ylim(0, 1)
&gt;&gt;&gt; 
</code></pre>

<p>However, this method also seems to give the same ylim for all subplots. Maybe I'm not accessing the right axis? I'd really appreciate some help. </p>
","8188435","4124317","2018-03-01 09:27:14","set individual ylim of seaborn lmplot columns","<python><pandas><matplotlib><seaborn>","1","1","1154"
"49049513","2018-03-01 12:12:47","4","","<p>As you've said, <code>@var1</code>, <code>@var2</code> and <code>@var3</code> are all column names.</p>

<p>However, SQL interprets the <code>@</code> symbol as a parameter for a value which you will supply later in your code.</p>

<p>So, your SQL code expects 6 values because of the three <code>(?)</code>s and three <code>@var</code>s. But you're only supplying 3 values (for the <code>(?)</code>s), meaning that the said error is occurring.</p>

<p>I would recommend naming your columns something without <code>'@'</code> so that there is less chance for errors.</p>

<p>See <a href=""https://stackoverflow.com/questions/361747/what-does-the-symbol-do-in-sql"">this question</a> for further clarification.</p>
","7908770","","","0","715","Adi219","2017-04-23 09:50:18","3109","540","642","43","49049246","49049612","2018-03-01 11:56:47","1","1178","<p>I am trying to put together a SQL query in python pandas. I have attempted different methods, but always getting the following error: 
<code>Incorrect number of bindings supplied. The current statement uses 6, and there are 3 supplied.</code></p>

<p>My code is as follows. What am I doing wrong?</p>

<pre><code>conn = sqlite3.connect(my_db)
df = pd.read_sql_query(
    con = conn,
    sql = """"""SELECT * FROM {table}
        WHERE @var1 = (?)
        AND @var2 = (?)
        AND @var3 = (?)
        ;"""""".format(table=table),
    params= (value1, value2, value3),
    )
</code></pre>
","6071128","","","Pandas read_sql_query using multiple AND statements","<python><sql><pandas>","2","3","587"
"49049517","2018-03-01 12:12:58","1","","<ol>
<li>Extract out the SQL command into a file.sql. Give the function either the path to the sql file or the text of the sql file. </li>
<li>Rename the flag to its purpose.</li>
<li>your if and elif both sets the flag to 1 so why the differences? Combine it to one condition</li>
<li>'500' should be a variable of the function.</li>
<li>Write a short description of what the function does in """""" """""". You can specify what every parameter is if you want.</li>
</ol>
","4948165","","","3","467","Eran Moshe","2015-05-28 08:26:52","1614","193","153","9","49049431","49049517","2018-03-01 12:07:20","0","168","<p>Whats the best way to refactor this code to clean it up:</p>

<p>1) Selects from the db adding a column for the percentage difference between two columns</p>

<p>2) Loops through the values of the columns</p>

<p>3) If the date is in the past </p>

<p>4) If the price is greater than 500 and the percentage difference is less than 1st argument set flag to 1</p>

<p>5) Else if the price is less than 500 and the percentage difference is less than 
2nd argument set flag to 1</p>

<p>6) Otherwise keep the flag as 0</p>

<pre><code>def calculateEmployeeSpend(read_cursor, flag_higher_amount, flag_lower_budget):

    read_cursor.execute(""SELECT distinct b.employee_id, b.amount, ""
                ""s.spend, b.date, b.amount - s.spend as spend_left,  ""
                ""100.0*(b.amount - s.spend) / b.amount As PercentDiff FROM employee_budget_upload ""
                ""As b JOIN employee_budget_spent As s ON  b.employee_id = s.employee_id where b.amount != 0"")

    for employee_id, amount, spend, date, spend_left, percent_diff in read_cursor:
        flag=0
        date_of_amount = dt.strptime(date, ""%d/%m/%Y"")
        if date_of_amount &lt;= dt.now():
            if amount &gt; 500 and percent_diff &lt; int(flag_higher_amount):
                flag=1

            if amount &lt; 500 and percent_diff &lt; int(flag_lower_amount):
                flag=1
</code></pre>

<p>Edit: </p>

<p>I have changed the ifs to one if: </p>

<pre><code>if amount &gt; 500 and percent_diff &lt; int(flag_higher_amount) or amount &lt; 500 and percent_diff &lt; int(flag_lower_amount):
                    flag=1
</code></pre>
","763179","763179","2018-03-01 12:24:21","Refactoring if statements and other code in python","<python>","3","2","1617"
"49049527","2018-03-01 12:13:25","0","","<p>I used seleneum which was perfect for this job, it is indeed slow but fits my purpose. I also used the seleneum firefox plugin to generate the python script as it was very challenging to find where exactly in the code as the button I had to press.</p>
","1435354","","","0","255","user1435354","2012-06-04 14:13:00","8","3","0","0","49041589","49041925","2018-03-01 02:12:42","0","560","<p>I have a problem getting javascript content into HTML to use it for scripting. I used multiple methods as phantomjs or python QT library and they all get most of the content in nicely but the problem is that there are javascript buttons inside the page like this:</p>

<p><a href=""https://i.stack.imgur.com/6hYVH.png"" rel=""nofollow noreferrer"">Pls see screenshot here</a></p>

<p>Now when I load this page from a script these buttons won't default to any value so I am getting back 0 for all SELL/NEUTRAL/BUY values below. Is there a way to set these values when you load the page from a script?</p>

<p>Example page with all the values is: <a href=""https://www.tradingview.com/symbols/NEBLBTC/technicals/"" rel=""nofollow noreferrer"">https://www.tradingview.com/symbols/NEBLBTC/technicals/</a></p>

<p>Any help would be greatly appreciated.</p>
","1435354","","","Scraping webpage generated by javascript","<python><web-scraping><scrapy><web-crawler><screen-scraping>","2","1","847"
"49049559","2018-03-01 12:15:36","3","","<p>C code such as this:</p>

<pre><code>#include &lt;stdio.h&gt;

int c;

int f (void)
{
  return 1;
}

int g (void)
{
  return ++c;
}

int main()
{
  c = 3;

  printf(""%d"", f() + g() + c);

  return 0;
}
</code></pre>

<p>does <em>not</em> invoke undefined behavior. It does however invoke <em>unspecified</em> behavior. These are different, formal terms: <a href=""https://stackoverflow.com/questions/2397984/undefined-unspecified-and-implementation-defined-behavior"">Undefined, unspecified and implementation-defined behavior</a> </p>

<p>Note first that <code>f() + g() + c</code> is <em>grouped</em> as <code>(f() + g()) + c</code> but that tells you nothing about the order in which the terms themselves are actually <em>evaluated</em>.</p>

<p>The result of this code can either be <code>1 + (3+1) + 3 = 8</code> or <code>1 + (3+1) + 4 = 9</code>, depending on if the operand <code>g()</code> is evaluated before or after the operand <code>c</code>. The order of evaluation of operands of the <code>+</code> operator is <em>unspecified</em>, so we can't know which operand that gets evaluated first, nor should we write code that relies on a certain order. </p>

<p>The code will only ever give either of the two mentioned results, it will not do anything completely crazy, like crashing or giving garbage results, which code containing <em>undefined</em> behavior could do. An example of undefined behavior would be <code>c++ + c++</code>.</p>

<p>The difference between the examples is where the <em>side effects</em> take place. See <a href=""https://stackoverflow.com/questions/4176328/undefined-behavior-and-sequence-points"">Undefined behavior and sequence points</a> </p>
","584518","2380830","2018-03-01 12:48:22","6","1683","Lundin","2011-01-21 13:46:43","122403","15108","1847","6077","49048370","49049400","2018-03-01 11:09:02","4","527","<p>In <strong>C</strong> or <strong>C++</strong> I know that there is something called </p>

<blockquote>
  <p>undefined behaviour</p>
</blockquote>

<p>In expression evaluation when some of the the expressions have side-effects. let's say I want to calculate the following:</p>

<pre><code>c = 10
f() + g() + c
</code></pre>

<p>but at some point g makes c = 5.(c is a glob variable)</p>

<p>What would be the behavior in python? Would it be undefined as <strong>C</strong>?</p>
","9004008","667266","2018-03-01 12:06:08","Undefined Behaviour in Python","<python><c++><c>","3","9","480"
"49049565","2018-03-01 12:16:04","3","","<p>I would try something like this:</p>

<pre><code>house_names = ['houseA', 'houseB', ...]
houses_dict = {}

for house in house_names:
    houses_dict[house] = {}

    with open(house + '.txt') as f:
        for line in f:
            species, num = line.rsplit(maxsplit=1)  # split off rightmost word
            houses_dict[house][species] = int(num)
</code></pre>

<p>The result will then be (e.g.):</p>

<pre><code>houses_dict = {
    'houseA': {
        'cats': 3
        'dogs': 1
        'birds': 4
    },
    'houseB': {
        'cats': 5
        'dogs': 3
        'birds': 1
    }
    ...
}
</code></pre>
","6445069","6445069","2018-03-01 12:47:24","10","615","Phydeaux","2016-06-09 11:15:54","2150","165","730","164","49049378","49049565","2018-03-01 12:03:52","2","64","<p>I have multiple text files. Each file is a list of animals and their counts for a house. Like this:</p>

<p>houseA.txt</p>

<pre><code>cats 3  
dogs 1  
birds 4
</code></pre>

<p>houseB.txt</p>

<pre><code>cats 5  
dogs 3  
birds 1
</code></pre>

<p>I have about 20 houses and each house has about 16000 species (so each file has about 16000 lines. All houses have the same species, just different counts for each specie. </p>

<p>My current script loops through each file, line by line, and captures the house, specie name and its count.</p>

<p>I want to create a dictionary of houses, where each house is a dictionary of animals and their counts. So from the example above, the result would look like this:</p>

<pre><code>dictOfDicts{houseA:{'cats': 3, 'dogs': 1, 'birds': 4}, houseB:{'cats': 5, 'dogs': 3, 'birds': 1}}
</code></pre>

<p>In case you're wondering, this will later be turned into a table:</p>

<pre><code>      house:   A   B
animal         
  cats         3   5
  dogs         1   3
 birds         4   1
</code></pre>

<p>Here's my script:</p>

<pre><code>#!/usr/bin/python3
import sys


houseL = []
dictList = []
with open(sys.argv[1], 'r') as files:
    for f in files:
        f = f.rstrip()
        with open(f, 'r') as aniCounts:
            house = str(aniCounts).split(sep='/')[2]  # this and the next line captures the house name from the file name.
            house = house.split('.')[0]
            houseL.append(house)

            for line in aniCounts:
                ani = line.split()[0]
                count = line.split()[1]
                #print(ani, ' ', count)
</code></pre>

<p>EDIT: Changed question to dict of dicts, thanks to a helpful commenter.</p>
","3140033","8710265","2018-03-01 12:24:07","Create multiple dynamic dictionaries in a dictionary","<python><python-3.x>","3","4","1702"
"49049612","2018-03-01 12:19:33","2","","<p><code>sqlite</code> interprets the <code>@</code> symbol, like <code>?</code>, as <a href=""https://www.sqlite.org/lang_expr.html"" rel=""nofollow noreferrer"">a parameter placeholder</a> (Search for ""Parameters""). If <code>@var1</code> is the name of a column, then it must escaped by surrounding it with backticks:</p>

<pre><code>df = pd.read_sql_query(
    con = conn,
    sql = """"""SELECT * FROM {table}
        WHERE `@var1` = (?)
        AND `@var2` = (?)
        AND `@var3` = (?)"""""".format(table=table),
    params= (value1, value2, value3), )
</code></pre>

<p>I <a href=""https://stackoverflow.com/a/49049513/190597"">agree with @AdiC</a>, though -- it would be more convenient to <a href=""https://stackoverflow.com/q/805363/190597"">rename your columns</a> so that they do not use characters with special meaning.</p>
","190597","190597","2018-03-01 12:26:27","0","825","unutbu","2009-10-15 12:48:20","601449","35556","17233","661","49049246","49049612","2018-03-01 11:56:47","1","1178","<p>I am trying to put together a SQL query in python pandas. I have attempted different methods, but always getting the following error: 
<code>Incorrect number of bindings supplied. The current statement uses 6, and there are 3 supplied.</code></p>

<p>My code is as follows. What am I doing wrong?</p>

<pre><code>conn = sqlite3.connect(my_db)
df = pd.read_sql_query(
    con = conn,
    sql = """"""SELECT * FROM {table}
        WHERE @var1 = (?)
        AND @var2 = (?)
        AND @var3 = (?)
        ;"""""".format(table=table),
    params= (value1, value2, value3),
    )
</code></pre>
","6071128","","","Pandas read_sql_query using multiple AND statements","<python><sql><pandas>","2","3","587"
"49049637","2018-03-01 12:21:20","0","","<p>You only ever fetch the contents of the page once, at the beginning of your script:</p>

<pre class=""lang-py prettyprint-override""><code>source = driver.page_source

bs_source = bs4.BeautifulSoup(source, ""lxml"")
</code></pre>

<p>As you navigate the calendar by clicking ""Next"", <code>bs_source</code> will continue to contain the source for the first page, meaning you will forever be re-processing the first page.</p>

<p>The simplest fix is to instantiate <code>bs_source</code> at the start of your loop, before you look for any elements.</p>
","199806","","","3","550","Ian Lesperance","2009-10-30 17:12:54","3757","155","9","4","49042607","49043867","2018-03-01 04:25:00","0","44","<pre><code>from selenium import webdriver
from selenium.webdriver.firefox.options import Options
import bs4
import datetime
import time

#options = Options()
#options.add_argument(""--headless"")
#driver = webdriver.Firefox(firefox_options=options)

driver = webdriver.Firefox()

driver.get(""https://www.rankonesport.com/Calendar/?D=e8bb5c10-8d0c-4b26-
b304-262397124de8"")

weekly = driver.find_element_by_id(""cmd_Weekly"").click()

source = driver.page_source

bs_source = bs4.BeautifulSoup(source, ""lxml"")

month = datetime.date.today().month

year_end = 5
total = 12
times = 0

if month &lt;= year_end:
    times = year_end - month

if month == year_end:
    times = 1

if month &gt;= year_end:
    value = month - year_end

    times = total - value

times *= 5

mylist = []
#{EventName:[Date, Where, Time(Start), Time(End)]}
mydict = {}

for x in range(times):


    events = bs_source.find('table', id='gv_Events')


    for tr in events.find_all('tr', class_='lightgray'):

        td = tr.find_all('td')
        mylist.append(td)

    for tr2 in events.find_all('tr', class_='white'):

        td2 = tr2.find_all('td')
        mylist.append(td2)

    next = driver.find_element_by_id('lnk_Next_Day').click()


for event in mylist:
    mydict.update({event[0].text: [event[2].text, event[1].text, 
    event[3].text, event[4].text]})

print(mylist)
print(mydict)
</code></pre>

<p>So my school has an online calendar that I am trying to scrape off of. My goal is to pull each event, that happens before the school year ends, and their corresponding properties such as time and date. </p>

<p>I have the script loop through the calendar portion that has the events by week and pull them off. The calendar is a JS based calendar so the link does not change when the script goes and clicks the next button. I store the events and their properties in a list and then throw them into a dictionary in order to easily access them by name. </p>

<p>What I want to happen is the dictionary to be full of as many events as the script loops through. Rather the dictionary only contains a select few which seem to be the first couple of events it parses through. The events have the same HTML ids and classes when the next page is pulled up so it should just rinse and repeat the code as many times as I have it.</p>

<p>If someone could point something out that I missed or lead me in the right direction that would be awesome as I have spent way to much time trying to figure this out myself.</p>

<p>Links:</p>

<p><a href=""https://www.rankonesport.com/Calendar/Daily.aspx?S=&amp;D=e8bb5c10-8d0c-4b26-b304-262397124de8&amp;Date=2/28/2018"" rel=""nofollow noreferrer"">Calendar</a><br>
<a href=""http://prntscr.com/il7hin"" rel=""nofollow noreferrer"">Calendar Outline</a></p>

<p>Dictionary Output:</p>

<pre><code>{'Sadie Ticket Sales': ['3/1/2018', 'New Cafeteria, 541 Chartres St. LaSalle, Lasalle, IL 61301', '11:00 AM', '1:00 PM'], 
 'Winter Guard Practice': ['3/3/2018', ' East Gym, 541 Chartres St. LaSalle, Lasalle, IL 61301', '5:00 PM', '8:00 PM'], 
 'Sadie Dance': ['3/3/2018', 'Sellett Gym, 541 Chartres St. LaSalle, Lasalle, IL 61301', '8:00 PM', '11:00 PM']}
</code></pre>

<p>^Should be way, way more events</p>

<p>List output:</p>

<pre><code>[[&lt;td&gt;Sadie Ticket Sales&lt;/td&gt;, &lt;td&gt;New Cafeteria, 541 Chartres St. LaSalle, Lasalle, IL 61301&lt;/td&gt;, &lt;td&gt;2/26/2018&lt;/td&gt;, &lt;td&gt;11:00 AM&lt;/td&gt;, &lt;td&gt;1:00 PM&lt;/td&gt;, &lt;td&gt;Non-Game Activity&lt;/td&gt;, &lt;td align=""center""&gt;&lt;a href=""javascript:__doPostBack('gv_Events','Outlook$0')""&gt;Sync&lt;/a&gt;&lt;/td&gt;],
 [&lt;td&gt;Winter Guard Practice&lt;/td&gt;, &lt;td&gt;North Balcony, 541 Chartres St. LaSalle, Lasalle, IL 61301&lt;/td&gt;, &lt;td&gt;2/27/2018&lt;/td&gt;, &lt;td&gt;6:30 PM&lt;/td&gt;, &lt;td&gt;9:00 PM&lt;/td&gt;, &lt;td&gt;Non-Game Activity&lt;/td&gt;, &lt;td align=""center""&gt;&lt;a href=""javascript:__doPostBack('gv_Events','Outlook$2')""&gt;Sync&lt;/a&gt;&lt;/td&gt;],
 ...]
</code></pre>

<p>It seems to repeat those events over and over in the list ^</p>

<p>Thanks.</p>

<p>Edit 1:</p>

<pre><code>mylist = []
#{EventName:[Date, Where, Time(Start), Time(End)]}
mydict = {}

for x in range(5):

    source = driver.page_source

    bs_source = bs4.BeautifulSoup(source, 'lxml')
    events = bs_source.find('table', id='gv_Events')


    for tr in events.find_all('tr', class_='lightgray'):

        td = tr.find_all('td')
        mylist.append(td)

    for tr2 in events.find_all('tr', class_='white'):

        td2 = tr2.find_all('td')
        mylist.append(td2)

    next = driver.find_element_by_id('lnk_Next_Day').click()


for event in mylist:
    mydict.update({event[0].text: [event[2].text, event[1].text, 
    event[3].text, event[4].text]})
</code></pre>
","8414357","8414357","2018-03-02 01:38:12","Trouble with updating lists and dictionaries in a for loop","<python><selenium><for-loop><beautifulsoup><html-parsing>","2","0","4797"
"49049654","2018-03-01 12:22:18","1","","<p>Try the <code>transpose</code> function. You simply change the first two axes.</p>

<pre><code>t = np.transpose(a, axes=(1, 0, 2))
</code></pre>
","7057528","","","0","148","jsmolka","2016-10-22 15:01:21","608","39","127","1","49049535","49049657","2018-03-01 12:14:07","0","76","<p>I have a 3 dimensional numpy array similar to this:</p>

<pre><code>a = np.array([[[1, 2],
               [3, 4]],
              [[5, 6],
               [7, 8]],
              [[9, 10],
               [11, 12]]])
</code></pre>

<p>What I'd like to do is intersperse each 2D array contained inside the outer array to produce this result:</p>

<pre><code>t = np.array([[[1, 2], [5, 6], [9, 10]],
              [[3, 4], [7, 8], [11, 12]]])
</code></pre>

<p>I could do this in Python like this, but I'm hoping there's a more efficient, numpy version:</p>

<pre><code>t = np.empty((a.shape[1], a.shape[0], a.shape[2]), a.dtype)
for i, x in np.ndenumerate(a):
   t[i[1], i[0], i[2]] = x
</code></pre>
","2422432","418374","2018-03-01 12:32:30","Intersperse items of a numpy array","<python><arrays><numpy><multidimensional-array>","2","4","699"
"49049657","2018-03-01 12:22:28","1","","<p>As @UdayrajDeshmukh said, you can use the <code>transpose</code> method (which, despite the name that evokes the ""transpose"" operator in linear algebra, is better understood as ""permuting the axes""):</p>

<pre><code>&gt;&gt;&gt; t = a.transpose(1, 0, 2)
&gt;&gt;&gt; t
array([[[ 1,  2],
        [ 5,  6],
        [ 9, 10]],

       [[ 3,  4],
        [ 7,  8],
        [11, 12]]])
</code></pre>

<p>The newly created object <code>t</code> is a shallow array looking into <code>a</code>'s data with a different permutation of indices.  To replicate your own example, you need to <code>copy</code> it, e.g. <code>t = a.transpose(1, 0, 2).copy()</code></p>
","418374","","","0","657","Cong Ma","2010-08-12 12:06:02","6529","597","249","19","49049535","49049657","2018-03-01 12:14:07","0","76","<p>I have a 3 dimensional numpy array similar to this:</p>

<pre><code>a = np.array([[[1, 2],
               [3, 4]],
              [[5, 6],
               [7, 8]],
              [[9, 10],
               [11, 12]]])
</code></pre>

<p>What I'd like to do is intersperse each 2D array contained inside the outer array to produce this result:</p>

<pre><code>t = np.array([[[1, 2], [5, 6], [9, 10]],
              [[3, 4], [7, 8], [11, 12]]])
</code></pre>

<p>I could do this in Python like this, but I'm hoping there's a more efficient, numpy version:</p>

<pre><code>t = np.empty((a.shape[1], a.shape[0], a.shape[2]), a.dtype)
for i, x in np.ndenumerate(a):
   t[i[1], i[0], i[2]] = x
</code></pre>
","2422432","418374","2018-03-01 12:32:30","Intersperse items of a numpy array","<python><arrays><numpy><multidimensional-array>","2","4","699"
"49049666","2018-03-01 12:23:08","0","","<p>If your 2 dataframes are <code>df1</code> and <code>df2</code> respectively, this is one way:</p>

<pre><code>s = df2.set_index('Country Code')['Country Name']
df1['Country Code'] = df1['Country Code'].map(s).fillna(df1['Country Code'])
</code></pre>

<p>This is also possible via <code>replace</code>, but <code>map</code> + <code>fillna</code> is generally more efficient.</p>
","9209546","","","0","382","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49047506","49049666","2018-03-01 10:22:56","1","81","<p>Hi, I have two data frames, one containing:-</p>

<pre><code>&lt;p&gt;Country Code | Population &lt;/p&gt;
</code></pre>

<p>and another containing:-</p>

<pre><code>&lt;p&gt;Country Code | Country Name. &lt;/p&gt;
</code></pre>

<p>I want to do a replace in the first data frame so that CountryCode = CountryName where applicable. Important to note if the lookup failed, i.e. no CountryCode matched in second data frame I would like to keep as is. Any ideas how this can be done? </p>

<p>Sample:-</p>

<pre><code>&lt;p&gt;Country Code | Population &lt;/p&gt;
&lt;p&gt;RSA | 100&lt;/p&gt;
&lt;p&gt;POL | 50&lt;/p&gt;

&lt;p&gt; Country Code | Country Name &lt;/p&gt;
&lt;p&gt; RSA | South Africa &lt;/p&gt;
</code></pre>

<p> Expected Output for DF1</p>

<pre><code>&lt;p&gt; Country Code | Population &lt;/p&gt;
&lt;p&gt; South Africa | 100 &lt;/p&gt;
&lt;p&gt; POL | 50 &lt;/p&gt;
</code></pre>
","6494381","9209546","2018-03-01 12:21:07","Replace Column in Data Frame from Lookup of other Data Frame","<python><pandas><dataframe>","2","2","901"
"49049665","2018-03-01 12:23:08","0","","<p>Since there seems to be several instances of keeping track of state, it might help in the long run to decouple the logic into classes and methods.</p>
","2630028","","","0","154","solstice333","2013-07-29 11:02:05","1591","115","747","4","49049431","49049517","2018-03-01 12:07:20","0","168","<p>Whats the best way to refactor this code to clean it up:</p>

<p>1) Selects from the db adding a column for the percentage difference between two columns</p>

<p>2) Loops through the values of the columns</p>

<p>3) If the date is in the past </p>

<p>4) If the price is greater than 500 and the percentage difference is less than 1st argument set flag to 1</p>

<p>5) Else if the price is less than 500 and the percentage difference is less than 
2nd argument set flag to 1</p>

<p>6) Otherwise keep the flag as 0</p>

<pre><code>def calculateEmployeeSpend(read_cursor, flag_higher_amount, flag_lower_budget):

    read_cursor.execute(""SELECT distinct b.employee_id, b.amount, ""
                ""s.spend, b.date, b.amount - s.spend as spend_left,  ""
                ""100.0*(b.amount - s.spend) / b.amount As PercentDiff FROM employee_budget_upload ""
                ""As b JOIN employee_budget_spent As s ON  b.employee_id = s.employee_id where b.amount != 0"")

    for employee_id, amount, spend, date, spend_left, percent_diff in read_cursor:
        flag=0
        date_of_amount = dt.strptime(date, ""%d/%m/%Y"")
        if date_of_amount &lt;= dt.now():
            if amount &gt; 500 and percent_diff &lt; int(flag_higher_amount):
                flag=1

            if amount &lt; 500 and percent_diff &lt; int(flag_lower_amount):
                flag=1
</code></pre>

<p>Edit: </p>

<p>I have changed the ifs to one if: </p>

<pre><code>if amount &gt; 500 and percent_diff &lt; int(flag_higher_amount) or amount &lt; 500 and percent_diff &lt; int(flag_lower_amount):
                    flag=1
</code></pre>
","763179","763179","2018-03-01 12:24:21","Refactoring if statements and other code in python","<python>","3","2","1617"
"49049678","2018-03-01 12:23:37","0","","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.replace.html"" rel=""nofollow noreferrer""><code>replace</code></a> by <code>Series</code> created by <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.set_index.html"" rel=""nofollow noreferrer""><code>set_index</code></a>:</p>

<pre><code>s = DF2.set_index('Country Code')['Country Name']
DF1['Country Code'] = DF1['Country Code'].replace(s)
print (DF1)
   Country Code  Population
0  South Africa         100
1           POL          50
</code></pre>
","2901002","2901002","2018-03-01 12:28:44","0","562","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49047506","49049666","2018-03-01 10:22:56","1","81","<p>Hi, I have two data frames, one containing:-</p>

<pre><code>&lt;p&gt;Country Code | Population &lt;/p&gt;
</code></pre>

<p>and another containing:-</p>

<pre><code>&lt;p&gt;Country Code | Country Name. &lt;/p&gt;
</code></pre>

<p>I want to do a replace in the first data frame so that CountryCode = CountryName where applicable. Important to note if the lookup failed, i.e. no CountryCode matched in second data frame I would like to keep as is. Any ideas how this can be done? </p>

<p>Sample:-</p>

<pre><code>&lt;p&gt;Country Code | Population &lt;/p&gt;
&lt;p&gt;RSA | 100&lt;/p&gt;
&lt;p&gt;POL | 50&lt;/p&gt;

&lt;p&gt; Country Code | Country Name &lt;/p&gt;
&lt;p&gt; RSA | South Africa &lt;/p&gt;
</code></pre>

<p> Expected Output for DF1</p>

<pre><code>&lt;p&gt; Country Code | Population &lt;/p&gt;
&lt;p&gt; South Africa | 100 &lt;/p&gt;
&lt;p&gt; POL | 50 &lt;/p&gt;
</code></pre>
","6494381","9209546","2018-03-01 12:21:07","Replace Column in Data Frame from Lookup of other Data Frame","<python><pandas><dataframe>","2","2","901"
"49049755","2018-03-01 12:29:01","2","","<p>One more version:</p>

<pre><code>from path import Path

dir_path = '/TEMP'

files_ls = [x for x in Path(dir_path).files() if 'house' in str(x)]

def read_file(path):
    lines = dict([row.strip().split(' ') for row in path.open(encoding='utf-8')])
    return lines

all_data = dict([(str(x.name),read_file(x)) for x in files_ls])

print(all_data)
</code></pre>

<p>Output:</p>

<pre><code>{'house1.txt': {u'birds': u'4', u'cats': u'3', u'dogs': u'1'}}
</code></pre>
","7373458","","","2","470","brc","2017-01-04 09:44:52","121","10","7","0","49049378","49049565","2018-03-01 12:03:52","2","64","<p>I have multiple text files. Each file is a list of animals and their counts for a house. Like this:</p>

<p>houseA.txt</p>

<pre><code>cats 3  
dogs 1  
birds 4
</code></pre>

<p>houseB.txt</p>

<pre><code>cats 5  
dogs 3  
birds 1
</code></pre>

<p>I have about 20 houses and each house has about 16000 species (so each file has about 16000 lines. All houses have the same species, just different counts for each specie. </p>

<p>My current script loops through each file, line by line, and captures the house, specie name and its count.</p>

<p>I want to create a dictionary of houses, where each house is a dictionary of animals and their counts. So from the example above, the result would look like this:</p>

<pre><code>dictOfDicts{houseA:{'cats': 3, 'dogs': 1, 'birds': 4}, houseB:{'cats': 5, 'dogs': 3, 'birds': 1}}
</code></pre>

<p>In case you're wondering, this will later be turned into a table:</p>

<pre><code>      house:   A   B
animal         
  cats         3   5
  dogs         1   3
 birds         4   1
</code></pre>

<p>Here's my script:</p>

<pre><code>#!/usr/bin/python3
import sys


houseL = []
dictList = []
with open(sys.argv[1], 'r') as files:
    for f in files:
        f = f.rstrip()
        with open(f, 'r') as aniCounts:
            house = str(aniCounts).split(sep='/')[2]  # this and the next line captures the house name from the file name.
            house = house.split('.')[0]
            houseL.append(house)

            for line in aniCounts:
                ani = line.split()[0]
                count = line.split()[1]
                #print(ani, ' ', count)
</code></pre>

<p>EDIT: Changed question to dict of dicts, thanks to a helpful commenter.</p>
","3140033","8710265","2018-03-01 12:24:07","Create multiple dynamic dictionaries in a dictionary","<python><python-3.x>","3","4","1702"
"49049800","2018-03-01 12:32:20","0","","<p>Maybe you can try <a href=""https://github.com/pyenv/pyenv"" rel=""nofollow noreferrer"">pyenv</a> to manage the python versions. <em>pyenv</em> allows you to set the python version (3.* or 2.*) globally, locally (in a specific project) or even in the current shell session (do some tests for example). Here is a short <a href=""http://bizhishui.com/Manage-Pythons"" rel=""nofollow noreferrer"">post</a> on how to install and use pyenv on Ubuntu and Mac.</p>
","6031168","","","0","454","Ming","2016-03-07 20:42:40","1","12","0","0","48920478","","2018-02-22 05:48:41","1","2726","<p>I want to import a package called mglearn that I installed in Python 3.</p>

<p>But keep getting the following error;</p>

<pre><code>ModuleNotFoundError: No module named 'mglearn'
</code></pre>

<p>I installed this package using the following command
(I have multiple Python environments on the same MAC.)</p>

<pre><code>$ python3.6 -m pip install --trusted-host pypi.python.org mglearn
</code></pre>

<p>I'm not sure if the following is the right way to confirm mglearn installed in Python3 but saw this; </p>

<pre><code>$ python3 -c ""help('modules')""|grep mglearn
_curses_panel       cmath               mglearn             stringprep
</code></pre>

<p>The PATH of my Mac is</p>

<pre><code>PATH=/Library/Frameworks/Python.framework/Versions/2.7/bin:/Library/Frameworks/Python.framework/Versions/3.6/bin:/Users/firstname.surname/.pyenv/versions/anaconda3-2.5.0/bin/:/Users/firstname.surname/.pyenv/shims:/Users/firstname.surname/.pyenv/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/sbin:/Applications/Wireshark.app/Contents/MacOS
</code></pre>

<p>Can anyone tell me what I need to do to import mglearn?</p>
","9179951","","","Python 3 on Mac : ModuleNotFoundError: No module named 'mglearn'","<python><python-3.x><python-import><importerror>","2","6","1130"
"49049809","2018-03-01 12:32:37","1","","<p>In the late 80's this may have been a simple task, just render some html to an image instead of the screen.</p>

<p>But these days web-pages require client-side execution to build parts of its DOM and re-render based on client-side initiated AJAX (or equivalent) requests... it's a whole thing ""web 2.0"" thing.</p>

<p>Rendering a web-site such as <a href=""http://google.com"" rel=""nofollow noreferrer"">http://google.com</a> as a simple html return should be easy, but rendering something like <a href=""https://www.facebook.com/"" rel=""nofollow noreferrer"">https://www.facebook.com/</a> or <a href=""https://www.kogan.com/"" rel=""nofollow noreferrer"">https://www.kogan.com/</a> will have many back &amp; fourth comms to display what you're expecting to see.</p>

<p>So restricting this to a pure python solution may not be plausible; I'm not aware of a python-based browser.
Consider running a separate service to take the screenshots, and use your core application (in python) to fetch requested screenshots.</p>

<p>I just tried a few with docker, many of them struggle with <code>https</code> and the aforementioned <code>ajax</code> behaviour.</p>

<p><a href=""https://hub.docker.com/r/earlyclaim/docker-manet/"" rel=""nofollow noreferrer"">earlyclaim/docker-manet</a> appears to work <a href=""https://manet.herokuapp.com/"" rel=""nofollow noreferrer"">demo page</a></p>

<p>edit: from your comments, you need the data from a graph that's rendered using a 2nd request.</p>

<p>you just need the json return from <a href=""https://www.minnowbooster.net/limit/chart"" rel=""nofollow noreferrer"">https://www.minnowbooster.net/limit/chart</a></p>

<pre><code>try:
    from urllib.request import urlopen  # py3
except ImportError:
    from urllib2 import urlopen  # py2
import json

url = 'https://www.minnowbooster.net/limit/chart'

response = urlopen(url)
data_str = response.read().decode()
data = json.loads(data_str)

print(data)
</code></pre>
","3016042","3016042","2018-03-01 13:14:57","5","1938","FraggaMuffin","2013-11-21 05:03:38","2192","83","125","8","49049208","49049809","2018-03-01 11:54:33","-3","1747","<p>How to make screenshot from any url (web page)?</p>

<p>I was trying:</p>

<pre><code>from .ghost import Ghost
ghost = Ghost(wait_timeout=4)
ghost.open('http://www.google.com')
ghost.capture_to('screen_shot.png')
</code></pre>

<p>Result:</p>

<pre><code>No module named '__main__.ghost'; '__main__' is not a package
</code></pre>

<p>I was trying also:</p>

<p><a href=""https://stackoverflow.com/questions/6572575/python-webkit-making-web-site-screenshots-using-virtual-framebuffer"">Python Webkit making web-site screenshots using virtual framebuffer</a></p>

<p><a href=""https://stackoverflow.com/questions/44926240/take-screenshot-of-multiple-urls-using-selenium-python"">Take screenshot of multiple URLs using selenium (python)</a></p>

<p><a href=""https://stackoverflow.com/questions/3586046/fastest-way-to-take-a-screenshot-with-python-on-windows"">Fastest way to take a screenshot with python on windows</a></p>

<p><a href=""https://stackoverflow.com/questions/12563350/take-a-screenshot-of-open-website-in-python-script"">Take a screenshot of open website in python script</a></p>

<p><strong>I've also tried other methods that are not listed here.</strong>
Nothing succeeded. Or an error or module is not found .. or or or.
I'm tired. Is there an easy way to make a screenshot of a web page using Python 3.X?</p>

<p>upd1:</p>

<pre><code>C:\prg\PY\PUMA\tests&gt;py save-web-html.py
Traceback (most recent call last):
File ""save-web-html.py"", line 2, in &lt;module&gt;
from .ghost import Ghost
ModuleNotFoundError: No module named '__main__.ghost'; '__main__' is not a package
</code></pre>

<p>upd2:</p>

<pre><code>C:\prg\PY\PUMA\tests&gt;py save-web-html.py
Exception ignored in: &lt;bound method Ghost.__del__ of &lt;ghost.ghost.Ghost object at 0x0000020A169CF860&gt;&gt;
Traceback (most recent call last):
  File ""C:\Users\Coar\AppData\Local\Programs\Python\Python36\lib\site-packages\ghost\ghost.py"", line 325, in __del__
    self.exit()
  File ""C:\Users\Coar\AppData\Local\Programs\Python\Python36\lib\site-packages\ghost\ghost.py"", line 315, in exit
    self._app.quit()
AttributeError: 'NoneType' object has no attribute 'quit'
Traceback (most recent call last):
  File ""save-web-html.py"", line 4, in &lt;module&gt;
    ghost = Ghost(wait_timeout=4)
TypeError: __init__() got an unexpected keyword argument 'wait_timeout'
</code></pre>
","8494024","8494024","2018-03-01 12:25:31","How to make screenshot from web page?","<python><python-3.x><module><screenshot><webpage>","1","5","2354"
"49049812","2018-03-01 12:32:45","1","","<p>While the difference has been answered by many answers, <a href=""https://mail.python.org/pipermail/python-list/2016-April/707470.html"" rel=""nofollow noreferrer"">https://mail.python.org/pipermail/python-list/2016-April/707470.html</a> makes an interesting point:</p>

<p>TL;DR: It's better to just raise a ""normal"" exception, and use <code>SystemExit</code> or <code>sys.exit</code> only at the top levels of a script.</p>

<blockquote>
  <blockquote>
    <p>I m on python 2.7 and Linux ,  I have a simple code  need suggestion if  I
    I could replace sys.exit(1) with raise  SystemExit .</p>
    
    <p>==Actual code==</p>

<pre><code>def main():    
    try:
       create_logdir()
       create_dataset()
       unittest.main()    
     except Exception as e:
       logging.exception(e)
       sys.exit(EXIT_STATUS_ERROR)

if __name__ == '__main__':    main()
</code></pre>
    
    <p>==Changed Code==</p>

<pre><code>def main():    
    try:
       create_logdir()
       create_dataset()
       unittest.main()    
    except Exception as e:
       logging.exception(e)
       raise SystemExit

if __name__ == '__main__':    
    main()
</code></pre>
  </blockquote>
  
  <p>I am against both of these personally. My preferred pattern is like
  this:</p>

<pre><code>  def main(argv):
    try:
      ...
    except Exception as e:
      logging.exception(e)
      return 1

  if __name__ == '__main__':
    sys.exit(main(sys.argv))
</code></pre>
  
  <p>Notice that main() is back to being a normal function with normal
  returns.</p>
  
  <p>Also, most of us would avoid the ""except Exception"" and just let a top
  level  except bubble out: that way you get a stack backtrace for
  debugging. I agree it  prevents logging the exception and makes for
  uglier console output, but I think  it is a win. And if you <em>do</em> want
  to log the exception there is always this:</p>
  
  <p>try:
      ...   except Exception as e:
      logging.exception(e)
      raise</p>
  
  <p>to recite the exception into the log and still let it bubble out
  normally.</p>
  
  <p>The problem with the ""except Exception"" pattern is that it catches and
  <em>hides</em> 
  <em>every</em> exception, not merely the narrow set of specific exceptions that you  understand.</p>
  
  <p>Finally, it is frowned upon to raise a bare Exception class. In 
  python 3 I  believe it is actually forbidden, so it is nonportable
  anyway. But even In  Python to it is best to supply an Exception
  instance, not the class:</p>
  
  <p>raise SystemExit(1)</p>
  
  <blockquote>
    <ol start=""2"">
    <li><p>All the functions in try block have exception bubbled out using raise</p>
    
    <p>Example for create_logdir() here is the function definition</p></li>
    </ol>
    
    <p>def create_logdir():</p>
    
    <p>try:
           os.makedirs(LOG_DIR)
       except OSError as e:
           sys.stderr.write(""Failed to create log directory...Exiting !!!"")
           raise
       print ""log file: "" + corrupt_log
       return True</p>
    
    <p>def main():
       try:
           create_logdir()
       except Exception as e:
           logging.exception(e)
           raise SystemExit</p>
    
    <p>(a) In case if create_logdir() fails we will get the below error ,is
    this fine or do I need to improve this code.</p>
    
    <p>Failed to create log directory...Exiting !!!ERROR:root:[Errno 17] File
    exists: '/var/log/dummy'</p>
    
    <p>Traceback (most recent call last):
     File ""corrupt_test.py"", line 245, in main
       create_logdir()
     File ""corrupt_test.py"", line 53, in create_logdir
       os.makedirs(LOG_DIR)
     File ""/usr/local/lib/python2.7/os.py"", line 157, in makedirs
    OSError: [Errno 17] File exists: '/var/log/dummy'</p>
  </blockquote>
  
  <p>I prefer the bubble out approach, perhap with a log or warning
  messages as you  have done, eg:</p>
  
  <p>logging.exception(""create_logdir failed: makedirs(%r): %s"" %
  (LOG_DIR, e))   raise</p>
  
  <p>(Also not that that log message records more context: context is very
  useful  when debugging problems.)</p>
  
  <p>For very small scripts sys.stderr.write is ok, but in general any of
  your  functions that turned out to be generally useful might migrate
  into a library  in order to be reused; consider that stderr is not
  always the place for  messages; instead reading for the logging module
  with error() or wanr() or  exception() as appropriate. There is more
  scope for configuring where the  output goes that way without wiring
  it into your inner functions.</p>
  
  <blockquote>
    <ol start=""3"">
    <li><p>Can I have just raise , instead of SystemExit or sys.exit(1) . This
    looks wrong to me</p>
    
    <p>def main():</p>
    
    <p>try:
       create_logdir()
    except Exception as e
       logging.exception(e)
       raise</p></li>
    </ol>
  </blockquote>
  
  <p>This is what I would do, myself.</p>
  
  <p>Think: has the exception been ""handled"", meaning has the situation
  been dealt  with because it was expected? If not, let the exception
  bubble out so that the  user knows that something <em>not</em> understood by
  the program has occurred.</p>
  
  <p>Finally, it is generally bad to SystemExit or sys.exit() from inside
  anything  other than the outermost main() function. And I resist it
  even there; the main  function, if written well, may often be called
  from somewhere else usefully,  and that makes it effectively a library
  function (it has been reused). Such a  function should not
  unilaterally abort the program. How rude! Instead, let the  exception
  bubble out: perhaps the <em>caller</em> of main() expects it and can handle 
  it. By aborting and not ""raise""ing, you have deprived the caller of
  the chance  to do something appropriate, even though you yourself
  (i.e. ""main"") do not know  enough context to handle the exception.</p>
  
  <p>So I am for ""raise"" myself. And then only because you want to log the
  error. If  you didn't want to log the exception you could avoid the
  try/except <em>entirely</em>  and have simpler code: let the caller worry
  about unhandled exceptions!</p>
</blockquote>
","1587329","","","0","6164","serv-inc","2012-08-09 11:15:03","19899","1344","5524","0","13992662","13992762","2012-12-21 15:20:15","42","41156","<p>Reading online some programmers use <code>sys.exit</code>, others use <code>SystemExit</code>.<br>
Sorry for the basic question:</p>

<ol>
<li>What is the difference?</li>
<li>When do I need to use SystemExit or sys.exit inside a function?</li>
</ol>

<p>Example</p>

<pre><code>ref = osgeo.ogr.Open(reference)
if ref is None:
    raise SystemExit('Unable to open %s' % reference)
</code></pre>

<p>or</p>

<pre><code>ref = osgeo.ogr.Open(reference)
if ref is None:
    print('Unable to open %s' % reference)
    sys.exit(-1)
</code></pre>
","1493192","2228912","2015-09-06 01:17:55","Python: using sys.exit or SystemExit differences and suggestions","<python><performance><coding-style>","7","3","543"
"49049870","2018-03-01 12:35:56","0","","<p>This gave me the correct output:</p>

<pre><code>for item in cl_used_items_raw[:2]:
    for k in wanted_keys:
        if k == 'Description':
            lines = str(''.join(item[k])).split()
            split_lines = [line.replace('\n', '').strip() for line in lines]
            split_lines = ' '.join(split_lines)
            print(split_lines)
        else:
            lines = str(item[k]).split()
            split_lines = [line.replace('\n', '').strip() for line in lines]
            print(""{}"".format(' '.join(split_lines) + '\t'))       
    print('\n')
</code></pre>
","7892695","","","0","580","Keenan Burke-Pitts","2017-04-20 00:12:20","127","95","32","0","49039340","","2018-02-28 22:02:18","2","85","<p>I have a list of items that are structured similarly to this:</p>

<pre><code>[{'Condition': '2013 Yamaha FJR 1300',
 'Date': '2018-02-28 11:30',
 'Description': ['\n        ',
  '\n2013 Yamaha FJR 1300 Sport Touring, 4 cylinder, 12.120 miles, silver, cruise control, traction control, ABS brakes, heated hand grips, Two Brothers exhaust, handle bar risers, 6.5 gal. gas tank, adjustable windshield, saddlebags, excellent condition, very clean.',
  '\n$ 7.500 (828) 250-0373 WWW.GREENVALLEYCARS.COM',
  '\n',
  '\n    '],
 'Images': [],
 'Latitude': '35.599694',
 'Location': ' (Asheville)',
 'Longitude': '-82.628866',
 'Price': '$7500',
 'Title': '2013 Yamaha FJR 1300',
 'Url': 'https://asheville.craigslist.org/mcd/d/2013-yamaha-fjr-1300/6513320993.html',
 '_id': {'$oid': '5a96dbee6f9ca5410cc9ed98'}},

{'Condition': '2014 Honda Accord Sedan',
 'Date': '2018-02-28 11:24',
 'Description': ['\n        ',
  '\n2014 Honda Accord  Automatic, White , On Tan, It has Only 41,980 Miles It Has Spoiler, Power Windows, and Mirrors, Tan Cloth Seats, Power Seats, 4 Cylinder, 4 Door, Radio, 6 CD Changer, FM,AM,CD, XM Radio, Bluetooth, Back up Camera, Side and Curtain Air Bag, 16 Inch Factory Wheels with Firestone  Great Tires, Tinted Glass, And Much More, Clean On inside, Runs and Drives Like New, Call Me for more info, 864-266-6936 Willing to Negotiate if offer is fair.....',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\nhonda, bmw, crv, mercedes, ford, mazda, lx, rx, ls, is, gs, 470 honda, lexus, toyota, ford, accord, civic, coupe, Mercedes,Honda Pilot, Lexus gx470 &amp; 460, Chevrolet Tahoe, suburban, Tahoe, land rover, Nissan armada, GMC Yukon, Terrian, CX7, BMW x5, GMC Terrian, B 2011, 2010, 2009, 2008, 2007, 2012, 2013, 2014, 2016, 2006, 2005, 2017, 2018, ',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n',
  '\n    '],
 'Images': ['https://images.craigslist.org/00b0b_gNOi9VtqAy3_600x450.jpg',
  'https://images.craigslist.org/00a0a_gs2eKxUlQho_600x450.jpg',
  'https://images.craigslist.org/00l0l_lPmE8ML0zcb_600x450.jpg',
  'https://images.craigslist.org/00x0x_bS9gCuxM7ID_600x450.jpg',
  'https://images.craigslist.org/01010_dTS4DnHjVWW_600x450.jpg',
  'https://images.craigslist.org/00w0w_70D0xeDKa7d_600x450.jpg',
  'https://images.craigslist.org/00606_4SUFT4ZCbmO_600x450.jpg',
  'https://images.craigslist.org/00k0k_1AQ7kVbviPN_600x450.jpg',
  'https://images.craigslist.org/00d0d_3STBecGHaXD_600x450.jpg',
  'https://images.craigslist.org/01717_guG6n90XfQt_600x450.jpg',
  'https://images.craigslist.org/00h0h_8be8866trLr_600x450.jpg',
  'https://images.craigslist.org/00B0B_gaQQvQHlARl_600x450.jpg',
  'https://images.craigslist.org/00b0b_ih84Nskx5xj_600x450.jpg',
  'https://images.craigslist.org/01616_aveWbY1HQvr_600x450.jpg',
  'https://images.craigslist.org/00x0x_Fflsg0wwsK_600x450.jpg',
  'https://images.craigslist.org/00b0b_6FBg7KV8HYv_600x450.jpg',
  'https://images.craigslist.org/00J0J_3vd5Ip3mQ5S_600x450.jpg',
  'https://images.craigslist.org/00L0L_loNV2CrnnLn_600x450.jpg',
  'https://images.craigslist.org/00K0K_fh8oSEa9fKn_600x450.jpg',
  'https://images.craigslist.org/00r0r_8P0SjsOgNd5_600x450.jpg',
  'https://images.craigslist.org/00k0k_ZY0ywNmKkr_600x450.jpg',
  'https://images.craigslist.org/00y0y_7Gie7XD8uuH_600x450.jpg',
  'https://images.craigslist.org/00c0c_2nVDzLJhnYi_600x450.jpg',
  'https://images.craigslist.org/00202_7k10eK3bxMn_600x450.jpg'],
 'Latitude': '35.039000',
 'Location': ' (Cowpens)',
 'Longitude': '-81.822000',
 'Price': '$10995',
 'Title': '2014 Honda Accord  White  41k',
 'Url': 'https://asheville.craigslist.org/ctd/d/2014-honda-accord-white-41k/6513312696.html',
 '_id': {'$oid': '5a96dbf16f9ca5410cc9ed99'}}]
</code></pre>

<p>When I run the following code:</p>

<pre><code>wanted_keys = ['Title', 'Location', 'Price', 'Description', 'Url', 'Latitude', 'Longitude'] 
for item in cl_used_items_raw[:2]:
    for k in wanted_keys:
        lines = str(item[k]).split()
        split_lines = [line.replace('\n', '').strip() for line in lines]
        print(""{}"".format(' '.join(split_lines) + '\t'))
    print('\n')
</code></pre>

<p>I get an ouput of:</p>

<pre><code>2013 Yamaha FJR 1300    
(Asheville) 
$7500   
['\n ', '\n2013 Yamaha FJR 1300 Sport Touring, 4 cylinder, 12.120 miles, silver, cruise control, traction control, ABS brakes, heated hand grips, Two Brothers exhaust, handle bar risers, 6.5 gal. gas tank, adjustable windshield, saddlebags, excellent condition, very clean.', '\n$ 7.500 (828) 250-0373 WWW.GREENVALLEYCARS.COM', '\n', '\n ']    
https://asheville.craigslist.org/mcd/d/2013-yamaha-fjr-1300/6513320993.html 
35.599694   
-82.628866  


2014 Honda Accord White 41k 
(Cowpens)   
$10995  
['\n ', '\n2014 Honda Accord Automatic, White , On Tan, It has Only 41,980 Miles It Has Spoiler, Power Windows, and Mirrors, Tan Cloth Seats, Power Seats, 4 Cylinder, 4 Door, Radio, 6 CD Changer, FM,AM,CD, XM Radio, Bluetooth, Back up Camera, Side and Curtain Air Bag, 16 Inch Factory Wheels with Firestone Great Tires, Tinted Glass, And Much More, Clean On inside, Runs and Drives Like New, Call Me for more info, 864-266-6936 Willing to Negotiate if offer is fair.....', '\n', '\n', '\n', '\n', '\n', '\n', '\nhonda, bmw, crv, mercedes, ford, mazda, lx, rx, ls, is, gs, 470 honda, lexus, toyota, ford, accord, civic, coupe, Mercedes,Honda Pilot, Lexus gx470 &amp; 460, Chevrolet Tahoe, suburban, Tahoe, land rover, Nissan armada, GMC Yukon, Terrian, CX7, BMW x5, GMC Terrian, B 2011, 2010, 2009, 2008, 2007, 2012, 2013, 2014, 2016, 2006, 2005, 2017, 2018, ', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n '] 
https://asheville.craigslist.org/ctd/d/2014-honda-accord-white-41k/6513312696.html  
35.039000   
-81.822000
</code></pre>

<p>I know I'm close but I'm struggling to determine how to write my for-loop to remove the additional whitespace characters in Description values while still maintaining the structure of the output I already have?</p>
","7892695","7892695","2018-02-28 23:37:10","Removing Unwanted Characters From List","<python><python-3.x><list><for-loop><whitespace>","3","0","6060"
"49049874","2018-03-01 12:36:09","0","","<p>the way I see it, your problem would be solved if you would have your module or package installed, like an yother package one installs and then imports (numpy, xml, json etc.)</p>

<p>I also have a package I constantly use in all my projects, <a href=""https://github.com/PetronelaCretu/pyUtilities"" rel=""nofollow noreferrer"">ulitilies</a>, and I know it's a pain with the importing.</p>

<p>here is a description on how to How to package a python application to make it pip-installable:
<a href=""https://marthall.github.io/blog/how-to-package-a-python-app/"" rel=""nofollow noreferrer"">https://marthall.github.io/blog/how-to-package-a-python-app/</a></p>
","5010285","","","0","656","Petronella","2015-06-15 07:34:40","664","99","10","2","48759465","","2018-02-13 04:28:48","10","1943","<p>I'm trying to keep a data science project well-organized so I've created a directory inside my <code>src</code> directory called <code>utils</code> that contains a file called <code>helpers.py</code>, which contains some helper functions that will be used in many scripts. What is the best practice for how I should import <code>func_name</code> from <code>src/utils/helpers.py</code> into a file in a totally different directory, such as <code>src/processing/clean_data.py</code>?</p>

<p>I see <a href=""https://stackoverflow.com/questions/4383571/importing-files-from-different-folder"">answers</a> to this question, and I've implemented a solution that works, but this feels ugly:</p>

<pre><code> sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))))
</code></pre>

<p>Am I doing this right? Do I need to add this to every script that wants to import <code>func_name</code>, like <code>train_model.py</code>?</p>

<p>My current project folder structure:</p>

<pre><code>myproject
    /notebooks
        notebook.ipynb
    /src
        /processing
            clean_data.py
        /utils
            helpers.py
        /models
            train_model.py
        __init__.py
</code></pre>

<p>Example files:</p>

<pre><code># clean_data.py

import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))))
from src.utils.helpers import func_name

func_name()


# helpers.py

def func_name():
    print('I'm a helper function.')
</code></pre>
","2569531","3154233","2018-02-13 04:38:12","Do I need to add my project directory to the system path in every script to import a function from another directory?","<python>","7","4","1542"
"49049881","2018-03-01 12:36:54","0","","<pre><code>lst = [{0 : 0.68426, 1: 0.26423}, {2: 0.6842332, 0: 0.9823}]

res = {}
for x in lst:
    for key, value in x.items():
        if key in res:
            res[key].append(value)
        else:
            res[key] = [value]
</code></pre>

<p>This returns you a dictionary of the form <code>{0: [0.68426, 0.9823]}</code> because this <code>{0 : 0.68426, 0: 0.9823}</code> is not possible.</p>
","7057528","","","0","400","jsmolka","2016-10-22 15:01:21","608","39","127","1","49049649","49049943","2018-03-01 12:22:03","-2","55","<pre><code>def query_RR(postings, qtext): 
   words = tokenize(qtext) 
   allpostings = [postings[w] for w in words]
   for a in allpostings: 
       print a.keys()
</code></pre>

<p>And this was the result of the query</p>

<pre><code>[0, 2, 3, 4, 6]
[1, 4, 5]
[0, 2, 4]
[4, 5] 
</code></pre>

<p>The query is taking a user input term (<code>qtext</code>), tokenizing and generating a postings list for each token. </p>

<p>The posting list is a list of nested dictionaries.
e.g. </p>

<pre><code>[{0 : 0.68426, 1: 0.26423}, {2: 0.6842332, 0: 0.9823}] 
</code></pre>

<p>For the common keys, how would you access the corresponding values, for my example the common value is <code>0</code>so how would you access values <code>{0 : 0.68426, 0: 0.9823}</code>?</p>
","9367401","6162307","2018-03-01 12:24:26","For the common keys, how would you access the corresponding values","<python><list><dictionary><key>","2","1","763"
"49049891","2018-03-01 12:37:31","1","","<p>Solved the issue in a slightly different way using offset (guess after a given time even I can learn it).</p>

<p>Since after the instance where I send a message I dont need the old updates anymore I used this:</p>

<pre><code>def get_update_id(updates):
    num_updates = len(updates[""result""])
    last_update = num_updates - 1
    update_id = updates[""result""][last_update][""update_id""]
    return (update_id)
</code></pre>

<p>where updates equals:</p>

<pre><code>def get_updates(OFFSET):
    url = URL + ""getUpdates?offset={}"".format(OFFSET)
    js = get_json_from_url(url)
    return js
</code></pre>

<p>As said the def is called after the send_message statement in the form of:</p>

<pre><code>OFFSET = get_update_id(get_updates(OFFSET))
</code></pre>

<p>which will make sure the last update in getUpdates will be the first update once the code is ran again</p>
","9422871","","","2","875","Wietse de Vries","2018-02-28 08:51:38","26","2","0","0","49025582","49049891","2018-02-28 09:01:56","2","1029","<p>I have recently been trying to create a functional telegram BOT using the official API but I have some issues. The BOT's goal is to forward all the messages received from person x to group y. </p>

<p>The BOT checks ""<a href=""https://api.telegram.org/bot"" rel=""nofollow noreferrer"">https://api.telegram.org/bot</a>{}/getUpdates"".format(TOKEN) for its latest received message so it can check what that message is and if it is send by person x. And this all used to work until my url stopped updating itself after it hit 100 records.</p>

<p>There must be a way to clear those records on an automatic basis right? I read a bit about ""-offset"" and tried to implement it via URL Query string, but it didn't seem to have a result.</p>

<p>Thank you for your help.</p>
","9422871","397817","2018-02-28 09:46:34","How to work around getUpdates limit? (Telegram BOT)","<python><bots><telegram>","2","0","766"
"49049919","2018-03-01 12:38:55","0","","<p>The issue here stems from a different behaviour of the <code>filter</code> method. You can see that in <a href=""https://stackoverflow.com/questions/41666977/python-2-vs-python-3-difference-in-behavior-of-filter"">this question</a>, or read up on it in the <a href=""https://docs.python.org/3/library/functions.html#filter"" rel=""nofollow noreferrer"">python3</a> or <a href=""https://docs.python.org/2.7/library/functions.html#filter"" rel=""nofollow noreferrer"">python2</a> docs.</p>

<p>In short: In python 2 it generates a <strong>list</strong>, so <code>ind_list[:][1]</code> are all lists of integers.</p>

<p>However, in python 3 it generates a <code>generator</code>, which is why you get the output <code>TypeError: int() argument must be a string, a bytes-like object or a number, not 'filter'</code>, since <code>ind_list[:][1]</code> all contain filter objects.</p>

<p>You can either convert all the outputs of the filter commands in the creation of <code>ind_list</code> to a list:</p>

<pre><code>list(filter(lambda x: x not in range(0,l//10))
</code></pre>

<p>or use python2. But I am guessing there is a specific reason for you to use python3</p>

<p><strong>Hint:</strong></p>

<p>Since you are using anaconda, you can simply do</p>

<pre><code>conda create -n py27 python=2.7 sklearn pandas numpy
</code></pre>

<p>followed by</p>

<pre><code>activate py27
</code></pre>

<p>in an anaconda prompt and it will give you a virtual environment with python2 to use</p>
","5012099","","","2","1479","FlyingTeller","2015-06-15 16:07:49","4958","597","62","128","49049291","","2018-03-01 11:59:11","-2","39","<p>I tried to test a code written in python 2 in free access <a href=""https://github.com/zhurak/kaggle-prudential"" rel=""nofollow noreferrer"">here</a>. When I run the code I encountered the following error related to <code>list</code></p>

<p>Many thanks for helps<br>
Jane
(I'm a newbee in python)</p>

<pre><code>Traceback       
    `(C:\Users\myusername\Anaconda3) C:\Users\myusername\Documents\DSSP7\Projet 
        Insurance\kaggle-prudential-master\code&gt;python.exe logRegression.py
        Traceback (most recent call last):
        File ""logRegression.py"", line 98, in &lt;module&gt;
        y_1, y_2 = train_ohd.iloc[X_1]['Response'], train_ohd.iloc[X_2]['Response']
        File ""C:\Users\myusername\Anaconda3\lib\site-
        packages\pandas\core\indexing.py"", line 1328, in __getitem__
        return self._getitem_axis(key, axis=0)
        File ""C:\Users\myusername\Anaconda3\lib\site-
        packages\pandas\core\indexing.py"", line 1738, in _getitem_axis
        return self._get_list_axis(key, axis=axis)
        File ""C:\Users\myusername\Anaconda3\lib\site-
        packages\pandas\core\indexing.py"", line 1715, in _get_list_axis
        return self.obj.take(key, axis=axis, convert=False)
        File ""C:\Users\myusername\Anaconda3\lib\site-
        packages\pandas\core\generic.py"", line 1928, in take
        convert=True, verify=True)
        File ""C:\Users\myusername
        \Anaconda3\lib\site-packages\pandas\core\internals.py"", line 3998, in take
        else np.asanyarray(indexer, dtype='int64'))
        File ""C:\Users\myusername
        Anaconda3\lib\site-packages\numpy\core\numeric.py"", line 583, in asanyarray
        return array(a, dtype, copy=False, order=order, subok=True)
        TypeError: int() argument must be a string, a bytes-like object or a number, 
        not 'filter' 
</code></pre>

<p><strong>logRegression.py</strong>    </p>

<pre><code>'import pandas as pd 
from sklearn.linear_model import LogisticRegression
import json
from sklearn import metrics
from label_decoders import *

config = json.load(open('settings.json'))
train = pd.read_csv(config['train'])
test = pd.read_csv(config['test'])

# combine train and test
all_data = train.append(test)

# Preprocess data

# create any new variables    
all_data['Product_Info_2_char'] = all_data.Product_Info_2.str[0]
all_data['Product_Info_2_num'] = all_data.Product_Info_2.str[1]

# factorize categorial variables
all_data['Product_Info_2'] = pd.factorize(all_data['Product_Info_2'])[0]
all_data['Product_Info_2_char'] = pd.factorize(all_data['Product_Info_2_char'])[0]
all_data['Product_Info_2_num'] = pd.factorize(all_data['Product_Info_2_num'])[0]

## combine features
# BMI by age
all_data['BMI_Age'] = all_data['BMI'] * all_data['Ins_Age']

## sum features
#  Med keyword sum
med_keyword_columns = all_data.columns[all_data.columns.str.startswith('Medical_Keyword_')]
all_data['Med_Keywords_Count'] = all_data[med_keyword_columns].sum(axis=1)

# handle missing values : eliminate missing values
## Use -1 for NA
all_data.apply(lambda x: sum(x.isnull()),1)
all_data['countna'] = all_data.apply(lambda x: sum(x.isnull()),1)
all_data.fillna(-1, inplace=True)

#fix the dtype of the label column(convert it to integer)
all_data['Response'] = all_data['Response'].astype(int)

# split train and test
train_ohd = all_data[all_data['Response']&gt;0].copy()
test_ohd = all_data[all_data['Response']&lt;1].copy()

# convert data 
features=train_ohd.columns.tolist()
features = [x.replace('=','_') for x in features]
features = [x.replace('_','i') for x in features]
train_ohd.columns = features
features_t=test_ohd.columns.tolist()
features_t = [x.replace('=','i') for x in features_t]
features_t = [x.replace('_','i') for x in features_t]
test_ohd.columns = features_t

features.remove(""Id"")
features.remove(""Response"")

train_ohd['lr1'] = [0]*train_ohd.shape[0]
train_ohd['lr2'] = [0]*train_ohd.shape[0]
train_ohd['lr3'] = [0]*train_ohd.shape[0]
train_ohd['lr4'] = [0]*train_ohd.shape[0]
train_ohd['lr5'] = [0]*train_ohd.shape[0]
train_ohd['lr6'] = [0]*train_ohd.shape[0]
train_ohd['lr7'] = [0]*train_ohd.shape[0]
train_ohd['lr8'] = [0]*train_ohd.shape[0]
train_ohd['lr9'] = [0]*train_ohd.shape[0]
train_ohd['lr10'] = [0]*train_ohd.shape[0]
train_ohd['lr11'] = [0]*train_ohd.shape[0]
train_ohd['lr12'] = [0]*train_ohd.shape[0]
train_ohd['lr13'] = [0]*train_ohd.shape[0]


l = train_ohd.shape[0]
ind_list = [(range(0,l//10), filter(lambda x: x not in range(0,l//10), range(0,l))), 
            (range(l//10,l//10*2), filter(lambda x: x not in range(l//10,l//10*2), range(0,l))),
            (range(l//10*2,l//10*3), filter(lambda x: x not in range(l//10*2,l//10*3), range(0,l))),
            (range(l//10*3,l//10*4), filter(lambda x: x not in range(l//10*3,l//10*4), range(0,l))),
            (range(l//10*4,l//10*5), filter(lambda x: x not in range(l//10*4,l//10*5), range(0,l))),
            (range(l//10*5,l//10*6), filter(lambda x: x not in range(l//10*5,l//10*6), range(0,l))),
            (range(l//10*6,l//10*7), filter(lambda x: x not in range(l//10*6,l//10*7), range(0,l))),
            (range(l//10*7,l//10*8), filter(lambda x: x not in range(l//10*7,l//10*8), range(0,l))),
            (range(l//10*8,l//10*9), filter(lambda x: x not in range(l//10*8,l//10*9), range(0,l))),
            (range(l//10*9,l), filter(lambda x: x not in range(l//10*9,l), range(0,l)))]



ld = [labels_decoder1,labels_decoder2,labels_decoder3,labels_decoder4,labels_decoder5,labels_decoder6,labels_decoder7,
      labels_decoder8,labels_decoder9,labels_decoder10,labels_decoder11,labels_decoder12,labels_decoder13]

# train the model
i = 0
for l in ld:
    i = i + 1    

    for j in range(10):

        X_1, X_2 = ind_list[j][1], ind_list[j][0]
        y_1, y_2 = train_ohd.iloc[X_1]['Response'], train_ohd.iloc[X_2]['Response']

# get preds based on train data      
        lr = LogisticRegression(random_state=1)
        lr.fit(train_ohd[features].iloc[X_1],l(y_1))
        train_ohd['lr%s' % (i)].iloc[X_2] = lr.predict_proba(train_ohd[features].iloc[X_2]).T[1]


train_ohd.to_csv(config['train_lr'],index=0)

y = train_ohd['Response']
#print(y)  mon rajout pour afficher en local

# test the model
i = 0
for l in ld:
    i = i + 1    

# Pas de y dans le test data

# get preds based on test data
###1
    lr = LogisticRegression(random_state=1)
    lr.fit(train_ohd[features],l(y)), i
    test_ohd['lr%s' % (i)] = lr.predict_proba(test_ohd[features]).T[1]

test_ohd.to_csv(config['test_lr'],index=0)
#y_pred = test_ohd   A SPEFICIER ce que l'on doit afficher cf kaggle ET A PRINT
#y_pred = test_ohd.to_csv(config['test_lr'],index=0)
`    
</code></pre>
","9340681","9149062","2018-03-01 12:17:41","Python 3 OS windows 10 error handling lists","<python><list><integer><python-2.x><kaggle>","1","2","6656"
"49049943","2018-03-01 12:40:56","0","","<p>Here is one way:</p>

<pre><code>lst = [{0: 0.68426, 1: 0.26423}, {2: 0.6842332, 0: 0.9823}] 

[d[0] for d in lst]       # [0.68426, 0.9823]
</code></pre>

<p>Or if you need a dictionary:</p>

<pre><code>{0: [d[0] for d in lst]}  # {0: [0.68426, 0.9823]}
</code></pre>

<p>If you need to work out your common dictionary keys:</p>

<pre><code>{i: [d[i] for d in lst] for i in set.intersection(*map(set, lst))}

# {0: [0.68426, 0.9823]}
</code></pre>

<p>Note that dictionary keys must be unique, so your required output is not possible.</p>
","9209546","9209546","2018-03-01 12:51:08","0","543","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49049649","49049943","2018-03-01 12:22:03","-2","55","<pre><code>def query_RR(postings, qtext): 
   words = tokenize(qtext) 
   allpostings = [postings[w] for w in words]
   for a in allpostings: 
       print a.keys()
</code></pre>

<p>And this was the result of the query</p>

<pre><code>[0, 2, 3, 4, 6]
[1, 4, 5]
[0, 2, 4]
[4, 5] 
</code></pre>

<p>The query is taking a user input term (<code>qtext</code>), tokenizing and generating a postings list for each token. </p>

<p>The posting list is a list of nested dictionaries.
e.g. </p>

<pre><code>[{0 : 0.68426, 1: 0.26423}, {2: 0.6842332, 0: 0.9823}] 
</code></pre>

<p>For the common keys, how would you access the corresponding values, for my example the common value is <code>0</code>so how would you access values <code>{0 : 0.68426, 0: 0.9823}</code>?</p>
","9367401","6162307","2018-03-01 12:24:26","For the common keys, how would you access the corresponding values","<python><list><dictionary><key>","2","1","763"
"49049944","2018-03-01 12:41:00","10","","<p>This is my solution, Works with Sendgrid V3</p>

<pre><code>    # Where it was uploaded Path.
    file_path = ""MY_FILE_PATH""

    with open(file_path, 'rb') as f:
        data = f.read()

    # Encode contents of file as Base 64
    encoded = base64.b64encode(data).decode()

    """"""Build attachment""""""
    attachment = Attachment()
    attachment.content = encoded
    attachment.type = ""application/pdf""
    attachment.filename = ""my_pdf_attachment.pdf""
    attachment.disposition = ""attachment""
    attachment.content_id = ""PDF Document file""

    sg = sendgrid.SendGridAPIClient(apikey=settings.SENDGRID_API_KEY)

    from_email = Email(""origin@gmail.com"")
    to_email = Email('recipient@gmail.com')
    content = Content(""text/html"", html_content)

    mail = Mail(from_email, 'Attachment mail PDF', to_email, content)
    mail.add_attachment(attachment)

    try:
        response = sg.client.mail.send.post(request_body=mail.get())
    except urllib.HTTPError as e:
        print(e.read())
        exit()
</code></pre>
","3061689","3061689","2018-03-15 23:28:32","0","1030","Eddwin Paz","2013-12-03 13:42:37","1762","622","236","37","40656019","40658111","2016-11-17 13:19:34","8","7691","<p>I'm trying to attach a PDF file to my email sent with sendgrid.</p>

<p>Here is my code :</p>

<pre><code>sg = sendgrid.SendGridAPIClient(apikey=os.environ.get('SENDGRID_API_KEY'))

from_email = Email(""from@example.com"")
subject = ""subject""
to_email = Email(""to@example.com"")
content = Content(""text/html"", email_body)

pdf = open(pdf_path, ""rb"").read().encode(""base64"")
attachment = Attachment()
attachment.set_content(pdf)
attachment.set_type(""application/pdf"")
attachment.set_filename(""test.pdf"")
attachment.set_disposition(""attachment"")
attachment.set_content_id(number)

mail = Mail(from_email, subject, to_email, content)
mail.add_attachment(attachment)

response = sg.client.mail.send.post(request_body=mail.get())

print(response.status_code)
print(response.body)
print(response.headers)
</code></pre>

<p>But the Sendgrid Python library is throwing an error HTTP Error 400: Bad Request. </p>

<p>What is wrong with my code ?</p>
","2519631","","","Python Sendgrid send email with PDF attachment file","<python><pdf><email-attachments><sendgrid>","3","2","941"
"49049978","2018-03-01 12:42:46","0","","<p>If you do not want to split yourself, use a <a href=""https://docs.python.org/3/library/csv.html#csv.DictReader"" rel=""nofollow noreferrer"">csv.DictReader</a> and ensure any animal with spaces inside its name is quoted in the file:</p>

<pre><code>from csv import DictReader

d = {}
files = [""h1.csv"",""h2.csv""]

for f in files:
  with open(f,""r"",encoding=""utf8"",newline="""") as  houseData:
    d[f] = {} # dict per house
    for row in DictReader(houseData, fieldnames=[""animal"",""count""], delimiter=' ' ):
      d[f][row[""animal""]] = int(row[""count""])  # access by given fieldnames

print(d)
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>{'h1.csv': {'cats': 3, 'dogs': 1, 'birds': 4}, 
 'h2.csv': {'cats': 5, 'dogs': 3, 'birds': 1, 'insects': 2402, 'Blue Flutterwings': 2}}
</code></pre>

<p><em>File</em> h1.csv</p>

<pre><code>cats 3
dogs 1
birds 4
</code></pre>

<p><em>File</em> h2.csv</p>

<pre><code>cats 5
dogs 3
birds 1
insects 2402
""Blue Flutterwings"" 2
</code></pre>

<p><strong>Caveat:</strong> If you harbour <code>Green Cantilopes</code> or <code>Blue Flutterwings</code> in your house, you have to quote them in the file - thats where this solution starts to shine - as it will automagically handle quoted strings in combination with <code>' '</code>  as delimiter .</p>
","7505395","7505395","2018-03-01 12:49:29","1","1298","Patrick Artner","2017-02-02 10:46:51","30736","5120","3506","4713","49049378","49049565","2018-03-01 12:03:52","2","64","<p>I have multiple text files. Each file is a list of animals and their counts for a house. Like this:</p>

<p>houseA.txt</p>

<pre><code>cats 3  
dogs 1  
birds 4
</code></pre>

<p>houseB.txt</p>

<pre><code>cats 5  
dogs 3  
birds 1
</code></pre>

<p>I have about 20 houses and each house has about 16000 species (so each file has about 16000 lines. All houses have the same species, just different counts for each specie. </p>

<p>My current script loops through each file, line by line, and captures the house, specie name and its count.</p>

<p>I want to create a dictionary of houses, where each house is a dictionary of animals and their counts. So from the example above, the result would look like this:</p>

<pre><code>dictOfDicts{houseA:{'cats': 3, 'dogs': 1, 'birds': 4}, houseB:{'cats': 5, 'dogs': 3, 'birds': 1}}
</code></pre>

<p>In case you're wondering, this will later be turned into a table:</p>

<pre><code>      house:   A   B
animal         
  cats         3   5
  dogs         1   3
 birds         4   1
</code></pre>

<p>Here's my script:</p>

<pre><code>#!/usr/bin/python3
import sys


houseL = []
dictList = []
with open(sys.argv[1], 'r') as files:
    for f in files:
        f = f.rstrip()
        with open(f, 'r') as aniCounts:
            house = str(aniCounts).split(sep='/')[2]  # this and the next line captures the house name from the file name.
            house = house.split('.')[0]
            houseL.append(house)

            for line in aniCounts:
                ani = line.split()[0]
                count = line.split()[1]
                #print(ani, ' ', count)
</code></pre>

<p>EDIT: Changed question to dict of dicts, thanks to a helpful commenter.</p>
","3140033","8710265","2018-03-01 12:24:07","Create multiple dynamic dictionaries in a dictionary","<python><python-3.x>","3","4","1702"
"49049985","2018-03-01 12:43:11","0","","<pre><code>#!/usr/bin/python
import sys
def check_ip(address):
    part=address.split(""."")
    temp=True
    if len(part) != 4:
            temp=False
            return temp
    for p in part:
            if not 0&lt;= int(p) &lt;= 255:
                    temp=False
                    return temp
            else:
                    temp=True
    return temp
if __name__==""__main__"":
    print check_ip(sys.argv[1])
</code></pre>

<p>Save the code with some name say- <code>check_ip.py</code> and run it as <code>python check_ip.py 192.168.560.25</code><br>
<strong>Note:-</strong>  Above code fails for the below ip address-<br>
<code>023.65.029.33</code></p>
","4886861","","","2","667","Yogesh Jilhawar","2015-05-11 10:07:36","1499","229","46","0","3462784","3462840","2010-08-11 20:59:17","34","73671","<p>What is the fastest way to check if a string matches a certain pattern? Is regex the best way?</p>

<p>For example, I have a bunch of strings and want to check each one to see if they are a valid IP address (valid in this case meaning correct format), is the fastest way to do this using regex? Or is there something faster with like string formatting or something. </p>

<p>Something like this is what I have been doing so far:</p>

<pre><code>for st in strs:
    if re.match('\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}', st) != None:
       print 'IP!'
</code></pre>
","417722","620444","2016-07-30 20:00:33","check if a string matches an IP address pattern in python?","<python>","18","0","564"
"49050035","2018-03-01 12:46:35","0","","<p>First of all the definition of 'best' depend on your goal, like: readability, efficiency, performance and so on.</p>

<p>In many cases I wold prefer to solve task like this by reading the whole dataset in pandas DataFrame and utilise one (or set off) convenient and expressive pandas idioms.
Or, by writing more sophisticated SQL statement which allow to solve the end to end task on database side.</p>

<p>As for common best practice for refactoring, I would recommend externalise the magic values like ""500"" or ""%d/%m/%Y"" to a constant or method parameter.
Give a ""flag"" more self-spoken name. 
If case with amount exactly equal to 500 is purposely should lead to flag equal to zero, then it should be better explicitly reflected in comments.
In order to avoid code duplication (flag=1) it is better to combine the if statements, like this:</p>

<pre><code>if amount &gt; 500 and percent_diff &lt; int(flag_higher_amount) or \
   amount &lt; 500 and percent_diff &lt; int(flag_lower_amount):
    flag=1
</code></pre>

<p>You also can create a function with self-spoken name, and move whole condition inside such a function:</p>

<pre><code>if is_percent_inside_amount_bounds(
     percent_diff, amount, flag_lower_amount, flag_higher_amount):
    flag = 1
</code></pre>

<p>or just</p>

<pre><code>flag = is_percent_inside_amount_bounds(
     percent_diff, amount, flag_lower_amount, flag_higher_amount)
</code></pre>

<p>In case of amount equal exactly 500 could be interpreted like amount&lt;=500 the condition could be transformed to more laconic:</p>

<pre><code>flag = percent_diff &lt; int(
    flag_lower_amount if amount&gt;500 else flag_higher_amount)
</code></pre>

<p>but I would not recommend to use ternary operator in production code in cases like this, because it usually reduce readability.</p>
","2037068","","","0","1816","Recontemplator","2013-02-03 12:14:12","56","6","34","0","49049431","49049517","2018-03-01 12:07:20","0","168","<p>Whats the best way to refactor this code to clean it up:</p>

<p>1) Selects from the db adding a column for the percentage difference between two columns</p>

<p>2) Loops through the values of the columns</p>

<p>3) If the date is in the past </p>

<p>4) If the price is greater than 500 and the percentage difference is less than 1st argument set flag to 1</p>

<p>5) Else if the price is less than 500 and the percentage difference is less than 
2nd argument set flag to 1</p>

<p>6) Otherwise keep the flag as 0</p>

<pre><code>def calculateEmployeeSpend(read_cursor, flag_higher_amount, flag_lower_budget):

    read_cursor.execute(""SELECT distinct b.employee_id, b.amount, ""
                ""s.spend, b.date, b.amount - s.spend as spend_left,  ""
                ""100.0*(b.amount - s.spend) / b.amount As PercentDiff FROM employee_budget_upload ""
                ""As b JOIN employee_budget_spent As s ON  b.employee_id = s.employee_id where b.amount != 0"")

    for employee_id, amount, spend, date, spend_left, percent_diff in read_cursor:
        flag=0
        date_of_amount = dt.strptime(date, ""%d/%m/%Y"")
        if date_of_amount &lt;= dt.now():
            if amount &gt; 500 and percent_diff &lt; int(flag_higher_amount):
                flag=1

            if amount &lt; 500 and percent_diff &lt; int(flag_lower_amount):
                flag=1
</code></pre>

<p>Edit: </p>

<p>I have changed the ifs to one if: </p>

<pre><code>if amount &gt; 500 and percent_diff &lt; int(flag_higher_amount) or amount &lt; 500 and percent_diff &lt; int(flag_lower_amount):
                    flag=1
</code></pre>
","763179","763179","2018-03-01 12:24:21","Refactoring if statements and other code in python","<python>","3","2","1617"
"49050064","2018-03-01 12:48:16","3","","<p>There is a top-level function called <code>tostring</code> (<a href=""https://docs.python.org/3.5/library/xml.etree.elementtree.html#xml.etree.ElementTree.tostring"" rel=""nofollow noreferrer"">docs</a>) that accepts an element, try</p>

<pre><code>print([ET.tostring(product) for product in products])
</code></pre>
","1453822","","","0","316","DeepSpace","2012-06-13 13:50:35","47949","4011","628","6175","49049996","49050064","2018-03-01 12:43:54","3","371","<p>I've the following code which parses an XML response and returns a list of Element objects representing products.</p>

<pre><code>tree =  ET.ElementTree(ET.fromstring(raw_xml_response))
products = root.findall('//Product')
</code></pre>

<p>I now need to get the raw XML from each Product so I can store it in a DB.  It seems Element doesn't have a method to do this - what's the customary way to get the raw XML from each Product Element?</p>

<p>Thanks,</p>
","1004781","","","How to get raw xml as string from Element","<python><xml><soap>","1","0","463"
"49050071","2018-03-01 12:48:36","3","","<p>Second query you've described can be done with custom type, for example:</p>

<pre><code>class AllPeopleType(graphene.ObjectType):
    count = graphene.Int()
    all_persons = graphene.List(YourPersonType)

    def resolve_count(self, info, **kwargs):
        # assumed that django used on backend
        return Person.objects.count()

    def resolve_all_persons(self, info, **kwargs):
        return Person.objects.all()
</code></pre>

<p>and query:</p>

<pre><code>class YourQuery(object):
    # person = ...
    people = graphene.Field(AllPeopleType)

    def resolve_people(self, info):
        return AllPeopleType()
</code></pre>
","1099876","","","0","641","ndpu","2011-12-15 12:50:20","17106","763","1765","39","48748236","","2018-02-12 13:59:47","1","1027","<p>I have successfully created an all graphene query that responds to </p>

<pre><code>query {
    person (id: ""Mary"") {
        id
        name
    }
}
</code></pre>

<p>I now want to extend this to be able to loop through all people and return similar data for each.</p>

<pre><code>query {
    people {
        count
        allPersons {
           name
        }
    }
}
</code></pre>

<p>How do I get the <code>resolve_allPersons</code> resolver in <code>people</code> to call the <code>person</code> resolver for each person?</p>
","2302244","1099876","2018-11-14 11:11:07","Setting up a plain graphene nested query","<python><graphene-python>","1","0","536"
"49050076","2018-03-01 12:49:03","2","","<p>You can't pad your array with string literals. Instead as it's mentioned in documentation you can use a <code>pad_with</code> function as follows:</p>

<pre><code>In [79]: def pad_with(vector, pad_width, iaxis, kwargs):
    ...:     pad_value = kwargs.get('padder', '?')
    ...:     vector[:pad_width[0]] = pad_value
    ...:     vector[-pad_width[1]:] = pad_value
    ...:     return vector
    ...: 

In [80]: 

In [80]: np.pad(a, 1, pad_with)
Out[80]: 
array([['?', '?', '?', '?', '?'],
       ['?', '#', '#', '#', '?'],
       ['?', '#', '#', '#', '?'],
       ['?', '#', '#', '#', '?'],
       ['?', '?', '?', '?', '?']], dtype='&lt;U1')
</code></pre>

<p>Note that in line <code>pad_value = kwargs.get('padder', '?')</code> in <code>pad_with</code> function you should use a default padding value in case there's no padding argument provided in <code>np.pad</code>'s caller. You an pass the intended <code>padder</code> as a keyword argument to the function.</p>

<pre><code>In [82]: np.pad(a, 1, pad_with, padder='*')
Out[82]: 
array([['*', '*', '*', '*', '*'],
       ['*', '#', '#', '#', '*'],
       ['*', '#', '#', '#', '*'],
       ['*', '#', '#', '#', '*'],
       ['*', '*', '*', '*', '*']], dtype='&lt;U1')
</code></pre>
","2867928","2867928","2018-03-01 13:01:35","0","1240","Kasramvd","2013-10-10 16:10:31","83554","6938","4534","1304","49049852","49050076","2018-03-01 12:34:58","1","798","<p>I have created a 2d Numpy string array like so:</p>

<pre><code>a = np.full((2, 3), '#', dtype=np.unicode)
print(a)
</code></pre>

<p>The output is:    </p>

<pre><code>array([['#', '#', '#'], ['#', '#', '#']], dtype=`'&lt;U1'`)
</code></pre>

<p>I would like to pad it with '?' on all sides with a width of 1. I'm expecting output as:</p>

<pre><code>array([
['?', '?', '?', '?', '?'],
['?', '#', '#', '#', '?'],
['?', '#', '#', '#', '?'],
['?', '#', '#', '#', '?'],
['?', '?', '?', '?', '?']],
dtype=`'&lt;U1')
</code></pre>

<p>I tried the following:</p>

<pre><code>b = np.pad(a, ((1, 1), (1, 1)), 'constant', constant_values=(('?', '?'), ('?', '?')))
</code></pre>

<p>But that gives the following error:</p>

<pre><code>File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
File ""/usr/lib/python3/dist-packages/numpy/lib/arraypad.py"", line 1357, in pad
    cast_to_int=False)
File ""/usr/lib/python3/dist-packages/numpy/lib/arraypad.py"", line 1069, in _normalize_shape
    return tuple(tuple(axis) for axis in arr.tolist())
AttributeError: 'tuple' object has no attribute 'tolist'
</code></pre>

<p>Similar code works for integers. What am I doing wrong for strings?</p>
","6695849","1000551","2018-03-01 12:41:43","Numpy string array pad with string","<python><string><python-3.x><numpy>","2","2","1173"
"49050095","2018-03-01 12:50:01","1","","<p>This might help</p>

<pre><code>from xml.dom.minidom import parse
dom = parse('C:\Users\qxn5622\Desktop\EF10018\DEFAULT.tbc')

propertyList = dom.getElementsByTagName('PROPERTY')
for prop in propertyList:
    if prop.getAttribute('name') == ""PrjFile"":
        myString = prop.getElementsByTagName(""VALUE"")
        print myString[0].firstChild.nodeValue
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>W:\_fdsw\Projects\HIL\releases\release_9_1_0\Config\CDNG\UX_EF_TSHIL\UX_EF_TSHIL.CDP
</code></pre>
","532312","","","0","514","Rakesh","2010-12-06 13:07:54","56694","5302","758","1508","49049822","49050095","2018-03-01 12:33:34","0","37","<p>I am triying to get the String ""W:_fdsw\Projects\HIL\releases\release_9_1_0\Config\CDNG\UX_EF_TSHIL\UX_EF_TSHIL.CDP"" and save it in a variable using minidom</p>

<pre><code>        &lt;TOOL id=""CONTROLDESKNG"" xsi:type=""tool""&gt;
        &lt;TOOL-HOST xsi:type=""unicode""&gt;tsp:QMUC633107:5018&lt;/TOOL-HOST&gt;
        &lt;TOOL-NAME xsi:type=""unicode""&gt;CONTROLDESKNG&lt;/TOOL-NAME&gt;
        &lt;START-OPTION xsi:type=""integer""&gt;0&lt;/START-OPTION&gt;
        &lt;START-PRIORITY xsi:type=""integer""&gt;0&lt;/START-PRIORITY&gt;
        &lt;SETTINGS xsi:type=""dynamicPropertySet""&gt;
            &lt;PROPERTY format-rev=""1"" name=""ExpName"" propertyType=""string"" readonly=""false"" xsi:type=""_property""&gt;
                &lt;VALUE xsi:type=""unicode""&gt;K53MU&lt;/VALUE&gt;
            &lt;/PROPERTY&gt;
            &lt;PROPERTY format-rev=""1"" name=""ModelDir"" propertyType=""uri"" readonly=""false"" xsi:type=""_property""&gt;
                &lt;VALUE xsi:type=""unicode""&gt;W:\_fdsw\Projects\HIL\releases\release_9_1_0\Config\CDNG\UX_EF_TSHIL\Variable Descriptions\UX_EF_TSHIL.sdf(#14)&lt;/VALUE&gt;
            &lt;/PROPERTY&gt;
            &lt;PROPERTY format-rev=""1"" name=""PrjFile"" propertyType=""uri"" readonly=""false"" xsi:type=""_property""&gt;
                &lt;VALUE xsi:type=""unicode""&gt;W:\_fdsw\Projects\HIL\releases\release_9_1_0\Config\CDNG\UX_EF_TSHIL\UX_EF_TSHIL.CDP&lt;/VALUE&gt;
            &lt;/PROPERTY&gt;
            &lt;PROPERTY format-rev=""1"" name=""RecordingFormat"" propertyType=""string"" readonly=""false"" xsi:type=""_property""&gt;
                &lt;VALUE xsi:type=""unicode""&gt;MDF&lt;/VALUE&gt;
            &lt;/PROPERTY&gt;
            &lt;PROPERTY format-rev=""1"" name=""ToolState"" propertyType=""string"" readonly=""false"" xsi:type=""_property""&gt;
                &lt;VALUE xsi:type=""unicode""&gt;Online&lt;/VALUE&gt;
            &lt;/PROPERTY&gt;
            &lt;PROPERTY format-rev=""1"" name=""VersionCDNG"" propertyType=""string"" readonly=""false"" xsi:type=""_property""&gt;
                &lt;VALUE xsi:type=""unicode""&gt;5.5&lt;/VALUE&gt;
            &lt;/PROPERTY&gt;
            &lt;PROPERTY format-rev=""1"" name=""VersionHILAPI"" propertyType=""string"" readonly=""false"" xsi:type=""_property""&gt;
                &lt;VALUE xsi:type=""unicode""&gt;2015-B&lt;/VALUE&gt;
            &lt;/PROPERTY&gt;
        &lt;/SETTINGS&gt;
    &lt;/TOOL&gt;
</code></pre>

<p>My code is: </p>

<pre><code>xmldoc = minidom.parse('C:\Users\qxn5622\Desktop\EF10018\DEFAULT.tbc')
propertyList = xmldoc.getElementsByTagName('PROPERTY')
for prop in propertyList:
    if prop.attributes[""name""].value == ""ModelDir"":
        myString = prop.getElementsByTagName(""VALUE"").value
</code></pre>

<p>I think the problem is that the element I am trying to get doesnt have any Id.
Can anybody help me?</p>
","4769095","","","parse in a xml file an element using minidom","<python><xml><minidom>","1","0","2783"
"49050101","2018-03-01 12:50:16","0","","<p>Doc says:</p>

<blockquote>
  <p>This function only picks up the <strong>'p'</strong> tags.It doesn’t pick up the <strong>'a'</strong> tags, because those tags define both “class” and “id”. It doesn’t pick up tags like 'html' and 'title', because those tags don’t define “class”.</p>
</blockquote>

<pre><code> soup.find_all(has_class_but_no_id)
# [&lt;p class=""title""&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;,
#  &lt;p class=""story""&gt;Once upon a time there were...&lt;/p&gt;,
#  &lt;p class=""story""&gt;...&lt;/p&gt;]
</code></pre>

<p>It is unclear and it leads people to expect a result without any a tag.They should change the statement or example.</p>
","8188893","","","0","673","user8188893","2017-06-20 13:36:41","6","9","0","0","49016527","","2018-02-27 19:30:14","-1","87","<p>I am newbie in BeautifulSoup4 and learning it very intensively. The problem is with the next piece of code(I found it in documentation on the page <strong><a href=""https://www.crummy.com/software/BeautifulSoup/bs4/doc/"" rel=""nofollow noreferrer"">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a></strong>, article about function definition): </p>

<pre><code>  def has_class_but_no_id(tag):
    return tag.has_attr('class') and not tag.has_attr('id')     (A)
  soup.find_all(has_class_but_no_id)
</code></pre>

<p>I expected to get result like this(seen in the documentation):</p>

<pre><code>  # [&lt;p class=""title""&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;,
  #  &lt;p class=""story""&gt;Once upon a time there were...&lt;/p&gt;,       (B)
  #  &lt;p class=""story""&gt;...&lt;/p&gt;]  
</code></pre>

<p>But I got the next result:</p>

<pre><code>  [&lt;p class=""title""&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;, &lt;p class=""story""&gt;Once 
  upon a time there were three little sisters; and their names were
  &lt;a class=""sister"" href=""http://example.com/elsie"" id=""link1""&gt;Elsie&lt;/a&gt;,                     
  &lt;a class=""sister"" href=""http://example.com/lacie"" id=""link2""&gt;Lacie&lt;/a&gt; and
  &lt;a class=""sister"" href=""http://example.com/tillie"" id=""link3""&gt;Tillie&lt;/a&gt;; 
  and they lived at the bottom of a well.&lt;/p&gt;, &lt;p class=""story""&gt;...&lt;/p&gt;]
</code></pre>

<p>I checked documentatation and found only the method <strong>.has_attr</strong> is deprecated. And no any more details. How can I change initial code (A) to get expected result (B)? Can anybody help to fix this problem? Thnx.</p>
","7637438","7637438","2018-02-28 08:51:10","BeautifulSoup4 documentation example doesn't work","<python><function><beautifulsoup>","2","4","1667"
"49050132","2018-03-01 12:51:46","1","","<p>A few problems:</p>

<ol>
<li>Please fix the indentation. The indentation levels are mismatched.</li>
<li>There's no need to take in the parameter <code>numCats</code> as it's changed to whatever the user provides anyway.</li>
<li>You're not calling the function <code>my_fun()</code>, meaning that there will never be any output, as functions only run when called.</li>
</ol>

<p>This should work:</p>

<pre><code>def my_fun():
    print('How many cats do you have?\n')
    numCats = input()
    try:
        if int(numCats) &gt; 3:
            print('That is a lot of cats.')
        else:
            print('That is not that many cats.')
    except ValueError:
        print(""Value error"")  

my_fun() ## As the function is called, it will produce output now
</code></pre>
","7908770","7908770","2018-03-01 12:58:09","2","779","Adi219","2017-04-23 09:50:18","3109","540","642","43","49050030","49050132","2018-03-01 12:45:55","0","129","<p>I did this example but it does not run with the try and except handling errors in Python.    </p>

<pre><code>def my_fun(numCats):
    print('How many cats do you have?')
    numCats = input()
    try:
        if int(numCats) &gt;=4:
            print('That is a lot of cats')
        else:
            print('That is not that many cats')
    except ValueError:
        print(""Value error"")
</code></pre>

<p>I tried:</p>

<pre><code>except Exception:
except  (ZeroDivisionError,ValueError) as e:
except  (ZeroDivisionError,ValueError) as error:
</code></pre>

<p>I did other example and it was able to catch <code>ZeroDivisionError</code>
I am using Jupyter notebook Python 3. 
<strong>Any help in this matter is highly appreciated.</strong></p>

<p>I am calling </p>

<pre><code>my_fun(int('six'))
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-39-657852cb9525&gt; in &lt;module&gt;()
----&gt; 1 my_fun(int('six'))

ValueError: invalid literal for int() with base 10: 'six'
</code></pre>
","8826524","8826524","2018-03-01 12:58:06","Try and Except Python","<python><function><exception><error-handling><try-catch>","2","5","1116"
"49050163","2018-03-01 12:53:26","1","","<p>So - Python's dynamism allows a function to check the frame object where it was called from. .</p>

<p>It would be better if you could pass the module explicitly to the class constructor, though:</p>

<pre><code>class MyObject:
    def __init__(self, module):
         self.module = module
         ...
</code></pre>

<p>And in the other files:</p>

<pre><code>m  = MyObject(__name__)
</code></pre>

<p>But, as I mentioned in the first line, you can get to the code calling
a module - save if you have an specialized metaclass, the code calling one class's <code>__init__</code> is where the object is instantiated. So you can write:</p>

<pre><code>import inspect

class MyObject:
    def __init__(self, module):
         caller_frame = inspect.currentframe().f_back
         self.module = caller_frame.f_globals.get(""__name__"", ""&lt;unknown module&gt;"")
         ...
</code></pre>

<p>The Frame object is an internal Python object that keeps the execution state of a code context while the program is being run. It contain references to globals and locals variables available to that frame, as well as code object, current source line, and so on. The topmost frame (0) is the current frame in execution  - the second one to the top (1) is the direct caller of the current function/method. The frame <code>.f_globals</code> attribute is a direct reference to the globals dictionary - the same that would be returned if one would call <code>globals()</code> inside that frame.</p>
","108205","108205","2018-03-01 14:00:54","6","1484","jsbueno","2009-05-16 17:35:21","62274","3753","2414","235","49047336","49050163","2018-03-01 10:13:13","0","41","<p>Using <code>__name__</code> inside a method references the module where the class was defined.</p>

<p>Is there a way instead for an object to get the module where it has been instantiated?</p>
","314508","","","Module of Instance in Python","<python><class><object><module>","1","4","197"
"49050209","2018-03-01 12:56:06","1","","<p>FiPy is a Python 2 package. </p>

<ul>
<li>You can convert the code to Py3k with <code>2to3</code>:
<a href=""https://www.ctcms.nist.gov/fipy/documentation/USAGE.html#running-under-python-3"" rel=""nofollow noreferrer"">https://www.ctcms.nist.gov/fipy/documentation/USAGE.html#running-under-python-3</a></li>
<li><p>You can use conda to maintain side-by-side Py2 and Py3k installations. Conda is our <a href=""https://www.ctcms.nist.gov/fipy/INSTALLATION.html#recommended-method"" rel=""nofollow noreferrer"">recommended pathway</a> these days, anyway. Those instructions <a href=""https://github.com/usnistgov/fipy/issues/530"" rel=""nofollow noreferrer"">need to be modified</a> to ask for a specific python version: </p>

<p><code>conda create --name &lt;MYFIPYENV&gt; --channel guyer --channel conda-forge fipy nomkl python=2.7</code></p></li>
</ul>
","2019542","","","12","845","jeguyer","2013-01-28 20:38:20","846","78","12","1","49028739","49050209","2018-02-28 11:41:22","0","739","<p>I'm trying to install FiPy on Python 3.6. and ran into trouble. I followed the installation instruction from the NIST website: <a href=""https://www.ctcms.nist.gov/fipy/INSTALLATION.html"" rel=""nofollow noreferrer"">https://www.ctcms.nist.gov/fipy/INSTALLATION.html</a></p>

<p>But at the last step <code>pip install fipy</code> I get an error that I don't understand: </p>

<blockquote>
  <p>(MYFIPYENV) >pip install fipy Collecting fipy   Cache
  entry deserialization failed, entry ignored   Cache entry
  deserialization failed, entry ignored<br>
  Downloading FiPy-3.1.3.tar.gz</p>

<pre><code>Complete output from command python setup.py egg_info:
Traceback (most recent call last):
  File ""&lt;string&gt;"", line 1, in &lt;module&gt;
  File ""C:\Users\AppData\Local\Temp\pip-build-9xzf0bmv\fipy\setup.py"",
line 61
    except ImportError, e:
                      ^
SyntaxError: invalid syntax

---------------------------------------- 
</code></pre>
  
  <p>Command ""python setup.py egg_info"" failed with error code 1 in
  C:\Users\AppData\Local\Temp\pip-build-9xzf0bmv\fipy\ Cache entry
  deserialization failed, entry ignored</p>
</blockquote>

<p>Could someone please tell me what's this error about and how to fix it?</p>

<p>To not dupplicate the question I tried following hints: </p>

<pre><code>&gt;pip upgrade 
&gt;pip install --upgrade setuptools
&gt;pip install ez_setup
</code></pre>

<p>Working on Windows 10.
Thanks in advance!</p>
","9089521","","","Error while install FiPy ""Command ""python setup.py egg_info"" failed with error code 1""","<python><pip><fipy>","2","0","1451"
"49050211","2018-03-01 12:56:27","0","","<p>I would do it this way-</p>

<pre><code>import sys
import time
loading= ""LOADING\n""
bar = ""[==========]""
print(loading)
for c in bar:
    time.sleep(0.3)
    sys.stdout.write(c)
    sys.stdout.flush()
</code></pre>

<p><strong>Explanation</strong>: The <code>for c in bar</code> loop means ""for each character c in the string bar"". And before printing each character there's the delay just like in your code. Then I've used <code>sys.stdout.write</code> instead of <code>print</code> to avoid printing newline. <code>sys.stdout.flush()</code> means to immediately print the output onto terminal which otherwise would stay in a buffer. You can imagine buffer to be like a internal variable which to which we can keep on appending using <code>print</code> or <code>sys.stdout.write</code>. More info on it <a href=""https://stackoverflow.com/questions/10019456/usage-of-sys-stdout-flush-method"">here</a> </p>

<p>If you need help understanding anything else feel free to comment :)</p>
","6242649","6242649","2018-03-07 01:02:54","2","986","Udayraj Deshmukh","2016-04-22 21:39:25","1076","261","447","76","49049940","","2018-03-01 12:40:36","0","79","<p>I'm trying to make a, ""fake"" loading bar as just a small task. I'm new to coding and this seems to work, but it seems a lot of code. I assume could be done in like 2 lines by someone with more skill than me. I would love to see how this could be refactored into a more efficient way. Any help would be greatly appreciated! </p>

<pre><code>loading_bar = ""LOADING\n[==========]""

print(loading_bar[0:10])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:11])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:12])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:13])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:14])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:15])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:16])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:17])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:18])
time.sleep(.300)
os.system('cls')
print(loading_bar)
</code></pre>

<p>I'm sorry if this isn't in the right place. I'm new to StackOverflow as well.</p>
","9428838","2650249","2018-03-01 13:35:33","Refactoring a fake loading bar?","<python><python-3.x>","2","3","1032"
"49050233","2018-03-01 12:57:33","0","","<p>i just solve this problem.The reason is i use this code:</p>

<pre><code> _, pred_label, loss_look = sess.run([train_step, output, tf.reduce_mean(loss)], feed_dict={dnn_object.x: data_batch, dnn_object.y: label_batch, dnn_object.keep_pro: 0.8})\
</code></pre>

<p>and the tf.reduce_mean(loss) has built a new Variable or Opt every loop when i am training my model.
and now i want to know how can i improve my GPU efficiency? or maybe it is Can not be artificially improved.</p>
","8976840","","","0","481","Liangzhenlin","2017-11-21 04:03:23","6","5","0","0","49041756","","2018-03-01 02:34:41","0","20","<p>This is my code, I tried several ways can not be solved,Wanted to know if it's good practice to do that and what would be the best way to do that?     </p>

<p>I've always suspected that I've added a new node in some places, but I can not find the reason. This problem I have never encountered before, I also try to manually clear the memory, but did not succeed. There is a problem, when running this code, my GPU work efficiency only 2%, can improve the efficiency of the GPU?</p>

<pre><code>import tensorflow as tf
import numpy as np
import sklearn.metrics
import copy
import time
import gc


class DataDeal():
    def __init__(self, batch_size):
        self._batch_size = batch_size

    def readTfrecord(self, file, epoch=None, isTrain=True):
        fileQueue = tf.train.string_input_producer(string_tensor=[file], num_epochs=epoch, shuffle=True)
        reader = tf.TFRecordReader()
        _, example_series = reader.read(queue=fileQueue)
        features = tf.parse_single_example(serialized=example_series,
                                           features={""label"": tf.FixedLenFeature([], tf.string),
                                                     ""data_raw"": tf.FixedLenFeature([], tf.string)})
        data = tf.decode_raw(features[""data_raw""], out_type=tf.float32)
        label = tf.decode_raw(features[""label""], out_type=tf.int32)
        data = tf.reshape(data, shape=(1, 600))
        label = tf.reshape(label, shape=(1, 2))
        if isTrain:
            data, label = tf.train.shuffle_batch([data, label], batch_size=self._batch_size, capacity=2000,
                                                 min_after_dequeue=500, num_threads=3)
        else:
            assert epoch == None, ""wrong!""
            data, label = tf.train.batch([data, label], batch_size=500)
        return (data, label)


class DNN(DataDeal):
    def __init__(self, layer_shape, epoch, eta, batch_size, norm=True, L2_loss=True):
        super(DNN, self).__init__(batch_size)
        self._layer_shape = [600] + layer_shape + [2]
        self.batch_size = batch_size
        self._norm = norm
        self.L2_loss = L2_loss
        self.eta = eta
        self.epoch = epoch
        with tf.name_scope(""input""):
            self.x = tf.placeholder(dtype=tf.float32, shape=(None, 600), name=""input_X"")
            self.y = tf.placeholder(dtype=tf.int32, shape=(None, 2), name=""label"")
            self.keep_pro = tf.placeholder(dtype=tf.float32, name=""keep_pro"")
            self._y = tf.cast(self.y, dtype=tf.float32)
        with tf.variable_scope(""dnn""):
            self._W = [tf.get_variable(name=""layerW_%d"" % index, shape=(x[0], x[1]), dtype=tf.float32,
                                       initializer=tf.truncated_normal_initializer())
                       for index, x in enumerate(list(zip(self._layer_shape[:-1], self._layer_shape[1:])))]
            self._B = [tf.get_variable(name=""layerB_%d"" % index, shape=(1, x1), dtype=tf.float32,
                                       initializer=tf.truncated_normal_initializer())
                       for index, x1 in enumerate(self._layer_shape[1:])]
            self.global_step = tf.get_variable(name=""global_step"", dtype=tf.int32, initializer=0,
                                               trainable=False)  # GLOBAL STEP

    def batch_normalization(self, input_):
        mean, var = tf.nn.moments(input_, [0, 1], keep_dims=True)
        shift = tf.get_variable(shape=[1, input_.get_shape().as_list()[-1]], dtype=tf.float32,
                                initializer=tf.zeros_initializer(), name=""shift_1"")
        scale = tf.get_variable(shape=[1, input_.get_shape().as_list()[-1]], dtype=tf.float32,
                                initializer=tf.constant_initializer(1.0), name=""scale_1"")
        # shift= tf.Variable(initial_value=tf.truncated_normal(shape=[1, input_.get_shape().as_list()[-1]],dtype=tf.float32))
        epsilon = 1e-3
        output = tf.nn.batch_normalization(input_, mean, var, shift, scale, epsilon)
        return output

    def run(self):
        first_output = tf.add(tf.matmul(self.x, self._W[0]), self._B[0])
        if self._norm:
            first_output = tf.nn.relu(self.batch_normalization(input_=first_output))  # relu+BN
        else:
            first_output = tf.nn.sigmoid(first_output)
        for i in range(1, len(self._W) - 1):
            if self._norm:
                first_output = tf.add(tf.matmul(first_output, self._W[i]), self._B[i])
                with tf.variable_scope(""layer%d"" % i):
                    first_output = tf.nn.relu(self.batch_normalization(input_=first_output))
            else:
                first_output = tf.sigmoid(tf.add(tf.matmul(first_output, self._W[i]), self._B[i]))
        first_output = tf.nn.dropout(first_output, keep_prob=self.keep_pro)
        last_output = tf.add(tf.matmul(first_output, self._W[-1]), self._B[-1])
        return last_output


if __name__ == ""__main__"":

    file_train = ""D:/traindata/XIEBO/train.tfrecords""
    file_test = ""D:/traindata/XIEBO/test.tfrecords""
    dnn_object = DNN(layer_shape=[512, 128],
                     epoch=5000,
                     eta=0.001,
                     batch_size=128,
                     norm=False,
                     L2_loss=True)
    data, label = dnn_object.readTfrecord(file=file_train, epoch=dnn_object.epoch,
                                          isTrain=True)
    data_test, label_test = dnn_object.readTfrecord(file=file_test, epoch=None, isTrain=False)
    output = tf.nn.softmax(dnn_object.run())
    tvars = copy.copy(tf.trainable_variables())
    loss = tf.nn.softmax_cross_entropy_with_logits(labels=dnn_object.y, logits=output)
    if dnn_object.L2_loss:
        loss_l2 = 0.0005 * tf.reduce_sum([tf.nn.l2_loss(x) for x in tvars])
        loss += loss_l2
    train_first_op = tf.train.GradientDescentOptimizer(learning_rate=dnn_object.eta).minimize(loss=loss,
                                                                                              global_step=dnn_object.global_step)
    variable_averages = tf.train.ExponentialMovingAverage(decay=0.999, num_updates=dnn_object.global_step)
    variable_averages_op = variable_averages.apply(tf.trainable_variables())
    with tf.control_dependencies([train_first_op]):
        train_step = tf.group(variable_averages_op)
    with tf.Session() as sess:
        sess.run(tf.local_variables_initializer())
        sess.run(tf.global_variables_initializer())
        # sess.graph.finalize()
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(sess=sess, coord=coord)
        data_test, label_test = sess.run([data_test, label_test])
        data_test = np.reshape(data_test, newshape=(-1, 600))
        label_test = np.reshape(label_test, newshape=(-1, 2))
        step = 0
        try:
            while not coord.should_stop():
                data_batch, label_batch = sess.run([data, label])
                data_batch = np.reshape(data_batch, newshape=(-1, 600))
                label_batch = np.reshape(label_batch, newshape=(-1, 2))
                _, pred_label, loss_look = sess.run([train_step, output, tf.reduce_mean(loss)], feed_dict={
                    dnn_object.x: data_batch, dnn_object.y: label_batch, dnn_object.keep_pro: 0.8})
                if (step != 0) &amp; (step % 100 == 0):
                    print(""now is step %d, trainning acc is %s, trainning loss is %s"" % (
                        step, np.mean(np.equal(np.argmax(pred_label, axis=1), np.argmax(label_batch, axis=1))),
                        loss_look
                    ))
                    del data_batch, label_batch, pred_label, loss_look
                    gc.collect()
                    pred_label, loss_look = sess.run([output, tf.reduce_mean(loss)], feed_dict={
                        dnn_object.x: data_test, dnn_object.y: label_test, dnn_object.keep_pro: 1.0})
                    print(""now is step %d, testing acc is %s, testing loss is %s"" % (
                        step, np.mean(np.equal(np.argmax(pred_label, axis=1), np.argmax(label_test, axis=1))),
                        loss_look
                    ))
                    del pred_label, loss_look
                    gc.collect()
                    print(step, time.strftime(""%Y-%m-%d %H:%M:%S"", time.localtime(time.time())))
                else:
                    del data_batch, label_batch, pred_label, loss_look
                    gc.collect()
                step += 1
        except tf.errors.OutOfRangeError as e:
            print(e, time.strftime(""%Y-%m-%d %H:%M:%S"", time.localtime(time.time())))
        finally:
            coord.request_stop()
            coord.join(threads=threads)
            print(""over"", time.strftime(""%Y-%m-%d %H:%M:%S"", time.localtime(time.time())))
</code></pre>
","8976840","","","My tensorflow code in the process of running, ROM memory continues to increase, eventually leading to memory crashes","<python><tensorflow>","1","0","8814"
"49050235","2018-03-01 12:57:38","1","","<p>Here is a reworked version of your code:</p>

<pre><code>def my_fun():
    numCats = input('How many cats do you have?\n')
    try:
        if int(numCats) &gt;= 4:
            return 'That is a lot of cats'
        else:
            return 'That is not that many cats'
    except ValueError:
        return 'Error: you entered a non-numeric value: {0}'.format(numCats)

my_fun()
</code></pre>

<p><strong>Explanation</strong></p>

<ul>
<li>You need to call your function for it to run, as above.</li>
<li>Indentation is important. This has been made consistent with guidelines.</li>
<li><code>input()</code> takes as a parameter a string which is displayed before the input.</li>
<li>Since the user provides input via <code>input()</code>, your function does not require an argument.</li>
<li>It is good practice to <code>return</code> values and, if necessary, print them afterwards. Rather than having your function <code>print</code> strings and <code>return</code> None.</li>
<li>Your error can be more descriptive, and include the inappropriate input itself.</li>
</ul>
","9209546","9209546","2018-03-01 13:00:39","2","1079","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49050030","49050132","2018-03-01 12:45:55","0","129","<p>I did this example but it does not run with the try and except handling errors in Python.    </p>

<pre><code>def my_fun(numCats):
    print('How many cats do you have?')
    numCats = input()
    try:
        if int(numCats) &gt;=4:
            print('That is a lot of cats')
        else:
            print('That is not that many cats')
    except ValueError:
        print(""Value error"")
</code></pre>

<p>I tried:</p>

<pre><code>except Exception:
except  (ZeroDivisionError,ValueError) as e:
except  (ZeroDivisionError,ValueError) as error:
</code></pre>

<p>I did other example and it was able to catch <code>ZeroDivisionError</code>
I am using Jupyter notebook Python 3. 
<strong>Any help in this matter is highly appreciated.</strong></p>

<p>I am calling </p>

<pre><code>my_fun(int('six'))
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-39-657852cb9525&gt; in &lt;module&gt;()
----&gt; 1 my_fun(int('six'))

ValueError: invalid literal for int() with base 10: 'six'
</code></pre>
","8826524","8826524","2018-03-01 12:58:06","Try and Except Python","<python><function><exception><error-handling><try-catch>","2","5","1116"
"49050246","2018-03-01 12:58:32","0","","<p>I think the best way is to use numpy roll function. </p>

<p>Extract the values of your index and then apply numpy roll each time with a different shift. Example :</p>

<pre><code>for year in years:
    col = pop_matrix.columns.tolist()[year]
    pop_matrix[col] = numpy.roll(a_vector, shift=year+1)
</code></pre>
","5956107","","","0","317","the hongkonger","2016-02-20 16:58:47","21","3","6","0","49049374","","2018-03-01 12:03:35","0","58","<p>I am trying to write a loop which fills the elements in a dataframe or matrix with the values of the previous year. The columns represent different years within the 50 year horizon. The rows represent different discrete ages (up to 50 years old). The initial distribution in year 1 (green vector) is given. I would like to successively move the elements through the df or matrix. Hence, element 1,1 depicts the surface of age 1 in year 1. As a consequence, that element moves to 2,2; 3,3 and so on. The last row should move to the first row in the next year (indicated by the blue arrow). </p>

<p><a href=""https://i.stack.imgur.com/lVyqb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lVyqb.png"" alt=""enter image description here""></a></p>

<p>I have tried to iterate through the dataframe, but I think the <strong>Keyerror</strong> has to do with the fact that [index-1] has to be bound?</p>

<pre><code>import numpy as np
import pandas as pd

years = np.arange(50)
a_vector = np.arange(50)
pop_matrix = pd.DataFrame(0, index=a_vector, columns=years)

#Initial vector (green)
A0 = 5000000
for a, rows in pop_matrix.iterrows():
    pop_matrix[0][a] = A0 / len(pop_matrix)

#Incorrect attempt
for t in years:
    for a, rows in pop_matrix.iterrows():
        if t-1 &gt;= 0 and a-1 &gt;= 0:
            pop_matrix[t][a] = pop_matrix[t-1][a-1]
</code></pre>
","","","","Filling dataframe with lagged values in Python","<python><pandas><loops>","1","0","1380"
"49050326","2018-03-01 13:03:58","1","","<p>I wanted to post this as a comment but couldn't because my reputation isn't high enough.</p>

<p>You're seeing the image in the simulater because it's setup to simulate the Echo Show. Your code needs to be optimized based on the device's type. Check <a href=""https://developer.amazon.com/docs/custom-skills/display-interface-reference.html"" rel=""nofollow noreferrer"">this</a> for more information</p>
","2650584","7117003","2018-03-04 21:36:18","0","404","user1","2013-08-04 14:18:48","184","44","73","0","48699733","","2018-02-09 06:09:52","4","755","<p>I am writing a simple skill and I want to show a full screen image. I found a piece of example code on the <a href=""https://developer.amazon.com/docs/custom-skills/include-a-card-in-your-skills-response.html"" rel=""nofollow noreferrer"">Alexa skill pages</a></p>

<pre><code>def build_speechlet_response(title, output, reprompt_text, should_end_session):
return {
""outputSpeech"": {""type"":""PlainText"",""text"":""This is your cow!""},
""card"": {
  ""type"": ""Standard"",
  ""title"": ""Cow picture"",
  ""text"": ""This is your cow"",
  ""image"": {
    ""smallImageUrl"": ""https://s3.amazonaws.com/icepick-alexa/cow.jpg"",
    ""largeImageUrl"": ""https://s3.amazonaws.com/icepick-alexa/cow.jpg""
           }
       } 
}
</code></pre>

<p>I know for a fact my image hosting is okay, because when I use a template I can show the image as a background image.. but I just want it fulscreen and not as a background. </p>

<p>This code works fine in the alexa skill online simulator and I see the image there. However when I run the code on my Alexa Echo Spot it shows the text but no image. I tried different images in different sizes but it doesnt help. </p>
","416460","","","Alexa skill image not showing","<python><alexa>","5","3","1132"
"49050421","2018-03-01 13:09:46","1","","<p>Your model has been initialized (and trained) to receive input from a shape (N,28) matrix. It expects 28 columns.</p>

<p>The way to fix this is to reshape your single input row to match:</p>

<pre><code>z = z[:, np.newaxis].T #(1,28) shape
</code></pre>

<p>Or:</p>

<pre><code>z = z.reshape(1,-1) #reshapes to (1,whatever is in there)
z = z.reshape(-1,28) #probably better, reshapes to (amount of samples, input_dim)
</code></pre>
","5212031","","","0","436","Uvar","2015-08-10 16:40:00","2749","154","75","4","49050306","49050421","2018-03-01 13:02:43","0","41","<p>I wanted to write a simple function to load a keras model from json and run a prediction. However everytime I run it i get the following error:</p>

<pre><code>ValueError: Error when checking : expected input_2 to have shape (28,) but got array with shape (1,)
</code></pre>

<p>The code below shows i've printed out the shape of the numpy array and it returns <code>(28,)</code>, this still happens if i leave it as a python list.</p>

<pre><code>def doit():
    # load json and create model
    json_file = open('model.json', 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    loaded_model = model_from_json(loaded_model_json)
    # load weights into new model
    loaded_model.load_weights(""model.h5"")
    x = [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
    z = np.array(x)
    print(z.shape)
    prediction = loaded_model.predict(z)
    return prediction
</code></pre>
","7112459","","","Keras shape error - im inputting the shape its asking for","<python><json><numpy><keras>","1","2","938"
"49050424","2018-03-01 13:09:53","2","","<p>AES deals with byte buffers, not strings. There's no reason to convert the buffer to a string before decrypting. Besides, that string is way too short for AES. How the <em>byte buffer</em> looks using various codepages has nothing to do with whether the <em>byte values</em> are correct.</p>

<p>I suspect there's a problem with the decryption code which wasn't posted. The OP attempted to convert the buffer to a string in order to compare the values. Base64 isn't broken though. There's no reason to look for bugs that weren't noticed by any .NET developer for over 15 years. </p>

<p>Without the code that attempts to decrypt the <code>bytes</code> buffer it's impossible to say what's wrong. That string looks way too short for AES though.</p>

<p>The rest is only meant to explain where <code>?</code> came from and why.</p>

<p><strong>Original Answer</strong></p>

<p>There are multiple problems with this code. The Base64 string you used on the C# side has an extra space. </p>

<p>Even after that's fixed, the codepage is definitely wrong. <a href=""https://msdn.microsoft.com/en-us/library/system.text.encoding.ascii(v=vs.100).aspx"" rel=""nofollow noreferrer"">Encoding.ASCII</a> is the 7-bit character set while the Python string contains <code>\xe4</code>, ie <code>ä</code>. This is neither an ASCII nor a UTF8 string. The character is definitely outside the valid range. You need to <em>know</em> the correct codepage to use to decode it.</p>

<p>Without knowing the actual codepage one can only guess.  One codepage that can decode this character is 1253, ie Latin1. If you use :</p>

<pre><code>byte[] bytes = Convert.FromBase64String(""UORSfV0="");
string s = Encoding.GetEncoding(1252).GetString(bytes);
</code></pre>

<p>You'll get back <code>PäR}]</code></p>

<p>If you used 1253 though you'd get <code>PδR}]</code>. 1251 would return <code>PдR}]</code>. Which one did you intent to use? </p>

<p>The only thing you can be certain about is that some codepages will fail and return <code>?</code>, or the well defined Unicode Replacement Character <code>�</code></p>

<p>To avoid conversion errors you should use UTF8 on Python and C#. C# and Windows in general uses Unicode (UTF16 specifically), which is why I could post those characters in the answer. No special encoding was involved. Most file-related classes use UTF8 by default and return Unicode strings. </p>
","134204","134204","2018-03-01 13:32:45","9","2385","Panagiotis Kanavos","2009-07-07 11:45:12","66909","16496","6310","2039","49049872","49050424","2018-03-01 12:36:07","-1","1021","<p>I'm trying to base64 encode a string in python and then decode in C#,
and as far as I can see right now, the problem is that base64.b64encoding from python is encoding in ASCII. And when i use Convert.FromBase64String it uses unicode..</p>

<p>Python :</p>

<pre><code>msg = cipher.encrypt(""hello"")
msgb64 = base64.b64encode(msg)
</code></pre>

<blockquote>
  <p>Encoded message: 
  b'UORSfV0=', cipher text before encoding: b'P\xe4R}]'</p>
</blockquote>

<p>C# :</p>

<pre><code>byte[] bytes = Convert.FromBase64String(""UORSfV0="");
string s = Encoding.ASCII.GetString(bytes);
</code></pre>

<blockquote>
  <p>To show the output in string show this before aes decryption : ""PäR}]""</p>
</blockquote>

<p>From this step the error starts, because its not the cipher text</p>

<p>Any suggestions for a solution to this?</p>
","9390320","9390320","2018-03-01 13:22:21","Encode base64 in Python and decode in C#","<c#><python>","2","6","823"
"49050461","2018-03-01 13:12:15","1","","<p>In this case django expected a list in ALLOWED_HOSTS, but environment variables are just a plan text, you have to convert before use it, fortunately python decouple has a optional parameter called cast</p>

<p>Consider the following .env file:</p>

<p>.env</p>

<pre><code>ALLOWED_HOSTS=127.0.0.1, .herokuapp.com
DEBUG=True
PORT=5403
</code></pre>

<p>To access these values in your setting.py you have to import the util class Csv, it will convert a plan string in a list, but pay attention in your .env file or environment variable don't forget to separate the values with comma and space (, ).
For built-in types you don't need to import any aditional class, you can use int, str, bool...</p>

<p>setting.py</p>

<pre><code>from decouple import config, Csv

ALLOWED_HOSTS = config('ALLOWED_HOSTS', default=[], cast=Csv())
DEBUG = config('DEBUG', default=False, cast=bool)
PORT= config('PORT', cast=int)
</code></pre>
","6540202","","","0","923","Ronald Theodoro","2016-07-02 00:13:54","41","2","0","0","49049026","","2018-03-01 11:44:04","2","370","<p>When my <code>settings.py</code> has <code>ALLOWED_HOSTS = []</code> - the server works fine. But When I do <code>ALLOWED_HOSTS = config('ALLOWED_HOSTS')</code> - it gives the error:</p>

<pre><code>DisallowedHost at /admin/login/
Invalid HTTP_HOST header: '127.0.0.1:8000'. You may need to add '127.0.0.1' to ALLOWED_HOSTS.
</code></pre>

<p>However when I go into python shell I'm successfully able to import <code>ALLOWED_HOSTS</code> - and it prints <code>[]</code> which is the correct value.</p>

<p>Any reason why I still get the error?</p>

<p>PS: The <code>config</code> is a feature of the <code>python-decouple</code> package - used to store sensitive values.</p>
","6733153","113962","2018-03-01 11:56:05","Invalid HTTP_HOST header: '127.0.0.1:8000' error when using python-decouple to set ALLOWED_HOSTS","<python><django>","2","2","678"
"49050472","2018-03-01 13:13:15","8","","<p>I think you need <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html"" rel=""nofollow noreferrer""><code>groupby</code></a> with custom lambda function or with loop:</p>

<pre><code>f = lambda x: x.to_csv(os.getcwd() + ""/data_{}.csv"".format(x.name.lower()), index=False)
df.groupby('CITY').apply(f)
</code></pre>

<hr>

<pre><code>for i, x in df.groupby('CITY'):
     x.to_csv(os.getcwd() + ""/data_{}.csv"".format(i.lower()), index=False)
</code></pre>

<p>EDIT by comment, thanks @Anton vBR:</p>

<pre><code>for i, x in df.groupby('CITY'):
    p = os.path.join(os.getcwd(), ""data_{}.csv"".format(i.lower()))
    x.to_csv(p, index=False)
</code></pre>
","2901002","7386332","2018-03-01 13:34:16","5","691","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49050455","49050472","2018-03-01 13:11:30","4","967","<p>I have a question very <a href=""https://stackoverflow.com/questions/36192633/python-pandas-split-a-data-frame-based-on-a-column-value"">similar to this one</a> but I need to take it a step further by saving split data frames to csv.</p>

<pre><code>import pandas as pd
import numpy as np
import os

df = pd.DataFrame({ 'CITY' : np.random.choice(['PHOENIX','ATLANTA','CHICAGO', 'MIAMI', 'DENVER'], 1000),
                    'DAY': np.random.choice(['Monday','Tuesday','Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], 1000),
                    'TIME_BIN': np.random.randint(1, 86400, size=1000),
                    'COUNT': np.random.randint(1, 700, size=1000)})

df['TIME_BIN'] = pd.to_datetime(df['TIME_BIN'], unit='s').dt.round('10min').dt.strftime('%H:%M:%S')
print(df)

OUTPUT:
         CITY  COUNT        DAY  TIME_BIN
0     ATLANTA    476   Thursday  12:20:00
1     PHOENIX     50   Saturday  15:40:00
2       MIAMI    250     Friday  08:20:00
3     CHICAGO    358     Monday  15:40:00
4     PHOENIX    217   Thursday  22:10:00
5       MIAMI     12   Thursday  21:40:00
6      DENVER     22     Friday  10:30:00
7     CHICAGO    645     Sunday  23:40:00
8       MIAMI    188     Sunday  08:40:00
</code></pre>

<p>I want to make a separate data frame for each city and save it as a .csv. The code below works but how do I do it Pythonicly without having to explicitly state each city? Real data set has about 20 cities so I don't want to repaste this 20 times. I think the code below can be done in 1-2 lines using a for loop but I don't know what it would look like. Something like ""for city in df['CITY']""</p>

<pre><code>df_phoenix = df[df['CITY'] == ""PHOENIX""]
df_atlanta = df[df['CITY'] == ""ATLANTA""]
df_chicago = df[df['CITY'] == ""CHICAGO""]
df_phoenix.to_csv(os.getcwd() + ""/data_phoenix.csv"")
df_atlanta.to_csv(os.getcwd() + ""/data_atlanta.csv"")
df_chicago.to_csv(os.getcwd() + ""/data_chicago.csv"")
</code></pre>
","8431275","","","Pandas split data frame into multiple csv's based on column value","<python><pandas><csv>","1","0","1939"
"49050485","2018-03-01 13:13:42","1","","<p><code>detectMultiScale</code> requires an image as the first argument, but you have forgotten to pass it.</p>

<p>Try:</p>

<pre><code>faces = front_cascade.detectMultiScale(
    img,  # don't forget this!
    scaleFactor=1.1,
    minNeighbors=5,
    minsize=(30,30)
)
</code></pre>
","6445069","","","0","286","Phydeaux","2016-06-09 11:15:54","2150","165","730","164","49050397","","2018-03-01 13:09:01","-3","163","<p>I'm a beginner and I got an error while worked with Python OpenCV.</p>

<p>My code:</p>

<pre><code>import cv2
import numpy as np
front_cascade = cv2.CascadeClassifier('../haarcascade_frontalface_default.xml')

img = cv2.imread('mimika-1024x572.jpg')


faces = front_cascade.detectMultiScale(
    scaleFactor=1.1,
    minNeighbors=5,
    minsize=(30,30)
)
#for (x, y, w, h) in faces:
#    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 155), 3)

print (faces)

cv2.imshow('frame', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre>

<p>And error:</p>

<pre><code>Traceback (most recent call last):
  File ""C:/cv/test2.py"", line 12, in &lt;module&gt;
    minsize=(30,30)
TypeError: Required argument 'image' (pos 1) not found
</code></pre>

<p>How can I resolve this error?</p>
","9428966","472495","2018-03-01 20:50:19","How to resolve the Python error ""Required argument 'x' not found""","<python><opencv>","1","2","792"
"49050534","2018-03-01 13:16:22","0","","<p>Try <code>Default</code> Encoding</p>

<blockquote>
  <p><code>byte[] bytes = Convert.FromBase64String(""UORSfV0 ="");</code><br>
  <code>string s = Encoding.ASCII.GetString(bytes);</code></p>
</blockquote>

<pre><code>byte[] bytes = Convert.FromBase64String(""UORSfV0 ="");
string s = Encoding.Default.GetString(bytes);
</code></pre>
","5901111","","","1","334","LuizLoyola","2016-02-09 01:59:55","152","78","45","2","49049872","49050424","2018-03-01 12:36:07","-1","1021","<p>I'm trying to base64 encode a string in python and then decode in C#,
and as far as I can see right now, the problem is that base64.b64encoding from python is encoding in ASCII. And when i use Convert.FromBase64String it uses unicode..</p>

<p>Python :</p>

<pre><code>msg = cipher.encrypt(""hello"")
msgb64 = base64.b64encode(msg)
</code></pre>

<blockquote>
  <p>Encoded message: 
  b'UORSfV0=', cipher text before encoding: b'P\xe4R}]'</p>
</blockquote>

<p>C# :</p>

<pre><code>byte[] bytes = Convert.FromBase64String(""UORSfV0="");
string s = Encoding.ASCII.GetString(bytes);
</code></pre>

<blockquote>
  <p>To show the output in string show this before aes decryption : ""PäR}]""</p>
</blockquote>

<p>From this step the error starts, because its not the cipher text</p>

<p>Any suggestions for a solution to this?</p>
","9390320","9390320","2018-03-01 13:22:21","Encode base64 in Python and decode in C#","<c#><python>","2","6","823"
"49050573","2018-03-01 13:18:43","1","","<p>This seems overcomplicated. Try this, using a <a href=""https://docs.python.org/3.1/tutorial/datastructures.html#list-comprehensions"" rel=""nofollow noreferrer"">list comprehension</a>:</p>

<pre><code>a = [1, 2]
b = [[5,6], [7,8]]

c = [[x] + b[i] for i, x in enumerate(a)]
</code></pre>
","6445069","","","0","289","Phydeaux","2016-06-09 11:15:54","2150","165","730","164","49050522","","2018-03-01 13:15:31","0","38","<pre><code>a = [1, 2]
b = [[5,6], [7,8]]
c = list(zip(a, b))
print(""c zipped:"", c)
i = 0
lenghta = len(a)
c = []
while i &lt; lengtha:
    temp_list = [a[i], b[i]]
    c.append(temp_list)
    i += 1
print(""c: "", c)
</code></pre>

<p>output:</p>

<pre><code>c zipped: [(1, [5, 6]), (2, [7, 8])] c:  [[1, [5, 6]], [2, [7, 8]]]
</code></pre>

<p>What I am expecting is:</p>

<pre><code>[[1, 5, 6], [2, 7, 8]]
</code></pre>
","8650053","6445069","2018-03-01 13:21:21","Concatenating list with nested list","<python>","4","0","420"
"49050596","2018-03-01 13:20:11","0","","<p>One clean way to do that is to have a class-attribute that will keep an explicit reference to each object created on that class, and then either accessing that straight, or having a classmethod to filter the isntances you want. </p>

<pre><code>class Player:

    _register = []

    def __init__(self,role, abilities, visiting, unique,Type)
        self.role = role
        self.abilities = abilities
        self.unique = unique
        self.visiting = visiting
        self.Type= Type
        self.__class__._register.append(self) # the "".__class__."" is not strictly needed;

    @classmethod
    def list(cls, Type=None):
        results = []
        for instance in self._results:
             if isinstance(instance, cls) and (Type is None or Type == instance.Type):
              results.append(instance)
        return results
</code></pre>
","108205","","","0","852","jsbueno","2009-05-16 17:35:21","62274","3753","2414","235","49042968","","2018-03-01 05:07:53","1","37","<p>So I'm looking for a way to list out all the instances of a subclass either through a regular method or a classmethod.
For example:</p>

<pre><code>class Player:

    def __init__(self,role, abilities, visiting, unique,Type)
        self.role = role
        self.abilities = abilities
        self.unique = unique
        self.visiting = visiting
        self.Type= Type

class Town(Player):
    def __init__(self,role,abilities,visiting,unique,Type):
        super().__init__(role,abilities,visiting,unique,Type)

Bodyguard= Town('Bodyguard', 'Choose someone to protect','Yes','No', 'Town Protective')
Crusader = Town('Crusader','Protect someone each night','Yes','No','Town Protective')
         .
         .
         .
</code></pre>

<p>I want to be able to group up all the <code>Type='Town Protective'</code> and print out a list of them. for example</p>

<pre><code>print(Town_Protectives)
</code></pre>

<p>Displays:</p>

<pre><code>['Bodyguard','Crusader'....]
</code></pre>

<p>This is just a little project used to help me learn Python so it's nothing serious. Thanks for all of your help! </p>
","9399165","7832176","2018-03-01 05:23:49","How do I list out all the instances of a subclass?","<python>","2","3","1108"
"49050599","2018-03-01 13:20:19","0","","<p>If you wan't to use a jit compiler, here is an example using Numba</p>

<pre><code>@nb.njit(fastmath=True,parallel=True)
def distance(Paticle_coords,indices_moved):
  dist_res=np.empty((indices_moved.shape[0],Paticle_coords.shape[0]),dtype=Paticle_coords.dtype)

  for i in range(indices_moved.shape[0]):
    Koord=Paticle_coords[indices_moved[i],:]
    dist_res[i,:]=np.sqrt((Koord[0]-Paticle_coords[:,0])**2+(Koord[1]-Paticle_coords[:,1])**2+(Koord[2]-Paticle_coords[:,2])**2)

  return dist_res
</code></pre>

<p><strong>Performance compared to Julien's solution</strong></p>

<pre><code>#Create Data
Paticle_coords=np.random.rand(10000000,3)
indices_moved=np.array([0,5,6,3,7],dtype=np.int64)
</code></pre>

<p>This gives on my Core i7-4771 0.15s for the Numba solution and 2.4s for Julien's solution.</p>
","4045774","","","4","813","max9111","2014-09-16 09:51:28","3366","935","425","4","49040621","","2018-03-01 00:01:44","1","366","<p>I am a bit new to numpy and I am trying to calculate the pairwaise distance between some of the elements of a numpy array.</p>

<p>I have a numpy n x 3 array with n 3D cartesian coordinates (x,y,z) representing particles in a grid. Some of these particles move as the program runs and I need to keep track of the distances of the ones that move. I hold a list of integers with the index of the particles that have moved. </p>

<p>I am aware of pdist but this calculates the distance between every pair of particles, which would be inefficient as only some of them have moved. Ideally, for example, if only 1,2 have moved then I would only calculate the distance of 1 with 2...N and 2 with 3...N</p>

<p>What would be the most efficient way of doing this? Right now I have a double loop which doesn't seem ideal...</p>

<p><code>for i in np.nditer(particles_moved):
    particles = particles[particles!=i]
    for j in np.nditer(particles):
        distance(xyz,i, j)</code></p>

<p>Thanks</p>
","9426281","","","Calculating the Euclidean distance between SOME entries of numpy array","<python><arrays><numpy><distance>","2","3","996"
"49050612","2018-03-01 13:21:02","3","","<p>You could use a regular expression for that. For instance, you could use capture groups for the characters that you want to keep, and perform a substitution where you only keep those captured characters:</p>

<pre><code>import re

def shorten(s):
    return re.sub(r'([A-Z])(?:[A-Z]*(?=[A-Z])|[^A-Z.]*)|\.(\d+)[^A-Z.]*', r'\1\2', s)  
</code></pre>

<p>Explanation:</p>

<ul>
<li><code>([A-Z])</code>: capture a capital letter</li>
<li><code>(?:    )</code>: this is a grouping to make clear what the scope is of the <code>|</code> operation inside of it. This is not a capture group like above (so this will be deleted)</li>
<li><code>[A-Z]*</code>: zero or more capital letters (greedy)</li>
<li><code>(?=[A-Z])</code>: one more capital letter should follow, but don't process it -- leave it for the next match</li>
<li><code>|</code>: logical OR</li>
<li><code>[^A-Z.]*</code>: zero or more non-capitals, non-point (following the captured capital letter): these will be deleted</li>
<li><code>\.(\d+)</code>: a literal point followed by one or more digits: capture the digits (in order to throw away the dot).</li>
</ul>

<p>In the replacement argument, the captured groups are injected again:</p>

<ul>
<li><code>\1</code>: first capture group (this is the capital letter)</li>
<li><code>\2</code>: second capture group (these are the digit(s) that followed a dot)</li>
</ul>

<p>In one match, only one of the capture groups will have something, the other will just be the empty string. But the regular expression matching is repeated throughout the whole input string. </p>
","5459839","5459839","2018-03-01 14:06:17","0","1582","trincot","2015-10-18 15:19:14","146082","12359","1531","1712","49050197","49050951","2018-03-01 12:55:32","1","67","<p>I am developing a script that creates abbrevations for a list of names that are too long for me to use. I need to split each name into parts divided by dots and then take each capital letter that is at a beginning of a word. Just like this: </p>

<p><strong>InternetGatewayDevice.DeviceInfo.Description</strong> -> <strong>IGD.DI.D</strong></p>

<p>However, if there are more consecutive capital letters (like in the following example), I only want to take the <strong>first</strong> one and then the one that is <strong>not</strong> followed by a capital letter. So, from ""<strong>WANDevice</strong>"" I want get ""<strong>WD</strong>"".  Like this:</p>

<p><strong>InternetGatewayDevice.WANDevice.1.WANConnectionDevice.1.WANIPConnection.1.PortMapping.7.ExternalPort -> IGD.WD1.WCD1.WC1.PM7.EP</strong></p>

<p>So far I have written this script: </p>

<pre><code>data = json.load(open('./cwmp/tr069/test.json'))

def shorten(i):
    x = i.split(""."")
    abbreviations = []
    for each in x:
        abbrev = ''
        for each_letter in each:
            if each_letter.isupper():
                abbrev = abbrev + each_letter
        abbreviations.append(abbrev)
    short_string = ""."".join(abbreviations)
    return short_string

for i in data[""mappings""][""cwmp_genieacs""][""properties""]:
    if ""."" in i:
        shorten(i)
    else:
        pass    
</code></pre>

<p>It works correctly ""translates"" the first example but I am not sure how to do the rest. I think if I had to, I would probably think of <strong>some</strong> way to do it (like maybe split the strings into single characters) but I am looking for an efficient &amp; smart way to do it. I will be grateful for any advice.</p>

<p>I am using Python 3.6.</p>

<p><strong>EDIT:</strong></p>

<p>I decided to try a different approach and iterate over single characters and I pretty easily achieved what I wanted. Nevertheless, thank you for your answers and suggestions, I will most certainly go through them.</p>

<pre><code>def char_by_char(i):
    abbrev= """"
    for index, each_char in enumerate(i):
        # Define previous and next characters 
        if index == 0:
            previous_char = None
        else:
            previous_char = i[index - 1]

        if index == len(i) - 1:
            next_char = None
        else:
            next_char = i[index + 1]
        # Character is uppercase
        if each_char.isupper():
            if next_char is not None:
                if next_char.isupper():
                    if (previous_char is ""."") or (previous_char is None):
                        abbrev = abbrev + each_char
                    else:
                        pass
                else:
                    abbrev = abbrev + each_char
            else:
                pass
        # Character is "".""
        elif each_char is ""."":
            if next_char.isdigit():
                pass
            else:
                abbrev = abbrev + each_char

        # Character is a digit              
        elif each_char.isdigit():
            abbrev = abbrev + each_char

        # Character is lowercase            
        else:
            pass
    print(abbrev)


for i in data[""mappings""][""cwmp_genieacs""][""properties""]:
    if ""."" in i:
        char_by_char(i)
    else:
        pass    
</code></pre>
","7838925","7838925","2018-03-01 13:38:53","How to get the first capital letter and then each that isn't followed by another capital letter in Python?","<python><python-3.x>","3","2","3309"
"49050649","2018-03-01 13:23:29","1","","<p>Using <code>zip</code> and <code>list comprehension</code></p>

<pre><code>a = [1, 2]
b = [[5,6], [7,8]]

[[i]+j for i,j in zip(a,b)]
#[[1, 5, 6], [2, 7, 8]]
</code></pre>
","6950186","","","1","175","Transhuman","2016-10-10 16:16:18","2986","182","7","16","49050522","","2018-03-01 13:15:31","0","38","<pre><code>a = [1, 2]
b = [[5,6], [7,8]]
c = list(zip(a, b))
print(""c zipped:"", c)
i = 0
lenghta = len(a)
c = []
while i &lt; lengtha:
    temp_list = [a[i], b[i]]
    c.append(temp_list)
    i += 1
print(""c: "", c)
</code></pre>

<p>output:</p>

<pre><code>c zipped: [(1, [5, 6]), (2, [7, 8])] c:  [[1, [5, 6]], [2, [7, 8]]]
</code></pre>

<p>What I am expecting is:</p>

<pre><code>[[1, 5, 6], [2, 7, 8]]
</code></pre>
","8650053","6445069","2018-03-01 13:21:21","Concatenating list with nested list","<python>","4","0","420"
"49050652","2018-03-01 13:23:37","1","","<p>you can also use itertools.chain</p>

<pre><code>&gt;&gt;&gt; from itertools import chain
&gt;&gt;&gt; a = [1, 2]
&gt;&gt;&gt; b = [[5,6], [7,8]]
&gt;&gt;&gt; c = [list(chain([x], y)) for (x, y) in zip(a, b)]
&gt;&gt;&gt; c
[[1, 5, 6], [2, 7, 8]]
</code></pre>
","3016042","","","0","264","FraggaMuffin","2013-11-21 05:03:38","2192","83","125","8","49050522","","2018-03-01 13:15:31","0","38","<pre><code>a = [1, 2]
b = [[5,6], [7,8]]
c = list(zip(a, b))
print(""c zipped:"", c)
i = 0
lenghta = len(a)
c = []
while i &lt; lengtha:
    temp_list = [a[i], b[i]]
    c.append(temp_list)
    i += 1
print(""c: "", c)
</code></pre>

<p>output:</p>

<pre><code>c zipped: [(1, [5, 6]), (2, [7, 8])] c:  [[1, [5, 6]], [2, [7, 8]]]
</code></pre>

<p>What I am expecting is:</p>

<pre><code>[[1, 5, 6], [2, 7, 8]]
</code></pre>
","8650053","6445069","2018-03-01 13:21:21","Concatenating list with nested list","<python>","4","0","420"
"49050676","2018-03-01 13:24:52","0","","<p>This could be done by adding you script to the python path/the folder with the libraries, then you can import it like any other library.</p>
","3430996","","","1","144","mrfred489","2014-03-17 23:13:41","70","14","5","0","49050622","","2018-03-01 13:21:33","0","74","<p>I am running SPSS 23, and i have a python file named <code>text_wrap.py</code></p>

<pre><code>import textwrap
def wrap_title(long_text):
    wtext=""+\n"".join(textwrap.wrap(long_text,55))
    return wtext
</code></pre>

<p>...which is located on a custom path on my computer, and which I want to call inside the SPSS syntax.
So far I tried:</p>

<pre><code>begin program.
import text_wrap
end program.
</code></pre>

<p>I got <code>""No module named text_wrap""</code>. Makes sense, since it is a user module, not stored in the Python folder.
I also tried</p>

<pre><code>begin program.
import ""c:/Custom_path/text_wrap""
end program.
</code></pre>

<p>and</p>

<pre><code>import ""c:/Custom_path/text_wrap.py""
</code></pre>

<p>but I got <code>""SyntaxError: invalid syntax""</code> in all three situations.</p>

<p>The only way I could get the .py file to run was by running it a script from, <code>""Utilities/Run script""</code>. But I would like to do this via SPSS syntax</p>
","4454635","4454635","2018-03-01 15:47:19","Import Python user-module using SPSS syntax","<python><spss>","1","0","977"
"49050712","2018-03-01 13:27:14","2","","<p>An ObjectDict instance <em>is a</em> regular dictionary via class inheritance. See <code>ObjectDict(dict)</code></p>

<p>The <code>__getattr__</code> magic function allows for the definition of dot-notation access for any object. And it simply calls normal dictionary access here</p>

<p>Similarly, <code>__setattr__</code> and <code>__delattr__</code> allows setting and deleting (using Python's <code>del</code> expression) values from dot-notation. However, to set nested values, you need the value of the first key to also be an ObjectDict </p>
","2308683","2308683","2018-04-01 18:52:09","0","552","cricket_007","2013-04-22 19:10:38","94731","41997","1888","5481","49050603","49050719","2018-03-01 13:20:30","-4","81","<pre><code>class ObjectDict(dict):
    """""" allows object style access for dictionaries """"""

    def __getattr__(self, name):
        if name in self:
            return self[name]
        else:
            raise AttributeError('No such attribute: %s' % name)

    def __setattr__(self, name, value):
        self[name] = value

    def __delattr__(self, name):
        if name in self:
            del self[name]
        else:
            raise AttributeError('No such attribute: %s' % name)
</code></pre>

<p>can someone explain this code for me ? I'm just a python beginner.</p>
","7900860","5851928","2018-03-01 13:21:16","python object style access for dictionaries ; cant figure it out","<python><getattr><setattr>","2","2","581"
"49050719","2018-03-01 13:27:28","0","","<p><strong><code>__getattr__</code></strong> is for when you want to <em>get</em> a data.</p>

<p><strong><code>__setattr__</code></strong> is for when you want to <em>set</em> a data.</p>

<p><strong><code>__delattr__</code></strong> is for when you want to <em>del</em> a data.</p>

<p>Now, the methods should be quite clear.</p>

<pre><code>def __getattr__(self, name):
    # if the key exists... return it.
    if name in self:
        return self[name]
    # if not : raise an error.
    else:
        raise AttributeError('No such attribute: %s' % name)

def __setattr__(self, name, value):
    # set VALUE as value, with NAME as key in the dict.
    self[name] = value

def __delattr__(self, name):
    # if the key ""name"" exists in the dictionnary... delete it
    if name in self:
        del self[name]
    # else, it doesnt exist, so cant delete it.
    else:
        raise AttributeError('No such attribute: %s' % name)
</code></pre>
","8003790","2308683","2018-04-01 18:51:34","2","946","IMCoins","2017-05-12 15:45:09","2382","354","179","6","49050603","49050719","2018-03-01 13:20:30","-4","81","<pre><code>class ObjectDict(dict):
    """""" allows object style access for dictionaries """"""

    def __getattr__(self, name):
        if name in self:
            return self[name]
        else:
            raise AttributeError('No such attribute: %s' % name)

    def __setattr__(self, name, value):
        self[name] = value

    def __delattr__(self, name):
        if name in self:
            del self[name]
        else:
            raise AttributeError('No such attribute: %s' % name)
</code></pre>

<p>can someone explain this code for me ? I'm just a python beginner.</p>
","7900860","5851928","2018-03-01 13:21:16","python object style access for dictionaries ; cant figure it out","<python><getattr><setattr>","2","2","581"
"49050724","2018-03-01 13:27:47","1","","<p>Thanks for the comments, I have resolved my issue.</p>

<p>WxWidgets has been updated 2 days ago. I have recompiled my dll with this new version and the bug is gone.</p>

<p>Sorry I couldn't find a more general approach to the problem.</p>
","2505797","","","0","243","y3t1","2013-06-20 15:18:15","101","7","4","0","49032819","","2018-02-28 15:14:03","2","296","<p>I am currently trying to port some code from a 32 bit windows XP computer to a 64 bit windows 10 computer. I need in my python code to import home developed C dlls as follow :</p>

<pre><code>    from ctypes import *
    [...]
    self.inter_test_dll = windll.LoadLibrary(""my.dll"")

    self.w = QtWidgets.QWidget()
    self.wid = self.w.winId()
    self.wid.setsize(64)
    print(self.wid)
    self.inter_test_dll.dll_load_window(int(self.wid), 'test')
    self.inter_test_dll.dll_connect(2, self.callback)
    [...]
</code></pre>

<p>The program crashes as soon as the dll is loaded with a cryptic </p>

<pre><code>    Windows Error 1114
</code></pre>

<p>Which means a dll crashed on initialization. I have tried my dll on my personal machine (64 bits Windows 7), no issue, it all works fine.
I have tried that dll on the same 64 bits Windows 10 machine from within a C program, LoadLibrary(""my.dll"") also fails but LoadLibraryEx(""my.dll"",NULL, DONT_RESOLVE_DLL_REFERENCE ) does work.</p>

<p>When I run a dependency walker on my dll, it seems to miss some 2 to 4 depth level dll, but it weirdly doesn't seem to affect its working when called properly from within the C program.</p>

<p>So my question is, is there a way to instantiate my dll within Python without an in-depth check of its dependencies ? If not, is there a way to  modify my windows behavior, in order to skip that check by default ?</p>

<p>Thanks a lot !</p>
","2505797","","","Windows Error 1114 while loading dll in Python","<python><windows><dll><dllimport>","1","6","1434"
"49050731","2018-03-01 13:28:17","0","","<p>Apparently I've solved with:</p>

<pre><code>class MyModelUpdateForm(forms.ModelForm):
    class Meta:
        model = MyModel
        fields = []

    def __init__(self, *args, **kwargs):
        initial = kwargs.get('initial', {})
        if hasattr(self, 'initial_values') and not kwargs.get('data'):
            for field_name, value in self.initial_values.items():
                if not getattr(kwargs.get('instance', None), field_name, None):
                    initial[field_name] = value
            kwargs.update({'initial': initial})
        super().__init__(*args, **kwargs)

        # Make fields mandatory
        if hasattr(self, 'required_fields'):
            for field_name in self.required_fields:
                self.fields[field_name].required = True
</code></pre>

<p>Even tough it works I wouldn't mind a less <strong>hackish</strong> solution if anyone has any :)</p>
","1191416","","","0","897","Leonardo","2012-02-06 01:52:58","1566","243","931","2","49049972","","2018-03-01 12:42:39","0","825","<p>I have a custom Django ModelForm that I use to update a model instance.<br>
This is the example model:</p>

<pre><code>class MyModel(models.Model):
    number = models.CharField(_(""Number""), max_length=30, unique=True)
    sent_date = models.DateField(_('Sent date'), null=True, blank=True)
</code></pre>

<p>When creating an instance I will pass only the <code>number</code> field, that is why I don't want the <code>sent_date</code> to be required.</p>

<p>Then I have a view that updates the <code>sent_date</code> field, using this custom form:</p>

<pre><code># Generic form updater
class MyModelUpdateForm(forms.ModelForm):
    class Meta:
        model = MyModel
        fields = []

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        # Make fields mandatory
        if hasattr(self, 'required_fields'):
            for field_name in self.required_fields:
                self.fields[field_name].required = True
        # Set initial values
        if hasattr(self, 'initial_values'):
            for field_name, value in self.initial_values.items():
                self.initial[field_name] = value


class SentForm(MyModelUpdateForm):
    required_fields = ['sent_date']
    initial_values = {'sent_date': datetime.date.today()}

    class Meta(MyModelUpdateForm.Meta):
        fields = ['sent_date']
        field_classes = {'sent_date': MyCustomDateField}

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs) 
</code></pre>

<p><code>MyModelUpdateForm</code> is a generic ancestor for concrete forms like <code>SentForm</code>. </p>

<p>In my view whenever there is a GET I manually instantiate the form with:</p>

<pre><code>my_form = SentForm({instance: my_model_instance})
</code></pre>

<p>So in this case I would expect the <code>sent_date</code> field to have an initial value set to today's date even tough the real model instance field is None.</p>

<p>If I inspect <code>my_form</code> object it does indeed have these attributes:</p>

<pre><code>initial: {'sent_date': datetime.date(2018, 3, 1)}
instance: my_model_instance
fields: {'sent_date':
            ...: ...,
            'initial': None # Why this is None?
            ...: ... 
         }
</code></pre>

<p>So apparently it should work but it doesn't: the field is always empty.</p>

<p>So I suspect that the value is coming from <code>my_model_instance.sent_date</code> that is in fact <code>None</code>.</p>

<p>The <code>initial['sent_date'] = datetime.date(2018, 3, 1)</code> is correct.<br>
On the other side <code>fields['sent_date']['initial'] = None</code> it's not.</p>

<p>How can I always show the <code>initial</code> value when <code>my_model_instance.sent_date</code> is <code>None</code>?</p>
","1191416","","","Django Form field initial value when updating an instance","<python><django><django-models><django-forms>","2","0","2764"
"49050736","2018-03-01 13:28:26","1","","<p>So I have solved the issue, which is of file compatibility. </p>

<p>I don't know what the right kind of wav file is (other than uncompressed). I had tried using a wav but it did not work. </p>

<p>However I finally tried .ogg since that was the only thing listed as working in the online manual for pygame. As soon as I used .ogg everything worked as planned. </p>

<p>For anyone else with this issue I used Audacity to export my .mp3 and .wav files to .ogg using defaults.</p>
","9425504","","","0","482","jjmc","2018-02-28 19:46:30","16","4","0","0","49037853","49050736","2018-02-28 20:18:17","1","1079","<p>I am trying to make a simple program that plays some narration, and has a sound effect on a trigger. Being new to python, I am just building up functions in layers. Getting music to work was easy, as it should be, but I cannot get sound to work. </p>

<p>I have read of a few people with similar issues, but either they are also unsolved, or the symptoms are slightly different, and the solutions don't work for me.</p>

<p>I have tried this on a pi3 (which is the end target), and windows 7, both running latest python 3, and pygame.</p>

<pre><code>import pygame
import time
import os

pygame.mixer.init()
#pygame.mixer.pre_init(44100, -16, 2, 2048)
pygame.init()
pygame.mixer.music.load(""English.mp3"")
pygame.mixer.music.play()
print (os.getcwd()) 
shot = pygame.mixer.Sound(""gun-gunshot-02.wav"")
shot.play()

while True:
    Time.sleep(1) # for testing and irritation prevention if sound ever plays
    shot.play()
</code></pre>

<p>I should also note that the sound effect <em>does</em> work if I play it using music, but of course it replaces the narration.</p>

<p>Error is as follows same on both machines, same with both mp3 and wav:</p>

<blockquote>
  <p>C:\Users\me\Documents\Interrupter
  Traceback (most recent call last):
  File ""C:/Users/me/Documents/Interrupter/simpletest.py"", line 11, in 
  shot = pygame.mixer.Sound(""gun-gunshot-02.wav"")
  pygame.error: Unable to open file 'gun-gunshot-02.wav'</p>
</blockquote>

<p>Thanks in advance</p>
","9425504","5411817","2018-02-28 21:01:10","pygame sound unable to open file","<python><pygame>","1","7","1462"
"49050769","2018-03-01 13:30:08","2","","<p>If want use your original solution add <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html"" rel=""nofollow noreferrer""><code>fillna</code></a> with cast to <code>int</code>:</p>

<pre><code>testdf = g.join(pd.get_dummies(g['accession'].apply(pd.Series).stack()).sum(level=0)).drop('accession', 1)

testdf = testdf.fillna(0).astype(int)
</code></pre>

<p>But better solution is use <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html"" rel=""nofollow noreferrer""><code>get_dummies</code></a> and then set <code>max</code> per index and per columns (in sample not necessary, in real data maybe):</p>

<pre><code>df1['accession'] = df1['gene'].map(df2.set_index('gene')['accession'])

df1 = pd.get_dummies(df1.set_index('genome')['accession']).max(level=0).max(level=0, axis=1)
</code></pre>

<p>Or use <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.crosstab.html"" rel=""nofollow noreferrer""><code>crosstab</code></a>, <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.clip_upper.html"" rel=""nofollow noreferrer""><code>clip_upper</code></a> and add missing categories by <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reindex.html"" rel=""nofollow noreferrer""><code>reindex</code></a>:</p>

<pre><code>df1 = (pd.crosstab(df1['genome'], df1['accession'])
        .clip_upper(1)
        .reindex(df1['genome'].unique(), fill_value=0))
</code></pre>

<p>Or:</p>

<pre><code>df1 = (df1.groupby(['genome', 'accession'])
         .size()
         .clip_upper(1)
         .unstack(fill_value=0)
         .reindex(df1['genome'].unique(), fill_value=0))
</code></pre>

<hr>

<pre><code>print (df1)
         accession1  accession2  accession3  accession4  accession5
genome                                                             
genome1           1           1           1           0           0
genome2           1           0           0           1           1
genome3           0           0           0           0           0
genome4           0           0           0           0           0
</code></pre>

<p>and last for write to file:</p>

<pre><code>df1.to_csv(outName, sep='\t')
</code></pre>
","2901002","2901002","2018-03-01 14:06:51","0","2257","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49050710","49050769","2018-03-01 13:27:05","1","181","<p>Command line:</p>

<p>files can be found at git-hub.</p>

<p>File1: </p>

<p><a href=""https://raw.githubusercontent.com/felipelira/files_to_test/master/file1.txt"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/felipelira/files_to_test/master/file1.txt</a></p>

<p>File2:</p>

<p><a href=""https://raw.githubusercontent.com/felipelira/files_to_test/master/file2.txt"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/felipelira/files_to_test/master/file2.txt</a></p>

<p>Command line:
    python teste2.py file1.txt file2.txt test</p>

<p>When converting a tabular file in a presence/absence matrix I missed some data in the end. The genomes without a match with an accession were not plot.</p>

<p>My previous result was something like this (according the script and example at the post <a href=""https://stackoverflow.com/q/49035358/5775504"">Convert tables to presence/absence matrix python - Solved</a>):</p>

<pre><code>genome  accession1  accession2  accession3  accession4  accession5
genome1           1           1           1           0           0
genome2           1           0           0           1           1
</code></pre>

<p>But I need the other genomes in my forward analysis.
I tried to arrange this moving the block that defines df2 before the df1:</p>

<pre><code>asmbly_dict = sys.argv[1]
blast_result = sys.argv[2]
outName = sys.argv[3] + '.txt'

with open(blast_result, 'r') as file2:
    col_genes = ['gene', 'accession']
    df2 = pd.read_csv(file2, sep='\t', header=None, names=col_genes)
    print df2

with open(asmbly_dict, 'r') as file1:
    col_asmbly = ['gene', 'genome']
    df1 = pd.read_csv(file1, sep='\t', header=None, names=col_asmbly)
    df1['accession'] = df1['gene'].map(df2.set_index('gene')['accession'])
    #print df1
    g = df1.groupby('genome')['accession'].apply(list).reset_index()
    testdf = g.join(pd.get_dummies(g['accession'].apply(pd.Series).stack()).sum(level=0)).drop('accession', 1)
    #print testdf.to_string(index=False)
    testdf.to_csv(outName, sep='\t', header=True, index=False)
</code></pre>

<p>Print of df2:</p>

<pre><code>    gene   accession
0  gene1  accession1
1  gene2  accession2
2  gene3  accession3
3  gene4  accession1
4  gene5  accession4
5  gene6  accession5
</code></pre>

<p>Print of df1:</p>

<pre><code>    gene   genome   accession
0  gene1  genome1  accession1
1  gene2  genome1  accession2
2  gene3  genome1  accession3
3  gene4  genome2  accession1
4  gene5  genome2  accession4
5  gene6  genome2  accession5
6  gene7  genome3         NaN
7  gene8  genome3         NaN
8  gene9  genome4         NaN
</code></pre>

<p>Print of testdf:</p>

<pre><code>genome  accession1  accession2  accession3  accession4  accession5
genome1         1.0         1.0         1.0         0.0         0.0
genome2         1.0         0.0         0.0         1.0         1.0
genome3         NaN         NaN         NaN         NaN         NaN
genome4         NaN         NaN         NaN         NaN         NaN
</code></pre>

<p>And the .csv file:</p>

<pre><code>genome  accession1  accession2  accession3  accession4  accession5
genome1         1.0         1.0         1.0         0.0         0.0
genome2         1.0         0.0         0.0         1.0         1.0
genome3
genome4
</code></pre>

<p>The problems are:</p>

<p>How to plot no decimals after numbers (1.0 -> 1) and how can I fill the empty values with zeros to print and write the file?</p>
","5775504","5775504","2018-03-01 13:53:24","Compare tables to create presence/absence matrix filling empty without decimals","<python><pandas><pandas-groupby>","1","1","3453"
"49050790","2018-03-01 13:31:04","1","","<p>The problem is that you are accessing your cells from <code>workbook</code> which does not have <code>cell</code> attribute. What you should access before then is the <code>worksheet</code> object. You can do that via:</p>

<pre><code>ws = wb.active
</code></pre>

<p>So a simple fix is to add the code above right after your <code>wb = ...</code>; and change the <code>wb</code> to <code>ws</code> within your loop. This will give you a local excel file with your data in the first column:</p>

<p><a href=""https://i.stack.imgur.com/Xo4EK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Xo4EK.png"" alt=""enter image description here""></a></p>
","3216980","","","0","665","Yilun Zhang","2014-01-20 22:22:55","3929","358","173","44","49050666","49050790","2018-03-01 13:24:32","0","1288","<pre><code>def save_data():
    wb = openpyxl.Workbook()
    print(entryArray)
    for b in range(len(entryArray)):
        temp = entryArray[b]
        wb.cell(row=b+1, column=1).value = temp
    wb.save('/home/'+getpass.getuser()+'/Desktop/FileName.xlsx')
</code></pre>

<p>i get the error message</p>

<pre><code>  File ""C:/Users/thoma/ownCloud/Computer Science/Project/Psudo code/1.2/Project 404.py"", line 292, in &lt;module&gt;
    save_data()
  File ""C:/Users/thoma/ownCloud/Computer Science/Project/Psudo code/1.2/Project 404.py"", line 258, in save_data
    wb.cell(row=b+1, column=1).value = temp
AttributeError: 'Workbook' object has no attribute 'cell'
</code></pre>

<p>this is the value of entryArray:
['58578', '876', '66', '98', '807', '78907', '90', '078907', '8967', '760', '658', '467', '58346', '54', '65', '785', '896', '9-08', '-980', '456', '456', '09', '87', '89', '765', '765', '765', '765']</p>

<p>how do I create an XLSX sheet then write these values into it using openpyxl. the XLSX sheet does not exist I need to create it during the functions running.</p>

<p>thanks in advance</p>
","9231920","","","how to write an array into an XLSX sheet using openpyxl","<python><arrays><excel><xlsx><openpyxl>","1","1","1111"
"49050827","2018-03-01 13:34:15","1","","<pre><code>import re
def foo(s):
    print(''.join(list(map(
        lambda matchobj: matchobj[0], re.finditer(
            r'(?&lt;![A-Z])[A-Z]|[A-Z](?![A-Z])|\.', s)))))
foo('InternetGatewayDevice.DeviceInfo.Description')
foo('WANDevice')
# output: 
# IGD.DI.D
# WD
</code></pre>

<p>There's three major parts to the regex:</p>

<ol>
<li>match if it's a capital letter with no capital letter in front of it <code>(?&lt;![A-Z])[A-Z]</code> or</li>
<li>match if it's a capital letter with no capital letter after it <code>[A-Z](?![A-Z])</code> or</li>
<li>if it's a literal period</li>
</ol>

<p><a href=""https://docs.python.org/3.6/library/re.html"" rel=""nofollow noreferrer"">https://docs.python.org/3.6/library/re.html</a></p>
","2630028","2630028","2018-03-01 13:41:03","0","728","solstice333","2013-07-29 11:02:05","1591","115","747","4","49050197","49050951","2018-03-01 12:55:32","1","67","<p>I am developing a script that creates abbrevations for a list of names that are too long for me to use. I need to split each name into parts divided by dots and then take each capital letter that is at a beginning of a word. Just like this: </p>

<p><strong>InternetGatewayDevice.DeviceInfo.Description</strong> -> <strong>IGD.DI.D</strong></p>

<p>However, if there are more consecutive capital letters (like in the following example), I only want to take the <strong>first</strong> one and then the one that is <strong>not</strong> followed by a capital letter. So, from ""<strong>WANDevice</strong>"" I want get ""<strong>WD</strong>"".  Like this:</p>

<p><strong>InternetGatewayDevice.WANDevice.1.WANConnectionDevice.1.WANIPConnection.1.PortMapping.7.ExternalPort -> IGD.WD1.WCD1.WC1.PM7.EP</strong></p>

<p>So far I have written this script: </p>

<pre><code>data = json.load(open('./cwmp/tr069/test.json'))

def shorten(i):
    x = i.split(""."")
    abbreviations = []
    for each in x:
        abbrev = ''
        for each_letter in each:
            if each_letter.isupper():
                abbrev = abbrev + each_letter
        abbreviations.append(abbrev)
    short_string = ""."".join(abbreviations)
    return short_string

for i in data[""mappings""][""cwmp_genieacs""][""properties""]:
    if ""."" in i:
        shorten(i)
    else:
        pass    
</code></pre>

<p>It works correctly ""translates"" the first example but I am not sure how to do the rest. I think if I had to, I would probably think of <strong>some</strong> way to do it (like maybe split the strings into single characters) but I am looking for an efficient &amp; smart way to do it. I will be grateful for any advice.</p>

<p>I am using Python 3.6.</p>

<p><strong>EDIT:</strong></p>

<p>I decided to try a different approach and iterate over single characters and I pretty easily achieved what I wanted. Nevertheless, thank you for your answers and suggestions, I will most certainly go through them.</p>

<pre><code>def char_by_char(i):
    abbrev= """"
    for index, each_char in enumerate(i):
        # Define previous and next characters 
        if index == 0:
            previous_char = None
        else:
            previous_char = i[index - 1]

        if index == len(i) - 1:
            next_char = None
        else:
            next_char = i[index + 1]
        # Character is uppercase
        if each_char.isupper():
            if next_char is not None:
                if next_char.isupper():
                    if (previous_char is ""."") or (previous_char is None):
                        abbrev = abbrev + each_char
                    else:
                        pass
                else:
                    abbrev = abbrev + each_char
            else:
                pass
        # Character is "".""
        elif each_char is ""."":
            if next_char.isdigit():
                pass
            else:
                abbrev = abbrev + each_char

        # Character is a digit              
        elif each_char.isdigit():
            abbrev = abbrev + each_char

        # Character is lowercase            
        else:
            pass
    print(abbrev)


for i in data[""mappings""][""cwmp_genieacs""][""properties""]:
    if ""."" in i:
        char_by_char(i)
    else:
        pass    
</code></pre>
","7838925","7838925","2018-03-01 13:38:53","How to get the first capital letter and then each that isn't followed by another capital letter in Python?","<python><python-3.x>","3","2","3309"
"49050951","2018-03-01 13:40:13","2","","<p>Here is a non-regex solution.</p>

<pre><code>def shorten(i):
    abr_list = []
    abrev = ''
    parts = i.split('.')
    for word in parts:
        for x in range(len(word)):
            if x == 0 and word[x].isupper() or word[x].isupper() and not word[x + 1].isupper() or word[x].isnumeric():
                abrev += word[x]
        abr_list.append(abrev)
        abrev = ''
    return join_parts(abr_list)


def join_parts(part_list):
    ret = part_list[0]
    for part in part_list[1:]:
        if not part.isnumeric():
            ret += '.%s' % part
        else:
            ret += part
    return ret
</code></pre>
","6594646","","","1","630","MalloyDelacroix","2016-07-15 14:22:43","1533","83","278","41","49050197","49050951","2018-03-01 12:55:32","1","67","<p>I am developing a script that creates abbrevations for a list of names that are too long for me to use. I need to split each name into parts divided by dots and then take each capital letter that is at a beginning of a word. Just like this: </p>

<p><strong>InternetGatewayDevice.DeviceInfo.Description</strong> -> <strong>IGD.DI.D</strong></p>

<p>However, if there are more consecutive capital letters (like in the following example), I only want to take the <strong>first</strong> one and then the one that is <strong>not</strong> followed by a capital letter. So, from ""<strong>WANDevice</strong>"" I want get ""<strong>WD</strong>"".  Like this:</p>

<p><strong>InternetGatewayDevice.WANDevice.1.WANConnectionDevice.1.WANIPConnection.1.PortMapping.7.ExternalPort -> IGD.WD1.WCD1.WC1.PM7.EP</strong></p>

<p>So far I have written this script: </p>

<pre><code>data = json.load(open('./cwmp/tr069/test.json'))

def shorten(i):
    x = i.split(""."")
    abbreviations = []
    for each in x:
        abbrev = ''
        for each_letter in each:
            if each_letter.isupper():
                abbrev = abbrev + each_letter
        abbreviations.append(abbrev)
    short_string = ""."".join(abbreviations)
    return short_string

for i in data[""mappings""][""cwmp_genieacs""][""properties""]:
    if ""."" in i:
        shorten(i)
    else:
        pass    
</code></pre>

<p>It works correctly ""translates"" the first example but I am not sure how to do the rest. I think if I had to, I would probably think of <strong>some</strong> way to do it (like maybe split the strings into single characters) but I am looking for an efficient &amp; smart way to do it. I will be grateful for any advice.</p>

<p>I am using Python 3.6.</p>

<p><strong>EDIT:</strong></p>

<p>I decided to try a different approach and iterate over single characters and I pretty easily achieved what I wanted. Nevertheless, thank you for your answers and suggestions, I will most certainly go through them.</p>

<pre><code>def char_by_char(i):
    abbrev= """"
    for index, each_char in enumerate(i):
        # Define previous and next characters 
        if index == 0:
            previous_char = None
        else:
            previous_char = i[index - 1]

        if index == len(i) - 1:
            next_char = None
        else:
            next_char = i[index + 1]
        # Character is uppercase
        if each_char.isupper():
            if next_char is not None:
                if next_char.isupper():
                    if (previous_char is ""."") or (previous_char is None):
                        abbrev = abbrev + each_char
                    else:
                        pass
                else:
                    abbrev = abbrev + each_char
            else:
                pass
        # Character is "".""
        elif each_char is ""."":
            if next_char.isdigit():
                pass
            else:
                abbrev = abbrev + each_char

        # Character is a digit              
        elif each_char.isdigit():
            abbrev = abbrev + each_char

        # Character is lowercase            
        else:
            pass
    print(abbrev)


for i in data[""mappings""][""cwmp_genieacs""][""properties""]:
    if ""."" in i:
        char_by_char(i)
    else:
        pass    
</code></pre>
","7838925","7838925","2018-03-01 13:38:53","How to get the first capital letter and then each that isn't followed by another capital letter in Python?","<python><python-3.x>","3","2","3309"
"49050962","2018-03-01 13:40:46","0","","<p>It sounds like you are just missing an indent:</p>

<pre><code>l= [1,5,6,7,8,['a','b','c','d']]
a= ['name 1','name 2',l]

for i in a:
   if type(i) == list:
      for j in i:
         if type(j) == list:
             for k in j:
                 print(k, end=' ')
         else:
             print(j, end=' ')


   else:
       print(i, end=' ')
</code></pre>
","3430996","","","1","363","mrfred489","2014-03-17 23:13:41","70","14","5","0","49050798","49050962","2018-03-01 13:31:49","-3","104","<p>I am stuck in Python. I need to create and parse a 3-level list.
For example, a list inside a list inside a list.</p>

<p>2 levels are working for me but going to the third is so much confusion please help</p>

<pre><code>l= [1,5,6,7,8,['a','b','c','d']]
a= ['name 1','name 2',l]

for i in a:
   if type(i) == type([]):
      for j in i:
         print(j, end=' ')
      for k in j:
         if type(j) == type([]):
             print('non')


else:
    print(i, end=' ')
</code></pre>
","8637130","1603480","2018-03-01 14:04:47","Three level list in PYTHON","<python>","3","3","489"
"49051051","2018-03-01 13:46:17","2","","<p>As mentioned in the updated question, this is because of a race condition. Below I put an initial example highlighting a simplistic race condition where the race is against the overall program exit, but this could also be caused by other types of scope exits or other general race conditions involving your process.</p>

<p>I copied your class definition and added some ""main"" code to run it, here's my full listing:</p>

<pre><code>import logging
import multiprocessing
import time


class ExtendedProcess(multiprocessing.Process):
    def __init__(self):
        super(ExtendedProcess, self).__init__()
        self.stop_request = multiprocessing.Event()

    def join(self, timeout=None):
        logging.debug(""stop request received"")
        self.stop_request.set()
        super(ExtendedProcess, self).join(timeout)

    def run(self):
        logging.debug(""process has started"")
        while not self.stop_request.is_set():
            print(""doing something"")
            time.sleep(1)
        logging.debug(""proc is stopping"")


if __name__ == ""__main__"":
    p = ExtendedProcess()
    p.start()
    while True:
        pass
</code></pre>

<p>The above code listing runs as expected for me using both Python 2.7.11 and 3.6.4. It loops infinitely and the process never terminates:</p>

<pre><code>ely@eschaton:~/programming$ python extended_process.py 
doing something
doing something
doing something
doing something
doing something
... and so on
</code></pre>

<p>However, if I instead use this code in my main section, it exits right away (as expected):</p>

<pre><code>if __name__ == ""__main__"":
    p = ExtendedProcess()
    p.start()
</code></pre>

<p>This exits because the interpreter reaches the end of the program, which in turn triggers automatically destroying the <code>p</code> object as it goes out of scope of the whole program.</p>

<p>Note this could also explain why it works for you in the debugger. That is an interactive programming session, so after you start <code>p</code>, the debugger environment allows you to wait around and inspect it ... it would not be automatically destroyed unless you somehow invoked it within some scope that is exited while stepping through the debugger.</p>

<p>Just to verify the join behavior too, I also tried with this main block:</p>

<pre><code>if __name__ == ""__main__"":
    log = logging.getLogger()
    log.setLevel(logging.DEBUG)
    p = ExtendedProcess()
    p.start()
    st_time = time.time()
    while time.time() - st_time &lt; 5:
        pass
    p.join()
    print(""Finished!"")
</code></pre>

<p>and it works as expected:</p>

<pre><code>ely@eschaton:~/programming$ python extended_process.py 
DEBUG:root:process has started
doing something
doing something
doing something
doing something
doing something
DEBUG:root:stop request received
DEBUG:root:proc is stopping
Finished!
</code></pre>
","567620","567620","2018-03-01 14:22:25","2","2874","ely","2011-01-07 23:55:27","44893","4128","1562","318","49050818","49051051","2018-03-01 13:33:28","2","239","<p>I have this code:</p>

<pre><code>class ExtendedProcess(multiprocessing.Process):
    def __init__(self):
        super(ExtendedProcess, self).__init__()
        self.stop_request = multiprocessing.Event()

    def join(self, timeout=None):
        logging.debug(""stop request received"")
        self.stop_request.set()
        super(ExtendedProcess, self).join(timeout)

    def run(self):
        logging.debug(""process has started"")
        while not self.stop_request.is_set():
            print ""doing something""
        logging.debug(""proc is stopping"")
</code></pre>

<p>When I call start() on the process it should be running forever, since self.stop_request() is not set. After some miliseconds join() is being called by itself and breaking run. What is going on!? why is join being called by itself?</p>

<p>Moreover, when I start a debugger and go line by line it's suddenly working fine.... What am I missing?</p>

<p>OK, thanks to ely's answer the reason hit me:</p>

<p><strong>There is a race condition -</strong></p>

<ol>
<li>new process created...</li>
<li>as it's starting itself and about to run logging.debug(""process has started"") the main function hits end.</li>
<li>main function calls sys exit and on sys exit python calls for all finished processes to close with join().</li>
<li>since the process didn't actually hit ""while not self.stop_request.is_set()"" join is called and ""self.stop_request.set()"". Now stop_request.is_set and the code closes.</li>
</ol>
","8952681","8952681","2018-03-01 14:09:29","Python multiprocessing.Process calls join by itself","<python><python-2.7><python-multiprocessing>","1","0","1488"
"49051054","2018-03-01 13:46:21","2","","<p>Ok,</p>

<pre><code>@patch('time.time', mock_time)
@patch('os.getpid', mock_os_pid)
</code></pre>

<p>is the solution. Sorry, for waste your time :)</p>
","1525701","","","0","156","XWizard","2012-07-14 14:52:00","41","42","5","0","49050713","49051054","2018-03-01 13:27:17","0","247","<p>I have following method for testing right log format.</p>

<pre><code>@patch('sys.stderr', new_callable=StringIO)
    @mock.patch('socket.gethostname', return_value='testing')
    def test_logging(self, gethostname_function, mock_stderr):
        logger = logging.getLogger('project.logging')
        app_logging.init_logging()

        logger.info('testing mesage')


        assert mock_stderr.getvalue() == '{""message"": ""testing mesage"", ""levelname"": ""INFO"", ""process"": 37284, ""asctime"": ""2018-03-01 13:23:33,968"", ""hostname"": ""testing""}\n'
</code></pre>

<p>where formatter looks like this:</p>

<pre><code>(message) (levelname) (process) (asctime)
</code></pre>

<p>How can I mock datetime and process id? Thanks</p>
","1525701","","","pytest - mock process and time","<python><mocking><pytest>","1","0","725"
"49051121","2018-03-01 13:50:06","1","","<p>There is a neat library for displaying progress in terminal, named <code>tqdm</code>. Install it with</p>

<pre><code>$ pip install tqdm
</code></pre>

<p>Example script:</p>

<pre><code>import time
from tqdm import tqdm

seconds = 10

for i in tqdm(range(seconds)):
    time.sleep(1)  # sleep one second in each iteration
</code></pre>

<p>Run the script:</p>

<pre><code>$ python spam.py
100%|██████████████████████████████| 10/10 [00:10&lt;00:00,  1.00s/it]
</code></pre>

<p><code>tqdm</code> is highly customizable, check out the documentation available on its <a href=""https://pypi.python.org/pypi/tqdm"" rel=""nofollow noreferrer"">PyPI page</a>. Example with prepending custom message before the progress bar:</p>

<pre><code>import time
from tqdm import tqdm

for i in tqdm(range(10), desc='LOADING'):
    time.sleep(1)
</code></pre>

<p>Output:</p>

<pre><code>$ python spam.py
LOADING: 100%|█████████████████████| 10/10 [00:10&lt;00:00,  1.00s/it]
</code></pre>
","2650249","","","0","973","hoefling","2013-08-04 10:33:30","21122","1974","2259","216","49049940","","2018-03-01 12:40:36","0","79","<p>I'm trying to make a, ""fake"" loading bar as just a small task. I'm new to coding and this seems to work, but it seems a lot of code. I assume could be done in like 2 lines by someone with more skill than me. I would love to see how this could be refactored into a more efficient way. Any help would be greatly appreciated! </p>

<pre><code>loading_bar = ""LOADING\n[==========]""

print(loading_bar[0:10])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:11])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:12])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:13])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:14])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:15])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:16])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:17])
time.sleep(.300)
os.system('cls')
print(loading_bar[0:18])
time.sleep(.300)
os.system('cls')
print(loading_bar)
</code></pre>

<p>I'm sorry if this isn't in the right place. I'm new to StackOverflow as well.</p>
","9428838","2650249","2018-03-01 13:35:33","Refactoring a fake loading bar?","<python><python-3.x>","2","3","1032"
"49051166","2018-03-01 13:52:18","1","","<p>Try this:</p>

<pre><code>Data['Married'].fillna(Data['Married'].mode(), inplace=True)
</code></pre>

<p>Or Try this:</p>

<pre><code>Data['Married'].fillna(Data['Married'].value_counts().index[0], inplace=True)
</code></pre>

<p>Ensure that dtype of your categorical variables is object or category.</p>
","9299259","9299259","2018-03-01 14:25:58","4","308","YOLO","2018-02-01 10:14:21","6163","703","352","26","49050974","49051166","2018-03-01 13:42:13","0","814","<p>I Have one data set which contains some categorical variables and they have some missing(NA/Null). I Want to fill these NA/Nulls with Mode of that Column.
I tired Following thing but This didn't work</p>

<pre><code>MD=Data['Gender'].mode()
Data['Gender'].fillna(value=MD,inplace=True)


MD=Data['Married'].mode()
Data['Married'].fillna(value=MD,inplace=True)

MD=Data['Dependents'].mode()
Data['Dependents'].fillna(value=MD,inplace=True)

MD=Data['Self_Employed'].mode()
Data['Self_Employed'].fillna(value=MD,inplace=True)

MD=Data['Credit_History'].mode()
Data['Credit_History'].fillna(value=MD,inplace=True)

Gender                26
Married                6
Dependents            30
Education              0
Self_Employed         64
ApplicantIncome        0
CoapplicantIncome      0
LoanAmount             0
Loan_Amount_Term       0
Credit_History       100
Property_Area          0
Loan_Status            0
</code></pre>

<p>Still its Showing missing values.</p>
","3503378","7954106","2018-03-01 15:11:17","How fill NA/Null for categorical Varibles in python using fillna() function","<python><pandas><numpy><machine-learning>","1","0","971"
"49051169","2018-03-01 13:52:28","3","","<p>Use <a href=""https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html"" rel=""nofollow noreferrer""><code>broadcasting</code></a> to create the 3D mask and then assign zeros with <code>boolean-indexing</code> -</p>

<pre><code>mask = idx[...,None] &gt; np.arange(a.shape[2])
a[mask] = 0
</code></pre>

<p>Alternatively, we can also use NumPy builtin for outer-greater comparison to get that mask -</p>

<pre><code>mask = np.greater.outer(idx, np.arange(a.shape[2]))
</code></pre>

<p>Run on given sample -</p>

<pre><code>In [34]: mask = idx[...,None] &gt; np.arange(a.shape[2])

In [35]: a[mask] = 0

In [36]: a
Out[36]: 
array([[[ 0,  0,  3],
        [ 0,  5,  6]],

       [[ 7,  8,  9],
        [ 0, 11, 12]],

       [[ 0, 22, 23],
        [ 0, 26, 27]]])
</code></pre>
","3293881","","","0","788","Divakar","2014-02-10 17:11:35","173564","13312","6892","97","49050500","49051169","2018-03-01 13:14:28","2","58","<p>I have a 3D array <code>a</code> with shape (m, n, p) and a 2D array <code>idx</code> with shape (m, n). I want all elements in <code>a</code> where the last axis index is smaller than the corresponding element in <code>idx</code> to be set to 0.</p>

<p>The following code works. My question is : is there a more efficient approach?</p>

<pre><code>a = np.array([[[1, 2, 3],
               [4, 5, 6]],

              [[7, 8, 9],
               [10, 11, 12]],

              [[21, 22, 23],
               [25, 26, 27]]])
idx = np.array([[2, 1],
                [0, 1],
                [1, 1]])
for (i, j), val in np.ndenumerate(idx):
    a[i, j, :val] = 0
</code></pre>

<p>The result is</p>

<pre><code>array([[[ 0,  0,  3],
        [ 0,  5,  6]],

       [[ 7,  8,  9],
        [ 0, 11, 12]],

       [[ 0, 22, 23],
        [ 0, 26, 27]]])
</code></pre>
","686806","","","Set 3D numpy array value to 0 if last axis index is smaller than value in another 2D array","<python><arrays><numpy>","1","0","859"
"49051181","2018-03-01 13:52:56","3","","<p>You could try to use the following code:</p>

<pre><code>query = WebDriverWait(self.browser, 5).until(
            expected_conditions.presence_of_element_located((By.ID, ""name"")))
query.send_keys('python')
WebDriverWait(self.browser, 5).until(lambda browser: query.get_attribute('value') == 'python')
self.browser.find_element_by_id(""button"").click()
</code></pre>

<p>This code should allow you to wait until a full string is entered in the field.</p>
","4549554","4549554","2018-03-01 14:56:00","0","457","Andersson","2015-02-10 08:27:34","40727","5512","1461","1828","49051111","","2018-03-01 13:49:24","3","2173","<p>I have a question regarding the send_keys function. How can I make the test wait for the entire content of send_keys to be entered? I can not use time.sleep, so I tried:</p>

<pre><code>WebDriverWait(self.browser, 5).until(
            expected_conditions.presence_of_element_located((By.ID, ""name"")))
query = driver.find_element_by_id('name') 
query.send_keys('python')
driver.find_element_by_id(""button"").click()
</code></pre>

<p>the app clicks the button before the action completes send_keys
thank you for an answer</p>
","9429143","","","python selenium send_keys wait","<python><selenium><selenium-webdriver><wait><sendkeys>","3","5","528"
"49051189","2018-03-01 13:53:21","3","","<p>Use the <code>subprocess</code> module to run <code>xscreensaver-command</code>:</p>

<pre><code>def check_screensaver():
    p = subprocess.run(['xscreensaver-command', '-time'], stdout=subprocess.PIPE)
    words = p.stdout.decode().split()
    return 'blanked' in words:
</code></pre>

<p>This simple code looks for the word 'blanked' in the output. You could parse it further to extract the time it was activated/deactivated.</p>
","17160","","","0","436","nosklo","2008-09-18 03:28:06","166916","7519","823","871","49050621","","2018-03-01 13:21:26","0","260","<p>I'm running OpenSUSE Leap 42.3 with XFCE and it uses xscreensaver.</p>

<p>I want to somehow get True if screensaver is currently working. You can't just look at process list, xscreensaver always sits there.</p>

<p>Is there any easy way to do that?</p>
","9429076","","","Get xscreensaver status in python","<python><linux><python-3.x><screensaver><xfce>","1","1","257"
"49051194","2018-03-01 13:53:42","0","","<pre><code>import boto
from boto.s3.key import Key
from boto.s3.connection import OrdinaryCallingFormat
from urllib import urlopen


def upload_images_s3(img_url):
    try:
        connection = boto.connect_s3('access_key', 'secret_key', calling_format=OrdinaryCallingFormat())       
        bucket = connection.get_bucket('boto-demo-1519388451')
        file_obj = Key(bucket)
        file_obj.key = img_url.split('/')[::-1][0]
        fp = urlopen(img_url)
        result = file_obj.set_contents_from_string(fp.read())
    except Exception, e:
        return e
</code></pre>
","5397229","5397229","2018-03-01 14:05:47","0","578","Shabari Prasad H.D","2015-10-01 11:13:52","1","2","0","0","14346065","14346212","2013-01-15 20:14:55","30","16880","<p>I'm working in a Python web environment and I can simply upload a file from the filesystem to S3 using boto's key.set_contents_from_filename(path/to/file). However, I'd like to upload an image that is already on the web (say <a href=""https://pbs.twimg.com/media/A9h_htACIAAaCf6.jpg:large"" rel=""noreferrer"">https://pbs.twimg.com/media/A9h_htACIAAaCf6.jpg:large</a>).</p>

<p>Should I somehow download the image to the filesystem, and then upload it to S3 using boto as usual, then delete the image? </p>

<p>What would be ideal is if there is a way to get boto's key.set_contents_from_file or some other command that would accept a URL and nicely stream the image to S3 without having to explicitly download a file copy to my server.</p>

<pre><code>def upload(url):
    try:
        conn = boto.connect_s3(settings.AWS_ACCESS_KEY_ID, settings.AWS_SECRET_ACCESS_KEY)
        bucket_name = settings.AWS_STORAGE_BUCKET_NAME
        bucket = conn.get_bucket(bucket_name)
        k = Key(bucket)
        k.key = ""test""
        k.set_contents_from_file(url)
        k.make_public()
                return ""Success?""
    except Exception, e:
            return e
</code></pre>

<p>Using set_contents_from_file, as above, I get a ""string object has no attribute 'tell'"" error. Using set_contents_from_filename with the url, I get a No such file or directory error . The <a href=""http://boto.cloudhackers.com/en/latest/s3_tut.html#storing-data"" rel=""noreferrer"">boto storage documentation</a> leaves off at uploading local files and does not mention uploading files stored remotely.</p>
","1141692","1141692","2013-01-15 21:17:59","Upload image available at public URL to S3 using boto","<python><django><amazon-s3><boto>","9","2","1581"
"49051202","2018-03-01 13:54:06","0","","<p>For me following worked.</p>

<h1>settings.py</h1>

<pre><code>DEBUG = True

STATIC_URL = '/static/'
STATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles') #this is not used
# Add static folder to STATIC_DIRS
STATICFILES_DIRS = [
    os.path.join(BASE_DIR, 'static'),
]
</code></pre>

<h1>urls.py</h1>

<pre><code>from django.conf.urls.static import static
from django.conf import settings

urlpatterns = [

] + static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)
</code></pre>

<blockquote>
  <p>Note</p>
  
  <p>This helper function works only in debug mode and only if the given
  prefix is local (e.g. /static/) and not a URL (e.g.
  <a href=""http://static.example.com/"" rel=""nofollow noreferrer"">http://static.example.com/</a>).</p>
  
  <p>Also this helper function only serves the actual STATIC_ROOT folder;
  it doesn’t perform static files discovery like
  django.contrib.staticfiles.</p>
</blockquote>
","1936024","1936024","2018-03-01 14:07:25","0","924","Kishor Pawar","2012-12-29 06:57:09","2141","501","1148","6","35507140","","2016-02-19 14:01:28","11","7879","<p>This question seems to be asked several time but I can not fix it. </p>

<p>I deployed a django app on production with <code>DEBUG = False</code>. I set my <code>allowed_host</code>. 
I used <code>{% load static from staticfiles %}</code> to load static files. I exactly write the settings sugested by Heroku doc : </p>

<pre><code>BASE_DIR = os.path.dirname(os.path.dirname(__file__))
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))

STATIC_ROOT = os.path.join(PROJECT_ROOT, 'staticfiles')
STATIC_URL = '/static/'

STATICFILES_DIRS = (
    os.path.join(PROJECT_ROOT, 'static'),
)

STATICFILES_STORAGE = 'whitenoise.django.GzipManifestStaticFilesStorage'
</code></pre>

<p>BUT I got an error 500. And got this traceback (by mail)</p>

<pre><code>...
`cache_name = self.clean_name(self.hashed_name(name))
 File ""/app/.heroku/python/lib/python3.5/site-    packages/django/contrib/staticfiles/storage.py"", line 94, in hashed_name (clean_name, self))
...
ValueError: The file ‘app/css/font.css’ could not be found with &lt;whitenoise.django.GzipManifestStaticFilesStorage object at 0x7febf600a7f0&gt;.`
</code></pre>

<p>When I run <code>heroku run python manage.py collectstatic --noinput</code> 
All seems ok :</p>

<p><code>276 static files copied to '/app/annuaire/staticfiles', 276 post-processed.</code></p>

<p>Does anyone have an idea to help me, please ?</p>

<p>Thanks</p>

<p>EDIT : </p>

<pre><code>annuaire
|-- /annuaire
|-- -- /settings.py
|-- /app
|-- -- /static/...`
</code></pre>

<p>wsgi.py</p>

<pre><code>from django.core.wsgi import get_wsgi_application
from whitenoise.django import DjangoWhiteNoise


application = get_wsgi_application()
application = DjangoWhiteNoise(application)
</code></pre>
","1542994","1542994","2016-02-19 16:33:18","Django staticfiles not found on Heroku (with whitenoise)","<python><django><heroku><django-staticfiles>","8","13","1728"
"49051221","2018-03-01 13:55:08","0","","<p>I am not sure if this will fix your problem. You can define a separate function that acquires frames from the camera and puts it in a queue. You can run this function in a separate thread. Refer to this <a href=""https://docs.python.org/2/library/threading.html"" rel=""nofollow noreferrer"">link</a> for documentation on threading. This speeds up the process of getting frames from the camera because the cap.read() function is a blocking function (if you are using cap=cv2.VideoCapture()). </p>

<p>The code would be something like this.</p>

<pre><code>def getf(queue):
    cap = cv2.VideoCapture(0)    
    while(processing):
        fr = {}
        ret, a = cap.read()
        if ret:
            fr[""imagecaptured""]=a
            queue.put(fr)
        else:
            #whatever you want to do when a frame is unable to be read from cam
    cap.release()

stream = threading.Thread(target=getf, args=queue)
</code></pre>

<p>Note that 'processing' in the above code example is a global variable. Now, you can define a function to set processing to be true, and start the thread with 'stream.start()' command or put this directly in the program. </p>

<p>Once the thread is started, frames are continuously put in queue for you to read when you want. With the below code, you have the frame.</p>

<pre><code>if not queue.empty():
    capturedframe = queue.get()
    frame = capturedframe[""imagecaptured""]
</code></pre>

<p>I used this method to stream from camera and at same time do something else. Referred from a <a href=""https://www.kurokesu.com/main/2016/08/01/opencv-usb-camera-widget-in-pyqt/"" rel=""nofollow noreferrer"">link</a> on making a webcam widget with pyqt. Note that the above code snippets are for an example and are not read to be run. Apart from definitions, I suggest you also include a condition to keep check on queue size. You can now modify this to use for your application and see if it does the job. You can also refer to this <a href=""https://www.pyimagesearch.com/2015/12/21/increasing-webcam-fps-with-python-and-opencv/"" rel=""nofollow noreferrer"">link</a> for a similar example.</p>
","6328116","","","0","2117","MK 62665","2016-05-13 00:46:23","105","39","22","0","49033670","","2018-02-28 15:58:26","0","1610","<p>Please help me understand why video recorded using Opencv is so slow. It does not reflect quick movements.
For example, if I move the camera then the movement is too slow in the video. Also, though I showed a picture in front of the camera for about 2 seconds, I did not see the picture in the recording.</p>

<p>Can someone explain me please what is going on here.
This is my simple code:</p>

<pre><code>fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter('output2.avi',fourcc, 30.0, (640,480))

while (True):

    camera.capture(stream, use_video_port=True, format='jpeg') 
    stream.seek(0)
    imageData = np.fromstring(stream.getvalue(), dtype=np.uint8)
    npImage = cv2.imdecode(imageData, 1) 
    out.write(npImage)
    stream.close()
</code></pre>
","5163452","6328116","2018-03-01 14:56:09","Opencv recorded video is too slow and camera update is very slow","<python><numpy><opencv><video><computer-vision>","2","3","773"
"49051225","2018-03-01 13:55:20","0","","<p>Just open your terminal and run this command thats for windows users
<code>pip install -U wxPython</code></p>

<p>for Ubuntu user you can use this</p>

<pre><code>pip install -U \
-f https://extras.wxpython.org/wxPython4/extras/linux/gtk3/ubuntu-16.04 \
wxPython
</code></pre>
","6258285","","","0","280","Japhet Johnson","2016-04-26 19:52:52","1","3","0","0","8609666","","2011-12-22 21:00:44","35","121554","<p>Im sorry to ask this question again. I have searched and found endles repeats of it both on stackoverflow and also on general google search. Unfortunatly I just cant get my system sorted.</p>

<p>I have the following:</p>

<pre><code>C:\Python27\Lib\site-packages\wx-2.8-msw-unicode
</code></pre>

<p>this folder contains the wx folder and also wx &amp; wxPython folders which each contain the 
<code>_init_.py</code> files</p>

<p>When I import wx I get the error message <code>""no module named wx""</code></p>

<p>What do I need to do in order to get Python to find the relevant files to allow me to ""import wx"" succesfully</p>
","975765","718618","2011-12-22 21:02:22","Python ImportError: No module named wx","<python><importerror><wxwidgets>","14","10","632"
"49051253","2018-03-01 13:57:07","14","","<p>My initial thought was to write a callable that returns the choices, that will be evaluated for each request.</p>

<pre><code>import datetime

def year_choices():
    return [(r,r) for r in range(1984, datetime.date.today().year+1)]

def current_year():
    return datetime.date.today().year

class MyModel(models.Model):
    year = models.IntegerField(_('year'), choices=year_choices, default=current_year)
</code></pre>

<p>However this doesn't work, because Django's check framework doesn't allow the year_choices to be used as the default. Even if you could hack the choices to be generated dynamically, it would have the disadvantage that Django would try to create a migration each year when the choices change. </p>

<p>You can avoid this by generating the choices at the form level instead. You can use validators in the model to prevent invalid data. Note that <code>MaxValueValidator</code> is wrapped in a function <code>max_value_current_year</code> to avoid a new migration every year.</p>

<pre><code>import datetime
from django.core.validators import MaxValueValidator, MinValueValidator

def current_year():
    return datetime.date.today().year

def max_value_current_year(value):
    return MaxValueValidator(current_year())(value)    

class MyModel(models.Model):
    year = models.IntegerField(_('year'), validators=[MinValueValidator(1984), max_value_current_year])

def year_choices():
    return [(r,r) for r in range(1984, datetime.date.today().year+1)]

class MyForm(forms.ModelForm):
    year = forms.TypedChoiceField(coerce=int, choices=year_choices, initial=current_year)
</code></pre>
","113962","5839007","2019-09-04 02:06:30","8","1618","Alasdair","2009-05-28 20:26:55","203443","9896","5891","530","49051017","49051253","2018-03-01 13:44:24","8","7470","<p>I want my users to enter their birth year. I don't want them to type the same in the form rather select the year from available options. I known that I can do something like this in my model if I needed to date instead of year:</p>

<pre><code>class MyModel(models.Model):

    birthday = models.DateField(null=True, blank=True)
</code></pre>

<p>I can do this in forms to let the user choose date from datepicker.</p>

<pre><code>    birthday = forms.fields.DateField(widget=forms.widgets.DateInput(attrs={'type': 'date'}))
</code></pre>

<p>For year, I can use a <code>CharField/IntegerField</code> with <code>choices</code> similar to what has been done in this <a href=""https://stackoverflow.com/a/24656072/8414030"">SO</a> answer. </p>

<pre><code>import datetime
YEAR_CHOICES = [(r,r) for r in range(1984, datetime.date.today().year+1)]

year = models.IntegerField(_('year'), choices=YEAR_CHOICES, default=datetime.datetime.now().year)
</code></pre>

<p>The problem, however, is that change of current year from say, 2018 to 2019, will not change the available options.</p>

<p>Can you help or provide hints to achieve what I want to do?</p>
","8414030","","","Year Field in Django","<python><django><django-models>","3","3","1150"
"49051272","2018-03-01 13:57:54","2","","<p>DRF documentation isn't verbose on this matter (or I've missed the piece where it is), but it mentions <a href=""https://github.com/encode/django-rest-framework/blob/3.6.2/rest_framework/schemas.py#L257"" rel=""nofollow noreferrer""><code>rest_framework.schemas.SchemaGenerator</code> class</a> and it seems that this class really does all the introspection stuff. Fortunately, the source code is well-structured and easy to read.</p>

<p>Those path fields are generated by <a href=""https://github.com/encode/django-rest-framework/blob/3.6.2/rest_framework/schemas.py#L517"" rel=""nofollow noreferrer""><code>get_path_fields</code></a> method (I found it by tracing the execution path: <code>get_schema</code> → <code>get_links</code> → <code>get_link</code>), and I found that descriptions <a href=""https://github.com/encode/django-rest-framework/blob/3.6.2/rest_framework/schemas.py#L540"" rel=""nofollow noreferrer"">come from model fields's <code>help_text</code></a> attribute.</p>

<p>So in my model I've specified:</p>

<pre><code>class MyResource(models.Model):
    slug = models.CharField(unique=True, help_text=_(""unique alphanumeric identifier""))
    ...
</code></pre>
","694682","694682","2019-02-28 20:35:10","2","1173","webbyfox","2011-04-06 10:57:45","708","93","105","11","49050094","49051272","2018-03-01 12:50:01","4","252","<p>My questions is:</p>

<p>how can i fill the field Description? in  tha table of Parameters in my docs page, here an example of my function and a screenshot how does it look</p>

<pre><code>def delete(self, request, id_):
    repository = self.get_object(id_, owner=request.user)
    repository.delete()
    return Response(status=status.HTTP_204_NO_CONTENT, headers={""web_words"": request.user.profile.web_words, ""repo_words"": request.user.profile.repo_words, ""files"": request.user.profile.files})
</code></pre>

<p><a href=""https://i.stack.imgur.com/dcDBa.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dcDBa.png"" alt=""enter image description here""></a></p>
","8807216","8807216","2018-03-01 14:34:32","Django restframework documenting Views","<python><django><django-rest-framework><documentation-generation>","1","2","681"
"49051287","2018-03-01 13:58:42","1","","<p>There's a catch when you set do_compression=True. For large files, MATLAB cannot load when saved with do_compression=True.</p>

<p>In my case, mat files under 2 GB didn't have any problem loading from my MATLAB (2017b) whether do_compression is True or False, but when I load 2.25 GB mat file saved using scipy.io.savemat() with compression, MATLAB failed to load even though I can load it from Python using loadmat().</p>

<p>In scipy.io.savemat manual, the default value of format = '5', which supports up to MATLAB 7.2. It is the latest version it supports. In MATLAB's save() documentation, however, it says it needs to be saved with '-v7.3' for files over 2GB. I think the reason scipy's savemat fails to save correctly is because it doesn't support MATLAB 7.3 version for mat files larger than 2GB.</p>

<p>Hopefully scipy will have an upgrade to fix this problem.</p>
","2158698","","","2","878","dbdq","2013-03-11 22:20:26","122","19","70","0","33565414","33565550","2015-11-06 11:06:07","7","2551","<p>Let's say I generate the following toy dataset from Matlab, and I save it as a mat file:</p>



<pre><code>&gt;&gt; arr = rand(100);
&gt;&gt; whos arr
  Name        Size             Bytes  Class     Attributes

  arr       100x100            80000  double
&gt;&gt; save('arr.mat', 'arr')
</code></pre>

<p>The saved <code>arr.mat</code> file is of size <code>75829 Bytes</code> according to the output of the <code>ls</code> command.</p>

<p>If I load the same file using <code>scipy.io.loadmat()</code> and save it again using <code>scipy.io.savemat()</code>:</p>



<pre><code>arr = io.loadmat('arr.mat')
with open('arrscipy.mat', 'w') as f:
    io.savemat(f, arr)
</code></pre>

<p>I obtain a file with a considerably different size (&sim; 4KB larger):</p>

<pre><code>$ ls -al
75829 Nov  6 11:52 arr.mat
80184 Nov  6 11:52 arrscipy.mat
</code></pre>

<p>I now have two binary mat files containing the same data. My understanding is that the size of a binary mat file is determined by the size of its contained variables, plus some overhead due to file headers. However <strong>the sizes of these two files are considerably different</strong>. Why is this? <a href=""https://stackoverflow.com/questions/23326266/saving-mat-files-in-different-numerical-data-formats-in-scipy-io-savemat"">Is it a data format problem?</a></p>

<p>I tried this with arrays of structures too, and the result is similar: scipy-saved mat files are larger than Matlab-saved ones.</p>
","1521571","-1","2017-05-23 12:07:36","Why does saving mat files with scipy result in larger file size than with Matlab?","<python><matlab><scipy><save>","2","0","1464"
"49051335","2018-03-01 14:01:16","1","","<p>I'm surprised no one mentioned mapping the file into memory: <a href=""https://docs.python.org/3.6/library/mmap.html"" rel=""nofollow noreferrer"">mmap</a></p>

<p>With this you can access the file as if it were already loaded into memory and the OS will take care of mapping it in and out as possible. Also, if you do this from 2 independent processes and they map the file ""shared"", they will share the underlying memory.</p>

<p>Once mapped, it will behave like a <a href=""https://docs.python.org/3.6/library/stdtypes.html#bytearray"" rel=""nofollow noreferrer"">bytearray</a>. You can use regular expressions, find or any of the other common methods.</p>

<p>Beware that this approach is a little OS specific. It will not be automatically portable.</p>
","3339058","","","0","753","Javier","2014-02-21 21:41:35","1998","170","866","57","3893885","3893931","2010-10-08 19:56:37","32","113189","<p>I need to search a pretty large text file for a particular string. Its a build log with about 5000 lines of text.  Whats the best way to go about doing that? Using regex shouldn't cause any problems should it? I'll go ahead and read blocks of lines, and use the simple find.</p>
","388025","3621464","2015-01-04 01:07:17","Cheap way to search a large text file for a string","<python>","9","4","282"
"49051342","2018-03-01 14:01:53","1","","<p>Let's take a look at each approach.</p>

<hr>

<h1>1.</h1>

<pre class=""lang-py prettyprint-override""><code>from selenium.webdriver.common.action_chains import ActionChains
element_ok = driver.find_element_by_xpath(""//input[@id='popup_ok']"")
Action.Chains(driver).move_to_element(element_ok).perform()
element.click()
</code></pre>

<p>This has two problems.</p>

<p><strong>First,</strong> you import <code>ActionChains</code>, but then try to use it as <code>Action.Chains</code>. Because you didn't import anything called <code>Action</code>, you'll likely see this error:</p>

<pre><code>NameError: name 'Action' is not defined
</code></pre>

<p>Removing the extra inner <code>.</code> should fix it:</p>

<pre class=""lang-py prettyprint-override""><code>ActionChains(driver).move_to_element(element_ok).perform()
</code></pre>

<p><strong>Second,</strong> you find the element and save it to a variable named <code>element_ok</code>. Then, however, you try to call <code>click()</code> on a variable named <code>element</code>. Because you haven't defined a variable with that name, you'll likely see this error:</p>

<pre><code>NameError: name 'element' is not defined
</code></pre>

<p>Calling <code>element_ok.click()</code> should fix it:</p>

<pre class=""lang-py prettyprint-override""><code>element_ok.click()
</code></pre>

<p><strong>Note:</strong> You probably don't need to use <code>ActionChains</code> at all. You should only need to tell Selenium to move to the element if the element is outside of the viewport, e.g., ""below the fold"":</p>

<pre class=""lang-py prettyprint-override""><code>element_ok = driver.find_element_by_xpath(""//input[@id='popup_ok']"")
element_ok.click()
</code></pre>

<hr>

<h1>2.</h1>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_xpath("".//*[@id='popup_ok']/div/input"").click()
</code></pre>

<p>This XPath query tells Selenium to:</p>

<ol>
<li>find an element with an <code>id</code> of <code>""popup_ok""</code> (A),</li>
<li>find a child of A that is a <code>&lt;div&gt;</code> (B),</li>
<li>find a child of B that is an <code>&lt;input&gt;</code> (C), then</li>
<li>return C.</li>
</ol>

<p>This does not make sense for your HTML. The element with <code>id</code> <code>""popup_ok""</code> is an <code>&lt;input&gt;</code>, which has neither a child <code>&lt;div&gt;</code> nor a grandchild <code>&lt;input&gt;</code>.</p>

<p>Since the element with <code>id</code> <code>""popup_ok""</code> (A) <em>is the <code>&lt;input&gt;</code> you want</em>, you can simply remove the remainder of the XPath query:</p>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_xpath("".//*[@id='popup_ok']"").click()
</code></pre>

<hr>

<h1>3.</h1>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_css_selector("".button_main[value='OK']"").click()
</code></pre>

<p>This CSS selector tells Selenium to find and return the element that:</p>

<ol>
<li>has the class <code>button_main</code> <em>and</em></li>
<li>has a <code>value</code> of <code>""OK""</code> (A).</li>
</ol>

<p>Your button meets requirement 2, but not 1. It has no class <code>button_main</code>. (There is no element with class <code>button_main</code>.)</p>

<p>Instead, you can use <code>*</code> to match any element regardless of class name:</p>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_css_selector(""*[value='OK']"").click()
</code></pre>

<p>However, this is not a great CSS selector. Because <code>*</code> matches any element, it has the potential to be slow.</p>

<p>Instead, you can match by the tag:</p>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_css_selector(""input[value='OK']"").click()
</code></pre>

<hr>

<h1>4.</h1>

<pre class=""lang-py prettyprint-override""><code>clear_button = driver.find_element_by_xpath(""//input[@id='popup_panel'][@type='button']"")
clear_button = driver.find_element_by_xpath(""//form[@id='popup_ok']/input[1]"")
</code></pre>

<p><strong>The first XPath query</strong> tells Selenium to:</p>

<ol>
<li>find an <code>&lt;input&gt;</code> element that
a. has <code>id</code> <code>""popup_panel""</code> and
b. has <code>type</code> <code>""button""</code>.</li>
</ol>

<p>Your button meets requirements 1 and 1b, but not 1a. The <code>id</code> <code>""popup_panel""</code> is used by the grandparent <code>&lt;div&gt;</code>.</p>

<p>To fix it, you could just remove that requirement:</p>

<pre class=""lang-py prettyprint-override""><code>clear_button = driver.find_element_by_xpath(""//input[@type='button']"")
</code></pre>

<p><strong>The second XPath query</strong> tells Selenium to:</p>

<ol>
<li>find a <code>&lt;form&gt;</code> element (A) that
a. has <code>id</code> <code>""popup_ok""</code>, then</li>
<li>find the first child of A that is an <code>&lt;input&gt;</code> (B).</li>
</ol>

<p>Your button meets requirement 2, but not 1. Its parent is neither a <code>&lt;form&gt;</code> tag nor has an <code>id</code> of <code>""popup_ok""</code>.</p>

<p>Instead, <em>the <code>&lt;input&gt;</code></em> has that <code>id</code>:</p>

<pre class=""lang-py prettyprint-override""><code>clear_button = driver.find_element_by_xpath(""//input[@id='popup_ok'][1]"")
</code></pre>

<p>Note: <code>[1]</code> selects the first matching element. Since <code>id</code> attributes should be unique, this is redundant and can be removed:</p>

<pre class=""lang-py prettyprint-override""><code>clear_button = driver.find_element_by_xpath(""//input[@id='popup_ok']"")
</code></pre>

<hr>

<h1>5.</h1>

<pre class=""lang-py prettyprint-override""><code>import keyboard
keyboard.press_and_release('shift+s, space')
</code></pre>

<p>This might not work for a lot of reasons, which are probably not worth getting into. Selenium has the ability to simulate keyboard events, so you probably don't need to use another Python package.</p>

<p>If you have the element that should receive the keyboard events, you can call <code>send_keys()</code> on it:</p>

<pre class=""lang-py prettyprint-override""><code>from selenium.webdriver.common.keys import Keys

element.send_keys(Keys.SPACE)
</code></pre>

<p>If you don't have the element, you can use <code>ActionChains</code> to send keyboard events to the currently active element:</p>

<pre><code>ActionChains(driver).send_keys(Keys.SPACE).perform()
</code></pre>
","199806","","","0","6340","Ian Lesperance","2009-10-30 17:12:54","3757","155","9","4","49041839","","2018-03-01 02:46:35","0","179","<p>First of all, sorry for my English. I'm from Buenos Aires, and I've started learning Python just a few weeks ago. Furthermore, I have a really basic knowledge in programming. All I was able to do so far was by getting the info from internet (no formal education in this matter-I was studying Accounting last year).</p>

<p>As of this post, I want to find an element in a web page but I can't seem to get it right. I've even tried to click on ""space"" key-the simplest thing to do in this case. </p>

<p>I want to click on ""OK"" button.</p>

<p>I have from ""Inspect element"":</p>

<pre><code>&lt;div class=""alert"" id=""popup_content""&gt;
  &lt;div id=""popup_message""&gt;No Pending Documents&lt;/div&gt;
  &lt;div id=""popup_panel""&gt;
    &lt;input id=""popup_ok"" type=""button"" value=""OK""&gt;
  &lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p><a href=""https://i.stack.imgur.com/VCRFt.jpg"" rel=""nofollow noreferrer"">print:</a>
I've tried these 5 codes:</p>

<pre class=""lang-py prettyprint-override""><code>from selenium.webdriver.common.action_chains import ActionChains
element_ok = driver.find_element_by_xpath(""//input[@id='popup_ok']"")
Action.Chains(driver).move_to_element(element_ok).perform()
element.click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_xpath("".//*[@id='popup_ok']/div/input"").click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>driver.find_element_by_css_selector("".button_main[value='OK']"").click()
</code></pre>

<pre class=""lang-py prettyprint-override""><code>clear_button = driver.find_element_by_xpath(""//input[@id='popup_panel'][@type='button']"")
clear_button = driver.find_element_by_xpath(""//form[@id='popup_ok']/input[1]"")
</code></pre>

<pre class=""lang-py prettyprint-override""><code>import keyboard
keyboard.press_and_release('shift+s, space')
</code></pre>

<p>Would someone help me get through this?</p>

<p>PS: I'm using selenium (read from it in the book 'Automate the Boring Stuff with Python. Practical Programming for Total Beginners'. And chrome webdriver.</p>
","9426664","199806","2018-03-01 12:25:06","Unable to find_element in web through Python (selenium)","<python><selenium>","4","0","2058"
"49051348","2018-03-01 14:02:26","2","","<p>You can put the options(years) in the form, using the <em>IntegerField</em> <strong>min_value</strong> and <strong>max_value</strong>. In model you can use the <em>IntegerField</em> without choices.</p>

<ul>
<li>Forms: <a href=""https://docs.djangoproject.com/en/2.0/ref/forms/fields/#integerfield"" rel=""nofollow noreferrer"">IntegerField</a></li>
<li><a href=""https://docs.djangoproject.com/en/2.0/topics/forms/"" rel=""nofollow noreferrer"">More about forms</a></li>
</ul>

<p>So, you won't worry about when the year change, because you will only change the options in the form.</p>

<p>If you want to change the year automatically, this could help you: <a href=""https://stackoverflow.com/questions/3470741/django-forms-integerfield-set-max-value-on-runtime"">Django forms integerField set max_value on runtime</a></p>
","880567","880567","2018-10-25 02:40:01","0","819","klassmann","2011-08-05 12:30:16","428","26","31","3","49051017","49051253","2018-03-01 13:44:24","8","7470","<p>I want my users to enter their birth year. I don't want them to type the same in the form rather select the year from available options. I known that I can do something like this in my model if I needed to date instead of year:</p>

<pre><code>class MyModel(models.Model):

    birthday = models.DateField(null=True, blank=True)
</code></pre>

<p>I can do this in forms to let the user choose date from datepicker.</p>

<pre><code>    birthday = forms.fields.DateField(widget=forms.widgets.DateInput(attrs={'type': 'date'}))
</code></pre>

<p>For year, I can use a <code>CharField/IntegerField</code> with <code>choices</code> similar to what has been done in this <a href=""https://stackoverflow.com/a/24656072/8414030"">SO</a> answer. </p>

<pre><code>import datetime
YEAR_CHOICES = [(r,r) for r in range(1984, datetime.date.today().year+1)]

year = models.IntegerField(_('year'), choices=YEAR_CHOICES, default=datetime.datetime.now().year)
</code></pre>

<p>The problem, however, is that change of current year from say, 2018 to 2019, will not change the available options.</p>

<p>Can you help or provide hints to achieve what I want to do?</p>
","8414030","","","Year Field in Django","<python><django><django-models>","3","3","1150"
"49051365","2018-03-01 14:03:08","0","","<p>As people mentioned we don't know what is exactly your purpose so it is hard to help you.</p>

<p>However, here are some tips:</p>

<ul>
<li>Elements in <code>for</code> loop shall indented</li>
<li>For checking types, you can use <code>isinstance</code></li>
<li>You can use new lines to increase visibility of the initial variable</li>
<li>Give better names to your variables</li>
</ul>

<p>A code solving your issue could look like this</p>

<pre><code>nested_list = [
    'name1',
    'name2',
    [
        1, 3, 5, 7,
        ['a', 'b', 'c', 'd']
    ]
]

for i in nested_list:
    if isinstance(i, list):
        for j in i:
            # Do something with j
            if isinstance(j, list):
                for k in j:
                    # Do something with k, like for example
                    print(""%s ==&gt; %s ==&gt; %s"" % (i, j, k))
    else:
        # Do something else with i, like for example
        print(""I: %s"" % i)`
</code></pre>

<p>An easier way if you just need to print the list is to use the module <code>pprint</code>. See <a href=""https://pymotw.com/2/pprint/"" rel=""nofollow noreferrer""><strong>PythonModuleOfTheWeek</strong></a> for a great tutorial.</p>

<p>You just have to do the following:</p>

<pre><code>import pprint

nested_list = [
    'name1',
    'name2',
    [
        1, 3, 5, 7,
        ['a', 'b', 'c', 'd']
    ]
]

pprint.pprint(nested_list)
</code></pre>
","1603480","1603480","2018-03-01 14:08:18","0","1412","Jean-Francois T.","2012-08-16 14:08:44","5954","547","244","2","49050798","49050962","2018-03-01 13:31:49","-3","104","<p>I am stuck in Python. I need to create and parse a 3-level list.
For example, a list inside a list inside a list.</p>

<p>2 levels are working for me but going to the third is so much confusion please help</p>

<pre><code>l= [1,5,6,7,8,['a','b','c','d']]
a= ['name 1','name 2',l]

for i in a:
   if type(i) == type([]):
      for j in i:
         print(j, end=' ')
      for k in j:
         if type(j) == type([]):
             print('non')


else:
    print(i, end=' ')
</code></pre>
","8637130","1603480","2018-03-01 14:04:47","Three level list in PYTHON","<python>","3","3","489"
"49051395","2018-03-01 14:04:38","0","","<p>Working code</p>

<pre><code>from tkinter import*
from tkinter import Tk, StringVar, ttk
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
import random
import datetime
import time;
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
start = Tk()
start.geometry(""100x600+0+0"")
start.title (""R.E.D Inventory Control System"")


#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Heading = Frame(start, width = 1000, height = 100, bd = 10, relief = 'raise')
Heading.pack(side = TOP)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
LowerHeading = Frame(start, width = 500, height  = 100, bd = 20, relief = 'raise')
LowerHeading.pack(side = BOTTOM)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
LMiddle = Frame(start, width = 500, height = 1000, bd = 12, relief = 'raise')
LMiddle.pack(side = LEFT)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
RMiddle = Frame(start, width = 500, height = 1000, bd = 12, relief = 'raise')
RMiddle.pack(side=RIGHT)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Title = Label(Heading, font=('arial',40,'bold'), text = ""R.E.D Inventory Control System"", bd = 10, width = 40, anchor = 'w')
      #justify = 'center')
Title.grid(row=0,column=0)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
info1=StringVar()
info2=StringVar()


info1.set(""0"")
info2.set("""")

def Product(event):
    if (info1.get()==""ID01""):
        info2.set(""Dress"")


#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
ProductID = Label(LMiddle, font=('arial',12,'bold'),text = ""Product ID"", bd = 10, width = 15, anchor = 'w')
ProductID.grid(row=0,column=0)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
ProductsID = ttk.Combobox(LMiddle, textvariable = info1 ,state='readonly', font=('arial',12,'bold'),  width =20)
ProductsID['value']=('','ID01','ID02','ID03','ID04','ID05')
ProductsID.current(0)
ProductsID.grid(row=0,column=1)
ProductsID.bind(""&lt;&lt;ComboboxSelected&gt;&gt;"", Product)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Description1 = Label(LMiddle, font=('arial',12,'bold'),text =""Description"", bd = 10, width = 15, anchor = 'w')
Description1.grid(row=2,column=0)
Description2 = Label(LMiddle, font=('arial',12,'bold'), textvariable = info2, bd = 10, width = 18, relief = 'sunken')
Description2.grid(row=2,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
DateStockBought1 = Label(LMiddle, font=('arial',12,'bold'), text =""Date Stock Bought"", bd = 10, width = 15, anchor = 'w')
DateStockBought1.grid(row=3,column=0)
DateStockBought2 = Label(LMiddle, font=('arial',12,'bold'), bd = 10, width = 18, relief = 'sunken')
DateStockBought2.grid(row=3,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Price1 = Label(LMiddle, font=('arial',12,'bold'), text =""Price"", bd = 10, width = 15, anchor = 'w')
Price1.grid(row=4,column=0)
Price2 = Label(LMiddle, font=('arial',12,'bold'), bd = 10, width = 18, relief = 'sunken')
Price2.grid(row=4,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
AmountLeft1 = Label(RMiddle, font=('arial',12,'bold'), text =""Amount Left"", bd = 10, width = 15, anchor = 'w')
AmountLeft1.grid(row=1,column=0)
AmountLeft2 = Label(RMiddle, font=('arial',12,'bold'), bd = 10, width = 18,     relief = 'sunken')
AmountLeft2.grid(row=1,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
CurrentSeason1 = Label(RMiddle, font=('arial',12,'bold'), text =""CurrentSeason"", bd = 10, width = 15, anchor = 'w')
CurrentSeason1.grid(row=2,column=0)
CurrentSeason2 = Label(RMiddle, font=('arial',12,'bold'), text = """", bd = 10, width = 18, relief = 'sunken')
CurrentSeason2.grid(row=2,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Discount1 = Label(RMiddle, font=('arial',12,'bold'), text =""Discount"", bd = 10, width = 15, anchor = 'w')
Discount1.grid(row=3,column=0)
Discount2 = Label(RMiddle, font=('arial',12,'bold'), bd = 10, width = 18, relief = 'sunken')
Discount2.grid(row=3,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
NewPrice1 = Label(RMiddle, font=('arial',12,'bold'), text =""New Price"", bd = 10, width = 15, anchor = 'w')
NewPrice1.grid(row=4,column=0)
NewPrice2 = Label(RMiddle, font=('arial',12,'bold'), bd = 10, width = 18, relief = 'sunken')
NewPrice2.grid(row=4,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#

start.mainloop()
</code></pre>

<p>You need to bind the combo box to the function </p>

<pre><code>ProductsID.bind(""&lt;&lt;ComboboxSelected&gt;&gt;"", Product)
</code></pre>

<p>and change the function argument to event</p>

<pre><code>def Product(event):
</code></pre>
","9314680","","","5","6890","Neil","2018-02-05 03:20:47","384","106","51","2","49049136","49051395","2018-03-01 11:50:39","-1","33","<p>The below program is supposed to be a stock management system.</p>

<pre><code>from tkinter import*
from tkinter import Tk, StringVar, ttk
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
import random
import datetime
import time;
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
start = Tk()
start.geometry(""100x600+0+0"")
start.title (""R.E.D Inventory Control System"")


#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Heading = Frame(start, width = 1000, height = 100, bd = 10, relief = 'raise')
Heading.pack(side = TOP)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
LowerHeading = Frame(start, width = 500, height  = 100, bd = 20, relief = 'raise')
LowerHeading.pack(side = BOTTOM)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
LMiddle = Frame(start, width = 500, height = 1000, bd = 12, relief = 'raise')
LMiddle.pack(side = LEFT)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
RMiddle = Frame(start, width = 500, height = 1000, bd = 12, relief = 'raise')
RMiddle.pack(side=RIGHT)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Title = Label(Heading, font=('arial',40,'bold'), text = ""R.E.D Inventory Control System"", bd = 10, width = 40, anchor = 'w')
      #justify = 'center')
Title.grid(row=0,column=0)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
info1=IntVar()
info2=StringVar()


info1.set(""0"")
info2.set("""")
</code></pre>

<p>The below section of code is supposed to change the values un the GUI when the value ID01 is selected in the GUI so that the description bar shows dress. I am not sure why this is working.</p>

<p>I would appreciate any help.</p>

<pre><code>#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
def Product():
    if (info1.get()==""ID01""):
        info2.set(""Dress"")


#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
ProductID = Label(LMiddle, font=('arial',12,'bold'),text = ""Product ID"", bd = 10, width = 15, anchor = 'w')
ProductID.grid(row=0,column=0)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
ProductsID = ttk.Combobox(LMiddle, variable = info1 ,state='readonly', font=('arial',12,'bold'),  width =20)
ProductsID['value']=('','ID01','ID02','ID03','ID04','ID05')
ProductsID.current(0)
ProductsID.grid(row=0,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Description1 = Label(LMiddle, font=('arial',12,'bold'),text =""Description"", bd = 10, width = 15, anchor = 'w')
Description1.grid(row=2,column=0)
Description2 = Label(LMiddle, font=('arial',12,'bold'), textvariable = info2, bd = 10, width = 18, relief = 'sunken')
Description2.grid(row=2,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
DateStockBought1 = Label(LMiddle, font=('arial',12,'bold'), text =""Date Stock Bought"", bd = 10, width = 15, anchor = 'w')
DateStockBought1.grid(row=3,column=0)
DateStockBought2 = Label(LMiddle, font=('arial',12,'bold'), bd = 10, width = 18, relief = 'sunken')
DateStockBought2.grid(row=3,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Price1 = Label(LMiddle, font=('arial',12,'bold'), text =""Price"", bd = 10, width = 15, anchor = 'w')
Price1.grid(row=4,column=0)
Price2 = Label(LMiddle, font=('arial',12,'bold'), bd = 10, width = 18, relief = 'sunken')
Price2.grid(row=4,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
AmountLeft1 = Label(RMiddle, font=('arial',12,'bold'), text =""Amount Left"", bd = 10, width = 15, anchor = 'w')
AmountLeft1.grid(row=1,column=0)
AmountLeft2 = Label(RMiddle, font=('arial',12,'bold'), bd = 10, width = 18,     relief = 'sunken')
AmountLeft2.grid(row=1,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
CurrentSeason1 = Label(RMiddle, font=('arial',12,'bold'), text =""CurrentSeason"", bd = 10, width = 15, anchor = 'w')
CurrentSeason1.grid(row=2,column=0)
CurrentSeason2 = Label(RMiddle, font=('arial',12,'bold'), text = """", bd = 10, width = 18, relief = 'sunken')
CurrentSeason2.grid(row=2,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Discount1 = Label(RMiddle, font=('arial',12,'bold'), text =""Discount"", bd = 10, width = 15, anchor = 'w')
Discount1.grid(row=3,column=0)
Discount2 = Label(RMiddle, font=('arial',12,'bold'), bd = 10, width = 18, relief = 'sunken')
Discount2.grid(row=3,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
NewPrice1 = Label(RMiddle, font=('arial',12,'bold'), text =""New Price"", bd = 10, width = 15, anchor = 'w')
NewPrice1.grid(row=4,column=0)
NewPrice2 = Label(RMiddle, font=('arial',12,'bold'), bd = 10, width = 18, relief = 'sunken')
NewPrice2.grid(row=4,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#

start.mainloop()
</code></pre>

<p>I am having trouble changing the descriptions within the GUI.</p>

<hr>

<p>If I add the below code why doesnt it work for the calculation part?</p>

<pre><code>def Product(event):
    if (info1.get()==""ID01""):
        info2.set(""Dress"")
        info3.set(""03/08/2016"")
        info4.set(""£8"")
        info5.set(""74"")
        info6.set(""Spring"")
        if (info7.get()==""10%""):
                Calculation=info4/0.1
                info8.set(Calculation)
</code></pre>
","8490800","8490800","2018-03-01 14:47:26","How do i implement code that changes the values in the GUI according to what the user clicks?","<python><tkinter>","1","0","7543"
"49051444","2018-03-01 14:07:09","0","","<p>In this <a href=""https://ericeastwood.com/blog/3/django-setup-for-wamp%20combined%20with%20httpd.apache.org/docs/2.4/vhosts/name-based.html"" rel=""nofollow noreferrer"">link</a>, you can find information about Django setup for WAMP. Also you may need to add port number to the database settings which is 3306 as default.</p>
","5618731","","","2","326","Emre Külah","2015-11-29 19:32:27","49","8","6","0","49051102","","2018-03-01 13:49:14","0","770","<p>I googgled alot and see many solutions, but none of them worked for me. I have a project in django and also an app as well. now, I want  a connection to mysql database that reside in wamp server in order to interact (sending data or getting data) to database through my app.I also installed MYSQLDB for python. and I have done neccessary things in settings.py file.following is content of settings.py regradding of database</p>

<pre><code>    DATABASES = {
    'default': {
        #'ENGINE': 'django.db.backends.sqlite3',
        'ENGINE': 'django.db.backends.mysql',
        'NAME':   'flask',
        'USERNAME':'root',
        'PASSWORD':'',
        'HOST':'127.0.0.1',
        'PORT':'',
    }
}
</code></pre>
","7784731","","","How to connect django project to mysql database if the mysql database reside in wamp server?","<python><mysql><django><database>","1","2","719"
"49051524","2018-03-01 14:12:06","1","","<p>Built off of <a href=""https://stackoverflow.com/a/523196/5044937"">Eric Walker's</a> solution, but for Django 2.0</p>

<pre><code># Standard Imports
import functools
import django.http

def ajax_login_required(view_func):
    @functools.wraps(view_func)
    def wrapper(request, *args, **kwargs):
        if request.user.is_authenticated:
            return view_func(request, *args, **kwargs)

        return django.http.JsonResponse('Unauthorized', status=401, safe=False)

    return wrapper
</code></pre>
","5044937","5044937","2018-03-01 16:07:17","0","511","Warren Spencer","2015-06-24 13:59:42","136","8","53","0","312925","523196","2008-11-23 20:35:16","49","18925","<p>I want to add some <a href=""http://en.wikipedia.org/wiki/Ajax_%28programming%29"" rel=""noreferrer"">Ajax</a>-niceness to my Django-coded website. </p>

<p>In my Django code, I use the <code>@login_required</code> decorator from <code>django.contrib.auth.decorators</code> to mark which view requires authentication. The default behavior when a not authenticated user clicks it is to redirect him/her to login page, and then pass the target page. </p>

<p>What I saw on some sites, and really liked, is that when user clicks a link leading to a place restricted to logged-only users, instead of getting redirected to a login page, he/she gets a popup window (via JavaScript) asking him/her to log in or register. There's no redirection part, so no need for a user to use the ""back"" key if he/she decides he/she really doesn't like the website enough to waste the time registering.</p>

<p>So, the qestion is:  how would you manage the task of automatically marking some links as ""restricted"" so JavaScript can handle their <code>onclick</code> event and display a ""please log in"" popup? </p>
","4172","63550","2009-12-11 14:55:11","Django authentication and Ajax - URLs that require login","<javascript><python><django><authentication>","5","0","1092"
"49051527","2018-03-01 14:12:15","3","","<p>I presume it stands for ""iterable slice"", since it takes the same arguments as the <code>slice</code> built-in but generates a sequence of results rather than returning a list.</p>

<p>You may be suffering from some slight misunderstanding of ""infinitive,"" which is a part of speech (in English, ""to fall"" is the infinitive of the verb ""fall""). You perhaps mean ""infinite,"" which is never-ending or uncountable.</p>

<p>If so, you have correctly observed that one advantage of the functions in <code>itertools</code> is that they can be applied to infinite sequences. This is because they return iterators that yield results on demand, rather than functions that return lists.</p>
","146073","146073","2018-03-02 20:48:35","4","684","holdenweb","2009-07-28 00:12:20","18765","2635","539","135","49051407","49051527","2018-03-01 14:05:15","1","158","<p>I'm new in Python and I'm not an English native speaker. Today I learned some functions in the itertools module. There is a function called islice. Does it stand for <code>infinitive slice</code>? As I understand it can be used to slice infinitive sequence of objects and is commonly used with <code>itertools.count()</code>. </p>
","1572028","1572028","2018-03-01 14:10:30","Want to confirm the meaning of the name islice in Python itertools.islice","<python><itertools>","2","2","334"
"49051591","2018-03-01 14:15:37","7","","<p>With the error code ""ValueError: right keys must be sorted"", the most effective solution is to add <code>sort_values</code> in the merge on the keys column:</p>

<pre><code>pd.merge_asof(FDMA,ZC[['DMA','Distance (Miles)']].sort_values('DMA'),on='DMA')
</code></pre>

<p>This ensures that the dataframe is sorted on the join keys as required by <code>pd.merge_asof</code>.</p>
","6361531","","","2","379","Scott Boston","2016-05-20 14:04:14","71354","3229","5259","200","49039153","49051591","2018-02-28 21:48:29","4","2916","<p>I would like to merge a target column from one data frame to another. The merged data frame has many more keys and they are are close, but do not exactly match the original data frame. See an example below:</p>

<p>Original data frame (FDMA)</p>

<pre><code>DMA 
130506  
130510  
130512  
130555  
130556  
</code></pre>

<p>Merged data frame (ZC)</p>

<pre><code>DMA        Distance (Miles)
1305060    303.87
1305061    305.35
1305062    278.80
1305065    299.94
1305067    291.83

pd.merge_asof(FDMA,ZC[['DMA','Distance (Miles)']],on='DMA')
</code></pre>

<p>This is what I am expecting</p>

<pre><code>DMA     Distance (Miles)
130506  303.87
130510  291.83
130512  XXX
130555  XXX
130556  XXX
</code></pre>

<p>I have tried the above code and get a ValueError: right keys must be sorted error. I have sorted the values and reset the indexes, but still get the error. Any help is appreciated!</p>
","9198908","9198908","2018-03-01 14:16:09","pandas merge_asof keys must be sorted error after sorting","<python><pandas><merge>","2","3","903"
"49051604","2018-03-01 14:15:56","0","","<p>Please import the library directly by pasting the Resnet code directly into your system or fork the TF slim library.</p>
","7842888","","","0","124","ReInvent_IO","2017-04-10 04:43:18","347","47","2","0","48893390","49051604","2018-02-20 20:07:21","0","292","<p>I am working on Tensorflow Slim Resnet_v2 model. My tensorflow version is (1.4.0) and python version is (3.5.4). I am doing an image classification with 2 labels as the output. I am using the tensorflow Slim resnet_v2 model for this classification. When I try to run the following code </p>

<pre><code>predictions,_ = nets.resnet_v2.resnet_v2(x,num_classes=2, is_training=True,
                                      global_pool=True,spatial_squeeze=True)
</code></pre>

<p>I am getting the below error. </p>

<pre><code>Traceback (most recent call last):

File ""&lt;ipython-input-2-a112bf21d73f&gt;"", line 1, in &lt;module&gt;
runfile('D:/Users/apxcm/Mammo_Transfer_learning/inception_fulltrain_azure.py', wdir='D:/Users/apxcm/Mammo_Transfer_learning')

File ""D:\Users\apxcm\AppData\Local\Continuum\anaconda3\envs\nnet\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 710, in runfile
execfile(filename, namespace)

File ""D:\Users\apxcm\AppData\Local\Continuum\anaconda3\envs\nnet\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 101, in execfile
exec(compile(f.read(), filename, 'exec'), namespace)

File ""D:/Users/apxcm/Mammo_Transfer_learning/inception_fulltrain_azure.py"", line 367, in &lt;module&gt;
main()

File ""D:/Users/apxcm/Mammo_Transfer_learning/inception_fulltrain_azure.py"", line 361, in main
resnet_full_classification()

File ""D:/Users/apxcm/Mammo_Transfer_learning/inception_fulltrain_azure.py"", line 326, in resnet_full_classification
predictions,_ = nets.resnet_v2.resnet_v2(x,num_classes=2, is_training=True,global_pool=True,spatial_squeeze=True)

TypeError: resnet_v2() got an unexpected keyword argument 'spatial_squeeze'
</code></pre>

<p>I cross-checked, the tensorflow slim source code (<a href=""https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v2.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v2.py</a>) and line number 159 states that spatial_squeeze is available. I don't why I am not able to use the argument. Could this be the because of the tensorflow version? If so, please let me know which version should I use.</p>
","7842888","","","Tensorflow slim resnet_v2() got an unexpected keyword argument 'spatial_squeeze'","<python><tensorflow><tensorflow-slim>","1","0","2160"
"49051606","2018-03-01 14:15:59","0","","<p>The fact I wasn't aware of is that pandas assigns new indices (starting with 0, increment 1) to the DataFrame when converting the resulting array of transform to a pandas DataFrame again:</p>

<pre class=""lang-python.js prettyprint-override""><code>X_model = pd.DataFrame(selector.transform(X_model), columns = X_columns)
</code></pre>

<p>When asking for a subset of rows with the ""old"" row indices, this gives other values than before. So, the sequence is still the same. However, I would like to preserve the original row indices. Therefore, I now set the indices according to the old indices still preserved in <strong><em>y_model</em></strong>.</p>

<pre><code>X_model = X_model.set_index(y_model.index)
</code></pre>
","7946516","","","0","725","Inco83","2017-05-01 08:55:50","15","6","1","0","49050166","49051606","2018-03-01 12:53:47","1","298","<p>I'm doing a variance threshold feature selection with sklearn on a pandas DataFrame. In order to avoid a bias from feature selection - VarianceThreshold is only the first step - I've divided the original dataset into a part for feature selection (<strong><em>X_selection</em></strong>, <strong><em>y_selection</em></strong>) and a part for modeling (<strong><em>X_model</em></strong>, <strong><em>y_model</em></strong>). Nevertheless, they contain the same columns in the same order. So, I've started by defining the selector and fit the data afterwards:</p>

<pre class=""lang-python.js prettyprint-override""><code># get column names
X_columns = X_selection.columns

# doing the variance threshold feature selection
selector = VarianceThreshold()
selector.fit(X_selection)

# filtering the selected column names
X_columns = X_columns[selector.get_support()]

# transform original data according to selector
X_selection = pd.DataFrame(selector.transform(X_selection), columns = X_columns)
X_model = pd.DataFrame(selector.transform(X_model), columns = X_columns)
</code></pre>

<p>Unfortunately, I've encountered that the rows in the resulting <strong><em>X_selection</em></strong> and <strong><em>X_model</em></strong> are jumbled. For example, prior to the transformation I've got for some, exemplary rows out of <strong><em>X_model</em></strong>:</p>

<pre><code>        COL_X
0       0.000000
1       0.000000
2       0.000000
10      0.000000
25      0.185185
150     0.037037
3333    0.000000
16000   0.000000
</code></pre>

<p>After the transformation, calling the same row indices of <strong><em>X_model</em></strong> gives me:</p>

<pre><code>        COL_X
0       0.000000
1       0.000000
2       0.111111
10      0.000000
25      0.000000
150     0.000000
3333    0.000000
16000   0.111111
</code></pre>

<p>In my understanding <em>transform</em> has shuffled the rows in a for me unknown manner. Though the relations to the <strong><em>y_model</em></strong> array with class labels is broken, because the order of rows is unchanged here. Thank you for any comments how to fix it or where my mistakes are hidden.</p>
","7946516","7946516","2018-03-01 14:16:28","Keep row indices of DataFrame at Variance Threshold transformation","<python><pandas><numpy><scikit-learn><feature-selection>","1","4","2130"
"49051608","2018-03-01 14:16:00","3","","<p>You are calling <code>self._word_to_id.values()</code> which returns the class <code>dict_values</code> and not <code>list</code>. <code>dict_values</code> does not inherit from <code>list</code> and does not have the <code>index</code> method because of that. </p>

<p>You need to convert your dictionary values into a <code>list</code> to use the <code>index</code> function. Try this:</p>

<pre><code>list(self._word_to_id.values()).index(data_x[index])
</code></pre>
","7057528","","","2","474","jsmolka","2016-10-22 15:01:21","608","39","127","1","49051492","","2018-03-01 14:10:19","5","4109","<p>I'm trying to rewrite this Python2 code to Python3 accepted syntax. The .index() methods generates the following error:</p>

<p>AttributeError: 'dict_values' object has no attribute 'index'</p>

<p>This is because .index() is no valid syntax in Python3. I've read that a list should be used to work around the problem, but I can't figure out how to do it. Anyone any idea how to work around the problem?</p>

<pre><code>words1 = [self._word_to_id.keys()[self._word_to_id.values().index(data_x[index])] for index in range(len(puncts) - 1)]
indices = [i for i, w in enumerate(words1) if w in PUNCTUATIONS]
for i in indices:
    words1[i], words1[i-1] = words1[i-1], words1[i] 
words2 = [self._word_to_id.keys([self._word_to_id.values().index(data_x[index])] for index in range(len(puncts) - 1, len(data_x))]
all_words = words1 + [puncts[-1]] + words2  
content = ' '.join(all_words)  
min_step = len(puncts)
</code></pre>
","9391383","","",".index() generates AttributeError: 'dict_values' object has no attribute 'index'","<python>","2","4","923"
"49051613","2018-03-01 14:16:10","1","","<p>It work find on my side </p>

<pre><code>l=[
'2017-11-01 06:00:00',
'2017-11-03 06:00:00']

ts = pd.Series(np.random.randn(len(l)), index=l)
ts.index=pd.to_datetime(ts.index)
ts.asfreq(freq=""D"")
Out[745]: 
2017-11-01 06:00:00   -0.467919
2017-11-02 06:00:00         NaN
2017-11-03 06:00:00    1.610024
Freq: D, dtype: float64
</code></pre>
","7964527","","","0","343","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49051409","49051613","2018-03-01 14:05:20","0","150","<p><strong>EDIT:</strong> <em>I had made a mistake and my index was starting at 00:00:00, not at 06:00:00 (see below). So this question is spurious, but of course Wen's solution is correct.</em></p>

<p>I have a dataframe whose index goes like this:</p>

<pre><code>2017-11-01 06:00:00
2017-11-02 06:00:00 
2017-11-03 06:00:00
...
</code></pre>

<p>and so on. But I have the suspicion there're missing entries, for instance, index for <code>2017-11-04 06:00:00</code> could be missing. I have used</p>

<pre><code>df = df.asfreq(freq=""1D"")
</code></pre>

<p>to fill with <code>NaN</code> the missing values, but it creates a new index that doesn't take into consideration the hours, it goes <code>2017-11-01, 2017-11-02</code> and so on, so the values in the adjacent column are all <code>NaN</code>!</p>

<p>How can I fix this? I don't see any option in <code>asfreq</code> that can solve it. Perhaps other tool? Thanks in advance.</p>
","6010635","6010635","2018-03-01 16:26:25","Using asfreq to resample a pandas dataframe","<python><pandas>","1","2","937"
"49051617","2018-03-01 14:16:26","2","","<p>You have to do this:</p>

<pre><code>logging.basicConfig(...)
logger = logging.getLogger()
</code></pre>

<p>In this way you can to perform asserts on <code>logger</code> object configured with the previous <code>basicConfig</code> call</p>
","3211950","3211950","2018-03-01 14:55:36","2","244","enneppi","2014-01-19 11:07:09","494","86","218","3","49051483","49051617","2018-03-01 14:09:44","0","47","<p>I am trying to test (pytest) some code in python.</p>

<p>I instantiate a logger object with </p>

<pre><code>import logging
logging.getLogger()
</code></pre>

<p>Now I would like to retrieve the logger object created in order to perform some asserts on it.</p>

<p>But if I inspect the global variables I cannot see it.</p>

<p>Where is the Logger object?</p>

<hr>

<p>EDIT: thanks for the responses below 
<code>logger=logging.GetLooger()</code></p>

<p>I am now facing the same problem with <code>logging.basicConfig()</code>.</p>

<p>And when I do <code>r=logging.basicConfig()</code> , the return value is <code>None</code>.
There is still no Logger object in the <code>globals</code></p>

<p>How to find the Logger object in this case?</p>
","4961888","4961888","2018-03-01 14:21:09","Where is Logger object?","<python>","2","7","750"
"49051639","2018-03-01 14:17:45","0","","<p>Just do some debug to understand what is <code>myEmailInfo</code>: it could be a tuple (as it is printed like one) or an object with a string representation being a tuple (i.e. method <code>__str__</code> returns a tuple).</p>

<p>To help you perform debug, I personally recommend some software like:</p>

<ul>
<li><strong>PyCharm</strong> (<a href=""https://www.jetbrains.com/pycharm"" rel=""nofollow noreferrer"">https://www.jetbrains.com/pycharm</a>), which has a free ""Community Edition""</li>
<li><strong>Visual Code</strong> (<a href=""https://code.visualstudio.com"" rel=""nofollow noreferrer"">https://code.visualstudio.com</a>) which is a free tool from Microsoft with a great community and amazing support of Python</li>
</ul>

<p>They both include some easy-to-use debuggers and amazing code completion for Python.</p>

<p>That does not answer the question (because we cannot without knowing more about your code), but that will help find the issue.</p>
","1603480","","","1","959","Jean-Francois T.","2012-08-16 14:08:44","5954","547","244","2","49050858","49051639","2018-03-01 13:35:38","-4","34","<p>Im using this to get the number of email messages in my inbox</p>

<pre><code>print(""There are: {0}"" .format(myEmailInfo))
</code></pre>

<p>It works sort of but what it returns is </p>

<pre><code>There Are (2,217715)
</code></pre>

<p>Any ideas why?</p>

<p>Thanks in Advance</p>
","504592","5851928","2018-03-01 13:36:50","Issue with Python .format()","<python><formatting>","1","5","285"
"49051692","2018-03-01 14:20:07","1","","<p>If you reference the modbus spec, you find that an exception to a function is made by setting the MSB in the function byte... effectively adding 0x80 to the function number in the reply.</p>

<p>In your example, you attempted to read Holding register. Your request used a function number of 0x03. The exception you received is that function 0x03 with the MSB set high, resulting in a reply function of 0x83. The exception code is the number that follows the function number, in your case it is 0x02.</p>

<p>In the Modbus Spec, an exception code of 2 is used when the register address is not supported.</p>

<p>BTW, modbus is an exceedingly simply protocol, and the original spec itself is quite small and easily available. If you plan on working with modbus at any depth, I would highly recommend at least having it at hand: <a href=""http://www.modbus.org/docs/Modbus_Application_Protocol_V1_1b3.pdf"" rel=""nofollow noreferrer"">Modbus Application Protocol v1.1</a> </p>
","9392634","","","0","973","Matt Andrews","2018-02-21 18:31:23","21","1","0","0","40983955","","2016-12-05 21:47:23","1","741","<p>I am using <a href=""https://github.com/pyhys/minimalmodbus"" rel=""nofollow noreferrer"">minimalmodbus</a> to communicate with a <a href=""http://www.pvi.com/pdf%20files/Love%20Control%20I.pdf"" rel=""nofollow noreferrer"">PID controller (Love 16C-3)</a> via RS485 using a <a href=""https://rads.stackoverflow.com/amzn/click/com/B005CPLOVW"" rel=""nofollow noreferrer"" rel=""nofollow noreferrer"">USB-RS485 adapter cable</a>.</p>

<p>However when trying to read the register, the following error is shown. What does this error mean?</p>

<pre><code>raise ValueError('The slave is indicating an error. The response is: {!r}'.format(response))
ValueError: The slave is indicating an error. The response is: '\x01\x83\x02\xc0\xf1'
</code></pre>

<p><strong>From Hardware's Manual</strong></p>

<p><a href=""https://i.stack.imgur.com/kUsT9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kUsT9.png"" alt=""enter image description here""></a></p>

<p><strong>Python Code</strong></p>

<pre><code>instrument = minimalmodbus.Instrument(port, 1, 'rtu')
instrument.serial.baudrate = 9600
instrument.serial.bytesize=8
instrument.serial.parity='E'
instrument.serial.stopbits=1
instrument.read_register(4096,1)
</code></pre>

<p><a href=""https://i.stack.imgur.com/vN2hR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vN2hR.png"" alt=""enter image description here""></a></p>
","741099","741099","2016-12-05 22:08:23","What is this error given by RS485 Modbus-RTU Device","<python><serial-port><modbus><rs485><minimalmodbus>","1","7","1386"
"49051693","2018-03-01 14:20:11","1","","<p>How many rels do your nodes have?</p>

<p>Usually I don't think that object mappers are good for mass insertions.</p>

<p>Please check out: <a href=""https://medium.com/@mesirii/5-tips-tricks-for-fast-batched-updates-of-graph-structures-with-neo4j-and-cypher-73c7f693c8cc"" rel=""nofollow noreferrer"">https://medium.com/@mesirii/5-tips-tricks-for-fast-batched-updates-of-graph-structures-with-neo4j-and-cypher-73c7f693c8cc</a></p>

<p>Can you enable query logging for queries taking longer than 1 second and share the queries that neomodel generates?</p>

<p><code>dbms.jvm.additional=-Xss256M</code> is excessive. That means every thread allocates 256M memory, usually 2M is good enough for that.</p>
","728812","","","1","702","Michael Hunger","2011-04-28 07:51:27","37752","6290","4659","24","49024029","","2018-02-28 07:22:52","2","458","<p>I am trying to use Neo4J with neomodel to represent some graph relationships. However I have performance issues when I am trying to construct a graph with millions of nodes and relationships.</p>

<p>When I have graph with 10k nodes and 30k relationships among them, it takes 4:20s to import it it Neo4j. It takes 1:40 to create nodes and 2:40 to create relationships with calling <code>foo.connect(bar)</code>. It's extremely slow. </p>

<p>When I have used batch api provided by neomodel, I am able to create all nodes in just 4s, but it doesn't affect the time needed for relationships creation.</p>

<p>Neomodel is using CYPHER queries to create relationships 1 by 1. So, I have decided to write my own queries, where I first match all nodes needed for creating 100 relationships and then I create those relationships. It happened once or twice that it finished in few seconds. In other cases it again takes minutes. When I use htop to see, what is going on, I can see, that 2 cores are fully utilized by neo4j database.</p>

<p>I have found following article: <a href=""https://neo4j.com/blog/import-10m-stack-overflow-questions/"" rel=""nofollow noreferrer"" title=""Import 10M Stack Overflow Questions into Neo4j In Just 3 Minutes"">Import 10M Stack Overflow Questions into Neo4j In Just 3 Minutes</a> which is using <code>neo4j-import</code>, but I would like to avoid it.</p>

<p>I am using default configuration, except that I am using <code>dbms.jvm.additional=-Xss256M</code> to be able to execute those batch relationships queries. I have unique index over property that I am using for node lookup. Before each experiment I delete all nodes and relationships.</p>

<p>Do you have any idea, how to speed it up? </p>
","7906602","2308683","2018-03-01 14:22:37","Neo4J with NeoModel: How to speed up graph creation?","<python><neo4j><graph-databases><neomodel>","1","0","1725"
"49051699","2018-03-01 14:20:53","0","","<p>instead of <code>json.load()</code>, use <code>json.loads()</code></p>

<p><a href=""https://stackoverflow.com/questions/32040541/strange-python-issue-unicode-object-has-no-attribute-read"">This error raised because the data is a unicode/str variable.</a></p>
","7407726","","","5","261","Brett Holman","2017-01-12 03:36:40","163","52","134","3","49051373","","2018-03-01 14:03:21","0","117","<p>Python 2.7</p>

<p>I am new to python and this is my first post for help. </p>

<p>I am sending a post request to the web and having a json file returned. It looks like this:</p>

<p><a href=""https://i.stack.imgur.com/NzIQs.jpg"" rel=""nofollow noreferrer"">json Example</a></p>

<p>if i do:</p>

<blockquote>
  <p>print data['result']</p>
</blockquote>

<p>I get all the items listed</p>

<p>if i do:</p>

<blockquote>
  <p>print data['result']['recordtype'] </p>
</blockquote>

<p>I get ""list indices must be integers, not str"" (because I need ['result'][0]['recordtype']? but that would limit it to only the first item)</p>

<p>I can get ""some"" info with:</p>

<blockquote>
  <p>print(data['result'](type is a list)</p>
  
  <p>print(data['result'][0])(type is a dict)</p>
  
  <p>print(data['result'][0]['columns'](type is a dict)</p>
</blockquote>

<p>But this only returns the first item. ([0]). Any other attempts gets me a ""must be integer not str"". </p>

<p>Ultimately, I would like to enter item ""id"" and have all the attributes ""itemid"", ""displayname"", ""columns"", etc returned for that item as variables. (""columns"" will vary from json file to json but the rest should remain uniform) </p>

<p>Questions:</p>

<p>How can I loop through all these items based on the ""id"" value and return all the values associated with that item as variables?</p>
","9420470","9420470","2018-03-01 18:28:32","Python parsing json file into something usable","<python><json>","3","1","1357"
"49051757","2018-03-01 14:23:26","5","","<blockquote>
  <p>So, basically does this mean that if my base class's metaclass is not
  ABCMeta(or derived from it), the class does not behave like an
  abstract class even though I have an abstract method in it?</p>
</blockquote>

<p>Correct.</p>

<p>All <code>abstractmethod</code> does is mark the method with <code>__isabstractmethod__ = True</code>.  <code>ABCMeta</code> does all the real work. <a href=""https://github.com/python/cpython/blob/3.6/Lib/abc.py#L9"" rel=""nofollow noreferrer"">Here</a> is the code for <code>abstractmethod</code>: </p>

<pre><code>def abstractmethod(funcobj):
    """"""A decorator indicating abstract methods.
    Requires that the metaclass is ABCMeta or derived from it.  A
    class that has a metaclass derived from ABCMeta cannot be
    instantiated unless all of its abstract methods are overridden.
    The abstract methods can be called using any of the normal
    'super' call mechanisms.
    Usage:
        class C(metaclass=ABCMeta):
            @abstractmethod
            def my_abstract_method(self, ...):
                ...
    """"""
        funcobj.__isabstractmethod__ = True
        return funcobj
</code></pre>
","768194","3444956","2018-03-01 14:37:46","0","1163","Colin","2011-05-24 17:14:13","1690","47","55","22","49051638","49051757","2018-03-01 14:17:37","5","536","<p>I was reading official python <a href=""https://docs.python.org/3/library/abc.html#abc.abstractmethod"" rel=""nofollow noreferrer"">documentation</a>.</p>

<p>In the mentioned link, the second line states that:</p>

<blockquote>
  <p>Using this decorator requires that the class’s metaclass is ABCMeta or
  is derived from it.</p>
</blockquote>

<p>But, I was successfully able to define the below given class.</p>

<pre><code>from abc import abstractmethod

class A(object):
    def __init__(self):
        self.a = 5
    @abstractmethod
    def f(self):
        return self.a

a = A()
a.f()
</code></pre>

<p>So, the code above worked fine.
And also, I was able to create a subclass</p>

<pre><code>class B(A):
    def __init__(self):
        super(B, self).__init__() 

b = B()
b.f()
</code></pre>

<p>Without overriding the abstract method defined above.</p>

<p>So, basically does this mean that if my base class's <code>metaclass</code> is not <code>ABCMeta</code>(or derived from it), the class does not behave like an abstract class even though I have an abstract method in it?</p>

<p>That means, the documentation needs more clarity?</p>

<p>Or, is this behaviour useful somehow and I'm missing the point.</p>
","3444956","3444956","2018-03-01 14:26:00","python - abstract method in normal class","<python><abstract-class><abstract-methods>","1","3","1219"
"49051778","2018-03-01 14:24:43","0","","<p>The smaller the gradient step size, the more iterations you need to train the model. This will increase training time, but can help to more accurately minimize the average error in your loss function.
<a href=""https://tech.yandex.com/catboost/doc/dg/concepts/parameter-tuning-docpage/#learning-rate"" rel=""nofollow noreferrer"">Read the official recomendations for tunning you CBR model</a></p>
","9429158","","","1","396","Vladimir Zhelivs","2018-03-01 13:35:26","1","5","0","0","48028814","","2017-12-29 21:50:00","0","601","<p>Is there any possibility to change (decrease) parameter 'learning rate', a gradient step coefficient,  during training the model CatBoostRegressor() ? It would reduce the iterations number and quicken the training?</p>
","7989415","","","Changing parameter 'learning_rate' for CatBoostRegressor","<python><gradient><boosting><catboost>","1","0","222"
"49051833","2018-03-01 14:27:59","4","","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.first_valid_index.html"" rel=""nofollow noreferrer""><code>first_valid_index</code></a> with <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.loc.html"" rel=""nofollow noreferrer""><code>loc</code></a>:</p>

<pre><code>s.loc[:s.first_valid_index()] = 0
</code></pre>

<p>Or <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.mask.html"" rel=""nofollow noreferrer""><code>mask</code></a> with <code>isnull</code> and forward filling <code>NaN</code>s:</p>

<pre><code>s = s.mask(s.ffill().isnull(), 0)
</code></pre>

<hr>

<pre><code>print (s)
0    0.0
1    0.0
2    4.0
3    5.0
4    NaN
5    7.0
dtype: float64
</code></pre>
","2901002","2901002","2018-03-01 14:33:47","0","755","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49051805","49051833","2018-03-01 14:26:39","2","321","<p>I have several <code>pd.Series</code> that usually start with some NaN values until the first real value appears. I want to pad these leading NaNs with 0, but not any NaNs that appear later in the series.</p>

<pre><code>pd.Series([nan, nan, 4, 5, nan, 7])
</code></pre>

<p>should become</p>

<pre><code>ps.Series([0, 0, 4, 5, nan, 7])
</code></pre>
","3104974","","","pandas fillna: How to fill only leading NaN from beginning of series until first value appears?","<python><pandas>","1","0","354"
"49051897","2018-03-01 14:31:14","5","","<p>Read the <a href=""https://docs.python.org/3/library/functions.html#chr"" rel=""nofollow noreferrer"">docs</a>:</p>

<blockquote>
  <p>chr(i)</p>
  
  <p>Return a string of one character whose ASCII code is the integer i.</p>
</blockquote>

<p>and</p>

<blockquote>
  <p>input([prompt])</p>
  
  <p>If the prompt argument is present, it is written to standard output without a trailing newline. The function then reads a line from input, converts it to a string (stripping a trailing newline), and returns that</p>
</blockquote>

<p>you don't need to convert the character. What you get from input is already a string</p>
","5012099","778533","2018-03-01 14:39:47","0","621","FlyingTeller","2015-06-15 16:07:49","4958","597","62","128","49051871","","2018-03-01 14:29:45","2","699","<p>so i want to do the same with alphabets that i did with numbers take a look</p>

<pre><code>num1=int(input(""enter Ist digit:""))
num2=int(input(""enter IInd digit:""))
num3=int(input(""enter IIIrd digit:""))
num4=int(input(""enter IVth digit:""))
num5=int(input(""enter Vth digit:""))
</code></pre>

<p>i want to enter letters instead of numbers 
so i changed it to</p>

<pre><code>alpha1=chr(input(""enter Ist letter""))
</code></pre>

<p>but i kept on getting the error</p>

<pre><code>   alpha1=chr(input(""enter Ist alphabet:""))
TypeError: an integer is required (got type str)
</code></pre>
","9429401","","","how to input alphabets in python","<python><python-3.x>","3","1","587"
"49051911","2018-03-01 14:31:38","0","","<p>simply 
     alpha1=input(""enter Ist letter"")</p>
","9425575","","","1","53","ferjani nasraoui","2018-02-28 20:00:58","24","5","2","0","49051871","","2018-03-01 14:29:45","2","699","<p>so i want to do the same with alphabets that i did with numbers take a look</p>

<pre><code>num1=int(input(""enter Ist digit:""))
num2=int(input(""enter IInd digit:""))
num3=int(input(""enter IIIrd digit:""))
num4=int(input(""enter IVth digit:""))
num5=int(input(""enter Vth digit:""))
</code></pre>

<p>i want to enter letters instead of numbers 
so i changed it to</p>

<pre><code>alpha1=chr(input(""enter Ist letter""))
</code></pre>

<p>but i kept on getting the error</p>

<pre><code>   alpha1=chr(input(""enter Ist alphabet:""))
TypeError: an integer is required (got type str)
</code></pre>
","9429401","","","how to input alphabets in python","<python><python-3.x>","3","1","587"
"49051939","2018-03-01 14:33:24","0","","<p>I'm a cartopy developer and I'd like to see what I can do, but your code snippet is a little bit impenetrable.  If I could access your data then it might not matter so much, but I can't, so I can't run it or debug it.</p>

<p>Can you cut down your script please to something self-contained or at least minimal, noiseless and clear.  Thanks.</p>

<p>Also you have a typo in your plot call so your transform is PlateCarre instead of Platecarree.  I don't know how much difference this will make but it's worth correcting.</p>
","6127966","","","1","527","Corinne Bosley","2016-03-29 07:45:07","54","25","6","0","49048411","","2018-03-01 11:10:53","1","365","<p>I am trying to plot contours over the north pole, using cartopy. I have used add_cyclic_point and this has successfully filled in the gap at the prime meridian in pcolormesh, but the contours do not cross successfully, and instead wrap all the way around the globe to connect (but it seems not always?) My longitudes go from 0-360 and I have tried to switch to -180-180 but still get the same issue.</p>

<p>Here is my code:</p>

<pre><code>import numpy as np
from netCDF4 import Dataset
import cartopy.crs as ccrs
import cartopy
from cartopy.util import add_cyclic_point as cycpt
import matplotlib.pyplot as plt


date = '2018_02_10'
pdatafile = Dataset(date+'_mslp.nc')
plat = np.array(pdatafile.variables['lat'])
plon = np.array(pdatafile.variables['lon'])
p = np.array(pdatafile.variables['slp'][0,:,:])

p_cyclic,lon_cyclic = cycpt(p,coord=plon)
lon_cyclic = np.ma.getdata(lon_cyclic)

plon2d,plat2d= np.meshgrid(lon_cyclic,plat)
p_cyclic = np.ma.getdata(p_cyclic)

g1000datafile = Dataset(date+'_1000mb_gph.nc')
g1lat = np.array(g1000datafile.variables['lat'])
g1lon = np.array(g1000datafile.variables['lon'])
g1000 = np.array(g1000datafile.variables['hgt'][0,0,:,:])
g1_cyclic,g1lon_cyclic = cycpt(g1000,coord=g1lon)
g1lon2d,g1lat2d= np.meshgrid(g1lon_cyclic,g1lat)
g1lon2d = np.ma.getdata(g1lon2d)
g1_cyclic = np.ma.getdata(g1_cyclic)

g500datafile = Dataset(date+'_500mb_gph.nc')
g5lat = np.array(g500datafile.variables['lat'])
g5lon = np.array(g500datafile.variables['lon'])
g500 = np.array(g500datafile.variables['hgt'][0,0,:,:])
g5_cyclic,g5lon_cyclic = cycpt(g500,coord=g5lon)
g5lon2d,g5lat2d= np.meshgrid(g5lon_cyclic,g5lat)
g5lon2d = np.ma.getdata(g5lon2d)
g5_cyclic = np.ma.getdata(g5_cyclic)

thickness = g5_cyclic - g1_cyclic

mslplevels=[960,970,980,990,1000,1010,1020,1030,1040,1050]
levels500hPa = [470,480,490,500,510,520,530,540,550,560]

ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=0))
ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())
plt.pcolormesh(plon2d,plat2d,thickness/10, transform=ccrs.PlateCarre(),cmap='inferno')
cbar=plt.colorbar()
cbar.set_label('ReTop (gpdam)')
cs=plt.contour(plon2d,plat2d,g5_cyclic/10,colors='w',transform=ccrs.PlateCarree(),\
           levels=levels500hPa)
plt.clabel(cs,inline=1,fontsize=6,fmt='%3.0f')
ax.coastlines()
plt.show()
plt.close()
</code></pre>

<p><a href=""https://i.stack.imgur.com/RImUf.png"" rel=""nofollow noreferrer"">an example plot</a></p>

<pre><code>import numpy as np
from netCDF4 import Dataset
import cartopy.crs as ccrs
from cartopy.util import add_cyclic_point as cycpt
import matplotlib.pyplot as plt

pdatafile = Dataset('X158.39.88.89.59.7.59.32.nc')
plat = np.array(pdatafile.variables['lat'])
plon = np.array(pdatafile.variables['lon'])
p = np.array(pdatafile.variables['slp'][0,:,:])

p_cyclic,lon_cyclic = cycpt(p,coord=plon)
lon_cyclic = np.ma.getdata(lon_cyclic)
p_cyclic = np.ma.getdata(p_cyclic)

plon2d,plat2d= np.meshgrid(lon_cyclic,plat)

ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=0))
ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())
plt.contour(plon2d,plat2d,g5_cyclic/10,colors='w',transform=ccrs.PlateCarree())
plt.clabel(cs,inline=1,fontsize=6,fmt='%3.0f')
ax.coastlines()
plt.show()
</code></pre>

<p><a href=""ftp://ftp.cdc.noaa.gov/Public/www/X158.39.88.89.59.7.59.32.nc"" rel=""nofollow noreferrer"">ftp://ftp.cdc.noaa.gov/Public/www/X158.39.88.89.59.7.59.32.nc</a></p>
","8436147","3938208","2018-04-30 18:49:56","cartopy North Pole Stereographic contour plot does not plot correctly even with cyclic point","<python><map-projections><cartopy>","2","1","3436"
"49051967","2018-03-01 14:34:31","0","","<p>The problem is your tensorflow is installed in conda environment. So firsly open the conda prompt as an administrator, then activate tensorflow environment by typing 'activate tensorflow' and then open your spyder gui by typing spyder. It will mostly solve problem.</p>
","2703626","","","0","273","Piyush","2013-08-21 12:39:21","134","50","42","0","45224889","45260185","2017-07-20 20:48:28","1","4645","<p>I visited <a href=""https://www.tensorflow.org/install/install_windows#common_installation_problems"" rel=""nofollow noreferrer"">the tensorflow page</a> and followed instructions from <code>Installing with Anaconda</code> section. When I tried to validate my installation, I got below errors</p>

<pre><code>(C:\ProgramData\Anaconda3) C:\Users\nik&gt;python
Python 3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:25:24) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; import tensorflow as tf
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
ModuleNotFoundError: No module named 'tensorflow'
&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
NameError: name 'tf' is not defined
&gt;&gt;&gt; exit
Use exit() or Ctrl-Z plus Return to exit
&gt;&gt;&gt; exit()
</code></pre>

<p>then i tried </p>

<pre><code>(C:\ProgramData\Anaconda3) C:\Users\nik&gt;activate tensorflow

(tensorflow) C:\Users\nik&gt;pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.2.1-cp35-cp35m-win_amd64.whl
Collecting tensorflow==1.2.1 from https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.2.1-cp35-cp35m-win_amd64.whl
  Using cached https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.2.1-cp35-cp35m-win_amd64.whl
Collecting bleach==1.5.0 (from tensorflow==1.2.1)
  Using cached bleach-1.5.0-py2.py3-none-any.whl
Collecting html5lib==0.9999999 (from tensorflow==1.2.1)
Collecting backports.weakref==1.0rc1 (from tensorflow==1.2.1)
  Using cached backports.weakref-1.0rc1-py3-none-any.whl
Collecting werkzeug&gt;=0.11.10 (from tensorflow==1.2.1)
  Using cached Werkzeug-0.12.2-py2.py3-none-any.whl
Collecting markdown&gt;=2.6.8 (from tensorflow==1.2.1)
Collecting protobuf&gt;=3.2.0 (from tensorflow==1.2.1)
Collecting numpy&gt;=1.11.0 (from tensorflow==1.2.1)
  Using cached numpy-1.13.1-cp35-none-win_amd64.whl
Collecting six&gt;=1.10.0 (from tensorflow==1.2.1)
  Using cached six-1.10.0-py2.py3-none-any.whl
Collecting wheel&gt;=0.26 (from tensorflow==1.2.1)
  Using cached wheel-0.29.0-py2.py3-none-any.whl
Collecting setuptools (from protobuf&gt;=3.2.0-&gt;tensorflow==1.2.1)
  Using cached setuptools-36.2.0-py2.py3-none-any.whl
Installing collected packages: six, html5lib, bleach, backports.weakref, werkzeug, markdown, setuptools, protobuf, numpy, wheel, tensorflow
Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-2.6.8 numpy-1.13.1 protobuf-3.3.0 setuptools-36.2.0 six-1.10.0 tensorflow-1.2.1 werkzeug-0.12.2 wheel-0.29.0

(tensorflow) C:\Users\nik&gt;python
Python 3.5.3 |Continuum Analytics, Inc.| (default, May 15 2017, 10:43:23) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')
&gt;&gt;&gt; sess = tf.Session()
2017-07-20 12:20:26.177654: W c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
2017-07-20 12:20:26.178276: W c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-20 12:20:26.178687: W c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-20 12:20:26.179189: W c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-20 12:20:26.179713: W c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-20 12:20:26.180250: W c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-20 12:20:26.180687: W c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-20 12:20:26.181092: W c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
&gt;&gt;&gt; print(sess.run(hello))
b'Hello, TensorFlow!'
</code></pre>

<p>My question as below - my main question is question 3: </p>

<ol>
<li>Am I suppose to validate installation after typing command -
<code>activate tensorflow</code> as shown in the second command block above? </li>
<li>why am i getting multiple instructions after
the command <code>sess = tf.Session()</code> ?</li>
<li><p><strong>Can i use tensorflow within the
SPYDER gui? how? I tried below but in the SPYDER gui, but didnt get any success :(</strong></p>

<p>activate tensorflow</p></li>
</ol>

<p>File """", line 1</p>

<pre><code>    activate tensorflow
                      ^

SyntaxError: invalid syntax


import tensorflow as tf

Traceback (most recent call last):


  File ""&lt;ipython-input-2-41389fad42b5&gt;"", line 1, in &lt;module&gt;
    import tensorflow as tf


ModuleNotFoundError: No module named 'tensorflow'
</code></pre>
","2543622","2543622","2017-07-22 21:11:04","installing tensorflow in windows anaconda - and running using it using Spyder GUI","<python><windows><tensorflow><anaconda><spyder>","3","11","6236"
"49051985","2018-03-01 14:35:27","5","","<p><a href=""https://bugs.python.org/issue30024"" rel=""noreferrer"">Issue 30024</a> discusses the problem and the patch.  But I did not find it immediately helpful.  It does mention that getting a proper, comprehensible test example would be a major step.</p>

<p>The <a href=""https://github.com/python/cpython/commit/f93234bb8a87855f295d441524e519481ce6ab13"" rel=""noreferrer"">patch</a> added the following:</p>

<p>In  Lib/test/test_import/data/circular_imports/binding.py:</p>

<pre><code>import test.test_import.data.circular_imports.binding2 as binding2
</code></pre>

<p>In  Lib/test/test_import/data/circular_imports/binding2.py:</p>

<pre><code>import test.test_import.data.circular_imports.binding as binding
</code></pre>

<p>Two submodules of a module import each other as some name.  Here is the test that presumably failed before:</p>

<pre><code>def test_binding(self):
    try:
        import test.test_import.data.circular_imports.binding
    except ImportError:
        self.fail('circular import with binding a submodule to a name failed')
</code></pre>
","722804","","","0","1068","Terry Jan Reedy","2011-04-24 17:44:02","13264","2153","202","90","49051706","49051985","2018-03-01 14:21:07","2","371","<p>This is a point from python 3.7 changelog.</p>

<blockquote>
  <p>bpo-30024: Circular imports involving absolute imports with binding a submodule to a name are now supported.</p>
</blockquote>

<p>What is the example of code that wouldn't work in 3.6 but works now?</p>
","5558953","","","What's new in python 3.7 about circular imports?","<python><python-3.7>","1","1","273"
"49052003","2018-03-01 14:36:23","8","","<p>For me working:</p>

<pre><code>df[[""C"",""D""]] = pd.DataFrame([arr], index=df.index)
</code></pre>

<p>Or <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.join.html"" rel=""noreferrer""><code>join</code></a>:</p>

<pre><code>df = df.join(pd.DataFrame([arr], columns=['C','D'], index=df.index))
</code></pre>

<p>Or <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.assign.html"" rel=""noreferrer""><code>assign</code></a>:</p>

<pre><code>df = df.assign(**pd.Series(arr, index=['C','D']))
</code></pre>

<hr>

<pre><code>print (df)
   A  B  C  D
0  1  2  7  8
1  3  4  7  8
</code></pre>
","2901002","2901002","2018-03-01 14:41:27","1","645","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49051969","49052003","2018-03-01 14:34:39","5","711","<p>So what I want to do is to add columns to a dataframe and fill them (all rows respectively) with a single value. </p>

<pre><code>import pandas as pd
import numpy as np

df = pd.DataFrame(np.array([[1,2],[3,4]]), columns = [""A"",""B""])
arr = np.array([7,8])

# this is what I would like to do
df[[""C"",""D""]] = arr

# and this is what I want to achieve
#    A  B  C  D
# 0  1  2  7  8
# 1  3  4  7  8
# but it yields an ""KeyError"" sadly
# KeyError: ""['C' 'D'] not in index""
</code></pre>

<p>I do know about the assign-functionality and how I would tackle this issue if I only were to add one column at once. I just want to know whether there is a clean and simple way to do this with multiple new columns as I was not able to find one.</p>
","4109714","","","How to assign values to multiple non existing columns in a pandas dataframe?","<python><pandas><numpy>","2","0","740"
"49052013","2018-03-01 14:36:57","0","","<p>I know that <code>split()</code> is the fastest and <code>replace()</code> is faster then regex, so:</p>

<pre><code>output = '""normal"" script'.replace('""', '').split()
</code></pre>

<p>Output: <code>['normal', 'script']</code></p>

<p>Execution Time: <code>3.490e-05 seconds</code>
Using regex you get time beetwen <code>0.2e-04</code> and <code>0.3e-04</code></p>
","6101071","6101071","2018-03-01 15:03:27","0","370","Srdjan M.","2016-03-22 21:01:48","2679","264","505","18","49051765","49052046","2018-03-01 14:23:55","0","71","<p>For example:</p>

<p>If the string is ' ""normal"" script ' - output should show that substring <code>normal</code> is in double quotes whereas the substring <code>script</code> is not. </p>

<p>To trace double quoted substring from a string, I tried with the regex:</p>

<blockquote>
  <p>r' ""([^""]*)"" '</p>
</blockquote>

<p>We can use <code>split()</code> method to get the substring without double quotes but I'm looking for an efficient approach.</p>

<p>Below is the code which I've tried - it returns list of substrings which are double quoted.</p>

<pre><code>import re
def demo(text):      
    matches = re.findall(r'""([^""]*)""', text)
    return matches

a = demo('""normal"" string ""is here""')
print(a)
</code></pre>

<p>Apart from finding double quoted substrings I'm also looking for substrings which are not double quoted.</p>

<p>For example, output of <code>demo('""normal"" string ""is here""')</code> should be:</p>

<p>double quoted: <code>['normal', 'is here']</code> </p>

<p>non double quoted: <code>['string']</code></p>
","2820154","2820154","2018-03-01 14:36:07","Regex: Given a string, find substring in double quotes and substring not in double quotes","<python><regex>","4","2","1039"
"49052032","2018-03-01 14:37:55","5","","<p>We are summing after sorting, so the order won't matter within the first <code>N=10</code> elements. Hence, we can use <code>np.argpartition</code> that avoids the sorting step and simply gives us the group of first <code>N</code> smallest numbers that could be summed over later on, like so -</p>

<pre><code>def sumSortNumPyArgpartition(x, N=10):
    return x[np.argpartition(x, N)[:N]].sum()
</code></pre>

<p>Timings on various datasets -</p>

<pre><code>In [39]: np.random.seed(0)
    ...: x = np.random.rand(1000000)

In [40]: %timeit sumSortNumpy(x)
    ...: %timeit sumSortNumPyArgpartition(x)
10 loops, best of 3: 78.6 ms per loop
100 loops, best of 3: 12.3 ms per loop

In [41]: np.random.seed(0)
    ...: x = np.random.rand(10000000)

In [42]: %timeit sumSortNumpy(x)
    ...: %timeit sumSortNumPyArgpartition(x)
1 loop, best of 3: 920 ms per loop
10 loops, best of 3: 153 ms per loop

In [43]: np.random.seed(0)
    ...: x = np.random.rand(100000000)

In [44]: %timeit sumSortNumpy(x)
    ...: %timeit sumSortNumPyArgpartition(x)
1 loop, best of 3: 10.6 s per loop
1 loop, best of 3: 978 ms per loop
</code></pre>
","3293881","","","0","1129","Divakar","2014-02-10 17:11:35","173564","13312","6892","97","49051835","49052032","2018-03-01 14:28:02","1","71","<p>I have a code where first I need to sort values and then I need to sum the first 10 elements. I would love to use Numba package to speed the run time, but it is not working, Numba is getting the code slower than just Numpy.</p>

<p>My first test, just for sum:</p>

<pre><code>import numpy as np
import numba
np.random.seed(0)

def SumNumpy(x):
    return np.sum(x[:10])

@numba.jit()
def SumNumpyNumba(x):
    return np.sum(x[:10])
</code></pre>

<p>My test:</p>

<pre><code>x = np.random.rand(1000000000)
%timeit SumNumpy(x)
%timeit SumNumpyNumba(x)
</code></pre>

<p>The results: </p>

<p>100000 loops, best of 3: 6.8 µs per loop</p>

<p>1000000 loops, best of 3: 715 ns per loop</p>

<p>Here its is okay, Numba is doing a good work. But when I try together np.sort and np.sum:</p>

<pre><code>def sumSortNumpy(x):
    y = np.sort(x)
    return np.sum(y[:10])

@numba.jit()
def sumSortNumpyNumba(x):
    y = np.sort(x)
    return np.sum(y[:10])
</code></pre>

<p>and test:</p>

<pre><code>x = np.random.rand(100000)
%timeit sumSortNumpy(x)
%timeit sumSortNumpyNumba(x)
</code></pre>

<p>Results: </p>

<p>100 loops, best of 3: 14.6 ms per loop</p>

<p>10 loops, best of 3: 20.6 ms per loop</p>

<p>Numba/Numpy get slower than just Numpy. So my question if is there something we could to improve the functiom ""sumSortNumpyNumba""? </p>

<p>I appreciate help. </p>

<p>Thanks.</p>
","6611148","3293881","2018-03-01 15:35:51","Efficiently compute sum of N smallest numbers in an array","<python><performance><numpy><numba>","1","0","1384"
"49052046","2018-03-01 14:38:26","1","","<p>You can search for both quoted and double-quoted strings in the same regular expression.</p>

<pre><code>import re

def dequote(s):
    return re.findall(r'(?:""([^""]*)"")|([^""]*)', s)

print(dequote('""normal"" script'))
print(dequote('another ""normal"" script with ""extra words in it""'))
</code></pre>

<p>Notice returned list of tuples contains both quoted and non-quoted strings. The quoted strings are in the first element of the tuples, the non-quoted strings are in the second element.</p>

<p>If you want the lists separate, it is a simple matter to separate them.</p>

<pre><code>result = dequote('another ""normal"" script with ""extra words in it""')

result_quoted = [t[0].strip() for t in result if t[0]]
result_unquoted = [t[1].strip() for t in result if t[1]]

print(""double quoted: {}\nnot double quoted{}"".format(
    result_quoted, result_unquoted))
</code></pre>

<p>The output of the entire program:</p>

<pre><code>$ python x.py 
[('normal', ''), ('', ' script'), ('', '')]
[('', 'another '), ('normal', ''), ('', ' script with '), ('extra words in it', ''), ('', '')]
double quoted: ['normal', 'extra words in it']
not double quoted['another', 'script with']
</code></pre>

<p>Note that you imply that a <code>re</code>-based solution will go faster than one based on <code>str.split()</code>. I'm not convinced of that. Consider these two solutions:</p>

<pre><code>def dequote_re(s):
    result = re.findall(r'(?:""([^""]*)"")|([^""]*)', s)
    result_quoted = [t[0].strip() for t in result if t[0]]
    result_unquoted = [t[1].strip() for t in result if t[1]]
    return result_quoted, result_unquoted

def dequote_split(s):
    result = s.split('""')
    result_unquoted = [item.strip() for item in result[0::2] if item]
    result_quoted = [item.strip() for item in result[1::2] if item]
    return result_quoted, result_unquoted
</code></pre>

<p>They give the same answers. Perhaps you should run timeit to find which is faster for you.</p>
","8747","8747","2018-03-01 14:50:53","0","1959","Robᵩ","2008-09-15 16:47:33","124214","7724","5618","743","49051765","49052046","2018-03-01 14:23:55","0","71","<p>For example:</p>

<p>If the string is ' ""normal"" script ' - output should show that substring <code>normal</code> is in double quotes whereas the substring <code>script</code> is not. </p>

<p>To trace double quoted substring from a string, I tried with the regex:</p>

<blockquote>
  <p>r' ""([^""]*)"" '</p>
</blockquote>

<p>We can use <code>split()</code> method to get the substring without double quotes but I'm looking for an efficient approach.</p>

<p>Below is the code which I've tried - it returns list of substrings which are double quoted.</p>

<pre><code>import re
def demo(text):      
    matches = re.findall(r'""([^""]*)""', text)
    return matches

a = demo('""normal"" string ""is here""')
print(a)
</code></pre>

<p>Apart from finding double quoted substrings I'm also looking for substrings which are not double quoted.</p>

<p>For example, output of <code>demo('""normal"" string ""is here""')</code> should be:</p>

<p>double quoted: <code>['normal', 'is here']</code> </p>

<p>non double quoted: <code>['string']</code></p>
","2820154","2820154","2018-03-01 14:36:07","Regex: Given a string, find substring in double quotes and substring not in double quotes","<python><regex>","4","2","1039"
"49052064","2018-03-01 14:39:21","5","","<p>Provide the <code>id_generator</code> function as the default value instead of the returned value of it. The function will be called every time when the new object is created.</p>

<p><code>reference = models.CharField(max_length=20, default=id_generator)</code></p>
","3867205","","","0","270","Sagar","2014-07-23 04:51:32","905","104","18","2","49051877","49052064","2018-03-01 14:30:13","1","245","<p>I have a django project built with <code>Django 1.10.7</code> and <code>mysql 14.14 Distrib 5.5.54</code></p>

<p>If I do:</p>

<pre><code>$ python manage.py makemigrations my_app
</code></pre>

<p>I get:</p>

<blockquote>
  <p>Migrations for 'my_app':<br>
    my_app/migrations/0023_auto_20180301_1419.py:<br>
      - Alter field reference on league</p>
</blockquote>

<p>Then:</p>

<pre><code>$ python manage.py migrate
</code></pre>

<blockquote>
  <p>Operations to perform:<br>
  Apply all migrations: admin, auth, contenttypes, my_app, sessions<br>
  Running migrations:<br>
  Applying my_app.0023_auto_20180301_1419... OK</p>
</blockquote>

<p>Then, just after, I do:</p>

<pre><code>$ python manage.py makemigrations my_app
</code></pre>

<p>I get:</p>

<blockquote>
  <p>Migrations for 'my_app':<br>
    my_app/migrations/0024_auto_20180301_1421.py:<br>
      - Alter field reference on league</p>
</blockquote>

<p>As you can see it is the same alteration as before. It seems that django does not make the migrations well, or does but does not detect anything.</p>

<p>In <code>models.py</code>, the class is as follows:</p>

<pre><code>class League(models.Model):
    name = models.CharField(max_length=50)
    id_creator = models.ForeignKey('auth.User', on_delete=models.CASCADE)
    id_tour = models.ForeignKey('Tour', on_delete=models.CASCADE)
    step = models.IntegerField(default=0)
    creation_date = models.DateTimeField(default=timezone.now)
    reference = models.CharField(max_length=20, default=id_generator())

    def __str__(self):
        return self.name
</code></pre>

<p>What have I done wrong ?</p>
","5446749","5446749","2018-03-01 15:15:58","Django makemigrations keeps making the same alteration","<python><mysql><django><python-3.x>","1","0","1633"
"49052090","2018-03-01 14:40:50","0","","<p>Python consider standard input as string and in the first case it convert the string to integer. But in the second case it will not work as it get input as string and chr(param) always expect an integer value where param should be a integer value (0-9) . So just use like below:-</p>

<pre><code>alpha1=(input(""enter Ist alphabet:""))[0]
</code></pre>
","8405835","","","0","354","Abhijit Pritam Dutta","2017-08-02 13:20:11","4709","632","89","22","49051871","","2018-03-01 14:29:45","2","699","<p>so i want to do the same with alphabets that i did with numbers take a look</p>

<pre><code>num1=int(input(""enter Ist digit:""))
num2=int(input(""enter IInd digit:""))
num3=int(input(""enter IIIrd digit:""))
num4=int(input(""enter IVth digit:""))
num5=int(input(""enter Vth digit:""))
</code></pre>

<p>i want to enter letters instead of numbers 
so i changed it to</p>

<pre><code>alpha1=chr(input(""enter Ist letter""))
</code></pre>

<p>but i kept on getting the error</p>

<pre><code>   alpha1=chr(input(""enter Ist alphabet:""))
TypeError: an integer is required (got type str)
</code></pre>
","9429401","","","how to input alphabets in python","<python><python-3.x>","3","1","587"
"49052131","2018-03-01 14:42:56","5","","<p>I believe most of people landed here are using ZSH thorugh iterm or whatever, and that brings you to <a href=""https://superuser.com/a/847543"">this answer</a>.</p>

<p>You have to add/modify your commands in <code>~/.zshrc</code> instead. </p>
","1638590","","","0","246","Mr. Crowley","2012-08-31 11:59:28","2110","81","178","0","18425379","18425592","2013-08-25 03:29:49","277","411677","<p>I'm running Mountain Lion and the basic default Python version is 2.7. I downloaded Python 3.3 and want to set it as default.</p>

<p>Currently:</p>

<pre><code>$ python
    version 2.7.5
$ python3.3
    version 3.3
</code></pre>

<p>How do I set it so that every time I run <code>$ python</code> it opens 3.3?</p>
","2228688","4601719","2018-08-31 14:57:01","How to set Python's default version to 3.x on OS X?","<python><python-3.x><macos><install>","17","3","318"
"49052141","2018-03-01 14:43:25","0","","<p>I have this case in many places in my app without having any problem. However, I use a different way to set up initial value of some fields of an existing instance. Instead of:</p>

<pre><code>self.initial[field_name] = value
</code></pre>

<p>I write, after having called <code>super()</code>:</p>

<pre><code>self.fields[field_name].initial = value
</code></pre>

<p>Can you try and tell the result ?</p>
","3380209","","","1","410","albar","2014-03-04 17:39:07","2159","107","56","13","49049972","","2018-03-01 12:42:39","0","825","<p>I have a custom Django ModelForm that I use to update a model instance.<br>
This is the example model:</p>

<pre><code>class MyModel(models.Model):
    number = models.CharField(_(""Number""), max_length=30, unique=True)
    sent_date = models.DateField(_('Sent date'), null=True, blank=True)
</code></pre>

<p>When creating an instance I will pass only the <code>number</code> field, that is why I don't want the <code>sent_date</code> to be required.</p>

<p>Then I have a view that updates the <code>sent_date</code> field, using this custom form:</p>

<pre><code># Generic form updater
class MyModelUpdateForm(forms.ModelForm):
    class Meta:
        model = MyModel
        fields = []

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        # Make fields mandatory
        if hasattr(self, 'required_fields'):
            for field_name in self.required_fields:
                self.fields[field_name].required = True
        # Set initial values
        if hasattr(self, 'initial_values'):
            for field_name, value in self.initial_values.items():
                self.initial[field_name] = value


class SentForm(MyModelUpdateForm):
    required_fields = ['sent_date']
    initial_values = {'sent_date': datetime.date.today()}

    class Meta(MyModelUpdateForm.Meta):
        fields = ['sent_date']
        field_classes = {'sent_date': MyCustomDateField}

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs) 
</code></pre>

<p><code>MyModelUpdateForm</code> is a generic ancestor for concrete forms like <code>SentForm</code>. </p>

<p>In my view whenever there is a GET I manually instantiate the form with:</p>

<pre><code>my_form = SentForm({instance: my_model_instance})
</code></pre>

<p>So in this case I would expect the <code>sent_date</code> field to have an initial value set to today's date even tough the real model instance field is None.</p>

<p>If I inspect <code>my_form</code> object it does indeed have these attributes:</p>

<pre><code>initial: {'sent_date': datetime.date(2018, 3, 1)}
instance: my_model_instance
fields: {'sent_date':
            ...: ...,
            'initial': None # Why this is None?
            ...: ... 
         }
</code></pre>

<p>So apparently it should work but it doesn't: the field is always empty.</p>

<p>So I suspect that the value is coming from <code>my_model_instance.sent_date</code> that is in fact <code>None</code>.</p>

<p>The <code>initial['sent_date'] = datetime.date(2018, 3, 1)</code> is correct.<br>
On the other side <code>fields['sent_date']['initial'] = None</code> it's not.</p>

<p>How can I always show the <code>initial</code> value when <code>my_model_instance.sent_date</code> is <code>None</code>?</p>
","1191416","","","Django Form field initial value when updating an instance","<python><django><django-models><django-forms>","2","0","2764"
"49052147","2018-03-01 14:43:56","1","","<p>With <a href=""https://pypi.python.org/pypi/regex/"" rel=""nofollow noreferrer"">regex</a> module:</p>

<pre><code>&gt;&gt;&gt; import re, regex
&gt;&gt;&gt; s='""normal"" string ""is here""'

&gt;&gt;&gt; re.findall(r'""([^""]*)""', s)
['normal', 'is here']

# change \w to appropriate character class as needed
&gt;&gt;&gt; regex.findall(r'""[^""]*""(*SKIP)(*F)|\w+', s)
['string']

# or a workaround, remove double quoted strings first
&gt;&gt;&gt; re.findall(r'\w+', re.sub(r'""([^""]*)""', '', s))
['string']
</code></pre>

<p>See <a href=""https://www.rexegg.com/backtracking-control-verbs.html#skipfail"" rel=""nofollow noreferrer"">Using (*SKIP)(*FAIL) to Exclude Unwanted Matches</a> for detailed explanation. To put it simply, append <code>(*SKIP)(*F)</code> to regex you want to exclude and using alternation define the ones you need</p>
","4082052","4082052","2018-03-01 14:49:18","0","831","Sundeep","2014-09-26 05:11:13","12843","1175","1136","195","49051765","49052046","2018-03-01 14:23:55","0","71","<p>For example:</p>

<p>If the string is ' ""normal"" script ' - output should show that substring <code>normal</code> is in double quotes whereas the substring <code>script</code> is not. </p>

<p>To trace double quoted substring from a string, I tried with the regex:</p>

<blockquote>
  <p>r' ""([^""]*)"" '</p>
</blockquote>

<p>We can use <code>split()</code> method to get the substring without double quotes but I'm looking for an efficient approach.</p>

<p>Below is the code which I've tried - it returns list of substrings which are double quoted.</p>

<pre><code>import re
def demo(text):      
    matches = re.findall(r'""([^""]*)""', text)
    return matches

a = demo('""normal"" string ""is here""')
print(a)
</code></pre>

<p>Apart from finding double quoted substrings I'm also looking for substrings which are not double quoted.</p>

<p>For example, output of <code>demo('""normal"" string ""is here""')</code> should be:</p>

<p>double quoted: <code>['normal', 'is here']</code> </p>

<p>non double quoted: <code>['string']</code></p>
","2820154","2820154","2018-03-01 14:36:07","Regex: Given a string, find substring in double quotes and substring not in double quotes","<python><regex>","4","2","1039"
"49052172","2018-03-01 14:45:02","6","","<p>Adding to the above perfect answers, in case you have a big dataset with lots of attributes, if you don't want to specify by hand all of the dummies you want, you can do set differences: </p>

<pre><code>len(df.columns) = 50
non_dummy_cols = ['A','B','C'] 
# Takes all 47 other columns
dummy_cols = list(set(df.columns) - set(non_dummy_cols))
df = pd.get_dummies(df, columns=dummy_cols)
</code></pre>
","1501476","","","0","404","Patric Fulop","2012-07-04 11:51:09","61","5","1","0","37265312","37269683","2016-05-17 00:37:09","13","22241","<pre><code>df = pd.DataFrame({'A': ['x', 'y', 'x'], 'B': ['z', 'u', 'z'],
                  'C': ['1', '2', '3'],
                  'D':['j', 'l', 'j']})
</code></pre>

<p>I just want Column A and D to get dummies not for Column B. If I used <code>pd.get_dummies(df)</code>, all columns turned into dummies. </p>

<p>I want the final result containing all of columns , which means column C and column B exit,like <code>'A_x','A_y','B','C','D_j','D_l'</code>.</p>
","5576930","5576930","2016-05-17 06:05:33","how to create dummies for certain columns by pandas get_dummies() method?","<python><pandas>","3","0","463"
"49052183","2018-03-01 14:45:22","0","","<p>If you have quite big string you may use regex to figure the occurrences and manage to break it in smaller pieces (depends what you expect to get and from where).</p>

<p>It seems your substrings are words.
For the double quoted or non double quoted strings you can split by substrings and ititerate as a list.</p>

<p>Spliting by double quoted or non double quoted may require for creating two lists.</p>

<p>Spliting by words you can create a single list of words and cheking the double quotation on outputing it.</p>

<p>Both of cases may cost almost the same, depending of the size of string you get.</p>

<p>I recommend using the <a href=""https://regexr.com"" rel=""nofollow noreferrer"">https://regexr.com</a> and try to get as most you can pieces of the string you may treat.</p>

<p>My Best.</p>
","9140008","","","0","804","David Allan Ribeiro","2017-12-26 00:25:26","1","2","0","0","49051765","49052046","2018-03-01 14:23:55","0","71","<p>For example:</p>

<p>If the string is ' ""normal"" script ' - output should show that substring <code>normal</code> is in double quotes whereas the substring <code>script</code> is not. </p>

<p>To trace double quoted substring from a string, I tried with the regex:</p>

<blockquote>
  <p>r' ""([^""]*)"" '</p>
</blockquote>

<p>We can use <code>split()</code> method to get the substring without double quotes but I'm looking for an efficient approach.</p>

<p>Below is the code which I've tried - it returns list of substrings which are double quoted.</p>

<pre><code>import re
def demo(text):      
    matches = re.findall(r'""([^""]*)""', text)
    return matches

a = demo('""normal"" string ""is here""')
print(a)
</code></pre>

<p>Apart from finding double quoted substrings I'm also looking for substrings which are not double quoted.</p>

<p>For example, output of <code>demo('""normal"" string ""is here""')</code> should be:</p>

<p>double quoted: <code>['normal', 'is here']</code> </p>

<p>non double quoted: <code>['string']</code></p>
","2820154","2820154","2018-03-01 14:36:07","Regex: Given a string, find substring in double quotes and substring not in double quotes","<python><regex>","4","2","1039"
"49052195","2018-03-01 14:46:06","2","","<p>After a quick look, the table in the page you referenced is actually coming through an iframe from a different page - <a href=""http://www2.bmf.com.br/pages/portal/bmfbovespa/lumis/lum-taxas-referenciais-bmf-ptBR.asp"" rel=""nofollow noreferrer"">http://www2.bmf.com.br/pages/portal/bmfbovespa/lumis/lum-taxas-referenciais-bmf-ptBR.asp</a>. If you run the same code on that base url, you should get the expected result - </p>

<pre><code>import requests
from bs4 import BeautifulSoup

url = 'http://www2.bmf.com.br/pages/portal/bmfbovespa/lumis/lum-taxas-referenciais-bmf-ptBR.asp'

r = requests.get(url)
soup = BeautifulSoup(r.text,'lxml')
soup.find_all(id = 'tb_principal1')
</code></pre>

<p>output</p>

<pre><code>[&lt;table id=""tb_principal1""&gt;
&lt;thead&gt;
&lt;tr&gt;
...
&lt;/table&gt;]
</code></pre>

<p>For reference, the easiest way I know to do this is by using the ""sources"" tab in the chrome page inspector. If you look a few divs above the table elements in the standard inspect element view, you'll see a form element with an action referencing that page also.</p>
","7465457","","","0","1082","Gasvom","2017-01-24 18:44:17","141","2","9","0","49051855","49052195","2018-03-01 14:29:07","0","321","<p>I've been trying to parse an HTML table from the following URL (<a href=""http://www.bmfbovespa.com.br/pt_br/servicos/market-data/consultas/mercado-de-derivativos/precos-referenciais/taxas-referenciais-bm-fbovespa/"" rel=""nofollow noreferrer"">http://www.bmfbovespa.com.br/pt_br/servicos/market-data/consultas/mercado-de-derivativos/precos-referenciais/taxas-referenciais-bm-fbovespa/</a>) but I can't find it using find_all.</p>

<p>The table has the id = 'tb_principal1'. When I try to use the following code, i keep getting an empty list.</p>

<pre><code>import requests
from bs4 import BeautifulSoup

url = 'http://www.bmfbovespa.com.br/pt_br/servicos/market-data/consultas/mercado-de-derivativos/precos-referenciais/taxas-referenciais-bm-fbovespa/'

r = requests.get(url)
soup = BeautifulSoup(r.text,'lxml')
soup.find_all(id = 'tb_principal1')
</code></pre>

<p>I tried some solutions that i found here but I can't find the table. Does anyone have experienced something similar? Could it be a problem with encoder?</p>

<p>I appreciate your help.</p>
","9163832","","","Can't find an HTML Table using BeautifulSoup in Python","<python><html><parsing><beautifulsoup>","1","0","1056"
"49052306","2018-03-01 14:51:11","1","","<p>You can using <code>assign</code> and pass a dict in it </p>

<pre><code>df.assign(**dict(zip(['C','D'],[arr.tolist()]*2)))
Out[755]: 
   A  B  C  D
0  1  2  7  7
1  3  4  8  8
</code></pre>
","7964527","","","2","194","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49051969","49052003","2018-03-01 14:34:39","5","711","<p>So what I want to do is to add columns to a dataframe and fill them (all rows respectively) with a single value. </p>

<pre><code>import pandas as pd
import numpy as np

df = pd.DataFrame(np.array([[1,2],[3,4]]), columns = [""A"",""B""])
arr = np.array([7,8])

# this is what I would like to do
df[[""C"",""D""]] = arr

# and this is what I want to achieve
#    A  B  C  D
# 0  1  2  7  8
# 1  3  4  7  8
# but it yields an ""KeyError"" sadly
# KeyError: ""['C' 'D'] not in index""
</code></pre>

<p>I do know about the assign-functionality and how I would tackle this issue if I only were to add one column at once. I just want to know whether there is a clean and simple way to do this with multiple new columns as I was not able to find one.</p>
","4109714","","","How to assign values to multiple non existing columns in a pandas dataframe?","<python><pandas><numpy>","2","0","740"
"49052319","2018-03-01 14:51:56","0","","<p>Accomplished what I wanted to by creating two threads, one that only collected the information and one that processed it. </p>
","8644790","","","0","130","Morgan Kohler","2017-09-20 22:17:19","12","5","0","0","49011579","49052319","2018-02-27 14:54:21","0","22","<p>I have two piped programs: a debug log which updates very quickly which sends the information to a python program which processes the information:</p>

<pre><code>./debugClient | python processor.py
</code></pre>

<p>The problem is, the debugClient program produces output real-time and the processor program needs to be able to process at real-time as well. It is entirely okay and expected that some information is missed as long as the program occurs real-time. However when the two are piped together I seem to only get old debug information going to processor.py. I understand why this might be the case as the two programs are supposed to run concurrently and the program involves more than just a STDIN loop. But I am confused on the buffer involved and why the new information isn't being sent instead of the old info. </p>
","8644790","465183","2018-02-27 15:26:10","Stop piped programs from exchanging outdated information","<python><bash><pipe>","1","2","835"
"49052366","2018-03-01 14:54:49","1","","<p>Use <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.agg.html"" rel=""nofollow noreferrer""><code>agg</code></a> by dictionary:</p>

<pre><code>d = {'size':'median', 'margin':'median', 'height':'median', 'type':'size'}
</code></pre>

<p>Or if many columns is possible create <code>dict</code> dynamically:</p>

<pre><code>d = dict.fromkeys(df.columns.difference(['type']), 'median')
d['type'] = 'size'
</code></pre>

<hr>

<pre><code>df = df.groupby('type').agg(d).rename(columns={'type':'count'}).reset_index()
</code></pre>

<p>Another alternative with <a href=""http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.join.html"" rel=""nofollow noreferrer""><code>join</code></a>:</p>

<pre><code>df = df.groupby('type').median().join(df.type.value_counts().rename('count')).reset_index()
</code></pre>

<hr>

<pre><code>print (df)
  type  margin  size  height  count
0    A     4.5   2.5       1      2
1    B     1.0   1.0       3      1
</code></pre>
","2901002","2901002","2018-03-01 15:06:07","0","1019","jezrael","2013-10-20 20:27:26","427380","89269","18260","743","49052311","49052366","2018-03-01 14:51:37","1","375","<p>I have this dataframe:</p>

<pre><code>df:
      type . size .  margin .  height
0 .      A .    2 .       5 .       1
1 .      A .    3 .       4 .       1
2 .      B .    1 .       1 .       3 
</code></pre>

<p>I want to groupby type, count the number of companies in each type and calculate the medians for all columns.</p>

<p>I know that for count is like this</p>

<pre><code>df=df.groupby('type').count('type')
</code></pre>

<p>But is there a way to use a one liner and put everything in the same df?</p>

<p>Something like:</p>

<pre><code>df=df.groupby('type').calculate_medians_and_counts
</code></pre>

<p>It should come out looking like this:</p>

<pre><code>type    count   size   margin   height
   A        2    2.5      4.5        1
   B        1      1        1        3

(size, margin and height are the medians from df)
</code></pre>
","5606352","472495","2018-03-05 13:56:21","Groupby, count and calculate medians in Pandas","<python><pandas><pandas-groupby>","2","1","858"
"49052374","2018-03-01 14:55:13","1","","<p>How about the following:</p>

<pre><code>import pandas as pd

df = pd.DataFrame({'Date': ['2014-12-30 23:00:00','2014-12-30 23:15:00','2014-12-30 23:30:00','2014-12-30 23:45:00','2014-12-31 00:00:00']})

DFHolidays = pd.DataFrame({'NAME': ['Neujahr', 'Heilige Drei Könige', 'Karfreitag', 'Ostersonntag', 'Ostermontag', '1. Mai', 'Erster Weihnachtsfeiertag', 'Zweiter Weihnachtsfeiertag'],
                           'DATE': ['2014-01-01','2014-01-06','2014-04-18','2014-04-20','2014-04-21','2014-05-01','2015-12-25','2015-12-26']})

# Ensure all dates are actually dates
df['Date'] = pd.to_datetime(df['Date'])
DFHolidays['DATE'] = pd.to_datetime(DFHolidays['DATE'])
DFHolidays.set_index('NAME', inplace=True)

# Loop over each holiday, apply the calculation
for holiday_name, date in DFHolidays['DATE'].to_dict().items():
    df[holiday_name] = date - df['Date']
</code></pre>

<p>This returns, with the sample data given:</p>

<pre><code>                 Date             Neujahr Heilige Drei Könige  \
0 2014-12-30 23:00:00 -364 days +01:00:00 -359 days +01:00:00   
1 2014-12-30 23:15:00 -364 days +00:45:00 -359 days +00:45:00   
2 2014-12-30 23:30:00 -364 days +00:30:00 -359 days +00:30:00   
3 2014-12-30 23:45:00 -364 days +00:15:00 -359 days +00:15:00   
4 2014-12-31 00:00:00 -364 days +00:00:00 -359 days +00:00:00   

           Karfreitag        Ostersonntag         Ostermontag  \
0 -257 days +01:00:00 -255 days +01:00:00 -254 days +01:00:00   
1 -257 days +00:45:00 -255 days +00:45:00 -254 days +00:45:00   
2 -257 days +00:30:00 -255 days +00:30:00 -254 days +00:30:00   
3 -257 days +00:15:00 -255 days +00:15:00 -254 days +00:15:00   
4 -257 days +00:00:00 -255 days +00:00:00 -254 days +00:00:00   

               1. Mai Erster Weihnachtsfeiertag Zweiter Weihnachtsfeiertag  
0 -244 days +01:00:00         359 days 01:00:00          360 days 01:00:00  
1 -244 days +00:45:00         359 days 00:45:00          360 days 00:45:00  
2 -244 days +00:30:00         359 days 00:30:00          360 days 00:30:00  
3 -244 days +00:15:00         359 days 00:15:00          360 days 00:15:00  
4 -244 days +00:00:00         359 days 00:00:00          360 days 00:00:00   
</code></pre>

<hr>

<h2>With changed sample data</h2>

<p>Understanding that the year of the data is important, we could do the following:</p>

<pre><code>import pandas as pd

df = pd.DataFrame({'Date': ['2016-02-15 23:00:00','2016-03-05 23:15:00','2016-12-30 23:30:00','2017-08-10 23:45:00','2017-09-01 00:00:00']})

DFHolidays = pd.DataFrame({'NAME': ['Neujahr','Karfreitag','Ostersonntag', 'Ostermontag', '1. Mai','Christi Himmelfahrt','Pfingstsonntag','Pfingstmontag', 'Tag der deutschen Einheit', 'Erster Weihnachtsfeiertag', 'Zweiter Weihnachtsfeiertag','Neujahr','Karfreitag','Ostersonntag',  'Ostermontag','1. Mai','Christi Himmelfahrt','Pfingstsonntag','Pfingstmontag', 'Tag der deutschen Einheit', 'Erster Weihnachtsfeiertag', 'Zweiter Weihnachtsfeiertag'],
                           'DATE': ['2016-01-01','2016-03-25','2016-03-27','2016-03-28','2016-05-01','2016-05-05','2016-05-15','2016-05-16','2016-10-03','2016-12-25','2016-12-26','2017-01-01','2017-04-14','2017-04-16','2017-04-17','2017-05-01','2017-05-25','2017-06-04','2017-06-05','2017-10-03','2017-12-25','2017-12-26']})

# Ensure all dates are actually dates
df['Date'] = pd.to_datetime(df['Date'])
DFHolidays['DATE'] = pd.to_datetime(DFHolidays['DATE'])

# Set up a year column in both dataframes ot join on shortly
DFHolidays['Year'] = DFHolidays['DATE'].dt.year
df['Year'] = df['Date'].dt.year

# Work out what all the holiday names are
holiday_names = DFHolidays['NAME'].unique()
DFHolidays = DFHolidays.pivot(index='Year', columns='NAME', values='DATE') \
                       .reset_index()

# Merge the frames
df = df.merge(DFHolidays, on='Year')

# Calculate the difference
for holiday in holiday_names:
    df[holiday] = df[holiday] - df['Date']
</code></pre>

<p>This gives us:</p>

<pre><code>                 Date  Year              1. Mai Christi Himmelfahrt  \
0 2016-02-15 23:00:00  2016    75 days 01:00:00    79 days 01:00:00   
1 2016-03-05 23:15:00  2016    56 days 00:45:00    60 days 00:45:00   
2 2016-12-30 23:30:00  2016 -244 days +00:30:00 -240 days +00:30:00   
3 2017-08-10 23:45:00  2017 -102 days +00:15:00  -78 days +00:15:00   
4 2017-09-01 00:00:00  2017 -123 days +00:00:00  -99 days +00:00:00   

  Erster Weihnachtsfeiertag          Karfreitag             Neujahr  \
0         313 days 01:00:00    38 days 01:00:00  -46 days +01:00:00   
1         294 days 00:45:00    19 days 00:45:00  -65 days +00:45:00   
2         -6 days +00:30:00 -281 days +00:30:00 -365 days +00:30:00   
3         136 days 00:15:00 -119 days +00:15:00 -222 days +00:15:00   
4         115 days 00:00:00 -140 days +00:00:00 -243 days +00:00:00   

          Ostermontag        Ostersonntag       Pfingstmontag  \
0    41 days 01:00:00    40 days 01:00:00    90 days 01:00:00   
1    22 days 00:45:00    21 days 00:45:00    71 days 00:45:00   
2 -278 days +00:30:00 -279 days +00:30:00 -229 days +00:30:00   
3 -116 days +00:15:00 -117 days +00:15:00  -67 days +00:15:00   
4 -137 days +00:00:00 -138 days +00:00:00  -88 days +00:00:00   

       Pfingstsonntag Tag der deutschen Einheit Zweiter Weihnachtsfeiertag  
0    89 days 01:00:00         230 days 01:00:00          314 days 01:00:00  
1    70 days 00:45:00         211 days 00:45:00          295 days 00:45:00  
2 -230 days +00:30:00        -89 days +00:30:00          -5 days +00:30:00  
3  -68 days +00:15:00          53 days 00:15:00          137 days 00:15:00  
4  -89 days +00:00:00          32 days 00:00:00          116 days 00:00:00  
</code></pre>

<p>To get just the number of days, change the last line to</p>

<pre><code>df[holiday] = df[holiday].dt.date - df['Date'].dt.date
</code></pre>
","5309300","5309300","2018-03-01 15:46:28","4","5834","asongtoruin","2015-09-07 13:27:25","6801","578","528","75","49051853","49052374","2018-03-01 14:29:04","1","395","<p>I have two dataframes.
Once the regular dataframe:</p>

<p><strong>df</strong></p>

<pre><code>Datum                   
...
2014-12-30 23:00:00 
2014-12-30 23:15:00 
2014-12-30 23:30:00 
2014-12-30 23:45:00 
2014-12-31 00:00:00 
...
2015-01-01 00:00:00 
2015-01-02 00:00:00 
2015-01-03 00:00:00 
2015-01-04 00:00:00 
2015-01-04 00:00:00 
2015-01-05 00:00:00 
...
</code></pre>

<p>and a Dataframe that includes the holiday dates. If, for example, the daterange of <strong>DF</strong> is 2014-2015, then DF-Holiday has the holidays of 2014 and 2015:</p>

<p><strong>DFHolidays</strong></p>

<pre><code>           DATE
NAME    
Neujahr 2014-01-01
Heilige Drei Könige 2014-01-06
Karfreitag  2014-04-18
Ostersonntag    2014-04-20
Ostermontag 2014-04-21
1. Mai  2014-05-01
...
Erster Weihnachtsfeiertag   2015-12-25
Zweiter Weihnachtsfeiertag  2015-12-26
...
</code></pre>

<p>Dataframe ""DF"" should now have a new column for each holiday, which calculates the distance in days to the holiday of his year for a given row.</p>

<p>example:</p>

<pre><code>                        Neujahr Heilige Drei Könige    Karfreitag      ...
...
2014-01-01 23:00:00       0               value             value
2014-01-02 23:15:00       1               value             value
2014-01-03 23:30:00       2               value             value
2014-01-04 23:45:00       3               value             value
2014-01-05 00:00:00       4               value             value
... 
</code></pre>

<p>i wrote following code.</p>

<pre><code>import datetime
from datetime import datetime
def computeDiff(x,y):
    x = pd.to_datetime(x).date()
    print(""x: "",x)
    mask = mask = (y.dt.year == x.year)
    y = y.loc[mask]
    y = y.get_value(0,0)
    print(""y: "",y)
    y = pd.to_datetime(y).date()
    return (y - x).days

for holiday in list(DFHolidays.index):
    day = DFHolidays.loc[holiday, 'DATE']
    df[holiday] = df['Datum'].apply(computeDiff, args=(day,))
</code></pre>

<p>That works, but it is very slow. How could i solve this more elegantly?</p>

<p><strong>EDIT:</strong> Full DFHolidays (in this example for just two years. Real datas are about 10+ Years.</p>

<pre><code>    DATE
NAME    
Neujahr 2016-01-01
Karfreitag  2016-03-25
Ostersonntag    2016-03-27
Ostermontag 2016-03-28
1. Mai  2016-05-01
Christi Himmelfahrt 2016-05-05
Pfingstsonntag  2016-05-15
Pfingstmontag   2016-05-16
Tag der deutschen Einheit   2016-10-03
Erster Weihnachtsfeiertag   2016-12-25
Zweiter Weihnachtsfeiertag  2016-12-26
Neujahr 2017-01-01
Karfreitag  2017-04-14
Ostersonntag    2017-04-16
Ostermontag 2017-04-17
1. Mai  2017-05-01
Christi Himmelfahrt 2017-05-25
Pfingstsonntag  2017-06-04
Pfingstmontag   2017-06-05
Tag der deutschen Einheit   2017-10-03
Erster Weihnachtsfeiertag   2017-12-25
Zweiter Weihnachtsfeiertag  2017-12-26
</code></pre>
","8736498","8736498","2018-03-01 15:08:43","Python pandas calculate distances between dates","<python><pandas><dataframe>","1","2","2829"
"49052388","2018-03-01 14:55:47","3","","<p>IIUC</p>

<pre><code>s=df.value.bfill()
s.loc[df.value.isnull()]=s.astype(int).astype(str)+'5D'
s
Out[771]: 
0      1
1    25D
2    25D
3      2
4      3
5      1
6      3
7    35D
8      3
Name: value, dtype: object
</code></pre>
","7964527","","","0","234","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49052270","49052388","2018-03-01 14:49:42","1","304","<p>I have a dataset and I want to fill the missing data  in the column 'value' with bfill with adding a string to it. Here is to code that I have: </p>

<pre><code>import pandas as pd
import numpy as np 
df = pd.DataFrame(
    {
        'category': ['X', 'X', 'X', 'X', 'X', 'X', 'Y', 'Y', 'Y'],
        'name': ['A','A', 'B','B','B','B', 'C','C','C'],
        'other_value': [10, np.nan, np.nan, 20, 30, 10, 30, np.nan, 30],
        'value': [1, np.nan, np.nan, 2, 3, 1, 3, np.nan, 3],
    }
)
print(df)

def fillValue(g):

    gNotNull = g.dropna()
    wtAvg = str(gNotNull[0])+'5D'
    return g.fillna(wtAvg)



ff=pd.DataFrame()
ff[""value""] = df['value'].transform(fillValue)
ff
</code></pre>

<p>The output that I am getting from this code is: </p>

<pre><code>value
0
1 
1
1.05D 
2
1.05D 
3
2 
4
3 
5
1 
6
3 
7
1.05D 
8
3 
</code></pre>

<p>the out put that I want is to get back filled  and look something like this:</p>

<pre><code>value
0
1 
1
25D 
2
35D 
3
2 
4
3 
5
1 
6
3 
7
85D 
8
3 
</code></pre>

<p>I appreciate if anyone can help.
Thanks</p>
","9264149","","","Filling Missing values Pandas Dataframe by specific value","<python><pandas><dataframe><fillna>","1","0","1059"
"49052399","2018-03-01 14:56:27","0","","<p>You can extend the base template and override the <code>logo</code> block and <code>logo_href</code> block.</p>

<p>Complete description of all the possible blocks you can override are documented <a href=""http://django-adminlte2.readthedocs.io/en/latest/templates_and_blocks.html#adminlte-lib-main-header-html"" rel=""nofollow noreferrer"">here</a></p>
","3867205","","","0","353","Sagar","2014-07-23 04:51:32","905","104","18","2","49049266","","2018-03-01 11:57:55","0","296","<p>I am using AdminLTE in my django admin site. I want to change its logo to my site name and also want to change its redirect link. But not getting any help related to that. Please give the solution if anyone has an idea about that.</p>
","7677528","","","Change logo of AdminLTE in django","<python><django><adminlte>","1","1","238"
"49052402","2018-03-01 14:56:35","0","","<p>You can use python to train your model with SKLearn as you suggested. This is a good post on getting started with that (make sure you use Sklearn and not Statsmodels).</p>

<p><a href=""https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9"" rel=""nofollow noreferrer"">https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9</a></p>

<p>When you have trained your model, you can convert it using Apple's coremltools:</p>

<p><a href=""https://github.com/apple/coremltools"" rel=""nofollow noreferrer"">https://github.com/apple/coremltools</a></p>

<p>When you've converted it you can add your .mlmodel file to your xcode project. You'll then need to write some code to get all of the your model inputs collected from your app and pass them as inputs to the model.</p>

<p>Good luck!</p>
","2874557","","","0","857","jamesonthecrow","2013-10-12 17:43:41","98","10","1","0","48928347","","2018-02-22 13:13:48","0","280","<p>I am new with machine learning and want to do following implementation</p>

<ul>
<li>Want to create a custom .mlmodel with input of ""xls or csv or nsdata of this files"" and output should be double or array.</li>
<li>Pythone file should be able to read input data because i am going to use train_data from this input.</li>
<li>Pythone will do some calculation on this input data and provide prediction on this (i will do this calculation using sklearn,LinearRegression) </li>
</ul>

<p>Can any one please help me how i can do this ?</p>
","1191683","","","Custom MLModel File","<python><ios><machine-learning><coreml><coremltools>","1","0","539"
"49052416","2018-03-01 14:57:12","1","","<p><code>slice</code> is a built-in class.  The prefix 'i' for 'iterator' is added to avoid confusion and a name clash if one does <code>from itertools import *</code>.</p>

<p>In Python 2, itertools also had <code>imap</code> and <code>ifilter</code>, to avoid clashing with the old versions of <code>map</code> and <code>filter</code>.  In Python 3, <code>imap</code> and <code>ifilter</code> became the new versions of <code>map</code> and <code>filter</code> and were hence removed from <code>itertools</code>.</p>
","722804","","","0","519","Terry Jan Reedy","2011-04-24 17:44:02","13264","2153","202","90","49051407","49051527","2018-03-01 14:05:15","1","158","<p>I'm new in Python and I'm not an English native speaker. Today I learned some functions in the itertools module. There is a function called islice. Does it stand for <code>infinitive slice</code>? As I understand it can be used to slice infinitive sequence of objects and is commonly used with <code>itertools.count()</code>. </p>
","1572028","1572028","2018-03-01 14:10:30","Want to confirm the meaning of the name islice in Python itertools.islice","<python><itertools>","2","2","334"
"49052418","2018-03-01 14:57:24","1","","<p>I like the <a href=""https://stackoverflow.com/a/49052433/778533"">Biopython solution</a> by @Chris_Rands better for small files, but here is a solution that only uses the batteries included with Python and is memory efficient. It assumes the fasta and fastq files to contain the same number of reads in the same order.</p>

<pre><code>with open('Input.fasta') as fasta, open('Input.fastq') as fastq, open('DesiredOutput.fastq', 'w') as fo:
    for i, line in enumerate(fastq):
        if i % 4 == 1:
            for j in range(2):
                line = fasta.readline()
        print(line, end='', file=fo)
</code></pre>
","778533","778533","2018-03-01 15:09:05","0","624","tommy.carstensen","2011-05-31 23:47:33","4373","1624","1969","13","49052163","49052433","2018-03-01 14:44:36","1","315","<p>I am trying to use python to find four-line blocks of interest in two separate files then print out some of those lines in controlled order.  Below are the two input files and an example of the desired output file.  Note that the DNA sequence in the Input.fasta is different than the DNA sequence in Input.fastq because the .fasta file has been read corrected.</p>

<p>Input.fasta</p>

<pre><code>&gt;read1
AAAGGCTGT
&gt;read2
AGTCTTTAT
&gt;read3
CGTGCCGCT
</code></pre>

<p>Input.fastq</p>

<pre><code>@read1
AAATGCTGT
+
'(''%$'))
@read2
AGTCTCTAT
+
&amp;---+2010
@read3
AGTGTCGCT
+
0-23;:677
</code></pre>

<p>DesiredOutput.fastq</p>

<pre><code>@read1
AAAGGCTGT
+
'(''%$'))
@read2
AGTCTTTAT
+
&amp;---+2010
@read3
CGTGCCGCT
+
0-23;:677
</code></pre>

<p>Basically I need the sequence line ""AAAGGCTGT"", 
""AGTCTTTAT"", and ""CGTGCCGCT"" from ""input.fasta"" and all other lines from ""input.fastq"". This allows the restoration of quality information to a read corrected .fasta file.</p>

<p>Here is my closest failed attempt:</p>

<pre><code>fastq = open(Input.fastq, ""r"")
fasta = open(Input.fasta, ""r"")

ReadIDs = []
IDs = []

with fastq as fq:
    for line in fq:
        if ""read"" in line:  
            ReadIDs.append(line)
            print(line.strip())
            for ID in ReadIDs:
                IDs.append(ID[1:6])
            with fasta as fa:
                for line in fa:
                    if any(string in line for string in IDs):
                        print(next(fa).strip())
            next(fq)
            print(next(fq).strip())
            print(next(fq).strip())
</code></pre>

<p>I think I am running into trouble by trying to nest ""with"" calls to two different files in the same loop.  This prints the desired lines for read1 correctly but does not continue to iterate through the remaining lines and throws an error ""ValueError: I/O operation on closed file""</p>
","6749238","6260170","2018-03-02 17:06:39","in python loop print lines from alternating files","<python><bioinformatics><biopython><fasta><fastq>","3","3","1893"
"49052433","2018-03-01 14:58:25","3","","<p>I suggest you use <a href=""http://biopython.org/"" rel=""nofollow noreferrer"">Biopython</a>, which will save you a lot of trouble as it provides nice parsers for these file formats, which handle not only the standard cases but also for example multi-line fasta.</p>

<p>Here is an implementation that replaces the fastq sequence lines with the corresponding fasta sequence lines:</p>

<pre><code>from Bio import SeqIO

fasta_dict = {record.id: record.seq for record in
              SeqIO.parse('Input.fasta', 'fasta')}

def yield_records():
    for record in SeqIO.parse('Input.fastq', 'fastq'):
        record.seq = fasta_dict[record.id]
        yield record

SeqIO.write(yield_records(), 'DesiredOutput.fastq', 'fastq')
</code></pre>

<p>If you don't want to use the headers but just rely on the order then the solution is even simpler and more memory efficient (just make sure the order and number of records is the same), no need to define the dictionary first, just iterate over the records together:</p>

<pre><code>fasta_records = SeqIO.parse('Input.fasta', 'fasta')
fastq_records = SeqIO.parse('Input.fastq', 'fastq')

def yield_records():
    for fasta_record, fastq_record in zip(fasta_records, fastq_records):
        fastq_record.seq = fasta_record.seq
        yield fastq_record
</code></pre>
","6260170","6260170","2018-03-02 10:08:16","3","1308","Chris_Rands","2016-04-27 07:30:21","19982","2918","1860","2071","49052163","49052433","2018-03-01 14:44:36","1","315","<p>I am trying to use python to find four-line blocks of interest in two separate files then print out some of those lines in controlled order.  Below are the two input files and an example of the desired output file.  Note that the DNA sequence in the Input.fasta is different than the DNA sequence in Input.fastq because the .fasta file has been read corrected.</p>

<p>Input.fasta</p>

<pre><code>&gt;read1
AAAGGCTGT
&gt;read2
AGTCTTTAT
&gt;read3
CGTGCCGCT
</code></pre>

<p>Input.fastq</p>

<pre><code>@read1
AAATGCTGT
+
'(''%$'))
@read2
AGTCTCTAT
+
&amp;---+2010
@read3
AGTGTCGCT
+
0-23;:677
</code></pre>

<p>DesiredOutput.fastq</p>

<pre><code>@read1
AAAGGCTGT
+
'(''%$'))
@read2
AGTCTTTAT
+
&amp;---+2010
@read3
CGTGCCGCT
+
0-23;:677
</code></pre>

<p>Basically I need the sequence line ""AAAGGCTGT"", 
""AGTCTTTAT"", and ""CGTGCCGCT"" from ""input.fasta"" and all other lines from ""input.fastq"". This allows the restoration of quality information to a read corrected .fasta file.</p>

<p>Here is my closest failed attempt:</p>

<pre><code>fastq = open(Input.fastq, ""r"")
fasta = open(Input.fasta, ""r"")

ReadIDs = []
IDs = []

with fastq as fq:
    for line in fq:
        if ""read"" in line:  
            ReadIDs.append(line)
            print(line.strip())
            for ID in ReadIDs:
                IDs.append(ID[1:6])
            with fasta as fa:
                for line in fa:
                    if any(string in line for string in IDs):
                        print(next(fa).strip())
            next(fq)
            print(next(fq).strip())
            print(next(fq).strip())
</code></pre>

<p>I think I am running into trouble by trying to nest ""with"" calls to two different files in the same loop.  This prints the desired lines for read1 correctly but does not continue to iterate through the remaining lines and throws an error ""ValueError: I/O operation on closed file""</p>
","6749238","6260170","2018-03-02 17:06:39","in python loop print lines from alternating files","<python><bioinformatics><biopython><fasta><fastq>","3","3","1893"
"49052441","2018-03-01 14:58:32","1","","<p>While I am not telling that your code has to resemble the code below, because the same behaviour can be written in some different ways and styles, it will do what you want.</p>

<p>I see two or three fundamental errors in your code.</p>

<p>You are passing the main root window as a parameter by calling <code>Tk()</code>.
That is wrong because there should be only one Tk instance, made with a <code>TK()</code> call in your tkinter program. Give it a name such as root and use that reference from them on.</p>

<p>Secondly, you don't see anything because you sleep forever without ever calling <code>mainloop()</code>, which you should, otherwise your program will not update the UI, nor it will respond to events.</p>

<p>mainloop is the tkinter's eventloop for the <code>Tk</code> instance. So setup your complete UI with all the widgets and make sure the code reaches and ending statement calling <code>root.mainloop()</code>.</p>

<p>Also you usually don't need to call <code>sleep()</code> and that is a blocking function. Any blocking function would also block the mainloop, inhibiting updates and event reception, until it returns.</p>

<p>Now follows some code</p>

<pre><code>from tkinter import ttk, Tk, Toplevel

root = Tk()
welcome_window = Toplevel(root)
welcome_window.title('Welcome')

lab_window = Toplevel(root)
lab_window.title('Lab')

root.withdraw() # hide root window
lab_window.withdraw() # hide lab window

def goto_lab():
    welcome_window.destroy()
    lab_window.deiconify() # show lab window

button1 = ttk.Button(welcome_window, text='Close',\
                     command=goto_lab)
button1.pack(padx=100, pady=50)

button2 = ttk.Button(lab_window, text='Close',\
                     command=quit)
button2.pack(padx=100, pady=50)

root.mainloop()
</code></pre>

<p>About giving some structure to your GUI code, as you are starting to learn tkinter, take a look at this <a href=""https://stackoverflow.com/questions/17466561/best-way-to-structure-a-tkinter-application"">thread</a></p>
","7857466","7857466","2018-03-02 15:07:54","0","2018","progmatico","2017-04-12 15:24:17","2420","352","1132","24","49048124","49052441","2018-03-01 10:55:09","0","1538","<p>I'm trying to use two windows with Tkinter: One welcome window appears, and when a button is clicked, another window opens (and the welcome window closes). However, currently the first window doesn't show up so the program can't verify the condition and move on to the second one. (It shows up if the condition isn't there, but in which case both windows appear at the same time)</p>

<pre><code>welWindow=New_Toplevel_1(Tk())
#wait until welWindow.getGo()==1
while welWindow.getGo()!=1:
    time.sleep(1)
#my variables get values from welWindow's variables
welWindow.destroy()
labWindow=(Tk())
labWindow.mainloop()
</code></pre>

<p>The destroy function in my New_Toplevel_1 class:</p>

<pre><code>def destroy(self):
    self.top.destroy()
</code></pre>

<p>(top is the Tk() used in the constructor)</p>

<p>As you have probably guessed I am very new to this, all tips/recommendations are welcome :)</p>
","6187682","6187682","2018-03-01 11:35:13","Python/Tkinter: multiple windows opened sequentially (and sharing information?)","<python><tkinter>","1","4","908"
"49052472","2018-03-01 15:00:26","0","","<p>Because <code>Restaurant</code>, indeed, does not have an attribute <code>flavours</code>; <code>IceCreamStand</code> does, or at least did, until you replaced that class with an instance of <code>Restaurant</code> with <code>IceCreamStand = Restaurant(...)</code>.</p>

<p>Use a different variable name (camel-case for class names, snake-case with initial lowercase for objects), and create an instance of <code>IceCreamStand</code>.</p>

<pre><code>ice_cream_stand = IceCreamStand(' Matt IceCream ', 'ice creams')
</code></pre>
","1126841","","","0","533","chepner","2012-01-02 21:41:39","295038","14033","16849","5091","49052359","49052472","2018-03-01 14:54:31","0","115","<pre><code>## class restaurant ##
</code></pre>

<blockquote>
  <p>Implemented superclass </p>
</blockquote>

<pre><code>class Restaurant():
def __init__(self, restaurant_name, cuisine_type):
    self.restaurant_name = restaurant_name
    self.cuisine_type = cuisine_type 
def describe_restaurant(self):
    print('This restaurant is called ' + self.restaurant_name + '.')
    print('This restaurant serves dishes acoording to ' + self.cuisine_type + '.')
def open_restaurant(self, hours):
    self.hours = hours
    print(self.restaurant_name.title() + ' is opened ' + str(hours) + '!')

class IceCreamStand(Restaurant):
def __init__(self, restaurant_name, cuisine_type):
    super().__init__(restaurant_name, cuisine_type)
    self.restaurant_name = restaurant_name
    self.cuisine_type = cuisine_type
    flavours = ['chocolate', 'vanilia', 'strawberry', 'lime', 'orange']
def flavours(self):
    print('Available flavours: ')
    for flavour in flavours:
        print(flavour)
IceCreamStand  = Restaurant(' Matt IceCream ', 'ice creams')
IceCreamStand.describe_restaurant()
IceCreamStand.flavours()
</code></pre>
","9423744","1126841","2018-03-01 14:58:17","AttributeError: 'Restaurant' object has no attribute 'flavours' - why?","<python><class><attributeerror>","1","2","1119"
"49052476","2018-03-01 15:00:34","1","","<pre><code>## Open the files (and close them after the 'with' block ends)
with open(""Input.fastq"", ""r"") as fq, open(""Input.fasta"", ""r"") as fa:

    ## Read in the Input.fastq file and save its content to a list
    fastq = fq.readlines()

    ## Do the same for the Input.fasta file
    fasta = fa.readlines()


## For every line in the Input.fastq file
for i in range(len(fastq)):
    print(fastq[i]))
    print(fasta[2 * i])
    print(fasta[(2 * i) + 1])
</code></pre>
","7908770","7908770","2018-03-01 15:06:45","4","471","Adi219","2017-04-23 09:50:18","3109","540","642","43","49052163","49052433","2018-03-01 14:44:36","1","315","<p>I am trying to use python to find four-line blocks of interest in two separate files then print out some of those lines in controlled order.  Below are the two input files and an example of the desired output file.  Note that the DNA sequence in the Input.fasta is different than the DNA sequence in Input.fastq because the .fasta file has been read corrected.</p>

<p>Input.fasta</p>

<pre><code>&gt;read1
AAAGGCTGT
&gt;read2
AGTCTTTAT
&gt;read3
CGTGCCGCT
</code></pre>

<p>Input.fastq</p>

<pre><code>@read1
AAATGCTGT
+
'(''%$'))
@read2
AGTCTCTAT
+
&amp;---+2010
@read3
AGTGTCGCT
+
0-23;:677
</code></pre>

<p>DesiredOutput.fastq</p>

<pre><code>@read1
AAAGGCTGT
+
'(''%$'))
@read2
AGTCTTTAT
+
&amp;---+2010
@read3
CGTGCCGCT
+
0-23;:677
</code></pre>

<p>Basically I need the sequence line ""AAAGGCTGT"", 
""AGTCTTTAT"", and ""CGTGCCGCT"" from ""input.fasta"" and all other lines from ""input.fastq"". This allows the restoration of quality information to a read corrected .fasta file.</p>

<p>Here is my closest failed attempt:</p>

<pre><code>fastq = open(Input.fastq, ""r"")
fasta = open(Input.fasta, ""r"")

ReadIDs = []
IDs = []

with fastq as fq:
    for line in fq:
        if ""read"" in line:  
            ReadIDs.append(line)
            print(line.strip())
            for ID in ReadIDs:
                IDs.append(ID[1:6])
            with fasta as fa:
                for line in fa:
                    if any(string in line for string in IDs):
                        print(next(fa).strip())
            next(fq)
            print(next(fq).strip())
            print(next(fq).strip())
</code></pre>

<p>I think I am running into trouble by trying to nest ""with"" calls to two different files in the same loop.  This prints the desired lines for read1 correctly but does not continue to iterate through the remaining lines and throws an error ""ValueError: I/O operation on closed file""</p>
","6749238","6260170","2018-03-02 17:06:39","in python loop print lines from alternating files","<python><bioinformatics><biopython><fasta><fastq>","3","3","1893"
"49052502","2018-03-01 15:01:36","1","","<p>I will using <code>median</code> base on index level=0+ <code>value_counts</code></p>

<pre><code>pd.concat([df.set_index('type').median(level=0),df.type.value_counts()],1)
Out[787]: 
      size  margin  height  type
type                            
A      2.5     4.5     1.0     2
B      1.0     1.0     3.0     1
</code></pre>
","7964527","","","0","333","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49052311","49052366","2018-03-01 14:51:37","1","375","<p>I have this dataframe:</p>

<pre><code>df:
      type . size .  margin .  height
0 .      A .    2 .       5 .       1
1 .      A .    3 .       4 .       1
2 .      B .    1 .       1 .       3 
</code></pre>

<p>I want to groupby type, count the number of companies in each type and calculate the medians for all columns.</p>

<p>I know that for count is like this</p>

<pre><code>df=df.groupby('type').count('type')
</code></pre>

<p>But is there a way to use a one liner and put everything in the same df?</p>

<p>Something like:</p>

<pre><code>df=df.groupby('type').calculate_medians_and_counts
</code></pre>

<p>It should come out looking like this:</p>

<pre><code>type    count   size   margin   height
   A        2    2.5      4.5        1
   B        1      1        1        3

(size, margin and height are the medians from df)
</code></pre>
","5606352","472495","2018-03-05 13:56:21","Groupby, count and calculate medians in Pandas","<python><pandas><pandas-groupby>","2","1","858"
"49052507","2018-03-01 15:01:44","2","","<p>I'm not an expert in python but from what i Know method can be
used as object so i think this will work.</p>

<pre class=""lang-py prettyprint-override""><code>    from openerp.addons.account_financial_report_webkit.report.common_reports \
        import CommonReportHeaderWebkit

    # first keep reference to the original method before you lose it.
    _super_is_initial_balance_enabled = CommonReportHeaderWebkit.is_initial_balance_enabled

    def is_initial_balance_enabled(self, main_filter):
        # execute it like super
        return _super_is_initial_balance_enabled(self, main_filter)

    CommonReportHeaderWebkit.is_initial_balance_enabled = is_initial_balance_enabled
</code></pre>
","6089852","","","2","700","Charif DZ","2016-03-20 15:02:36","11309","1651","903","46","49048167","49052507","2018-03-01 10:57:30","3","284","<p>I have to modify a method in Odoo. The problem is that the class which contains the method is not declared as usual (it's not using the Odoo API), so I don't know how to emulate the <code>_inherit</code> parameter of the Odoo API.</p>

<p>This is the class which contains the method (the module is <code>account_financial_report_webkit</code>, from OCA):</p>

<pre><code>...
from openerp.addons.account.report.common_report_header \
    import common_report_header

class CommonReportHeaderWebkit(common_report_header):
    ...
</code></pre>

<p>And the method I want to modify is this one (it's inside <code>CommonReportHeaderWebkit</code> class):</p>

<pre><code>def is_initial_balance_enabled(self, main_filter):
    if main_filter not in ('filter_no', 'filter_year', 'filter_period'):
        return False
    return True
</code></pre>

<p>To overwrite it, I did monkey patching in my custom module:</p>

<pre><code>from openerp.addons.account_financial_report_webkit.report.common_reports \
    import CommonReportHeaderWebkit

def is_initial_balance_enabled(self, main_filter):
    if main_filter not in ('filter_no', 'filter_date', 'filter_period'):
        return False
    return True

CommonReportHeaderWebkit.is_initial_balance_enabled = is_initial_balance_enabled
</code></pre>

<p>This is working OK, but the problem is this way I'm overwriting the whole method and I would like to use <code>super</code>, because now I have to do the same with other method and I can't overwrite its whole code.</p>

<p>Does anyone know how to this in a right way?</p>
","2886640","2886640","2018-03-01 11:05:48","How to inherit from a pure Python class in Odoo to modify a method?","<python><python-2.7><odoo-8><odoo>","1","0","1569"
"49052552","2018-03-01 15:03:39","0","","<p>For list with <code>str</code>:</p>

<pre><code>x = ['a','c','e']
str1 = ''.join(x)
</code></pre>

<p>For list with <code>int</code>:</p>

<pre><code>x = [1,2,3]
str1=''.join(str(y) for y in x)
</code></pre>

<p>This should work for you.</p>
","9354049","9354049","2018-03-01 15:07:19","2","245","Shubhitgarg","2018-02-13 09:21:41","545","107","10","36","49052479","","2018-03-01 15:00:35","-3","42","<p>okay so after a lot of searching i decided to ask the question i've tried doing print[0] but i got the error</p>

<pre><code>Traceback (most recent call last):
</code></pre>

<p>File """", line 1, in 
    print[0]
TypeError: 'builtin_function_or_method' object is not subscriptable</p>

<pre><code> ['a', 'c', 'e']
[1, 3, 5]
</code></pre>

<p>these are my 2 outputs i want to remove the commas and the inverted commas and make it look like</p>

<pre><code>ace
135
</code></pre>
","9429401","","","How do I strip commas, brackets in shell","<python><python-3.x>","3","0","479"
"49052567","2018-03-01 15:04:37","3","","<pre><code>with open('test.txt', 'r') as f:
    for line in f.readlines():
        if ':' in line:
            # Remove
        else:
            # Keep
</code></pre>
","7295475","7295475","2018-03-01 15:21:28","5","167","Kyrylo","2016-12-14 08:48:47","368","29","11","2","49052446","49052580","2018-03-01 14:58:44","0","195","<p>I have code that will remove a string from a file if the string contains <code>:</code> at the <strong>start</strong> of the string. </p>

<pre><code>with open(""test1.txt"") as the_file:
    for each_line in the_file:
        each_line = "" "".join(filter(lambda x:x[0]!=':', each_line.split()))
        print(each_line)
</code></pre>

<p>What is the correct expression to remove the string if it contains <code>:</code> <strong>anywhere</strong> in the string?</p>

<p>For example if the file contains <code>:raining, raining:, rai:ning</code>, It will only remove <code>:raining</code>. I want to remove all of these words from the file.</p>
","8939405","6101071","2018-03-01 15:11:47","Python Regex - remove words containing "":"" from file","<python><regex><python-3.x><regex-negation>","2","0","644"
"49052572","2018-03-01 15:04:45","3","","<p>In Python 3.6+ you can use the class-level type hints - these would not generate attributes in the class. I.e.</p>

<pre><code>class Request(_Request):
    user: Optional[User]
</code></pre>

<p>This would not create an attribute in the class, only an annotation.</p>

<pre><code>&gt;&gt;&gt; Request.user
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
AttributeError: type object 'Request' has no attribute 'user'

&gt;&gt;&gt; Request.__annotations__
{'user': typing.Union[foo.User, NoneType]}
</code></pre>

<p>In Python 3.5 it is possible to make a function that returns a non-data descriptor (i.e. a descriptor <strong>without</strong> <code>__set__</code>); this would be overridable by an instance attribute but it comes with <em>some minimal</em> runtime overhead - the descriptor will be fetched from <code>__dict__</code> and checked if it defines the <code>__set__</code> slot - even for all reads. It could then look something like</p>

<pre><code>class Request(_Request):
    user = typed(User)
</code></pre>

<p>where the <code>typed</code> is defined as</p>

<pre><code>def typed(type: Type[T]) -&gt; T:
    ... return a dummy non-data-descriptor...
</code></pre>

<p>This should be enough for PyCharm to infer the types correctly.</p>
","918959","","","0","1292","Antti Haapala","2011-08-30 04:12:50","95962","18212","5184","12430","34230618","49052572","2015-12-11 18:55:32","9","1394","<p>I'd like to add Python 3.5 type hints for dynamically generated object attributes, so that IDEs correctly autocomplete them. Here by ""dynamical"" I mean that the attribute is not present during class creation or in <code>__init__</code> or any other method.</p>

<p>E.g. is there a way to add these through comments or other tricks? If not I can fallback to add dummy class attributes.</p>

<p>Example::</p>

<pre><code> class Request:
      """"""Example HTTP request object.

      We have `get_user()`  but we do not declare it anyhere.
      """"""

 ...


 # Pyramid's way of plugging in methods and properties to request, enabled addon capabilities for the framework
 # adds Request.user - done in different part of application lifecycle, not during class creation
 config.add_request_method(auth.get_user, 'user', reify=True)
</code></pre>

<p>The goal is to make this work so that PyCharm and other IDEs would complete this attribute.</p>
","315168","","","Python 3.5 type hinting dynamically generated instance attributes","<python><pycharm><python-3.5>","2","1","943"
"49052580","2018-03-01 15:05:06","1","","<p>This might help. Removes all string which has <code>"":""</code> in it. </p>

<pre><code>a = "":raining, raining:, rai:ning  aaaaaaa""
def removeStr(val):
    if "":"" not in val:
        return val

each_line = "" "".join(filter(removeStr, a.split()))
print each_line
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>aaaaaaa
</code></pre>
","532312","","","1","345","Rakesh","2010-12-06 13:07:54","56694","5302","758","1508","49052446","49052580","2018-03-01 14:58:44","0","195","<p>I have code that will remove a string from a file if the string contains <code>:</code> at the <strong>start</strong> of the string. </p>

<pre><code>with open(""test1.txt"") as the_file:
    for each_line in the_file:
        each_line = "" "".join(filter(lambda x:x[0]!=':', each_line.split()))
        print(each_line)
</code></pre>

<p>What is the correct expression to remove the string if it contains <code>:</code> <strong>anywhere</strong> in the string?</p>

<p>For example if the file contains <code>:raining, raining:, rai:ning</code>, It will only remove <code>:raining</code>. I want to remove all of these words from the file.</p>
","8939405","6101071","2018-03-01 15:11:47","Python Regex - remove words containing "":"" from file","<python><regex><python-3.x><regex-negation>","2","0","644"
"49052581","2018-03-01 15:05:09","0","","<p>I just learned, inspired from <a href=""https://www.scivision.co/install-pip-in-cygwin/"" rel=""nofollow noreferrer"">https://www.scivision.co/install-pip-in-cygwin/</a> and the answer before, that instead of using pip, you just have to use pip2 for python2 or pip3 for python 3 in cygwin on windows. Wondered about this the whole day...</p>
","7435224","","","0","341","DanielW","2017-01-18 10:57:12","1","0","0","0","18641438","32027563","2013-09-05 16:24:59","82","76002","<p>I have Python 3 installed on Cygwin. However, I am unable to install Python 3 packages via <code>pip</code>. Is there a way to do this?</p>
","2317459","","","Installing Pip-3.2 on Cygwin","<python><python-3.x><cygwin><pip>","6","5","143"
"49052660","2018-03-01 15:09:03","0","","<pre><code>''.join(a)
print ''.join(a)
</code></pre>

<p>And for the integer list [1,3,5] first change elements to strings using:</p>

<pre><code>map(lambda x: str(x), [1,3,5])
</code></pre>

<p>and then issue the same line as the first. Then you can change back to int if you wish.</p>
","5401731","","","0","287","rbs","2015-10-02 14:28:26","54","11","9","0","49052479","","2018-03-01 15:00:35","-3","42","<p>okay so after a lot of searching i decided to ask the question i've tried doing print[0] but i got the error</p>

<pre><code>Traceback (most recent call last):
</code></pre>

<p>File """", line 1, in 
    print[0]
TypeError: 'builtin_function_or_method' object is not subscriptable</p>

<pre><code> ['a', 'c', 'e']
[1, 3, 5]
</code></pre>

<p>these are my 2 outputs i want to remove the commas and the inverted commas and make it look like</p>

<pre><code>ace
135
</code></pre>
","9429401","","","How do I strip commas, brackets in shell","<python><python-3.x>","3","0","479"
"49052682","2018-03-01 15:10:06","1","","<p>You cannot make the assignment <code>label[i] = something</code> because it doesn't exist.
Use <code>.append()</code> instead</p>

<pre><code>label = []
for i in range(23411):
    if ageNew[i] &lt;= 7:
        res = 0
    elif ageNew[i] &lt;= 42:
        res = 1
    else:
        res = 2
    label.append(res)
</code></pre>
","4948165","4948165","2018-03-01 15:11:06","0","328","Eran Moshe","2015-05-28 08:26:52","1614","193","153","9","49052612","49052682","2018-03-01 15:06:59","0","62","<p>I have an empty list called 'label', where depending on which bucket is more appropriate, it will fill the 'label' list with 0,1,or 2. </p>

<p>'label' is associated to the 3 'buckets':</p>

<pre><code># Bucket 0: 0 -7 Days --------------------------&gt; 0
# Bucket 1: 1 - 6 Weeks (8 - 42 Days) ----------&gt; 1
# Bucket 2: 7+ Weeks (49+ Days) ----------------&gt; 2
</code></pre>

<p>I have another list has a length of 23411. This list's contents consist of 0 days to 1099 days. So based on this list's contents, it should populate the 'label' list. </p>

<p>I have tried this <code>for-loop</code> &amp; <code>if-else</code> statement to do what I want, however it is giving me a <code>IndexError: list assignment index out of range</code>:</p>

<pre><code>label = []
for i in range(23411):
    if ageNew[i] &lt;= 7:
        label[i] = 0
    elif ageNew[i] &lt;= 42:
        label[i] = 1
    else:
        label[i] = 2
</code></pre>

<p>For example:</p>

<pre><code>list: [0, 8, 14, 14, 45, 1056, 1]
label: [0, 1, 1, 1, 2, 2, 0]
</code></pre>
","8778033","8778033","2018-03-01 15:36:35","Making a list based on a criteria of another list","<python><list><for-loop><if-statement>","5","2","1049"
"49052705","2018-03-01 15:11:11","1","","<p>Your list is empty so <code>[i]</code> won't work the way you expecting because that index does not exist. What about:</p>

<pre><code>label = []
for i in range(23411):
    val = None
    if ageNew[i] &lt;= 7:
        val = 0
    elif ageNew[i] &lt;= 42:
        val = 1
    else:
        val = 2
    label.append(val)
</code></pre>

<p>This should work.</p>
","5395497","","","0","362","Pierluigi","2015-10-01 01:14:19","318","63","4","1","49052612","49052682","2018-03-01 15:06:59","0","62","<p>I have an empty list called 'label', where depending on which bucket is more appropriate, it will fill the 'label' list with 0,1,or 2. </p>

<p>'label' is associated to the 3 'buckets':</p>

<pre><code># Bucket 0: 0 -7 Days --------------------------&gt; 0
# Bucket 1: 1 - 6 Weeks (8 - 42 Days) ----------&gt; 1
# Bucket 2: 7+ Weeks (49+ Days) ----------------&gt; 2
</code></pre>

<p>I have another list has a length of 23411. This list's contents consist of 0 days to 1099 days. So based on this list's contents, it should populate the 'label' list. </p>

<p>I have tried this <code>for-loop</code> &amp; <code>if-else</code> statement to do what I want, however it is giving me a <code>IndexError: list assignment index out of range</code>:</p>

<pre><code>label = []
for i in range(23411):
    if ageNew[i] &lt;= 7:
        label[i] = 0
    elif ageNew[i] &lt;= 42:
        label[i] = 1
    else:
        label[i] = 2
</code></pre>

<p>For example:</p>

<pre><code>list: [0, 8, 14, 14, 45, 1056, 1]
label: [0, 1, 1, 1, 2, 2, 0]
</code></pre>
","8778033","8778033","2018-03-01 15:36:35","Making a list based on a criteria of another list","<python><list><for-loop><if-statement>","5","2","1049"
"49052711","2018-03-01 15:11:24","1","","<p>The problem is because a variable that is created within a function only exists as long as the function is executed and the elimination of <code>downloader</code> will also eliminate the thread. For this there are 2 solutions:</p>

<ul>
<li>Make a <code>downloader</code> member of the class:</li>
</ul>

<hr>

<pre><code>def start_download(self):
    print(""AAAA"")
    self.downloader = Job(""http://www.baidu.com"")
    print(""BBB"")
    self.downloader.data_downloaded.connect(self.update_download_process)
    print(""ccc"")
    self.downloader.start()
    print(""ddd"")
</code></pre>

<ul>
<li>Pass a parent to Job:</li>
</ul>

<hr>

<pre><code>class Job(QThread):
    data_downloaded = pyqtSignal(str)

    def __init__(self, url, parent=None):
        QThread.__init__(self, parent)

    [...]


class SearchWindow(QWidget):
    [...]
    def start_download(self):
        print(""AAAA"")
        downloader = Job(""http://www.baidu.com"", self)
        print(""BBB"")
        downloader.data_downloaded.connect(self.update_download_process)
        print(""ccc"")
        downloader.start()
        print(""ddd"")
</code></pre>
","6622587","","","1","1123","eyllanesc","2016-07-21 23:29:11","114264","27275","2584","21000","49048136","49052711","2018-03-01 10:56:02","0","194","<p>Can somebody help me out, app just crashes.</p>

<p>I've done the research and found <a href=""https://stackoverflow.com/questions/46677940/pyqt5-cannot-update-progress-bar-from-thread-and-received-the-error-cannot-crea"">this</a>
and below is my code:</p>

<pre><code>from PyQt5.QtCore import QThread, pyqtSignal
import threading
import time

class Job(QThread):
    data_downloaded = pyqtSignal(str)

    def __init__(self, url):
        QThread.__init__(self)
        # self.__flag = threading.Event()
        # self.__flag.set()
        # self.__running = threading.Event()
        # self.__running.set()


    def run(self):
        for i in range(100):
            self.data_downloaded.emit(""B"")  # 朝connect的函数发射一个进度信号
            time.sleep(1)

    # def pause(self):
    #     self.__flag.clear()     # 设置为False, 让线程阻塞
    #
    # def resume(self):
    #     self.__flag.set()    # 设置为True, 让线程停止阻塞
    #
    # def stop(self):
    #     self.__flag.set()       # 将线程从暂停状态恢复, 如何已经暂停的话
    #     self.__running.clear()        # 设置为False
</code></pre>

<p>Main window:</p>

<pre><code>from xxx import Job 
class SearchWindow(QWidget):
    ......
    ...... # There's a QTableWidget on main window, after right clicked ""Start Download"", Job will be created 
    ......

    def right_click_from_download_list_context(self):
        row_num = []
        for i in self.download_list.selectionModel().selection().indexes():
            row_num.append(i.row())
        popMenu = QMenu(self)
        self.start_download_action = QAction('Start Download', self)
        self.remove_task_action = QAction('删除此任务', self)
        self.start_download_action.triggered.connect(self.start_download)
        self.remove_task_action.triggered.connect(partial(self.remove_task, row_num))
        popMenu.addAction(self.start_download_action)
        popMenu.addAction(self.remove_task_action)
        popMenu.exec_(QCursor.pos())

    def start_download(self):
        print(""AAAA"")
        downloader = Job(""http://www.baidu.com"")
        print(""BBB"")
        downloader.data_downloaded.connect(self.update_download_process)
        print(""ccc"")
        downloader.start()
        print(""ddd"")

    @pyqtSlot(str)
    def update_download_process(self, data_process):
        print(data_process)
</code></pre>

<p>I've done some debugging, ""AAAA"",""BBB"",""ccc"",""ddd"" can be successfully print out, so I guess the error is in my Job QThread.</p>

<p>Can someone do me a favor, I just can NOT find where can be the error. Thanks in advance :)</p>
","5541297","6622587","2018-03-01 15:06:39","PyQt5 - update Qtablewidget with QThread","<python><pyqt><pyqt5><qthread><qtablewidget>","1","0","2533"
"49052715","2018-03-01 15:11:34","0","","<p>Try this:</p>

<pre><code>label = []
for i in lists:
    if i &lt;= 7:
        label.append(0)
    elif i &gt;= 8 and i &lt;= 42:
        label.append(1)
    else:
        label.append(2)
#output
[0, 1, 1, 1, 2, 2, 2, 0]
</code></pre>

<p>label</p>
","9299259","","","0","252","YOLO","2018-02-01 10:14:21","6163","703","352","26","49052612","49052682","2018-03-01 15:06:59","0","62","<p>I have an empty list called 'label', where depending on which bucket is more appropriate, it will fill the 'label' list with 0,1,or 2. </p>

<p>'label' is associated to the 3 'buckets':</p>

<pre><code># Bucket 0: 0 -7 Days --------------------------&gt; 0
# Bucket 1: 1 - 6 Weeks (8 - 42 Days) ----------&gt; 1
# Bucket 2: 7+ Weeks (49+ Days) ----------------&gt; 2
</code></pre>

<p>I have another list has a length of 23411. This list's contents consist of 0 days to 1099 days. So based on this list's contents, it should populate the 'label' list. </p>

<p>I have tried this <code>for-loop</code> &amp; <code>if-else</code> statement to do what I want, however it is giving me a <code>IndexError: list assignment index out of range</code>:</p>

<pre><code>label = []
for i in range(23411):
    if ageNew[i] &lt;= 7:
        label[i] = 0
    elif ageNew[i] &lt;= 42:
        label[i] = 1
    else:
        label[i] = 2
</code></pre>

<p>For example:</p>

<pre><code>list: [0, 8, 14, 14, 45, 1056, 1]
label: [0, 1, 1, 1, 2, 2, 0]
</code></pre>
","8778033","8778033","2018-03-01 15:36:35","Making a list based on a criteria of another list","<python><list><for-loop><if-statement>","5","2","1049"
"49052747","2018-03-01 15:12:56","0","","<p>Some things to note:</p>

<ul>
<li><p>contrary to how <code>vis</code> is passed as argument and needs to maintain its state throughout the recursive search, this is not how <code>path</code> should work: it should be a local variable that only takes the return value from the recursive call and prepends the current cell (<code>start</code>) to it.</p></li>
<li><p><code>vis</code> should not be a <code>deque</code>, but a <code>set</code>, which is more suitable for quickly knowing whether a cell was visited before.</p></li>
</ul>

<p>Here is how you could code it:</p>

<pre><code>def pathsolve(self, start, end, vis=set()):
    z=self.__getitem__(start)
    x,y=start
    if start == end:
        return [end]
    if start in vis or z==0:
        return None
    vis.add(start)
    for step in [(x+z,y),(x-z,y),(x,y+z),(x,y-z)]:
        if self.onboard(step):
            path=self.pathsolve(step, end, vis)
            if path: # prepend current cell to the path that was found
                return [start] + path
    return None # None of the possible directions led to the end point.
</code></pre>

<p>This assumes of course that your other methods are well implemented.</p>

<p>See it run on <a href=""https://repl.it/@trincottrincots/MazeWithoutWalls"" rel=""nofollow noreferrer"">repl.it</a>.</p>

<p>For the following maze:</p>

<pre><code>[
    [1,1,2,0,0],
    [3,1,0,1,3],
    [1,0,2,0,2]
]
</code></pre>

<p>...and starting at the lower-left corner, targetting the top-right corner, it gives this path of (x, y) coordinates (x = column, y = row):</p>

<pre><code>[(0, 2), (0, 1), (3, 1), (4, 1), (1, 1), (1, 0), (2, 0), (4, 0)]
</code></pre>
","5459839","5459839","2018-03-01 15:24:43","1","1661","trincot","2015-10-18 15:19:14","146082","12359","1531","1712","49051378","49052747","2018-03-01 14:03:38","1","50","<p>I've been working on this for a while, this is what I've got so far... this code doesn't work. This code is just for reference. The assignment is a maze without walls. I have to use a recursive algorithm.  Each space has a number, when I land on a space, that number tells me how much I can move in a specific direction. I have to return the path. (I already did the version where I return True or False if there is a solution.) I can't seem to return the path itself. </p>

<pre><code>def pathsolve(self, start, end, vis=None):


    z=self.__getitem__(start)
    x,y=start




    b=False

    if path==None:
        path=deque()

    if vis==None:
        vis=deque()

    if start == end:
        vis.appendleft(start)
        return True
    elif start in path:
        return False
    elif z==0:
        return False
    else:
        #visited.add(start)
        path.append(start)


        if self.onboard((x+z,y)) and (x+z,y) not in path:
            #print(""going to""+str((x+z,y))+"" by ""+str(z)+"" from ""+str    (start))
            b=self.pathsolve((x+z,y),end, path)

            #print()
        if self.onboard((x,y+z)) and (x,y+z) not in path and b == False:
            #print(""xgoing to""+str((x,y+z))+"" by ""+str(z)+"" from ""+str(start))
            b=self.pathsolve((x,y+z),end, path)

            #print()
        if self.onboard((x,y-z)) and (x,y-z) not in path and b == False:
            #print(""ygoing to""+str((x,y-z))+"" by ""+str(z)+"" from ""+str(start))
            #print(self.onboard((x,y-z)))
            b=self.pathsolve((x,y-z),end, path)
            #print(path)
        if self.onboard((x-z,y)) and (x-z,y) not in path and b == False:
            #print(""zgoing to""+str((x-z,y))+"" by ""+str(z)+"" from ""+str(start))
            #print(end)
            b=self.pathsolve((x-z,y),end, path)

       # if b==True and start is not  
            vis.appendleft(start)
    return b
</code></pre>
","9424435","9424435","2018-03-01 14:38:33","Can't seem to create recursive algorithm for wallless maze","<python><recursion><maze>","1","0","1918"
"49052755","2018-03-01 15:13:24","0","","<p>Yes <code>BIGDL</code> is actively maintained. The proper way to define a bigdl model is by using <code>sequential API</code> or <code>functional API</code>.<br>
Sequential API</p>

<pre><code>model = Sequential()
model.add(Linear(...))
model.add(Sigmoid())
model.add(Softmax())  
</code></pre>

<p>Functional API</p>

<pre><code>linear = Linear(...)()
sigmoid = Sigmoid()(linear)
softmax = Softmax()(sigmoid)
model = Model([linear], [softmax])
</code></pre>

<p>see <a href=""https://bigdl-project.github.io/0.4.0/#ProgrammingGuide/Model/Sequential/"" rel=""nofollow noreferrer"">here</a>.</p>
","4117331","","","1","594","ashwinids","2014-10-07 13:18:45","2097","134","447","13","49039294","","2018-02-28 21:58:57","0","185","<p>Running BigDL example at: <a href=""https://bigdl-project.github.io/0.4.0/#ProgrammingGuide/optimization/"" rel=""nofollow noreferrer"">https://bigdl-project.github.io/0.4.0/#ProgrammingGuide/optimization/</a> in PySpark local node: </p>

<pre><code>from bigdl.nn.layer import Linear
from bigdl.util.common import *
from bigdl.nn.criterion import MSECriterion
from bigdl.optim.optimizer import Optimizer, MaxIteration
import numpy as np

sc = SparkContext(appName=""simple"",conf=create_spark_conf())
init_engine()

model = Linear(2, 1)
samples = [
  Sample.from_ndarray(np.array([5, 5]), np.array([2.0])),
  Sample.from_ndarray(np.array([-5, -5]), np.array([-2.0])),
  Sample.from_ndarray(np.array([-2, 5]), np.array([1.3])),
  Sample.from_ndarray(np.array([-5, 2]), np.array([0.1])),
  Sample.from_ndarray(np.array([5, -2]), np.array([-0.1])),
  Sample.from_ndarray(np.array([2, -5]), np.array([-1.3]))
]

train_data = sc.parallelize(samples, 1)
optimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4)
optimizer.optimize()
model.get_weights()[0]
</code></pre>

<p>Results in the following exception. Other then BigDL tests work in PySpark. Environment: openjdk version ""1.8.0_141, Python 3.5.3 (default, Jan 19 2017, 14:11:04) 
[GCC 6.3.0 20170118] on linux </p>

<p>Any ideas? Is BigDL a live project, actively maintained?  </p>

<pre><code>Setting default log level to ""WARN"".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
    2018-02-28 22:40:20 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-02-28 22:40:20 WARN  Utils:66 - Your hostname, dk resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
2018-02-28 22:40:20 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2018-02-28 22:40:24 WARN  SparkContext:66 - Using an existing SparkContext; some configuration may not take effect.
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
                                                                                                                                                                                                                                                                                                                                                                        /usr/local/lib/python3.5/dist-packages/bigdl/util/engine.py:41: UserWarning: Find both SPARK_HOME and pyspark. You may need to check whether they match with each other. SPARK_HOME environment variable is set to: /opt/spark, and pyspark is found in: /usr/local/lib/python3.5/dist-packages/pyspark/__init__.py. If they are unmatched, please use one source only to avoid conflict. For example, you can unset SPARK_HOME and use pyspark only.
warnings.warn(warning_msg)
Prepending /usr/local/lib/python3.5/dist-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
creating: createLinear
creating: createMSECriterion
creating: createMaxIteration
creating: createDefault
creating: createSGD
creating: createDistriOptimizer
Traceback (most recent call last):
  File ""simple.py"", line 22, in &lt;module&gt;
    optimizer.optimize()
  File ""/usr/local/lib/python3.5/dist-packages/bigdl/optim/optimizer.py"", line 591, in optimize
    jmodel = callJavaFunc(get_spark_context(), self.value.optimize)
  File ""/usr/local/lib/python3.5/dist-packages/bigdl/util/common.py"", line 590, in callJavaFunc
    result = func(*args)
  File ""/usr/local/lib/python3.5/dist-packages/py4j/java_gateway.py"", line 1133, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File ""/usr/local/lib/python3.5/dist-packages/py4j/protocol.py"", line 319, in get_return_value
    format(target_id, ""."", name), value)
py4j.protocol.Py4JJavaError: An error occurred while calling o48.optimize.
: java.lang.ExceptionInInitializerError
    at com.intel.analytics.bigdl.optim.DistriOptimizer.optimize(DistriOptimizer.scala:860)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
    at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
    at py4j.Gateway.invoke(Gateway.java:280)
    at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    at py4j.commands.CallCommand.execute(CallCommand.java:79)
    at py4j.GatewayConnection.run(GatewayConnection.java:214)
    at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException
    at java.util.concurrent.ThreadPoolExecutor.&lt;init&gt;(ThreadPoolExecutor.java:1314)
    at java.util.concurrent.ThreadPoolExecutor.&lt;init&gt;(ThreadPoolExecutor.java:1237)
    at java.util.concurrent.Executors.newFixedThreadPool(Executors.java:151)
    at com.intel.analytics.bigdl.parameters.AllReduceParameter$.&lt;init&gt;(AllReduceParameter.scala:47)
    at com.intel.analytics.bigdl.parameters.AllReduceParameter$.&lt;clinit&gt;(AllReduceParameter.scala)
    ... 12 more
</code></pre>
","1226649","1016128","2019-04-07 12:49:02","Simple PySpark BigDL test: Optimizer fails","<python><apache-spark><pyspark><bigdl>","1","0","5802"
"49052759","2018-03-01 15:13:29","1","","<p>The c3d library I suppose you use(<a href=""https://pypi.python.org/pypi/c3d/0.2.1"" rel=""nofollow noreferrer"">https://pypi.python.org/pypi/c3d/0.2.1</a>) includes a script for converting C3D data to CSV format (c3d2csv).</p>
","3211950","","","4","227","enneppi","2014-01-19 11:07:09","494","86","218","3","49052588","49052759","2018-03-01 15:05:25","2","738","<p>Hi i have a project were the user uploads a .c3d file to be able to display the data on charts, so i am making it for when the user uploads a the file it gets converted into a .csv file so i can get the values but i am having no luck trying to convert from the .c3d file to the .csv extension. </p>

<p>i have used the following documentation <a href=""http://c3d.readthedocs.io/en/stable/"" rel=""nofollow noreferrer"">http://c3d.readthedocs.io/en/stable/</a> </p>

<p>but there much isn't much information on this out there </p>

<p>this is the following code i use to print the data:</p>

<pre><code>import c3d

reader = c3d.Reader(open('file.c3d', 'rb'))
     for i, points, analog in reader.read_frames():
     print('frame {}: {}'.format(i, points.round(2)))
</code></pre>
","8996762","","","How to convert from c3d file to csv","<python><csv><numpy>","1","0","778"
"49052762","2018-03-01 15:13:38","2","","<p><code>workspace.xml</code> should not be added to Git at all. To remove it now, please ask your partner to run <code>git rm --cached .idea/workspace.xml</code> and then commit this change.</p>

<p>For <code>vcs.xml</code>, you can simply delete your own copy of this file before you run the update. It will be replace with a copy from the repository, which will have the same contents.</p>
","147024","","","0","393","yole","2009-07-29 11:24:12","67090","5745","427","349","49052653","49052762","2018-03-01 15:08:57","0","379","<p>Currently I'm working on a project via bitbucket with a partner, I was recently trying to go with <code>git checkout develop</code> but then an error occured:</p>

<pre><code>C:\Users\xx\IdeaProjects\x&gt;git checkout develop
error: Your local changes to the following files would be overwritten by checkout:
    .idea/workspace.xml
Please commit your changes or stash them before you switch branches.
error: The following untracked working tree files would be overwritten by checkout:
    .idea/vcs.xml
Please move or remove them before you switch branches.
Aborting
</code></pre>

<p>I tried to just do it and I tried to solve the problem using ""git stash save"" but nothing seems to work. On my partners work the error doesn't show up and he's able to move forward with our project but I'm not sure how to solve this problem. I hope someone is gonna be able to help me with this, since I don't even know why the error occurs.</p>
","6362437","7295475","2018-03-01 15:16:42","Error switching branches in intellij concerning .idea files","<python><git><intellij-idea><bitbucket>","1","4","935"
"49052847","2018-03-01 15:17:56","0","","<p>Just in case you actually want <code>numpy</code>:</p>

<pre><code>import numpy as np
x=np.array((12,32,54,1,2,43,4))
res=np.zeros(x.shape)
res[x&lt;=3] = 0
res[np.logical_and(x&gt;3,x&lt;=10)] = 1
res[x&gt;10] = 2
print(res)
array([ 2.,  2.,  2.,  0.,  0.,  2.,  1.])
</code></pre>

<p>You can convert your list to a <code>numpy</code> array using:</p>

<pre><code>x=np.array(your_list)
</code></pre>
","6881240","","","0","405","kabanus","2016-09-26 08:52:21","14417","1159","910","577","49052612","49052682","2018-03-01 15:06:59","0","62","<p>I have an empty list called 'label', where depending on which bucket is more appropriate, it will fill the 'label' list with 0,1,or 2. </p>

<p>'label' is associated to the 3 'buckets':</p>

<pre><code># Bucket 0: 0 -7 Days --------------------------&gt; 0
# Bucket 1: 1 - 6 Weeks (8 - 42 Days) ----------&gt; 1
# Bucket 2: 7+ Weeks (49+ Days) ----------------&gt; 2
</code></pre>

<p>I have another list has a length of 23411. This list's contents consist of 0 days to 1099 days. So based on this list's contents, it should populate the 'label' list. </p>

<p>I have tried this <code>for-loop</code> &amp; <code>if-else</code> statement to do what I want, however it is giving me a <code>IndexError: list assignment index out of range</code>:</p>

<pre><code>label = []
for i in range(23411):
    if ageNew[i] &lt;= 7:
        label[i] = 0
    elif ageNew[i] &lt;= 42:
        label[i] = 1
    else:
        label[i] = 2
</code></pre>

<p>For example:</p>

<pre><code>list: [0, 8, 14, 14, 45, 1056, 1]
label: [0, 1, 1, 1, 2, 2, 0]
</code></pre>
","8778033","8778033","2018-03-01 15:36:35","Making a list based on a criteria of another list","<python><list><for-loop><if-statement>","5","2","1049"
"49052851","2018-03-01 15:18:13","0","","<p>The code doesn't work because you've named the underlying attributes the same as the corresponding properties.</p>

<p>You need to use the same attribute names as the property getters/setters are referring to:</p>

<pre><code>class States:
    def __init__(self, f=0, n=0):
        self._state = n          # &lt;-- changed here
        self._level_state = f    # &lt;-- changed here

    @property
    def state(self, n):
        return self._state

    @state.setter
    def state(self, n):
        self._state = n

    @property
    def level_state(self, f):
        return self._level_state

    @level_state.setter
    def state(self, f):
        self._level_state = f
</code></pre>

<p>But the simple solution for this case would be to not use properties at all:</p>

<pre><code>class States:
    def __init__(self, f=0, n=0):
        self.state = n
        self.level_state = f
    # done
</code></pre>
","4621513","","","2","913","mkrieger1","2015-03-01 23:32:35","5181","1330","1053","2791","49051965","49052851","2018-03-01 14:34:24","0","46","<p>I read a bit about getters and setters, but haven't quite figured it out. One of my issues is the declaration in the <strong>init</strong> method: how can I change only one attribute if the method needs to arguments? Any other methods are of course welcome as well.</p>

<pre><code>class States:
    def __init__(self, f=0, n=0):
        self.state = n
        self.level_state = f

    @property
    def state(self, n):
        return self._state

    @state.setter
    def state(self, n):
        self._state = n

    @property
    def level_state(self, f):
        return self._level_state

    @level_state.setter
    def state(self, f):
        self._level_state = f
</code></pre>

<p>Example situation, changing the attributes individually:</p>

<p>Situation1:</p>

<pre><code>States().state = 3
</code></pre>

<p>Situation2:</p>

<pre><code>States().level_state = 2
</code></pre>
","9351296","9351296","2018-03-01 15:06:26","How do change class attributes individually?","<python><python-3.x><class><getter-setter>","1","5","890"
"49052858","2018-03-01 15:18:40","0","","<p>You might check your python version. I tried to deploy my Django project so my procfile looks like this <code>web: gunicorn blog.wsgi --log-file -</code> and I also got the same error <code>couldn't find that process type</code>.  and I found that <a href=""https://devcenter.heroku.com/articles/python-runtimes"" rel=""nofollow noreferrer"">Heroku</a> only support python-3.6.4 and python-2.7.14 while I just had python3.5. You can type:</p>

<pre><code>python -V
</code></pre>

<p>to see what python version you are using now. if not, you can download python 3.6. I followed this <a href=""https://askubuntu.com/questions/865554/how-do-i-install-python-3-6-using-apt-get"">How do I install Python 3.6 using apt-get?</a> </p>

<blockquote>
  <p>Ubuntu 14.04 and 16.04</p>
  
  <p>If you are using Ubuntu 14.04 or 16.04, you can use Felix Krull's
  deadsnakes PPA at
  <a href=""https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa"" rel=""nofollow noreferrer"">https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa</a>:</p>
  
  <p><code>sudo add-apt-repository ppa:deadsnakes/ppa</code> </p>
  
  <p><code>sudo apt-get update</code></p>
  
  <p><code>sudo apt-get install python3.6</code></p>
  
  <p>Alternatively, you can use J Fernyhough's PPA at
  <a href=""https://launchpad.net/~jonathonf/+archive/ubuntu/python-3.6"" rel=""nofollow noreferrer"">https://launchpad.net/~jonathonf/+archive/ubuntu/python-3.6</a>:</p>
  
  <p><code>sudo add-apt-repository ppa:jonathonf/python-3.6</code> </p>
  
  <p><code>sudo apt-get update</code></p>
  
  <p><code>sudo apt-get install python3.6</code></p>
</blockquote>

<p>and remember to keep you python 3.5. Don't remove it. and specify your python version in the runtime.txt file: <code>python-3.6.4</code> and run:</p>

<p><code>heroku ps:scale web=1 --app [my app's name]</code></p>

<p>and the problem solved. I hope my answer might help you.</p>
","9106048","9106048","2018-03-01 15:25:31","0","1887","Ieni Yuan","2017-12-16 05:05:23","1","0","0","0","48512013","","2018-01-30 00:10:12","5","11037","<p>I'm trying to deploy a simple python bot on Heroku but I get the error<br>
<code>couldn't find that process type</code>   </p>

<p>When I try to scale the dynos. I already made a procfile and it looks like this:<br>
<code>web: gunicorn dep:app</code>, where ""dep"" is the name of my python code  </p>

<p>What could be the reason?</p>
","9217311","1033581","2018-05-21 11:10:42","Couldn't find that process type, Heroku","<python><heroku>","3","0","337"
"49052929","2018-03-01 15:22:01","6","","<p>I don't see anything wrong with what you are doing now. But for aesthetic purposes, here are a couple of alternatives with some minimal functions.</p>

<pre><code>def doubler(x, y, z):
    return 2*(x + y + z)

def halver(x, y, z):
    return 0.5*(x + y + z)

def doubler_halver_sumprod(*args):
    return doubler(*args) * halver(*args)

dhs = lambda *args: doubler(*args) * halver(*args)

doubler_halver_sumprod(1, 2, 3)  # 36
dhs(1, 2, 3)                     # 36
</code></pre>

<p>If you want a truly extendible, functional approach, extracting arguments once, this could work:</p>

<pre><code>from operator import mul, methodcaller
from functools import reduce

def prod(iterable):
    return reduce(mul, iterable, 1)

def doubler(x, y, z):
    return 2*(x + y + z)

def halver(x, y, z):
    return 0.5*(x + y + z)

def dhs2(*args):
    return prod(map(methodcaller('__call__', *args), (doubler, halver)))

def dhs3(*args):
    return prod(f(*args) for f in (doubler, halver))

dhs2(1, 2, 3)  # 36
dhs3(1, 2, 3)  # 36
</code></pre>
","9209546","9209546","2018-03-01 16:45:03","7","1039","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49052689","","2018-03-01 15:10:20","4","136","<p>I have a given function</p>

<pre><code>def unnorm(x, alpha, beta):
    return (1 + alpha * x + beta * x ** 2)
</code></pre>

<p>Which I then integrate to find a normalization constant for in a range, and turn it to a lambda function that takes the same parameters as <code>unnorm</code>. Now, to create a fit-able object, I combine the functions like this:</p>

<pre><code>def normalized(x, alpha, beta):
    return unnorm(x, alpha, beta) * norm(x, alpha, beta)
</code></pre>

<p>Which is nice and all, but there's still repetition and pulling names from the global namespace.</p>

<p>How can I combine the two functions in a cleaner fashion, without having to re-write parameters? E.g</p>

<pre><code>def normalized(func, normalizer):
    return func * normalizer
</code></pre>

<p>Full code:</p>

<pre><code>import sympy
import numpy as np
import inspect

def normalize_function(f, xmin, xmax):
    """"""
    Normalizes function to PDF in the given range
    """"""
    # Get function arguments
    fx_args = inspect.getfullargspec(f).args
    # Convert to symbolic notation
    symbolic_args = sympy.symbols(fx_args)
    # Find definite integral
    fx_definite_integral = sympy.integrate(f(*symbolic_args), (symbolic_args[0], xmin, xmax))
    # Convert to a normalization multiplication term, as a real function
    N = sympy.lambdify(expr = 1 / fx_definite_integral, args = symbolic_args)
    return N

def unnorm(x, alpha, beta):
    return (1 + alpha * x + beta * x ** 2)

norm = normalize_function(unnorm, -1, 1)

# How do I condense this to a generic expression?
def normalized(x, alpha, beta):
    return unnorm(x, alpha, beta) * norm(x, alpha, beta)

x = np.random.random(100)

print(normalized(x, alpha = 0.5, beta = 0.5))
</code></pre>
","7026806","7026806","2018-03-01 15:17:22","How can I combine two functions that take the same arguments?","<python>","2","2","1748"
"49052933","2018-03-01 15:22:05","0","","<p>Try:</p>

<pre><code>if len(row) &gt; 0 and productid==row[0]:
   #rest of the code here ...
</code></pre>

<p>You need to make sure row list has a length to be indexed.</p>
","7055163","7055163","2018-03-01 17:45:13","1","177","Adminy","2016-10-21 20:49:00","82","21","10","0","38061114","","2016-06-27 18:47:18","0","108","<pre><code>if productid==row[0]: #This means it runs every row in the reader file which is the csv file in this case
    price = row[2]
    stocklevel = row[3]
    reorderlevel = row[4]
    targetlevel = row[5]
    total = float(amount)*float(price)
    totalprice = float(totalprice)+float(total)
    stocklevel = float(stocklevel)-float(amount)
    newstock = (stocklevel)
    b = open('products.csv', 'w')
    a = csv.writer(b)
    data = [['row[3]', 'row[4]', 'row[5]'],
           ['293', '219'],
           ['54', '13']]
    a.writerows(data)
    b.close()
</code></pre>

<p>Basically I keep getting this error File </p>

<blockquote>
  <p>""E:\Python Programme\pythonv5.py"", line 71, in 
      productlist()   File ""E:\Python Programme\pythonv5.py"", line 9, in productlist
      print(row[0]+"" ""+row[1]+"" ""+row[2]) IndexError: list index out of range</p>
</blockquote>
","6341764","5969411","2016-06-27 19:52:18","i keep getting indexerror:index list out of range on python","<javascript><python><python-2.7><python-3.x><indexing>","1","2","875"
"49053024","2018-03-01 15:26:11","0","","<p>This could be a solution:</p>

<pre><code>def fun1(a,b):
    return a+b

def fun2(c,d,e):
    return c+d+e


def compose(f1,f2):
    n1 = len(f1.__code__.co_varnames)
    n2 = len(f2.__code__.co_varnames)

    F1 = lambda x : f1(*[x[i] for i in range(0,n1)])*f2(*[x[i] for i in range(n1,n1+n2)])
    return F1

print(compose(fun1,fun2)([1,2,3,4,5]))
</code></pre>
","914693","","","0","367","linello","2011-08-26 19:20:32","3799","484","461","12","49047684","49048074","2018-03-01 10:31:04","2","97","<p>I am facing a challenging issue in order to make my Python3 code more elegant.</p>

<p>Suppose I have a number function with variable number of different inputs, for example something like this:</p>

<pre><code>def fun1(a,b):
    return a+b

def fun2(c,d,e):
    return c*d + e

def fun3(x):
    return x*x
</code></pre>

<p>These functions needs to be agglomerated in a single function that needs to be used as the optimization function of a numerical solver.</p>

<p>However I need to create different combinations of various operations with these functions, like for example multiplying the output of the first two functions and summing by the third.</p>

<p>The manual solution is to create a specific lambda function:</p>

<pre><code>fun = lambda x : fun1(x[0],x[1])*fun2(x[2],x[3],x[4]) + fun3(x[4])
</code></pre>

<p>but the number of functions I have is large and I need to produce all the possibile combinations of them.
I would like to systematically be able to compose these functions and always knowing the mapping from the arguments of higher level function  <code>fun</code> to the lower level arguments of each single function.
In this case I manually specified that <code>x[0]</code> corresponds to the argument <code>a</code> of <code>fun1</code>, <code>x[1]</code> corresponds to argument <code>b</code> of <code>fun1</code> etcetera.</p>

<p>Any idea?</p>
","914693","","","Producing combinations of lambda functions compositions","<python><design-patterns><lambda><functional-programming>","2","1","1378"
"49053053","2018-03-01 15:27:34","0","","<p>Regarding your question</p>

<blockquote>
  <p>How to check if a daemon service is running</p>
</blockquote>

<p>in RHEL/CentOS v4.x/5.x/6.x and Fedora Linux (older version) Verify Cron Service
You can simply use any one of the following command to see if crond is running or not, enter:</p>

<pre><code>$ pgrep crond
</code></pre>

<p>OR</p>

<pre><code>$ service crond status
</code></pre>

<p>Sample outputs:</p>

<pre><code># crond (pid 4370) is running...
</code></pre>

<p>If it is not running type the following two command to start crond:</p>

<pre><code>$ chkconfig crond on
$ service crond start
</code></pre>

<p>Verify cron is running by viewing log file, enter:</p>

<pre><code>$ tail -f /var/log/cron
</code></pre>

<p>A note about CentOS/RHEL v7.x+ and latest version of Fedora Linux
You need to use the following command to find out if the crond is running or not:</p>

<pre><code>$ systemctl status crond.service
</code></pre>

<p>Sample outputs:</p>

<pre><code>Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled)
   Active: active (running) since Tue 2015-05-19 14:53:32 EDT; 3min 7s ago
 Main PID: 1292 (crond)
   CGroup: /system.slice/crond.service
           â””â”€1292 /usr/sbin/crond -n
</code></pre>

<p>If not running configure the crond service to start automatically on boot:</p>

<pre><code>$ sudo systemctl enable crond.service
$ sudo systemctl start crond.service
</code></pre>

<p>A note about Debian / Ubuntu Linux (older version) Cron service
On a Debian and Ubuntu Linux cron logs its action logged to the syslog facility i.e. use /var/log/messages file:</p>

<pre><code>$ tail -f /var/log/messages
</code></pre>

<p>Find out if cron daemon is running or not, enter:</p>

<pre><code>$ pgrep cron
</code></pre>

<p>If not running start it, enter:</p>

<pre><code>$ update-rc.d cron defaults
$ /etc/init.d/cron start
</code></pre>

<p>A note about Debian Linux v8.x+ and latest version of Ubuntu Linux
The syntax is as follows to check if the cron service is running or not:</p>

<pre><code># systemctl status cron
</code></pre>

<p>Sample outputs:</p>

<pre><code>â— cron.service - Regular background program processing daemon
   Loaded: loaded (/lib/systemd/system/cron.service; enabled)
   Active: active (running) since Tue 2015-05-19 11:49:32 IST; 12h ago
     Docs: man:cron(8)
 Main PID: 1053 (cron)
   CGroup: /system.slice/cron.service
           â”œâ”€1053 /usr/sbin/cron -f
           â””â”€3020 /usr/bin/atop -a -w /var/log/atop/atop_20150520 600
</code></pre>

<p>If not running configure the crond service to start automatically on boot:</p>

<pre><code>$ sudo systemctl enable cron.service
$ sudo systemctl start cron.service
</code></pre>
","5859583","","","0","2703","CatChMeIfUCan","2016-01-30 00:07:06","151","64","15","5","49052676","49053053","2018-03-01 15:09:43","1","667","<p>How can I set up a cron job to monitor multiple PIs (via SSH) that are running the same daemon script (service)?</p>

<p>I was thinking of using a cron job to monitor the service status and write to a file on my server if the status of the service is active or inactive, and then I can later use the contents of that file to display the results of the Cron job onto a web page (but that is for me to figure out later).</p>

<p>I'm open to other options if someone can figure out an easier way using a different tool, E.g. bash script, python script, PHP etc, </p>
","9360242","","","How to check if a daemon service is running via Cron job or script?","<php><python><bash><cron><daemon>","2","0","567"
"49053132","2018-03-01 15:31:26","0","","<p>So the problem has to do with the fact that the wheel files have the text 'manylinux1'.</p>

<p>First, find out which platforms <code>pip</code> checks for. You can do this using a handy feature in <code>pip</code> (found on <a href=""https://github.com/tensorflow/tensorflow/issues/9722"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/issues/9722</a>):</p>

<pre><code>$ python -c 'from pip import pep425tags; print pep425tags.supported_tags'
[('cp27', 'cp27mu', 'linux_x86_64'), ('cp27', 'none', 'linux_x86_64'), ('py2', 'none', 'linux_x86_64'), ('cp27', 'none', 'any'), ('cp2', 'none', 'any'), ('cp26', 'none', 'any'), ('cp25', 'none', 'any'), ('cp24', 'none', 'any'), ('cp23', 'none', 'any'), ('cp22', 'none', 'any'), ('cp21', 'none', 'any'), ('cp20', 'none', 'any'), ('py27', 'none', 'any'), ('py2', 'none', 'any'), ('py26', 'none', 'any'), ('py25', 'none', 'any'), ('py24', 'none', 'any'), ('py23', 'none', 'any'), ('py22', 'none', 'any'), ('py21', 'none', 'any'), ('py20', 'none', 'any')]
</code></pre>

<p>The first result shows that we should swap the 'manylinux1' with simply 'linux':</p>

<pre><code>$ wget https://pypi.python.org/packages/13/7f/735fbc0dd78c91ad3693cfdfe5c91603899fc8e24909f935d46d2fde6559/vtk-8.1.0-cp27-cp27mu-manylinux1_x86_64.whl#md5=49c8d620b2affe2dc2284048659115e5
--2018-03-01 14:29:06--  https://pypi.python.org/packages/13/7f/735fbc0dd78c91ad3693cfdfe5c91603899fc8e24909f935d46d2fde6559/vtk-8.1.0-cp27-cp27mu-manylinux1_x86_64.whl
Resolving pypi.python.org (pypi.python.org)... 151.101.16.223, 2a04:4e42:4::223
Connecting to pypi.python.org (pypi.python.org)|151.101.16.223|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 48860459 (47M) [binary/octet-stream]
Saving to: ‘vtk-8.1.0-cp27-cp27mu-manylinux1_x86_64.whl’

100%[====================================================================================================================================================================================================================&gt;] 48,860,459  90.5MB/s   in 0.5s

2018-03-01 14:29:07 (90.5 MB/s) - ‘vtk-8.1.0-cp27-cp27mu-manylinux1_x86_64.whl’ saved [48860459/48860459]
</code></pre>

<p>Rename using a symbollic link:</p>

<pre><code>$ ln -s vtk-8.1.0-cp27-cp27mu-manylinux1_x86_64.whl vtk-8.1.0-cp27-cp27mu-linux_x86_64.whl
</code></pre>

<p>Now install:</p>

<pre><code>$ pip install vtk-8.1.0-cp27-cp27mu-linux_x86_64.whl
</code></pre>

<p>That should fix it!</p>
","750670","","","2","2461","polarise","2011-05-12 13:53:29","1494","117","294","4","49053131","","2018-03-01 15:31:26","2","470","<p>I know that VTK is now available as a wheel in PyPI (<a href=""https://pypi.python.org/pypi/vtk/8.1.0"" rel=""nofollow noreferrer"">https://pypi.python.org/pypi/vtk/8.1.0</a>) but I am not able to install it. Is there a way around this?</p>

<p>When I try this is what I get:</p>

<pre><code>$ pip install vtk
Collecting vtk
  Could not find a version that satisfies the requirement vtk (from versions: )
No matching distribution found for vtk
</code></pre>

<p>I have tried pointing to the wheel's URL but still the same problem.</p>

<pre><code>$ pip install https://pypi.python.org/packages/13/7f/735fbc0dd78c91ad3693cfdfe5c91603899fc8e24909f935d46d2fde6559/vtk-8.1.0-cp27-cp27mu-manylinux1_x86_64.whl#md5=49c8d620b2affe2dc2284048659115e5
vtk-8.1.0-cp27-cp27mu-manylinux1_x86_64.whl is not a supported wheel on this platform.
</code></pre>

<p>Here is my platform information:</p>

<pre><code>$ uname -a
Linux [hostname-withheld] 3.10.0-514.16.1.el7.x86_64 #1 SMP Fri Mar 10 13:12:32 EST 2017 x86_64 x86_64 x86_64 GNU/Linux
</code></pre>
","750670","","","Failure installing VTK from PyPI on x86_64","<python><pip><vtk>","1","0","1040"
"49053153","2018-03-01 15:32:27","1","","<p>The error message indicates that you need to include an attribute called <code>name</code> for each of your <code>country</code> nodes. Try this:</p>

<pre><code>import xml.etree.cElementTree as ET

root = ET.Element(""root"")
ET.SubElement(root, ""country"", name=""Narnia"")
ET.SubElement(root, ""country"", name=""Wakanda"")
ET.SubElement(root, ""country"", name=""Panama"")
tree = ET.ElementTree(root)
tree.write(""/tmp/vulnerable-countries.xml"")
</code></pre>

<p>Result:</p>

<pre class=""lang-xml prettyprint-override""><code>&lt;root&gt;&lt;country name=""Narnia"" /&gt;&lt;country name=""Wakanda"" /&gt;&lt;country name=""Panama"" /&gt;&lt;/root&gt;
</code></pre>
","8747","","","1","653","Robᵩ","2008-09-15 16:47:33","124214","7724","5618","743","49053076","49053153","2018-03-01 15:28:51","0","505","<p>I am currently taking part in a Cyber Challenge, however I have beeen asked to produce an xml file which contains nodes and atributes: </p>

<pre><code>Generate a valid xml file at /tmp/vulnerable-countries.xml.
It should contain a list of country nodes attached to a root node
that have name attributes, the third node should be Panama.
</code></pre>

<p>I have looked everywhere for information on this and I cam up with the following.
However, after submitting this code I get the following:</p>

<pre><code>import xml.etree.cElementTree as ET

root = ET.Element(""root"")
ET.SubElement(root, ""Country"")
ET.SubElement(root, ""Country"")
ET.SubElement(root, ""Panama"")
tree = ET.ElementTree(root)
tree.write(""/tmp/vulnerable-countries.xml"")
</code></pre>

<p>Format of /tmp/vulnerable-countries.xml was not correct. It should contain 3 country nodes with name attributes, with the third being Panama.</p>

<p>Can anyone help?</p>
","4357196","","","Coding an XML document with python?","<python><xml><elementtree>","1","0","930"
"49053156","2018-03-01 15:32:42","1","","<p>If you don't reshape your data at all sklearn gives you a hint:</p>

<pre><code>Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.
</code></pre>

<p>As your data has a single feature, you have to reshape it to (-1, 1) instead of (1, -1)</p>
","7726586","","","0","335","maria","2017-03-17 10:34:50","86","27","8","0","49052420","","2018-03-01 14:57:28","1","425","<pre><code>import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
Dataset = pd.read_csv('Salary_Data.csv')
Salary , YearsExperience = Dataset['Salary'] ,Dataset['YearsExperience'] 
X_train, X_test, y_train, y_test = train_test_split(YearsExperience , 
Salary, test_size=0.33, random_state=42)
Regressor = LinearRegression()
Regressor.fit(X_train.values.reshape(1,-1),y_train.values.reshape(1,-1))    
y_pred = Regressor.predict(X_test.values.reshape(1,-1))
</code></pre>

<p>So I've written this code do do a linear regression . But I get an error on the .predict line where the error says </p>

<pre><code>ValueError: shapes (1,10) and (20,20) not aligned: 10 (dim 1) != 20 (dim 0)
</code></pre>

<p>but when I keep the test_size as 0.5 the error does not occur . Can you explain why this happens ? What do I do ? </p>
","8097625","","","Getting shape not aligned error sklearn .","<python><machine-learning><scikit-learn><linear-regression><sklearn-pandas>","1","1","888"
"49053162","2018-03-01 15:32:56","2","","<p>The problem that seems you are having comes from the permutation that you are doing, by commenting these two lines:</p>

<pre><code># np.random.seed(1)
# df = df.loc[np.random.permutation(len(df))]
</code></pre>

<p>This is because when you clean your data, you end up with only 201 rows from 204 of them. By debugging the dataframe that you provide to the knn function, you can find that indeed, three of the rows are now 'nan' for all columns once the numeric_cars_normalized have been permuted.</p>

<p>and rerunning the code, you will obtain results. But there is an additional change that you should do, as knn works better with arrays, you should change the dataframes (series) to values with the correct dimension and then operate with them. In your particular case, all of them are series, you can change them by:</p>

<pre><code>series.values.reshape(-1, 1)
</code></pre>

<p>Here is the knn function with all the changes:
    def knn_train_test(df, train_columns, predict_feature, k_value):</p>

<pre><code>    #print(train_columns, k_value)
    # Randomly resorts the DataFrame to mitigate sampling bias
    #np.random.seed(1)
    #df = df.loc[np.random.permutation(len(df))]

    # Split the DataFrame into ~75% train / 25% test data sets
    split_integer = round(len(df) * 0.75)
    train_df = df.iloc[0:split_integer]
    test_df = df.iloc[split_integer:]

    train_features = train_df[train_columns].values.reshape(-1, 1)
    train_target = train_df[predict_feature].values.reshape(-1, 1)

    # Trains the model
    knn = KNeighborsRegressor(n_neighbors=k_value)
    knn.fit(train_features, train_target)

    # Test the model &amp; return calculate mean square error
    predictions = knn.predict(test_df[train_columns].values.reshape(-1,   1))
    print(""predictions"")
    mse = mean_squared_error(y_true=test_df[predict_feature], y_pred=predictions)
    return mse
</code></pre>

<p>With that, and if I get the correct input file, this is what I got:</p>

<pre><code>predictions
{'normalized_losses': [100210405.34, 116919980.22444445, 88928383.280000001, 62378305.931836732, 65695537.133086421], 'wheel_base': [10942945.5, 31106845.595555563, 34758670.590399988, 29302177.901632652, 25464306.165925924], 'length': [71007156.219999999, 37635782.111111119, 33676038.287999995, 29868192.295918364, 22553474.111604933], 'width': [42519394.439999998, 25956086.771111108, 15199079.0744, 10443175.389795918, 8440465.6864197534], 'height': [117942530.56, 62910880.079999998, 41771068.588, 33511475.561224483, 31537852.588641971], 'curb_weight': [14514970.42, 6103365.4644444454, 6223489.0728000011, 7282828.3632653067, 6884187.4446913591], 'bore': [57147986.359999999, 88529631.346666679, 68063251.098399997, 58753168.154285707, 42950965.435555562], 'stroke': [145522819.16, 98024560.913333327, 61229681.429599993, 36452809.841224492, 25989788.846172832], 'compression_ratio': [93309449.939999998, 18108906.400000002, 30175663.952, 44964197.869387761, 39926111.747407407], 'horsepower': [25158775.920000002, 17656603.506666664, 13804482.193600001, 15772395.163265305, 14689078.471851852], 'peak_rpm': [169310760.66, 86360741.248888895, 51905953.367999993, 46999120.435102046, 45218343.222716056], 'city_mpg': [15467849.460000001, 12237327.542222224, 10855581.140000001, 11479257.790612245, 11047557.746419754], 'highway_mpg': [17384289.579999998, 15877936.197777782, 7720502.6856000004, 6315372.4963265313, 7118970.4081481481]}
</code></pre>
","7879739","7879739","2018-03-01 15:39:29","4","3459","OscarD","2017-04-17 16:41:14","96","4","19","0","49042340","49053162","2018-03-01 03:50:30","1","565","<p>Prior to attempting the fit I have thoroughly cleaned my data frame and ensured that the entire data frame has no inf or NaN values and is composed of entirely non-null float64 values.  However, I still redundantly verified this using np.isinf(), df.isnull().sum() and df.info() methods.  All my research showed that others with the same issue had NaN, inf, or object data type in their data frame.  This is not so in my case. Lastly, I found a vaguely similar <a href=""https://stackoverflow.com/questions/43335489/error-in-fit-transform-input-contains-nan-infinity-or-a-value-too-large-for-dt"">case</a> which found a resolution using this code: </p>

<pre><code>df = df.apply(lambda x: pd.to_numeric(x,errors='ignore'))
</code></pre>

<p>This did not help in my situation.  How can I resolve this ValueError exception?</p>

<pre><code>from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
import pandas as pd
import numpy as np

# Read csv file and assign column names
headers=['symboling','normalized_losses','make','fuel_type','aspiration','num_of_doors',
         'body_style','drive_wheels','engine_location','wheel_base','length','width',
        'height','curb_weight','engine_type','num_of_cylinders','engine_size','fuel_system',
        'bore','stroke','compression_ratio','horsepower','peak_rpm','city_mpg','highway_mpg',
        'price']
cars = pd.read_csv('imports-85.data.txt', names=headers)

# Select only the columns with continuous values from - https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.names
continuous_values_cols = ['normalized_losses', 'wheel_base', 'length', 'width', 'height', 'curb_weight', 
                          'bore', 'stroke', 'compression_ratio', 'horsepower', 'peak_rpm', 'city_mpg', 'highway_mpg', 'price']
numeric_cars = cars[continuous_values_cols].copy()

# Clean Data Set by Convert missing values (?) with np.NaN then set the type to float
numeric_cars.replace(to_replace='?', value=np.nan, inplace=True)
numeric_cars = numeric_cars.astype('float')

# Because the column we're trying to predict is 'price', any row were price is NaN will be removed.""
numeric_cars.dropna(subset=['price'], inplace=True)

# All remaining NaN's will be filled with the mean of its respective column
numeric_cars = numeric_cars.fillna(numeric_cars.mean())

# Create training feature list and k value list
test_features = numeric_cars.columns.tolist()
predictive_feature = 'price'
test_features.remove(predictive_feature)
k_values = [x for x in range(10) if x/2 != round(x/2)]

# Normalize columns
numeric_cars_normalized = numeric_cars[test_features].copy()
numeric_cars_normalized = numeric_cars_normalized/ numeric_cars.max()
numeric_cars_normalized[predictive_feature] = numeric_cars[predictive_feature].copy()


def knn_train_test(df, train_columns, predict_feature, k_value):

    # Randomly resorts the DataFrame to mitigate sampling bias
    np.random.seed(1)
    df = df.loc[np.random.permutation(len(df))]

    # Split the DataFrame into ~75% train / 25% test data sets
    split_integer = round(len(df) * 0.75)
    train_df = df.iloc[0:split_integer]
    test_df = df.iloc[split_integer:]

    train_features = train_df[train_columns]
    train_target = train_df[predict_feature]

    # Trains the model
    knn = KNeighborsRegressor(n_neighbors=k_value)
    knn.fit(train_features, train_target)

    # Test the model &amp; return calculate mean square error
    predictions = knn.predict(test_df[train_columns])
    print(""predictions"")
    mse = mean_squared_error(y_true=test_df[predict_feature], y_pred=predictions)
    return mse


# instantiate mse dict
mse_dict = {}

# test each feature and do so with a range of k values
# in an effot to determine the optimal training feature and k value
for feature in test_features:

    mse = [knn_train_test(numeric_cars_normalized,feature, predictive_feature, k) for k in k_values]
    mse_dict[feature] = mse

print(mse_dict)
</code></pre>

<p>Here's the full error trace back:</p>

<pre><code>C:\ProgramData\Anaconda3\lib\site-packages\sklearn\utils\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.
  DeprecationWarning)
Traceback (most recent call last):
  File ""C:\DATAQUEST\06_MachineLearning\01_ML_Fundamentals\06_GuidedProject_PredictingCarPrices\PredictingCarPrices.py"", line 76, in &lt;module&gt;
    mse = [knn_train_test(numeric_cars_normalized,feature, predictive_feature, k) for k in k_values]
  File ""C:\DATAQUEST\06_MachineLearning\01_ML_Fundamentals\06_GuidedProject_PredictingCarPrices\PredictingCarPrices.py"", line 76, in &lt;listcomp&gt;
    mse = [knn_train_test(numeric_cars_normalized,feature, predictive_feature, k) for k in k_values]
  File ""C:\DATAQUEST\06_MachineLearning\01_ML_Fundamentals\06_GuidedProject_PredictingCarPrices\PredictingCarPrices.py"", line 60, in knn_train_test
    knn.fit(train_features, train_target)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\sklearn\neighbors\base.py"", line 741, in fit
    X, y = check_X_y(X, y, ""csr"", multi_output=True)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\sklearn\utils\validation.py"", line 521, in check_X_y
    ensure_min_features, warn_on_dtype, estimator)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\sklearn\utils\validation.py"", line 407, in check_array
    _assert_all_finite(array)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\sklearn\utils\validation.py"", line 58, in _assert_all_finite
    "" or a value too large for %r."" % X.dtype)
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
</code></pre>

<p>Here's the code and output I used to verify that there are no NaN or inf values in my DataFrame:</p>

<pre><code># Verify data for NaN and inf
print(len(numeric_cars_normalized))
# 201

print(numeric_cars_normalized.info())
# &lt;class 'pandas.core.frame.DataFrame'&gt;
# Int64Index: 201 entries, 0 to 204
# Data columns (total 14 columns):
# bore                 201 non-null float64
# city_mpg             201 non-null float64
# compression_ratio    201 non-null float64
# curb_weight          201 non-null float64
# height               201 non-null float64
# highway_mpg          201 non-null float64
# horsepower           201 non-null float64
# length               201 non-null float64
# normalized_losses    201 non-null float64
# peak_rpm             201 non-null float64
# price                201 non-null float64
# stroke               201 non-null float64
# wheel_base           201 non-null float64
# width                201 non-null float64
# dtypes: float64(14)
# memory usage: 23.6 KB
# None

print(numeric_cars_normalized.isnull().sum())
# bore                 0
# city_mpg             0
# compression_ratio    0
# curb_weight          0
# height               0
# highway_mpg          0
# horsepower           0
# length               0
# normalized_losses    0
# peak_rpm             0
# price                0
# stroke               0
# wheel_base           0
# width                0
# dtype: int64

# The loop below, essentially does the same as the above
# verification, but using different methods
# the purpose is to prove there's no nan or inf in my data set
index = []
NaN_counter = []
inf_counter = []
for col in numeric_cars_normalized.columns:
    index.append(col)
    # inf counter
    col_isinf = np.isinf(numeric_cars_normalized[col])
    if col_isinf.value_counts().index[0] == False:
        inf_counter.append(col_isinf.value_counts()[0])

    # nan counter    
    col_isnan = np.isnan(numeric_cars_normalized[col])
    if col_isnan.value_counts().index[0] == False:
        NaN_counter.append(col_isnan.value_counts()[0])

data_check = {'NOT_NaN_count': NaN_counter, 'NOT_inf_count': inf_counter}
data_verification = pd.DataFrame(data=data_check, index=index)
print(data_verification)

#                    NOT_NaN_count  NOT_inf_count
# bore                         201            201
# city_mpg                     201            201
# compression_ratio            201            201
# curb_weight                  201            201
# height                       201            201
# highway_mpg                  201            201
# horsepower                   201            201
# length                       201            201
# normalized_losses            201            201
# peak_rpm                     201            201
# price                        201            201
# stroke                       201            201
# wheel_base                   201            201
# width                        201            201
</code></pre>

<p>I may have found the problem, but still not sure how to fix it.</p>

<pre><code># Here's a another methodology for extra redudnant data checking
index = []
NaN_counter = []
inf_counter = []

for col in numeric_cars_normalized.columns:
    index.append(col)
    inf_counter.append(np.any(np.isfinite(numeric_cars_normalized[col])))
    NaN_counter.append(np.any(np.isnan(numeric_cars_normalized[col])))

data_check = {'Any_NaN': NaN_counter, 'Any_inf': inf_counter}
data_verification = pd.DataFrame(data=data_check, index=index)
print(data_verification)

                   Any_NaN  Any_inf
# bore                 False     True
# city_mpg             False     True
# compression_ratio    False     True
# curb_weight          False     True
# height               False     True
# highway_mpg          False     True
# horsepower           False     True
# length               False     True
# normalized_losses    False     True
# peak_rpm             False     True
# price                False     True
# stroke               False     True
# wheel_base           False     True
# width                False     True
</code></pre>

<p>So clearly I have inf in my DataSet, but I'm not sure why or how to fix it.</p>
","8328781","8328781","2018-03-01 14:19:17","ValueError: Input contains NaN, infinity or a value too large for dtype('float64') using fit from KNeighborsRegressor","<python><python-3.x><pandas><numpy><scikit-learn>","1","2","10031"
"49053202","2018-03-01 15:34:20","-1","","<p>An abstract data type in python is one which you would make yourself, </p>

<p>Take for example a <code>list</code> and a <code>hashset</code>, they both form an abstract data type <code>dictionary</code> even though in python it would appear as a build in. Abstraction is the technique in which you can make abstract data types or it can be viewed as a concept rather that a data type.</p>

<p>I'm not sure if I can provide any links, you learn this stuff at university.</p>
","7055163","","","0","479","Adminy","2016-10-21 20:49:00","82","21","10","0","40314047","","2016-10-28 22:28:52","1","1705","<p>I am really tired searching about what is really abstract data type in python? </p>

<p>I found this statement everywhere:</p>

<blockquote>
  <p>ADT defined in terms of its data items and associated operations , not
  its implementation.</p>
</blockquote>

<p>So what exactly this statement means , Please explain. </p>

<pre><code>  My question is what is abstract data type in python and is it same as abstraction
 in python object oriented ?
</code></pre>

<p>If you explain with good theory and provide links with good article and blogs that would be helpful for me.</p>
","7087428","7087428","2016-10-28 23:07:27","What really is abstract data type in python?","<python><python-2.7><python-3.x>","1","3","579"
"49053217","2018-03-01 15:35:08","0","","<p>You need to use another getSubset:</p>

<pre><code>   fo = ..... fieldOutput object
   f = fo.getSubset(sectionPoint=sp)
</code></pre>

<p>Section point objects can be found in the odb:</p>

<pre><code>   odbname = 'mine.odb'
   odb = session.odbs[odbname]
   sp = odb.sectionCategories.values()[0]
</code></pre>

<p>If you want a particular section point number, each section Point object has the property </p>

<pre><code>   sp.number
</code></pre>
","3203246","","","0","454","johnzilla","2014-01-16 15:52:51","153","24","109","1","48885426","","2018-02-20 12:34:02","0","416","<p>I have this code:</p>

<pre><code>def get_field(odb, step, frame, field, element):
    if field == 'E':
        function = get_strain
        for f in odb.steps[step].frames[frame].fieldOutputs[field].getSubset(region=element_set).values:
            data = function(f.data)
            dict_data[index] = data
            index += 1
        return dict_data
</code></pre>

<p>I want to include section points and section category. What should I change in this code to achieve that?</p>
","9385617","5459839","2018-02-21 17:47:47","How do I extract stress/strain at sectionpoints using abaqus python script?","<python>","1","0","490"
"49053273","2018-03-01 15:37:25","1","","<p>Check the first element of the array returned by <code>np.random.get_state()</code>, it seems exactly the random seed to me.</p>
","9149306","","","1","132","Dong Justin","2017-12-28 12:45:52","37","12","5","0","32172054","32172816","2015-08-23 22:10:14","47","17008","<p>The following imports NumPy and sets the seed.</p>

<pre><code>import numpy as np
np.random.seed(42)
</code></pre>

<p>However, I'm not interested in setting the seed but more in reading it. <code>random.get_state()</code> does not seem to contain the seed. The <a href=""http://docs.scipy.org/doc/numpy/reference/routines.random.html"">documentation</a> doesn't show an obvious answer.</p>

<p>How do I retrieve the current seed used by <code>numpy.random</code>, assuming I did not set it manually?</p>

<p>I want to use the current seed to carry over for the next iteration of a process.</p>
","1014587","1461210","2015-08-24 00:15:31","How can I retrieve the current seed of NumPy's random number generator?","<python><numpy><random><random-seed><mersenne-twister>","3","4","596"
"49053307","2018-03-01 15:39:24","0","","<p>As suggested by @languitar in the comments you would have <code>file://</code> which of course it should work for windows, but moving to a platform like android, you have different file system there, you don't have <code>C</code> drive. So make sure you got an alternative location on the android.</p>
","7055163","","","0","305","Adminy","2016-10-21 20:49:00","82","21","10","0","42419712","","2017-02-23 15:19:58","0","45","<p>I would like to modify this script to use offline files, if I download the files from url works, but if the same file as I withdraw from hard drives, does not open, someone helps me to understand why and how to do, thank you.</p>

<pre><code>    def INDEX():
    TVLIST('https://www.*********/playlist/*******/test.m3u')


def TVLIST(url):
    try:
        m3u = getHtml(url)
        parsem3u(m3u)
    except:
        addDir('Nothing found', '', '', '', Folder=False)
    xbmcplugin.endOfDirectory(int(sys.argv[1]))

urlopen = urllib2.urlopen
Request = urllib2.Request

def getHtml(url, referer=None, hdr=None, data=None):
    if not hdr:
        req = Request(url, data, headers)
    else:
        req = Request(url, data, hdr)
    if referer:
        req.add_header('Referer', referer)
    if data:
        req.add_header('Content-Length', len(data))
    response = urlopen(req)
    if response.info().get('Content-Encoding') == 'gzip':
    buf = StringIO( response.read())
    f = gzip.GzipFile(fileobj=buf)
    data = f.read()
    f.close()
else:
    data = response.read()    
response.close()
return data

def parsem3u(html, sitechk=True):
    match = re.compile('#.+,(.+?)\n(.+?)\n').findall(html)
    txtfilter = txtfilter = GETFILTER()
    txtfilter = txtfilter.split(',') if txtfilter else []
    txtfilter = [f.lower().strip() for f in txtfilter]
    i = 0
    count = 0
    for name, url in match:
        status = """"
        url = url.replace('\r','')
        if not txtfilter or any(f in name.lower() for f in txtfilter):
            if sitechk:
                if i &lt; 5:
                    try:
                        siteup = urllib.urlopen(url).getcode()
                        status = "" [COLOR red]offline[/COLOR]"" if siteup != 200 else "" [COLOR green]online[/COLOR]""
                    except: status = "" [COLOR red]offline[/COLOR]""
                    i += 1
            addPlayLink(name+status, url, 3, uiptvicon)
            count += 1
    return count
</code></pre>

<p>I thought, was enough to put the local path</p>

<pre><code>def INDEX():
TVLIST(r'c:\Desktop\IPTVLIST\M3U\playlist\test.m3u')
</code></pre>

<p>who explains why it does not work and how can I do? Thank you</p>
","7611820","","","Use of files on hard drives instead of url with python","<python><python-2.7><python-3.x>","1","5","2214"
"49053346","2018-03-01 15:41:09","0","","<p>Alternative solution. RDD is working, therefore, bring back the cols you need in the lambda function : </p>

<pre><code>col_rdd  = test_data.rdd.map(lambda x: addPred(x.features))
</code></pre>

<p>becomes</p>

<pre><code>col_rdd  = test_data.rdd.map(lambda x: (x.neededCols, addPred(x.features)))
</code></pre>
","5013752","","","1","315","Steven","2015-06-16 04:27:36","4021","506","146","66","49051910","","2018-03-01 14:31:38","0","511","<p>The Schema of my dataframe is:</p>

<pre><code>root
     |-- _10: string (nullable = true)
     |-- _11: string (nullable = true)
     |-- _12: string (nullable = true)
     |-- _13: string (nullable = true)
     |-- _14: string (nullable = true)
     |-- _15: string (nullable = true)
     |-- _16: string (nullable = true)
     |-- _17: string (nullable = true)
     |-- _18: string (nullable = true)
     |-- _19: string (nullable = true)
     |-- _20: string (nullable = true)
     |-- _21: string (nullable = true)
     |-- _22: string (nullable = true)
     |-- _23: string (nullable = true)
     |-- _24: string (nullable = true)
     |-- _25: string (nullable = true)
     |-- id: long (nullable = true)
     |-- features: array (nullable = true)
     |    |-- element: double (containsNull = true)
</code></pre>

<p>I want to do some operation using the features array and store the result in a new column: Prediction</p>

<pre><code>def addPred(inp):
    global weights, bias
    for j in range(0,len(weights)):
        if j==0:
            out = sigmoid(np.dot(inp,weights[j]) + bias[j])
        elif j==len(weights)-1:
            out = softmax(np.dot(out,weights[j]) + bias[j])
        else:
            out = sigmoid(np.dot(out,weights[j]) + bias[j])

    if out[0]&gt;out[1]:
        return -1*out[0]
    return out[1]
</code></pre>

<p>Using this UDF and the following code I'm trying to add a new column to the dataframe directly.</p>

<pre><code>udf_addPred = udf(addPred, DoubleType())
test_data = test_data.withColumn('pred', udf_addPred('features'))
</code></pre>

<p>But it's giving me all kind's of errors.  </p>

<ul>
<li>Sometimes 'not serializable error'</li>
<li>Sometimes 'RDD is empty error'</li>
</ul>

<p>But if I do the same operation using rdd map, it works using the following code</p>

<pre><code>col_rdd  = test_data.rdd.map(lambda x: addPred(x.features))
</code></pre>

<ul>
<li>I tried debugging the issue myself but can't figure out the source of error</li>
<li>Doing it the RDD way and then merging the column will require twice the computation</li>
<li>Can someone please point out the error or suggest a better alternative?</li>
</ul>

<p>EDIT:</p>

<p>Output for test_data.rdd.first():</p>

<pre><code>Row(_10=u'Abu Dhabi Global Market', _11=u'Abu Dhabi Media Company', _12=u'Abu Dhabi Global Market (ADGM) BuildingADGM Square Al Maryah Island PO Box 111999', _13=u'Abu Dhabi Media P.O. Box 63', _14=u'Abu Dhabi', _15=u'Abu Dhabi', _16=u'Abu Dhabi', _17=u'Abu Dhabi', _18=u'United Arab Emirates', _19=u'United Arab Emirates', _20=None, _21=None, _22=u'557942700', _23=u'552544884', _24=u'www.adgm.com', _25=u'http://www.admedia.ae', id=4, features=[0.4782608695652174, 0.2592592592592593, 1.0, 1.0, 1.0, 0.14285714285714285, 0.0, 0.19999999999999996])
</code></pre>

<p>Weights and bias are corresponding things from Spark's Multilayer Perceptron </p>

<pre><code>def extWeights():
    weights = []
    bias = []
    last = 0
    for i in range(0,len(model.layers)-1):
        curr = (model.layers[i]+1)*model.layers[i+1]
        weights.append(np.reshape(model.weights[last:last+curr],((model.layers[i]+1),model.layers[i+1])))
        bias.append(weights[i][model.layers[i]])
        weights[i] = weights[i][:model.layers[i]]
        last += curr
    return weights, bias
</code></pre>
","3908641","3908641","2018-03-01 15:31:11","Pyspark UDF for Dataframe vs RDD","<python><apache-spark><pyspark><spark-dataframe><rdd>","1","14","3333"
"49053359","2018-03-01 15:42:04","0","","<p>First of all, I want to thank every one that helped me to find a solution. I have to say that this is my first time posting a question in stackoverflow and the experience has been very nice. I also want to thank @AnkitMalik and @NoticeMeSenpai because their effort helped me to find a very good solution. </p>

<p>My question was about merging data frames in a <code>dictionary {}</code> by using <code>functools.reduce()</code>. But, as was pointed out by @AnkitMalik, this only works for <code>lists []</code>. @NoticeMeSenpai recomended the use of <code>pandas.concat()</code> in order to make this work. The code below is the one that works for me:</p>

<pre><code>import pandas as pd
import subprocess
import os

path='C:\Users\ra\Desktop\Px\a'

df = [] #makes a list of data frames
x = [#vector that contains the name of the csv files as strings]
for j in x:
    df.append((pd.read_csv(os.path.join(path,r'%s.csv' % j))).set_index('D').rename(columns={'C':'%s' % j}), axis=1)) #appends every csv file in folder 'a' as a data frame in list 'df', sets the column 'D' as index and renames the column 'C' as the name of csv file.

df_concat = pd.concat(df, axis=1) #concats every data frame in the list 'df'
df_concat.to_csv(os.path.join(path,r'xxx.csv')) # saves the concatenated data frame in the 'xxx' csv file in folder 'a'.
</code></pre>
","9370758","9370758","2018-03-05 21:17:40","0","1348","Alberto_Márquez","2018-02-16 17:12:32","1","2","0","0","49040837","49053359","2018-03-01 00:27:11","0","1583","<p>The data that I'm using looks like this:</p>

<pre><code>csv1 = pd.DataFrame({'D': [1-10, 2-10, 3-10, 4-10,...], #dates
...:                'C': [#, #, #, #,...]} #values

csv2 = pd.DataFrame({'D': [3-10, 4-10, 5-10, 6-10,...], #dates
...:                'C': [#, #, #, #,...]} #values

csv3 = pd.DataFrame({'D': [5-10, 6-10, 7-10, 8-10,...], #dates
...:                'C': [#, #, #, #,...]} #values
.
.
.
csv100 = pd.DataFrame({'D': [5-10, 6-10, 7-10, 8-10,...], #dates
...:                'C': [#, #, #, #,...]} #values
</code></pre>

<p>I want a data frame like this:</p>

<pre><code>df_merged = pd.DataFrame({'D': [1-10,2-10,3-10,4-10,5-10,6-10...] #dates
...:                  'C1': [#, #, #, #, #, #...]} #values
                      'C2': [#, #, #, #, #, #...]} #values
                      'C3': [#, #, #, #, #, #...]} #values
                      .
                      .
                      .
                      'C100': [#, #, #, #, #, #]} #values
</code></pre>

<p>I have been trying to merge multiple data frames, around 100, that have the same columns but different rows (they don’t have the same order), I would like to do it by the column 'date' (to merge every row with the same date). Because the amount of data frames is high, and changes over time (today I could have 110, tomorrow I could have 90...), the method of using a loop to merge each one of them is too slow. By researching for a solution, I found that the consensus is to use dictionaries. I applied this solution to my code but I got an error and I don’t know how to solve it. The code is the following</p>

<pre><code>import pandas as pd
import subprocess
import os
from functools import reduce

path=r'C:\Users\ra\Desktop\Px\a' #Folder 'a' path

df = {} #Dictionary of data frames from csv files in Folder 'a'
x = [#vector that contains the name of the csv file as string]
i = 0
for j in range(len(x)):
    df['df%s' %j] = (pd.read_csv(os.path.join(path,r'%s.csv' % x[i]))) #Assigns a key to the data frame Ex.:'df1' (the key is a string and I think this is the problem)
    df['df%s' %j].rename(columns={'C': '%s' % x[i]}, inplace=True) #Renames the column 'C' of every data frame to the name of the file
    i += 1

df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['D'],how='outer'),df) #Merges every data frame to a single data frame 'df_merged' by column 'D' that represents the date.
</code></pre>

<p>The problem is in the last line, the output is the following:</p>

<pre><code>---&gt; df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['D'],how='outer'),df)
.
.
.
ValueError: can not merge DataFrame with instance of type &lt;class 'str'&gt;
</code></pre>

<p>If I change the key from string to integer (by changing the vector x to simple numbers 'j') I get the following output:</p>

<pre><code>---&gt; df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['D'],how='outer'),df)
.
.
.
ValueError: can not merge DataFrame with instance of type &lt;class 'int'&gt;
</code></pre>

<p>To make the code work, I tried to find a way to convert the string keys to names. But, apparently, that is a sin. Also, according to @AnkitMalik the 'reduce' method can't be used with dictionaries. How can I merge all this data frames by the column 'D' in a pythonic way if the keys in the dictionary are strings/integers? Or, How can I make a dynamic list of data frames if their number changes over time depending on the amount of csv files in folder 'a'?</p>
","9370758","7851470","2019-04-25 09:26:39","Merge multiple pandas data frames in a dictionary if keys are strings/integers","<python><pandas><dataframe><dictionary><merge>","3","4","3483"
"49053389","2018-03-01 15:43:31","2","","<p>I would chain different permutations of the string characters with a length constraint:</p>

<pre><code>import itertools

def generate(vals=""abc""):
    return ("""".join(x) for x in itertools.chain.from_iterable(itertools.permutations(vals,i+1) for i in range(0,len(vals))))

print(list(generate(""abc""))) # force iteration to print result
</code></pre>

<p>result:</p>

<pre><code>['a', 'b', 'c', 'ab', 'ac', 'ba', 'bc', 'ca', 'cb', 'abc', 'acb', 'bac', 'bca', 'cab', 'cba']
</code></pre>

<p>Edit: seems that I produced a variant of the powerset recipe (<a href=""https://stackoverflow.com/questions/1482308/whats-a-good-way-to-combinate-through-a-set"">what&#39;s a good way to combinate through a set?</a>), not considering the empty string, considering order of the characters (<code>abc</code> and <code>cba</code> are 2 different items) and using <code>str.join</code> to generate strings directly.</p>
","6451573","","","0","908","Jean-François Fabre","2016-06-10 19:19:53","113106","37329","9248","14670","49053216","49053674","2018-03-01 15:35:04","4","849","<p>I have the following list:</p>

<pre><code>['a', 'b', 'c']
</code></pre>

<p>I'm looking into a way to generate all possible strings that contain these characters with the following restrictions:</p>

<ul>
<li>a character may not occur multiple times (<code>aab</code>, <code>aba</code>, <code>abca</code> etc. is invalid)</li>
<li>a character may be excluded (<code>ab</code> is valid even if <code>c</code> is not present; <code>a</code> is also valid even if <code>b</code> and <code>c</code> are not present)</li>
</ul>

<p>I can use </p>

<pre><code>[''.join(p) for p in permutations('abc')]
</code></pre>

<p>to generate all strings that contain <code>a</code>, <code>b</code> and <code>c</code>. However I have to also do</p>

<pre><code>[''.join(p) for p in permutations('ab')]
[''.join(p) for p in permutations('ac')]
[''.join(p) for p in permutations('bc')]
</code></pre>

<p>As you can probably tell if the initial list of available characters is long I need to do a lot of work. So I'm looking for an elegant way in Python to generate all of the above with just the list of allowed characters as input:</p>

<pre><code>def generate(vals=['a', 'b', 'c']):
  # The initial list of allowed characters also has to be part of the 
  # final list since these also represent valid values
  res = vals
  # Generate all possible strings and store in res

  return res
</code></pre>

<p>I need this since I want to provide a parameter for a POST request for my web server, where a parameter (let's call it <code>val</code>) can take different unique values (either single characters or a combination of those) in order to trigger some data generation. The list of available values will grow over time so I'd like to make it easier to process the request by automating the check if the given values for <code>val</code> is a valid one.</p>

<p>I've been also thinking of iterating through each element of the list of allowed characters and concatenating it the rest ('a', 'ab', 'ac', 'abc', 'b', 'ba', 'bc' etc.) but I have no idea how to do that.</p>
","1559401","","","How to generate all combinations of a set of characters without repetitions?","<python><python-2.7>","3","2","2056"
"49053392","2018-03-01 15:43:38","1","","<p>If all you're doing to creating a dictionary, just use the <code>create dictionary</code> keyword. However, if you want to create your own keyword which takes a variable number of keyword arguments, use a dictionary as the argument:</p>

<pre><code>My Keyword
    [Arguments]  &amp;{args}

    [Return]  ${args}
</code></pre>

<p>This keyword will return a dictionary made up of the keys and values passed in to the keyword</p>
","7432","","","0","431","Bryan Oakley","2008-09-15 13:43:53","242164","25962","12755","11112","49046397","","2018-03-01 09:21:24","0","617","<p>How to create dictionary when keyword does not know how many args?</p>

<p>I wrote below code, And I want dictionary</p>

<pre><code>${aaaaa} = {'A':'aaa', 'B':'bbb', 'C':'ccc'}
${bbbbb} = {'A':'aaa', 'B':'bbb', 'C':'ccc', 'D': 'ddd'}
</code></pre>

<p>Where should I change My Keyword?</p>

<pre><code>*** Settings ***
Library       Collections

*** Test Cases ***
Test AAA
    ${aaaaa}    My Keyword    A=aaa    B=bbb    C=ccc
    ${bbbbb}    My Keyword    A=aaa    B=bbb    C=ccc    D=ddd

*** Keywords ***
My Keyword
    [Arguments]    @{args}
    ${resp}    Create Dictionary    ${args}
    [Return]    ${resp}
</code></pre>
","5939036","5939036","2018-03-01 09:34:58","Robot Framework how to create dictionary with unknown number of keys?","<python><robotframework>","1","3","633"
"49053407","2018-03-01 15:44:01","1","","<p>You can use recursion with a generator expression:</p>

<pre><code>def permutation(s, current = []):
   if len(current) == len(s):
      yield current
   else:
      yield current
      for i in s:
        if current.count(i) == 0:
            for h in permutation(s, current + [i]):
               yield h

print(map(''.join, list(permutation(['a', 'b', 'c']))[1:]))
</code></pre>

<p>Output:</p>

<pre><code>['a', 'ab', 'abc', 'ac', 'acb', 'b', 'ba', 'bac', 'bc', 'bca', 'c', 'ca', 'cab', 'cb', 'cba']
</code></pre>
","7326738","","","0","521","Ajax1234","2016-12-21 16:39:57","49079","3709","2930","360","49053216","49053674","2018-03-01 15:35:04","4","849","<p>I have the following list:</p>

<pre><code>['a', 'b', 'c']
</code></pre>

<p>I'm looking into a way to generate all possible strings that contain these characters with the following restrictions:</p>

<ul>
<li>a character may not occur multiple times (<code>aab</code>, <code>aba</code>, <code>abca</code> etc. is invalid)</li>
<li>a character may be excluded (<code>ab</code> is valid even if <code>c</code> is not present; <code>a</code> is also valid even if <code>b</code> and <code>c</code> are not present)</li>
</ul>

<p>I can use </p>

<pre><code>[''.join(p) for p in permutations('abc')]
</code></pre>

<p>to generate all strings that contain <code>a</code>, <code>b</code> and <code>c</code>. However I have to also do</p>

<pre><code>[''.join(p) for p in permutations('ab')]
[''.join(p) for p in permutations('ac')]
[''.join(p) for p in permutations('bc')]
</code></pre>

<p>As you can probably tell if the initial list of available characters is long I need to do a lot of work. So I'm looking for an elegant way in Python to generate all of the above with just the list of allowed characters as input:</p>

<pre><code>def generate(vals=['a', 'b', 'c']):
  # The initial list of allowed characters also has to be part of the 
  # final list since these also represent valid values
  res = vals
  # Generate all possible strings and store in res

  return res
</code></pre>

<p>I need this since I want to provide a parameter for a POST request for my web server, where a parameter (let's call it <code>val</code>) can take different unique values (either single characters or a combination of those) in order to trigger some data generation. The list of available values will grow over time so I'd like to make it easier to process the request by automating the check if the given values for <code>val</code> is a valid one.</p>

<p>I've been also thinking of iterating through each element of the list of allowed characters and concatenating it the rest ('a', 'ab', 'ac', 'abc', 'b', 'ba', 'bc' etc.) but I have no idea how to do that.</p>
","1559401","","","How to generate all combinations of a set of characters without repetitions?","<python><python-2.7>","3","2","2056"
"49053425","2018-03-01 15:44:58","0","","<p>My try. Very simple for with a temporary string as reference during the loop.</p>

<pre><code>s = 'abbcccd'
new = ''
temp = ''
for i, letter in enumerate(s):
    if i == 0:
        temp += letter
        continue
    if letter == temp[-1]:
        temp += letter
    elif letter != temp[-1]:
        new += temp[-1]
        if len(temp) &gt; 1:
            new += str(len(temp))
            temp = letter

new += temp[-1]
if len(temp) &gt; 1:
    new += str(len(temp))
</code></pre>

<p>as result you should get:</p>

<pre><code>print (s)
&gt;&gt;&gt;'ab2c3d'
</code></pre>
","8683073","8683073","2018-03-02 09:26:27","0","577","el_Rinaldo","2017-09-27 12:44:43","525","34","21","3","49046227","","2018-03-01 09:10:39","-5","57","<p>Suppose I am having the string ""abbcccd"" then it should show ""ab2c3d""
Likewise I need to get the output?</p>
","8931031","","","Count the consecutive letter in a string if the value 1 is there then it should be empty?","<python>","1","2","112"
"49053442","2018-03-01 15:46:24","0","","<p>S, X and T are all scalar. I am assuming you want to plot a vector against vector.</p>

<p>I think you are trying to do this:</p>

<pre><code>import math
import matplotlib.pyplot as mpl
import numpy as np

Q = 13.6
m_e = 9.11e-31
k = 8.6e-5
c = 3e8
eta = 4e-10
S=[]
X=[]
for T in np.arange(3000,4500):
    tmp=3.84*eta*((k*T)/(m_e*c**2))**(3/2)*(Q/(k*T))
    S.append(tmp)
    X.append((-1 + np.sqrt(1+(4*tmp)))/(2*tmp))

%matplotlib inline

mpl.plot(S, X)
mpl.show()
</code></pre>
","4877653","4877653","2018-03-01 15:51:36","0","485","Ankit Malik","2015-05-08 05:26:48","75","19","2","0","49053296","","2018-03-01 15:38:38","0","36","<p>I'm sure this question has been asked numerous times before but alas I cannot find the correct answer. I'm trying to plot really simple code however when it executes the final result is just an empty graph. Code below:</p>

<pre><code>import math
import matplotlib.pyplot as mpl
import numpy as np

Q = 13.6
m_e = 9.11e-31
k = 8.6e-5
c = 3e8
eta = 4e-10

for T in np.arange(3000,4500):

    S = 3.84*eta*((k*T)/(m_e*c**2))**(3/2)*(Q/(k*T))
    X = (-1 + np.sqrt(1+(4*S)))/(2*S)

%matplotlib inline

mpl.plot(S, T)
mpl.show()
</code></pre>

<p>I realise that is the way with code it's probably a very trivial answer but I can't find the problem. Thanks in advance for any help!</p>
","9429743","5851928","2018-03-01 15:45:42","Python3 [Jupyter] code is not showing data on graph","<python><matplotlib><physics>","3","2","684"
"49053484","2018-03-01 15:48:39","1","","<p>I found the solution . The example here really helps..
<a href=""http://effbot.org/zone/tkinter-window-size.htm"" rel=""nofollow noreferrer"">LINK</a> </p>

<p>The format of frames in the window was like following</p>

<p>[Frame CON]  -[Frame Header]  -[Frame Content] -[Content Canvas] > [/Frame CON]</p>

<p>I binded on_change function to self.CON ; container frame since the container frame will change each time CON content changed.</p>

<pre><code>self.CON.bind(""&lt;Configure&gt;"", self.on_change)
</code></pre>

<p>I changed on_change function to :</p>

<pre><code>def on_change(self,event):
    self.Content.configure(scrollregion=self.Content.bbox(""all""))
    self.Content.configure(height=self.CON.winfo_height()-60)
</code></pre>

<p>So on an event, on_change event gets the height of CON container frame and applies height-60 to canvas each time CON changed.</p>

<p>This really worked for the scrollbar to be resize when content created...</p>

<p>Also added an event handler to the root window ..This will resize the scrollbar when the window size changes.</p>

<pre><code>self.bind('&lt;Configure&gt;', self.on_change)
</code></pre>

<p>Seems like everything works fine now ...</p>
","7685914","7685914","2018-03-02 02:57:36","0","1196","user7685914","2017-03-09 17:15:29","38","34","4","0","49052789","","2018-03-01 15:14:47","0","51","<p>I create a simple application interface in python with tkinter.</p>

<p><em>[you can run the code]</em></p>

<p>It has 2 frames inside [self.CON] frame.
Frame one is for header [self.HeaderFrame] and second frame [self.CFrame] is a dynamically populated list inside scrolling canvas [self.Content]. 
Since the number of items in scrolling canvas [self.Content] will change, I need to resize the canvas each time list was populated or window resized.</p>

<pre><code>from tkinter import *
import tkinter.font as font
from PIL import Image, ImageTk

class wmGUI (object):    
    def __init__ (self,tittle,itemnum):
        self.tittle=tittle

        self.GUI = wmWINDOW(self.tittle,itemnum)


class wmWINDOW(Tk):    
    windowwidth,windowheight,sliderresizer = 250,600,100

    def __init__ (self,tittle,itemnum):
        super().__init__()    
        WW = self.winfo_screenwidth()
        WH = self.winfo_screenheight()
        print('WW : %d &amp; WH : %d' % (WW,WH))
        geometry = '{width}x{height}+{pos_x}+{pos_y}'.format(height=WH, width=self.windowwidth, pos_y=0, pos_x=WW-self.windowwidth-20)
        self.geometry(geometry)
        self.configure(background='grey')
        self.title(""GUI"")
        self.itemnum=itemnum
        self.resizable(width=False, height=True)
        self.attributes('-topmost',True)
        self.CreateMenus()
        self.Myfont= font.Font(family=""Arial"", size=8, weight=font.NORMAL)
        self.Myfont2 = font.Font(family=""Helvetica"", size=9, weight=font.BOLD)
        self.Myfont3 = font.Font(family=""Helvetica"", size=7, weight=font.BOLD)
        self.CON=Frame(self,width=self.windowwidth,height=WH)
        self.MakeHeader()
        self.MakeContent()
        self.CON.pack(fill=BOTH, expand=YES)
        self.RUN()

    def MakeHeader (self):

        self.HeaderFrame= Frame(self.CON, width=self.windowwidth,height=60, background='Blue',borderwidth=0 )
        self.HeaderFrame.propagate(1)
        hImage = Image.open(""images/header.jpg"")
        headerImage=ImageTk.PhotoImage(hImage, width= self.windowwidth, height=60)
        self.headerLabel=Label(self.HeaderFrame,image=headerImage, width= self.windowwidth, height=60, borderwidth=0, highlightthickness=0)
        self.headerLabel.image=headerImage
        self.headerLabel.pack( )
        self.HeaderFrame.pack( padx=0,pady=0,ipadx=0,ipady=0)

    def MakeContent (self):

        self.CFrame = Frame(self.CON, width=self.windowwidth,bg=""cyan"")
        self.Content = Canvas(self.CFrame, width=self.windowwidth-15, bg=""green"",borderwidth=0, highlightthickness=0)
        self.ContentFrame = Frame(self.Content, bg=""#EBEBEB"",height=100)
        self.Content.create_window(0, 0, window=self.ContentFrame, anchor='nw')
        self.ContentFrame.bind(""&lt;Configure&gt;"", self.on_change)
        self.Items()
        self.CScrollbar = Scrollbar(self.CFrame, orient=VERTICAL , width=15)
        self.CScrollbar.config(command=self.Content.yview)
        self.Content.config(yscrollcommand=self.CScrollbar.set)
        self.CScrollbar.grid(row=0, column=1, sticky=""ns"")
        self.Content.grid(row=0, column=0, sticky=""nsew"")
        self.CFrame.pack(fill=BOTH, expand=YES)
        self.Content.configure(height=self.CON.winfo_reqheight() - 60)

    def on_change(self,event):
        self.Content.configure(scrollregion=self.Content.bbox(""all""))

    def Items(self):
        for n in range(self.itemnum):
                LabelFrame(self.ContentFrame, text='Example Item {}'.format(n) , font=self.Myfont3, bg=""yellow"", fg=""black"",width=self.windowwidth,height=40).grid()

    def RUN (self):
        self.mainloop()

    def CreateMenus(self):
        #MAIN MENUBAR
        MenuBar = Menu(self) #Creates Menu bar
        self.config(menu=MenuBar)

        # FILE MENU
        FileMenu=Menu(MenuBar,tearoff=0)
        FileMenu.add_command(label=""Open"",command=None) #command=bewritten
        FileMenu.add_command(label=""Close"",command=None)  
        FileMenu.add_separator()  
        FileMenu.add_command(label=""Reset"",  accelerator=""Ctrl + Shift + r"")  
        FileMenu.add_separator()
        FileMenu.add_command(label=""Quit"", command= None,accelerator=""Ctrl q"") 
        MenuBar.add_cascade(label=""File"",menu=FileMenu)

WMGUI=wmGUI('My Window',50)
</code></pre>

<p>I assume to resize the canvas [self.Content] <strong>I should retrieve the window inner height.</strong> But I can not find a method for it.
How can i do this ?</p>
","7685914","3938208","2018-05-03 18:40:23","Python Tkinter AutoResizing scrolling Canvas in window","<python><tkinter><scroll><tkinter-canvas>","1","0","4447"
"49053529","2018-03-01 15:50:29","1","","<p>Try</p>

<pre><code>import numpy as np
x = np.array([[ 1.    ,  2.    ,  3.    ],
       [ 1.    ,  2.    ,  3.    ],
       [ 1.    ,  0.98  ,  0.9895],
       [ 0.98  ,  1.    ,  0.9817],
       [ 0.9895,  0.9817,  1.    ],
       [ 4.    ,  2.2965,  2.624 ],
       [ 2.2965,  4.    ,  2.3426],
       [ 2.624 ,  2.3426,  4.    ]])

x1 = x[2:,:]

x2 = x1.reshape(2,3,3)

CC ,FZ = x2
</code></pre>

<p>Result:</p>

<pre><code>In [23]: CC
Out[23]: 
array([[ 1.    ,  0.98  ,  0.9895],
       [ 0.98  ,  1.    ,  0.9817],
       [ 0.9895,  0.9817,  1.    ]])

In [24]: FZ
Out[24]: 
array([[ 4.    ,  2.2965,  2.624 ],
       [ 2.2965,  4.    ,  2.3426],
       [ 2.624 ,  2.3426,  4.    ]])
</code></pre>
","2817602","","","2","708","Demetri Pananos","2013-09-26 01:47:37","2557","325","151","34","49052934","49053529","2018-03-01 15:22:06","1","37","<p>So I have a file that looks something like this: </p>

<pre><code># 3  # Number of network ROIs
# 2  # Number of netcc matrices
# WITH_ROI_LABELS
    001             002              003
      1               2                3
# CC
  1.0000          0.9800          0.9895
  0.9800          1.0000          0.9817
  0.9895          0.9817          1.0000
# FZ
  4.0000          2.2965          2.6240
  2.2965          4.0000          2.3426
  2.6240          2.3426          4.0000
</code></pre>

<ul>
<li>I want to extract the 3x3 matrix labelled ""CC"" </li>
<li>I want to extract the 3x3 matrix labelled ""FZ"" </li>
</ul>

<p>So I did the following: </p>

<pre><code>file=/users/3dfile1
A= numpy.genfromtxt(file)
m= A[:,:]
m
</code></pre>

<p>So the output I get looks like this: </p>

<pre><code>array([[ 1.    ,  2.    ,  3.    ],
       [ 1.    ,  2.    ,  3.    ],
       [ 1.    ,  0.98  ,  0.9895],
       [ 0.98  ,  1.    ,  0.9817],
       [ 0.9895,  0.9817,  1.    ],
       [ 4.    ,  2.2965,  2.624 ],
       [ 2.2965,  4.    ,  2.3426],
       [ 2.624 ,  2.3426,  4.    ]])
</code></pre>

<p>However, my question is... if I have multiple files. Where the matrix size is NOT CONSISTENT.  This means that in some files the matrix will be 3x3, some files 8x8, 1x1, etc. In this case, how can I code something that will:</p>

<ul>
<li>differentiate the matrix CC from FZ </li>
<li>extract the matrix (can detect the size of matrix somehow and give me the exact matrix I'm looking for)</li>
</ul>
","8138398","2147347","2018-03-01 15:39:42","How can I extract two separate matrices from a file?","<python><numpy><matrix>","1","11","1509"
"49053536","2018-03-01 15:50:49","1","","<p>You are not doing anything with the values you create in the for loop. Therefore, when you come to plot, you just have 1 value of <code>S</code> and <code>X</code> and <code>T</code>, therefore, your graph will be empty.</p>

<p>One way to fix this would be to append the values into a list which you can then pass to a call to <code>plot</code>:</p>

<pre><code>Q = 13.6
m_e = 9.11e-31
k = 8.6e-5
c = 3e8
eta = 4e-10

S_list = []
X_list = []

for T in np.arange(3000,4500):

    S = 3.84*eta*((k*T)/(m_e*c**2))**(3/2)*(Q/(k*T))
    X = (-1 + np.sqrt(1+(4*S)))/(2*S)
    S_list.append(S)
    X_list.append(X)
</code></pre>

<p>I'm not sure if you actually want to plot the values of <code>S</code> against <code>T</code>, but if you do, then you would do something like:</p>

<pre><code>mpl.plot(S_list, np.arange(3000,4500))
mpl.show()
</code></pre>

<p>Which gives something like:</p>

<p><a href=""https://i.stack.imgur.com/ad54w.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ad54w.png"" alt=""enter image description here""></a></p>

<p><strong>Edit:</strong></p>

<p>You don't actually need to do any loops here, <code>numpy</code> can handle the complete calculation:</p>

<pre><code>T = np.arange(3000,4500)

S = 3.84*eta*((k*T)/(m_e*c**2))**(3/2)*(Q/(k*T))
X = (-1 + np.sqrt(1+(4*S)))/(2*S)

mpl.plot(S, T)
mpl.show()
</code></pre>

<p>Would give you the same figure</p>
","5851928","5851928","2018-03-01 16:03:48","2","1399","DavidG","2016-01-28 12:17:14","13142","1875","1418","8903","49053296","","2018-03-01 15:38:38","0","36","<p>I'm sure this question has been asked numerous times before but alas I cannot find the correct answer. I'm trying to plot really simple code however when it executes the final result is just an empty graph. Code below:</p>

<pre><code>import math
import matplotlib.pyplot as mpl
import numpy as np

Q = 13.6
m_e = 9.11e-31
k = 8.6e-5
c = 3e8
eta = 4e-10

for T in np.arange(3000,4500):

    S = 3.84*eta*((k*T)/(m_e*c**2))**(3/2)*(Q/(k*T))
    X = (-1 + np.sqrt(1+(4*S)))/(2*S)

%matplotlib inline

mpl.plot(S, T)
mpl.show()
</code></pre>

<p>I realise that is the way with code it's probably a very trivial answer but I can't find the problem. Thanks in advance for any help!</p>
","9429743","5851928","2018-03-01 15:45:42","Python3 [Jupyter] code is not showing data on graph","<python><matplotlib><physics>","3","2","684"
"49053557","2018-03-01 15:51:36","1","","<p>This might help.</p>

<pre><code># -*- coding: utf-8 -*-

d = [{'grade': '1', 'past_student_sum': 1611},
 {'grade': '2', 'past_student_sum': 1631},
 {'grade': '3', 'past_student_sum': 1598},
 {'grade': '1', 'current_student_sum': 1611},
 {'grade': '2', 'current_student_sum': 1631},
 {'grade': '3', 'current_student_sum': 1598}]

e = {}
for i in d:
    if i[""grade""] not in e:
        e[i[""grade""]] = i
    else:
        if i.get(""current_student_sum"", None):
            e[i[""grade""]].update({""current_student_sum"": i[""current_student_sum""]})

print [i[1] for i in e.items()]
</code></pre>

<p><strong>Output</strong>:</p>

<pre><code>[{'grade': '1', 'current_student_sum': 1611, 'past_student_sum': 1611}, {'grade': '3', 'current_student_sum': 1598, 'past_student_sum': 1598}, {'grade': '2', 'current_student_sum': 1631, 'past_student_sum': 1631}]
</code></pre>
","532312","","","0","867","Rakesh","2010-12-06 13:07:54","56694","5302","758","1508","49053435","49053663","2018-03-01 15:45:42","1","220","<p>I have a list of dictionaries as follows</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611}, 
 {'grade': '2', 'past_student_sum': 1631}, 
 {'grade': '3', 'past_student_sum': 1598}, 
 {'grade': '1', 'current_student_sum': 1611}, 
 {'grade': '2', 'current_student_sum': 1631}, 
 {'grade': '3', 'current_student_sum': 1598}]
</code></pre>

<p>I got this list by combining 2 query sets in the following fashion:</p>

<pre><code>grade_list = list(past_enrollments) + list(current_enrollments)
</code></pre>

<p>Is there a better alternatives to combine these in such a way to get a list that looks like this:</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611, 'current_student_sum': 1621},
 {'grade': '2', 'past_student_sum': 1511, 'current_student_sum': 1521}]
</code></pre>
","6168639","6906028","2018-03-01 15:49:43","Group a large list of dictionaries by key value in django","<python><django>","6","2","788"
"49053573","2018-03-01 15:52:16","2","","<p>Here's one solution using a dict to group and merge the records by <code>grade</code>:</p>

<pre><code>from collections import defaultdict

grade_map = defaultdict(dict)
for grade_info in grade_list:
    grade_map[grade_info['grade']].update(grade_info)
print(list(grade_map.values()))
</code></pre>
","219640","219640","2018-03-01 15:59:36","3","303","Erik Cederstrand","2009-11-26 19:18:18","4341","563","380","21","49053435","49053663","2018-03-01 15:45:42","1","220","<p>I have a list of dictionaries as follows</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611}, 
 {'grade': '2', 'past_student_sum': 1631}, 
 {'grade': '3', 'past_student_sum': 1598}, 
 {'grade': '1', 'current_student_sum': 1611}, 
 {'grade': '2', 'current_student_sum': 1631}, 
 {'grade': '3', 'current_student_sum': 1598}]
</code></pre>

<p>I got this list by combining 2 query sets in the following fashion:</p>

<pre><code>grade_list = list(past_enrollments) + list(current_enrollments)
</code></pre>

<p>Is there a better alternatives to combine these in such a way to get a list that looks like this:</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611, 'current_student_sum': 1621},
 {'grade': '2', 'past_student_sum': 1511, 'current_student_sum': 1521}]
</code></pre>
","6168639","6906028","2018-03-01 15:49:43","Group a large list of dictionaries by key value in django","<python><django>","6","2","788"
"49053619","2018-03-01 15:54:18","2","","<p>You get this problem because variable 'text' type is string after you read data from the file. You need to convert data type.  </p>

<p>Here is the working code:</p>

<pre><code>from collections import Counter
import ast

f = open(""POS.txt"", ""r"")
text = f.read()
# print(type(text)) returns string


text = ast.literal_eval(text)
# print (type(text)) returns list

counts = Counter(tag for word, tag in text)
print(counts)
</code></pre>
","4450090","4450090","2018-03-01 16:11:49","1","440","szerszen","2015-01-13 16:26:31","789","203","96","17","49053567","49053619","2018-03-01 15:52:05","0","35","<p>i use python 2.7 and i try to find how each of the POS in my file occur i write this code :</p>

<pre><code>     from collections import Counter
     f = open(""POS.txt"",""r"")
     text = f.read()
     print(text)
     counts = Counter(tag for word,tag in text)
     print(counts)
</code></pre>

<p>and the output was as here :</p>

<pre><code>      File ""C:/Python27/Lib/countPOS.py"", line 10, in &lt;genexpr&gt;
      counts = Counter(tag for word,tag in text)
      ValueError: need more than 1 value to unpack
</code></pre>

<p>How to solve this error ? and this is the input in my file: </p>

<pre><code> [(u'\u0627', 'JJ'), (u'\u0644', 'NNP'), (u'\u062d', 'NNP'), (u'\u064e', 
 'NNP'), (u'\u0631', 'NNP'), (u'\u0652', 'NNP'), (u'\u0628', 'NNP'), 
 (u'\u064f', 'NN')]
</code></pre>
","9288931","1255289","2018-10-10 22:24:01","How to solve ValueError: need more than 1 value to unpack?","<python><count>","1","7","788"
"49053621","2018-03-01 15:54:24","2","","<p>Well, one way would be a decorator that implements <code>*</code> and so on for functions:</p>

<pre><code>class composable:
    def __init__(self, func):
        self.func = func

    def __call__(self, *args, **kwargs):
        return self.func(*args, **kwargs)

    def __mul__(self, other):
        if callable(other):
            def wrapper(*args, **kwargs):
                return self(*args, **kwargs) * other(*args, **kwargs)
            return self.__class__(wrapper)
        return NotImplemented

@composable
def f(x):
    return 2 * x

@composable
def g(x):
    return x + 1

h = f * g # (2*x) * (x+1)
print(h(2))
# 12
</code></pre>

<p>You would need to add similar definitions for <code>__add__</code>, <code>__sub__</code>, <code>__div__</code> and probably for the reverse methods <code>__rmul__</code> and so on.</p>
","4042267","4042267","2018-03-01 15:59:48","2","838","Graipher","2014-09-15 11:02:12","5186","486","1152","21","49052689","","2018-03-01 15:10:20","4","136","<p>I have a given function</p>

<pre><code>def unnorm(x, alpha, beta):
    return (1 + alpha * x + beta * x ** 2)
</code></pre>

<p>Which I then integrate to find a normalization constant for in a range, and turn it to a lambda function that takes the same parameters as <code>unnorm</code>. Now, to create a fit-able object, I combine the functions like this:</p>

<pre><code>def normalized(x, alpha, beta):
    return unnorm(x, alpha, beta) * norm(x, alpha, beta)
</code></pre>

<p>Which is nice and all, but there's still repetition and pulling names from the global namespace.</p>

<p>How can I combine the two functions in a cleaner fashion, without having to re-write parameters? E.g</p>

<pre><code>def normalized(func, normalizer):
    return func * normalizer
</code></pre>

<p>Full code:</p>

<pre><code>import sympy
import numpy as np
import inspect

def normalize_function(f, xmin, xmax):
    """"""
    Normalizes function to PDF in the given range
    """"""
    # Get function arguments
    fx_args = inspect.getfullargspec(f).args
    # Convert to symbolic notation
    symbolic_args = sympy.symbols(fx_args)
    # Find definite integral
    fx_definite_integral = sympy.integrate(f(*symbolic_args), (symbolic_args[0], xmin, xmax))
    # Convert to a normalization multiplication term, as a real function
    N = sympy.lambdify(expr = 1 / fx_definite_integral, args = symbolic_args)
    return N

def unnorm(x, alpha, beta):
    return (1 + alpha * x + beta * x ** 2)

norm = normalize_function(unnorm, -1, 1)

# How do I condense this to a generic expression?
def normalized(x, alpha, beta):
    return unnorm(x, alpha, beta) * norm(x, alpha, beta)

x = np.random.random(100)

print(normalized(x, alpha = 0.5, beta = 0.5))
</code></pre>
","7026806","7026806","2018-03-01 15:17:22","How can I combine two functions that take the same arguments?","<python>","2","2","1748"
"49053628","2018-03-01 15:54:51","4","","<p>You can get it from <code>play</code> object, and you can access that inside <code>on_play_start</code>.</p>

<p>Like this:</p>

<pre><code>def v2_playbook_on_play_start(self, play):
    vm = play.get_variable_manager()
    extra_vars = vm.extra_vars
    self.run_id = extra_vars['runID']
</code></pre>

<p>And then, when you dump your results somewhere in <code>on_stats</code> (for example), you can refer <code>self.run_id</code> to access your <code>runID</code> extra variable.</p>
","2795592","","","1","490","Konstantin Suvorov","2013-09-19 13:14:39","43854","3534","223","249","49052942","49053628","2018-03-01 15:22:30","1","321","<p>I'm trying to write a callback plugin that will time each task. That wasn't the tough part.
But I've a series of playbooks that run to provision and configure an instance. For each run of a sequence, I want to pass a runID to each playbook and that runID is constant for one run, something like this:</p>

<pre><code>ansible-playbook -e ""runID=seq198837"" provision.yml
ansible-playbook -e ""runID=seq198837"" build.yml
ansible-playbook -e ""runID=seq198837"" deploy.yml
</code></pre>

<p>The callback plugin I'm writing has to collect time information for each task in a plugin, label them with the runID and deposit them to a logging agent.</p>

<p>I've tried several hooks and events in the callback plugin but am unable to get the runID extra argument passed to the playbook. Is there any way to access that variable?</p>
","225499","","","In Ansible, how to access extra arguments supplied to playbook in callback plugins?","<python><ansible>","1","0","824"
"49053629","2018-03-01 15:54:56","9","","<p>I was surprised to see there is no code sample for <a href=""https://github.com/mstamy2/PyPDF2"" rel=""nofollow noreferrer"">PyPDF2</a> when the questions is explicitly asking for PyPDF2, so here it is:</p>

<pre><code>from PyPDF2 import PdfFileReader, PdfFileWriter

fin = open('source.pdf', 'rb')
reader = PdfFileReader(fin)
writer = PdfFileWriter()

writer.appendPagesFromReader(reader)
metadata = reader.getDocumentInfo()
writer.addMetadata(metadata)

# Write your custom metadata here:
writer.addMetadata({
    '/Some': 'Example'
})

fout = open('result.pdf', 'wb')
writer.write(fout)

fin.close()
fout.close()
</code></pre>
","330867","633961","2019-08-21 14:36:16","1","629","Cyril N.","2010-05-02 15:24:00","25226","1537","3787","17","46849733","46910796","2017-10-20 13:06:16","2","3656","<p>I want to add a metadata key-value pair to the metadata of a pdf file.</p>

<p>I found a several years old answer, but I think this is way to complicated. I guess there is an easier way today: <a href=""https://stackoverflow.com/a/3257340/633961"">https://stackoverflow.com/a/3257340/633961</a></p>

<p>I am not married with pypdf2, if there is an easier way, then I go this way?</p>
","633961","633961","2017-11-01 11:42:39","Change metadata of pdf file with pypdf2","<python><pdf><pypdf2><pdf-manipulation>","4","0","385"
"49053648","2018-03-01 15:55:41","3","","<p>Like some commentators stated, there is no easy a resilient way to do this in pure Python with only asyncIO, but with the <strong>apscheduler</strong> library it becomes actually quite easy.</p>

<pre><code>from apscheduler.schedulers.asyncio import AsyncIOScheduler
import asyncio
import os

def tick():
    print('Tick! The time is: %s' % datetime.datetime.now())


if __name__ == '__main__':
    scheduler = AsyncIOScheduler()
    scheduler.add_job(tick, 'cron', minute='*')
    scheduler.start()
    print('Press Ctrl+{0} to exit'.format('Break' if os.name == 'nt' else 'C'))

    # Execution will block here until Ctrl+C (Ctrl+Break on Windows) is pressed.
    try:
        asyncio.get_event_loop().run_forever()
    except (KeyboardInterrupt, SystemExit):
        pass
</code></pre>
","865662","","","0","792","jbssm","2011-07-27 14:44:03","3444","217","100","9","49035403","49053648","2018-02-28 17:31:07","3","716","<p>I'm trying to run several functions at the same time (approximately or course) with different parameters and repeat that at the start of every minute.</p>

<p>I managed to get an <code>asyncio</code> example to run where I get a function <code>callback</code> to run at specific times with a different parameter, but what I can't figure out is how to run it (and keep running it forever) at very specific times (i.e. I want to run it at the start of every minute, so at 19:00:00, 19:01:00, etc..).</p>

<p>Asyncio <code>call_at</code> should be able to do that, but it uses a time format that is not the standard python time format and I can't figure out to specify that time format as the 00 seconds of the next minute.</p>

<pre><code>import asyncio
import time


def callback(n, loop, msg):
    print(msg)
    print('callback {} invoked at {}'.format(n, loop.time()))


async def main(loop):
    now = loop.time()
    print('clock time: {}'.format(time.time()))
    print('loop  time: {}'.format(now))

    print('registering callbacks')
    loop.call_at(now + 0.2, callback, 1, loop, 'a')
    loop.call_at(now + 0.1, callback, 2, loop, 'b')
    loop.call_soon(callback, 3, loop, 'c')

    await asyncio.sleep(1)


event_loop = asyncio.get_event_loop()
try:
    print('entering event loop')
    event_loop.run_until_complete(main(event_loop))
finally:
    print('closing event loop')
    event_loop.close()
</code></pre>
","865662","","","Using asyncio to run a function at the start (00 seconds) of every minute","<python><python-asyncio>","3","0","1427"
"49053663","2018-03-01 15:56:06","5","","<p>Instead of building a list of dictionaries from <code>past_enrollments</code> and <code>current_enrollments</code>, I would instead build  another dictionary using the <code>grade</code> value as a key.  The easiest way to do this would probably be with a <a href=""https://docs.python.org/3/library/collections.html#collections.defaultdict"" rel=""noreferrer""><code>defaultdict</code></a></p>

<pre><code>from collections import defaultdict
from itertools import chain

grades = defaultdict(dict)

for d in chain(past_enrollments, current_enrollments):
    grades[d['grade']].update(d)
</code></pre>

<p>Then our finished dictionaries are just the values of that dictionary</p>

<pre><code>grades = list(grades.values())
print(grades)
# [{'grade': '1', 'past_student_sum': 1611, 'current_student_sum': 1611}, 
#  {'grade': '2', 'past_student_sum': 1631, 'current_student_sum': 1631}, 
#  {'grade': '3', 'past_student_sum': 1598, 'current_student_sum': 1598}]
</code></pre>
","6779307","","","3","974","Patrick Haugh","2016-08-31 14:38:46","36209","4654","2715","1256","49053435","49053663","2018-03-01 15:45:42","1","220","<p>I have a list of dictionaries as follows</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611}, 
 {'grade': '2', 'past_student_sum': 1631}, 
 {'grade': '3', 'past_student_sum': 1598}, 
 {'grade': '1', 'current_student_sum': 1611}, 
 {'grade': '2', 'current_student_sum': 1631}, 
 {'grade': '3', 'current_student_sum': 1598}]
</code></pre>

<p>I got this list by combining 2 query sets in the following fashion:</p>

<pre><code>grade_list = list(past_enrollments) + list(current_enrollments)
</code></pre>

<p>Is there a better alternatives to combine these in such a way to get a list that looks like this:</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611, 'current_student_sum': 1621},
 {'grade': '2', 'past_student_sum': 1511, 'current_student_sum': 1521}]
</code></pre>
","6168639","6906028","2018-03-01 15:49:43","Group a large list of dictionaries by key value in django","<python><django>","6","2","788"
"49053674","2018-03-01 15:56:39","1","","<p>There are correct answers already been posted but I wanted to give it a shot, made it as readable as I can.</p>

<pre><code>from itertools import permutations as p

def gen(lst):
    y = [[a for a in p(lst,y)] for y in range(1,len(lst)+1)]

    this = []
    for i in y:
        while len(i)&gt;0:
            this.append(i.pop())
    return [''.join(x) for x in this]

print(gen(['a','b','c']))
</code></pre>
","8291840","8291840","2018-03-01 16:17:10","2","413","Işık Kaplan","2017-07-11 19:57:28","1547","224","20","23","49053216","49053674","2018-03-01 15:35:04","4","849","<p>I have the following list:</p>

<pre><code>['a', 'b', 'c']
</code></pre>

<p>I'm looking into a way to generate all possible strings that contain these characters with the following restrictions:</p>

<ul>
<li>a character may not occur multiple times (<code>aab</code>, <code>aba</code>, <code>abca</code> etc. is invalid)</li>
<li>a character may be excluded (<code>ab</code> is valid even if <code>c</code> is not present; <code>a</code> is also valid even if <code>b</code> and <code>c</code> are not present)</li>
</ul>

<p>I can use </p>

<pre><code>[''.join(p) for p in permutations('abc')]
</code></pre>

<p>to generate all strings that contain <code>a</code>, <code>b</code> and <code>c</code>. However I have to also do</p>

<pre><code>[''.join(p) for p in permutations('ab')]
[''.join(p) for p in permutations('ac')]
[''.join(p) for p in permutations('bc')]
</code></pre>

<p>As you can probably tell if the initial list of available characters is long I need to do a lot of work. So I'm looking for an elegant way in Python to generate all of the above with just the list of allowed characters as input:</p>

<pre><code>def generate(vals=['a', 'b', 'c']):
  # The initial list of allowed characters also has to be part of the 
  # final list since these also represent valid values
  res = vals
  # Generate all possible strings and store in res

  return res
</code></pre>

<p>I need this since I want to provide a parameter for a POST request for my web server, where a parameter (let's call it <code>val</code>) can take different unique values (either single characters or a combination of those) in order to trigger some data generation. The list of available values will grow over time so I'd like to make it easier to process the request by automating the check if the given values for <code>val</code> is a valid one.</p>

<p>I've been also thinking of iterating through each element of the list of allowed characters and concatenating it the rest ('a', 'ab', 'ac', 'abc', 'b', 'ba', 'bc' etc.) but I have no idea how to do that.</p>
","1559401","","","How to generate all combinations of a set of characters without repetitions?","<python><python-2.7>","3","2","2056"
"49053688","2018-03-01 15:57:17","0","","<p>You information looks a lot like json and that's what the API is returning. If that's the case, and you are turning it into a dictionary, then you might me better off using python's json library or even panda's built it read_json format. </p>

<p><a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html"" rel=""nofollow noreferrer"">Pandas read json</a></p>

<p><a href=""https://docs.python.org/2/library/json.html"" rel=""nofollow noreferrer"">Python's json</a></p>
","3271569","","","1","494","randyjp","2014-02-04 15:54:46","39","5","18","0","49052687","49057668","2018-03-01 15:10:18","0","427","<pre><code>Dict = {'Things' : {'Car':'Lambo', 'Home':'NatureVilla', 'Gadgets':{'Laptop':{'Programs':{'Data':'Excel', 'Officework': 'Word', 'Coding':{'Python':'PyCharm', 'Java':'Eclipse', 'Others': 'SublimeText'}, 'Wearables': 'SamsungGear', 'Smartphone': 'Nexus'}, 'clothes': 'ArmaaniSuit', 'Bags':'TravelBags'}}}}



d = {(i,j,k,l,m,n): Dict[i][j][k][l][m][n]
     for i in Dict.keys()
     for j in Dict[i].keys()
     for k in Dict[j].keys()
     for l in Dict[k].keys()
     for m in Dict[l].keys()
     for n in Dict[n].keys()
     }

mux = pd.MultiIndex.from_tuples(d.keys())
df = pd.DataFrame(list(d.values()), index=mux)
print (df)
</code></pre>

<p><strong>What I have already done:</strong>
I tried to Multiindex this Irregular Data using pandas but I am getting KeyError at 'Car'. Then I tried to handle exceptions and tried to PASS it but then it results in a Syntax Error. So May be I lost the direction. If there is any other module or way I can index this irregular data and put it in a table somehow. I have a chunk of raw data like this.</p>

<p><strong>What I am trying to do:</strong>
I wanted to use this data for printing in QTableView which is from PyQt5 (Making a program with GUI). </p>

<p><strong>Conditions:</strong>
This Data keeps on updating every hour from an API.</p>

<p><strong>What I have thought till now:</strong>
May be I can append all this data to MySQL. But then when this data updates from API, only Values will change, rest of the KEYS will be the same. But then It will require more space.</p>

<p><strong>References:</strong>
<a href=""https://stackoverflow.com/questions/41278428/how-to-convert-a-3-level-dictionary-to-a-desired-format?noredirect=1&amp;lq=1"">How to convert a 3-level dictionary to a desired format?</a></p>

<p><a href=""https://stackoverflow.com/questions/47416113/how-to-build-a-multiindex-pandas-dataframe-from-a-nested-dictionary-with-lists?noredirect=1&amp;lq=1"">How to build a MultiIndex Pandas DataFrame from a nested dictionary with lists</a></p>

<p>Any Help will be appreciated. Thanks for reading the question. </p>
","9429073","","","How to convert Multilevel Dictionary with Irregular Data to Desired Format","<python><pandas><dictionary><dataframe><qtableview>","2","0","2088"
"49053701","2018-03-01 15:58:02","0","","<pre><code>import math
import matplotlib.pyplot as mpl
import numpy as np

Q = 13.6
m_e = 9.11e-31
k = 8.6e-5
c = 3e8
eta = 4e-10
x=[]
t=[]
for T in np.arange(3000,4500):
    S = 3.84*eta*((k*T)/(m_e*c**2))**(3/2)*(Q/(k*T))
    X = (-1 + np.sqrt(1+(4*S)))/(2*S)
    x.append(X)
    t.append(T)

mpl.plot(x,t)
mpl.show()
</code></pre>
","2597213","","","0","334","efirvida","2013-07-18 20:50:53","2405","352","1885","15","49053296","","2018-03-01 15:38:38","0","36","<p>I'm sure this question has been asked numerous times before but alas I cannot find the correct answer. I'm trying to plot really simple code however when it executes the final result is just an empty graph. Code below:</p>

<pre><code>import math
import matplotlib.pyplot as mpl
import numpy as np

Q = 13.6
m_e = 9.11e-31
k = 8.6e-5
c = 3e8
eta = 4e-10

for T in np.arange(3000,4500):

    S = 3.84*eta*((k*T)/(m_e*c**2))**(3/2)*(Q/(k*T))
    X = (-1 + np.sqrt(1+(4*S)))/(2*S)

%matplotlib inline

mpl.plot(S, T)
mpl.show()
</code></pre>

<p>I realise that is the way with code it's probably a very trivial answer but I can't find the problem. Thanks in advance for any help!</p>
","9429743","5851928","2018-03-01 15:45:42","Python3 [Jupyter] code is not showing data on graph","<python><matplotlib><physics>","3","2","684"
"49053708","2018-03-01 15:58:24","0","","<p>You can hold <code>start_time</code> in session, and check it after post request was made:</p>

<pre><code>@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST':
        time_diff = time.clock() - session.get('start_time', 0)
        print time_diff

    session['start_time'] = time.clock()
    return render_template('index.html')
</code></pre>

<p>Otherwise this verable will be lost after every request.</p>
","9365820","","","1","447","dodd0ro","2018-02-15 16:03:49","132","10","153","0","49032259","","2018-02-28 14:47:23","0","369","<p>I would like to measure time a user needs to take a decision (or just pressing the ""submit"" button in this case). In the python itself I normally measure the time of code with</p>

<pre><code>start_time = time.clock()
time_diff = start_time - time.clock()
</code></pre>

<p>However, in the web application I can't wrap my head around how it should work.</p>

<pre><code>@app.route('/survey')
def main():
    user = request.cookies.get('user')
if not user:
    return redirect(url_for('login'))
    msg = ''
    word = request.args.get('word')
    score = request.args.get('score')
start_time = time.clock()
if score:
    time_diff = start_time - time.clock()
    record_to_csv(user, word, score, time_diff)
return render_template(
    'main.html',
    self_url=url_for('main'),
    word=choice(words),
    msg=msg,
)
</code></pre>

<p>My first idea was just to put start_time before ""if score"" and then measure the time right after. But somehow I always get the same time of -4.10546782348e-07. So I wonder if the problem is that I fail to put the time measurement on the right place in the loop or if it is a completely wrong approach. Any comments are very appreciated.</p>
","5672618","","","Measure time between submits in Flask","<python><flask><time>","2","2","1179"
"49053726","2018-03-01 15:59:06","0","","<p>Here's what I have so far:</p>

<pre><code>import re
rawtext = 'TABLE OF CONTENTS 1 TRANSACTION OVERVIEW 10 1.1 Structure diagram 10 1.2 Risk factors 10 1.3 Principal parties 11 1.4 Notes 12 1.5 Credit structure 18 1.6 Portfolio information 19 1.7 Portfolio documentation 23 1.8 General 29 2 RISK FACTORS 31 '
print(rawtext)
matches = re.finditer(r'(\d+(?:\.\d+)?)\s+(\D*?)\s+(\d+)', rawtext)
for m in matches:
   print((m[1], m[2], m[3]))

# output
# TABLE OF CONTENTS 1 TRANSACTION OVERVIEW 10 1.1 Structure diagram 10 1.2 Risk factors 10 1.3 Principal parties 11 1.4 Notes 12 1.5 Credit structure 18 1.6 Portfolio information 19 1.7 Portfolio documentation 23 1.8 General 29 2 RISK FACTORS 31
# ('1', 'TRANSACTION OVERVIEW', '10')
# ('1.1', 'Structure diagram', '10')
# ('1.2', 'Risk factors', '10')
# ('1.3', 'Principal parties', '11')
# ('1.4', 'Notes', '12')
# ('1.5', 'Credit structure', '18')
# ('1.6', 'Portfolio information', '19')
# ('1.7', 'Portfolio documentation', '23')
# ('1.8', 'General', '29')
# ('2', 'RISK FACTORS', '31')
</code></pre>

<p>I just noticed your edits. Let me see if this even answers your question, and I'll append any edits to this answer.</p>

<p><strong>EDIT</strong>: Ok, I think this answers most of the question, at least from what I've interpreted. Now it's just an issue of organizing the data to however you see fit. <code>m[1]</code> is the section number, <code>m[2]</code> is the section name, and <code>m[3]</code> is the page number.</p>

<p><strong>EDIT</strong>: Also, to explain the regex pattern, it's basically in 3 parts:</p>

<ol>
<li><code>(\d+(?:\.\d+)?)</code> capture the section number which may be an integer or a decimal number</li>
<li><code>(\D*?)</code> capture 0 or more non-digits non greedy</li>
<li><code>(\d+)</code> capture the page number</li>
</ol>

<p><strong>EDIT</strong>: had a typo in my 1-3 explanation above. Note the <code>?</code> at the end of (1) <code>(?:\.\d+)?</code>. It means match 0 or 1, in other words, the optional floating point value</p>
","2630028","2630028","2018-03-01 17:43:23","1","2037","solstice333","2013-07-29 11:02:05","1591","115","747","4","49052931","49053726","2018-03-01 15:22:03","0","69","<p>I'm working with some text that follows a specific pattern (it's a Table of Contents) that I'm trying to extract. For example,</p>

<pre><code>rawtext = 'TABLE OF CONTENTS 1 TRANSACTION OVERVIEW 10 1.1 Structure diagram 10 1.2 Risk factors 10 1.3 Principal parties 11 1.4 Notes 12 1.5 Credit structure 18 1.6 Portfolio information 19 1.7 Portfolio documentation 23 1.8 General 29 2 RISK FACTORS 31 '
</code></pre>

<p>The text follows a specific pattern, namely: (Section Number) then (Section Name) and finally (Page Number).</p>

<p>I'm not very good with regular expressions but have cobbled together some checks to extract and put these variables in a dataframe.</p>

<p>This works fine for extracting the Section Name and Section Page (though I'm sure it could be improved), but I can't identify the Section Number using this method, since we can have both integers (e.g. '2' for the 'RISK FACTORS' section), decimals (e.g. '1.1' for the 'Structure diagram' section), or none at all (e.g. the 'TABLE OF CONTENTS' text has no section number preceding it).</p>

<p>I think a more efficient way would be to pass everything into a python function (re.match? re.findall?) and extract everything according to the pattern itself, i.e. NUMBERS OR DECIMALS (IF PRESENT) ; (Letters and spaces in between the letters) ; NUMBERS</p>

<p>So this would mean having an output like:</p>

<pre><code>import pandas as pd
import re
import numpy as np
toc = pd.DataFrame()
toc['SectionName'] = re.findall(r'[A-Za-z-]+[ ]+[A-Za-z]*[ ]*[A-Za-z]*[ ]*[A-Za-z]*[ ]*[A-Za-z]*[ ]*[A-Za-z]*[ ]*', rawtext) # get the section names
toc['SectionPage'] = re.findall(r'[ ]+[0-9]*[ ]+', rawtext) # get the page numbers
toc.loc[1,'SectionNum'] = np.nan
toc.loc[1,'SectionNum'] = 1
toc.loc[2,'SectionNum'] = 1.1
toc.loc[3,'SectionNum'] = 1.2
toc.loc[4,'SectionNum'] = 1.3
toc.loc[5,'SectionNum'] = 1.4
toc.loc[6,'SectionNum'] = 1.5
toc.loc[7,'SectionNum'] = 1.6
toc.loc[8,'SectionNum'] = 1.7
toc.loc[9,'SectionNum'] = 1.8
toc.loc[10,'SectionNum'] = 2

toc = toc[['SectionNum', 'SectionName', 'SectionPage']]
print(toc)
</code></pre>

<p>I really can't manage this though; I've been trying for a few days now and have tried searching all over Stack Overflow but no luck (apologies if I've missed an obvious answer to this posted elsewhere). Would anyone have any thoughts or even advice to get further on the road to a solution?</p>

<p>Thank you so much in advance! </p>
","2679611","2679611","2018-03-01 15:57:42","Split string text following a specific pattern in Python","<python><regex><python-3.x>","2","4","2443"
"49053744","2018-03-01 16:00:00","0","","<p>In your dataframe it appears that 'Group' is in the index, the purpose of the index is to label each row.  Therefore, is unusual and uncommon to have blank row indexes.</p>

<p>You you could so this:</p>

<pre><code>df2.reset_index().set_index('Group', append=True).swaplevel(0,1,axis=0)
</code></pre>

<p>Or if you really must show blank row indexes you could do this, but you must change the dtype of the index to str.</p>

<pre><code>df1 = df.set_index('Group').astype(str)
df1.index = df1.index.where(~df1.index.duplicated(),[' '])
</code></pre>
","6361531","","","1","553","Scott Boston","2016-05-20 14:04:14","71354","3229","5259","200","49053080","49053744","2018-03-01 15:28:59","0","295","<p>I have a table: <a href=""https://i.stack.imgur.com/ZP6Gx.png"" rel=""nofollow noreferrer"">Table</a></p>

<p>How would I roll up Group, so that the group numbers don't repeat? I don't want to pd.df.groupby, as I don't want to summarize the other columns. I just want to not repeat item labels, sort of like an Excel pivot table. </p>

<p>Thanks! </p>
","8785098","","","Python Pandas Don't Repeat Item Labels","<python><pandas>","1","2","351"
"49053752","2018-03-01 16:00:21","4","","<p>You can use <a href=""http://robotframework.org/robotframework/latest/libraries/BuiltIn.html#Return%20From%20Keyword"" rel=""nofollow noreferrer"">Return from keyword</a> or <a href=""http://robotframework.org/robotframework/latest/libraries/BuiltIn.html#Return%20From%20Keyword%20If"" rel=""nofollow noreferrer"">Return from keyword if</a> to return from the middle of a keyword.</p>

<h2>Example</h2>

<pre><code>*** Keywords ***
Is number even or odd?
    [Arguments]  ${number}
    log  number is ${number}
    Return from keyword if  int('${number}')%2 == 0  even
    Return from keyword  odd

*** Test cases ***
Test even number
    ${result}=  Is number even or odd?  4
    should be equal  ${result}  even

Test odd number
    ${result}=  Is number even or odd?  5
    should be equal  ${result}  odd
</code></pre>
","7432","","","0","818","Bryan Oakley","2008-09-15 13:43:53","242164","25962","12755","11112","49051972","49053752","2018-03-01 14:34:52","0","2036","<p>I want to return a value from a keyword and exit keyword, just like you would do it in a programming language when you return values from functions. The keyword selects a random item from the list on the page, but if the page contains only 1 item then the whole thing crashes. I can't come to a solution and this is what i've done atm:</p>

<pre><code>Get Random Item From Page
    # Pass the general list items xpath to the argument
    [Arguments]  ${element_path}
    ${elements}=  Get Element Count  ${element_path}
    Run Keyword If  ${elements} == 1  [Return]  ${element_path}[1]
    ${random}=  FakerLibrary.Random Int  1  ${elements}
    [Return]  ${element_path}[${random}]
</code></pre>

<p>The problem is that it continues to execute the keywords after the first return tag. What am i doing wrong?</p>
","6686406","7432","2018-03-01 16:02:20","RobotFramework - How to Return Value from Keyword and Stop?","<python><robotframework>","1","1","817"
"49053757","2018-03-01 16:00:44","1","","<p>This could help you.</p>

<pre><code>your_list = [
             {'grade': '1', 'past_student_sum': 1611},
             {'grade': '2', 'past_student_sum': 1631},
             {'grade': '3', 'past_student_sum': 1598},
             {'grade': '1', 'current_student_sum': 1611},
             {'grade': '2', 'current_student_sum': 1631},
             {'grade': '3', 'current_student_sum': 1598}
             ]



from itertools import groupby

result = []
key_func = lambda x: x['grade']

for i, j in groupby(sorted(your_list, key=key_func), key=key_func):
    group = {}
    for k in j:
        group.update(k)
    result.append(group)

print(result)
# [{'grade': '1', 'current_student_sum': 1611, 'past_student_sum': 1611}, {'grade': '2', 'current_student_sum': 1631, 'past_student_sum': 1631}, {'grade': '3', 'current_student_sum': 1598, 'past_student_sum': 1598}]
</code></pre>
","6699447","6699447","2018-03-01 16:06:54","0","879","Abdul Niyas P M","2016-08-10 09:05:34","2281","443","435","117","49053435","49053663","2018-03-01 15:45:42","1","220","<p>I have a list of dictionaries as follows</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611}, 
 {'grade': '2', 'past_student_sum': 1631}, 
 {'grade': '3', 'past_student_sum': 1598}, 
 {'grade': '1', 'current_student_sum': 1611}, 
 {'grade': '2', 'current_student_sum': 1631}, 
 {'grade': '3', 'current_student_sum': 1598}]
</code></pre>

<p>I got this list by combining 2 query sets in the following fashion:</p>

<pre><code>grade_list = list(past_enrollments) + list(current_enrollments)
</code></pre>

<p>Is there a better alternatives to combine these in such a way to get a list that looks like this:</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611, 'current_student_sum': 1621},
 {'grade': '2', 'past_student_sum': 1511, 'current_student_sum': 1521}]
</code></pre>
","6168639","6906028","2018-03-01 15:49:43","Group a large list of dictionaries by key value in django","<python><django>","6","2","788"
"49053758","2018-03-01 16:00:47","0","","<pre><code>rawtext = 'TABLE OF CONTENTS 1 TRANSACTION OVERVIEW 10 1.1 Structure diagram 10 1.2 Risk factors 10 1.3 Principal parties 11 1.4 Notes 12 1.5 Credit structure 18 1.6 Portfolio information 19 1.7 Portfolio documentation 23 1.8 General 29 2 RISK FACTORS 31 '

title = ""TABLE OF CONTENTS""

text = rawtext[20:]
wordList = text.split()

indexList = []
lessonList = []
pageList= []
lessonBlank = []
for element in wordList:

    if lessonBlank == []:
        lessonBlank.append(element)
        indexList.append(element)

    else:

        try:
            temp = float(element)

            pageList.append(int(element))
            lessonBlank = []

        except ValueError as e:

            lessonBlank.append(element)
            lessonList[-1] = lessonList[-1] + "" "" + element
</code></pre>
","7908770","","","0","805","Adi219","2017-04-23 09:50:18","3109","540","642","43","49052931","49053726","2018-03-01 15:22:03","0","69","<p>I'm working with some text that follows a specific pattern (it's a Table of Contents) that I'm trying to extract. For example,</p>

<pre><code>rawtext = 'TABLE OF CONTENTS 1 TRANSACTION OVERVIEW 10 1.1 Structure diagram 10 1.2 Risk factors 10 1.3 Principal parties 11 1.4 Notes 12 1.5 Credit structure 18 1.6 Portfolio information 19 1.7 Portfolio documentation 23 1.8 General 29 2 RISK FACTORS 31 '
</code></pre>

<p>The text follows a specific pattern, namely: (Section Number) then (Section Name) and finally (Page Number).</p>

<p>I'm not very good with regular expressions but have cobbled together some checks to extract and put these variables in a dataframe.</p>

<p>This works fine for extracting the Section Name and Section Page (though I'm sure it could be improved), but I can't identify the Section Number using this method, since we can have both integers (e.g. '2' for the 'RISK FACTORS' section), decimals (e.g. '1.1' for the 'Structure diagram' section), or none at all (e.g. the 'TABLE OF CONTENTS' text has no section number preceding it).</p>

<p>I think a more efficient way would be to pass everything into a python function (re.match? re.findall?) and extract everything according to the pattern itself, i.e. NUMBERS OR DECIMALS (IF PRESENT) ; (Letters and spaces in between the letters) ; NUMBERS</p>

<p>So this would mean having an output like:</p>

<pre><code>import pandas as pd
import re
import numpy as np
toc = pd.DataFrame()
toc['SectionName'] = re.findall(r'[A-Za-z-]+[ ]+[A-Za-z]*[ ]*[A-Za-z]*[ ]*[A-Za-z]*[ ]*[A-Za-z]*[ ]*[A-Za-z]*[ ]*', rawtext) # get the section names
toc['SectionPage'] = re.findall(r'[ ]+[0-9]*[ ]+', rawtext) # get the page numbers
toc.loc[1,'SectionNum'] = np.nan
toc.loc[1,'SectionNum'] = 1
toc.loc[2,'SectionNum'] = 1.1
toc.loc[3,'SectionNum'] = 1.2
toc.loc[4,'SectionNum'] = 1.3
toc.loc[5,'SectionNum'] = 1.4
toc.loc[6,'SectionNum'] = 1.5
toc.loc[7,'SectionNum'] = 1.6
toc.loc[8,'SectionNum'] = 1.7
toc.loc[9,'SectionNum'] = 1.8
toc.loc[10,'SectionNum'] = 2

toc = toc[['SectionNum', 'SectionName', 'SectionPage']]
print(toc)
</code></pre>

<p>I really can't manage this though; I've been trying for a few days now and have tried searching all over Stack Overflow but no luck (apologies if I've missed an obvious answer to this posted elsewhere). Would anyone have any thoughts or even advice to get further on the road to a solution?</p>

<p>Thank you so much in advance! </p>
","2679611","2679611","2018-03-01 15:57:42","Split string text following a specific pattern in Python","<python><regex><python-3.x>","2","4","2443"
"49053774","2018-03-01 16:01:31","0","","<p>I'm going to make up some data as it's easier to describe what's happening.</p>

<p>This is what I think your code is attempting to do and a much simpler alternative:</p>

<pre><code>import pandas as pd

df = pd.DataFrame([[1, 10, 5], [2, 20, 10], [1, 10, 15],
                   [3, 30, 20], [2, 20, 25], [1, 10, 30]],
                  columns=['asin', 'views_count', 'col'])

s = int(df.groupby(['asin', 'views_count']).sum().reset_index()['views_count'].sum())
# 60

t = df.drop_duplicates(['asin', 'views_count'])['views_count'].sum()
# 60
</code></pre>

<p>The first attempt is isolating data for unique <code>asin</code> &amp; <code>view_count</code> combinations via a <code>groupby</code>. To query the required column again, <code>reset_index</code> is called. Then the subtotals are summed one final time. But you can do the same by dropping duplicates rows.</p>
","9209546","9209546","2018-03-01 16:10:28","4","877","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49053494","49053774","2018-03-01 15:48:50","0","84","<p>For my task, I need to understand some Python Pandas Code in order to make some modification and reimplement it using another programming language(Java).
I took some online tutorials, but still have issues with Pandas. For example, this lines:</p>

<pre><code>uniq_page_df = df.groupby([""asin"", ""views_count""])
uniq_page_df = uniq_page_df.sum().reset_index()
sum_views_count = int(uniq_page_df[""views_count""].sum())
</code></pre>

<p>In this part, as I understand, author tries to calculate total views count. So my question is, why do we need to group by and calculate sum for each group(line 2) and then calculate overall sum(line 3)? Why we cannot calculate it without grouping by? Or I didn’t understand this part of code correctly.</p>

<p>Another question is, why do we need to <code>reset_index()</code> after calculating <code>sum()</code> on line 2?</p>

<p><strong>UPDATE</strong>: all columns in data frame are: asin, product_group, category_description, views_count</p>
","8541082","8541082","2018-03-01 16:09:47","Sum of grouped by data in Pandas (Python)","<python><pandas><dataframe>","2","0","985"
"49053823","2018-03-01 16:03:35","1","","<p>I prefer <a href=""https://stackoverflow.com/a/49053663/778533"">the answer by Patrick</a> myself. Are you allowed to use pandas? Then you can use <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.group_by.html"" rel=""nofollow noreferrer"">groupby</a> and <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_dict.html"" rel=""nofollow noreferrer"">to_dict</a>. Also needed are <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sum.html"" rel=""nofollow noreferrer"">sum</a> and <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html"" rel=""nofollow noreferrer"">reset_index</a>.</p>

<pre><code>import pandas as pd
df = pd.DataFrame(grade_list).groupby('grade').sum().reset_index().to_dict('records')
</code></pre>
","778533","778533","2018-03-01 16:12:30","0","843","tommy.carstensen","2011-05-31 23:47:33","4373","1624","1969","13","49053435","49053663","2018-03-01 15:45:42","1","220","<p>I have a list of dictionaries as follows</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611}, 
 {'grade': '2', 'past_student_sum': 1631}, 
 {'grade': '3', 'past_student_sum': 1598}, 
 {'grade': '1', 'current_student_sum': 1611}, 
 {'grade': '2', 'current_student_sum': 1631}, 
 {'grade': '3', 'current_student_sum': 1598}]
</code></pre>

<p>I got this list by combining 2 query sets in the following fashion:</p>

<pre><code>grade_list = list(past_enrollments) + list(current_enrollments)
</code></pre>

<p>Is there a better alternatives to combine these in such a way to get a list that looks like this:</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611, 'current_student_sum': 1621},
 {'grade': '2', 'past_student_sum': 1511, 'current_student_sum': 1521}]
</code></pre>
","6168639","6906028","2018-03-01 15:49:43","Group a large list of dictionaries by key value in django","<python><django>","6","2","788"
"49053835","2018-03-01 16:04:07","0","","<p>I took Parfait's advice and first concatenated both dataframes into one, then a coworker gave me a solution to iterate through the dataframe. The dataframe consisted of ~117M rows with ~246K person IDs. My coworker's solution was to create a dictionary where each key is a person ID, and the value for each key is a list of row indices for that person ID in the dataframe. You then use .iloc to slice the dataframe by referencing the values in the dictionary. Finished running in about one hour. </p>

<pre><code>idx = df1['person'].reset_index().groupby('person')['index'].apply(tuple).to_dict()

for i in range(ranges):
    mrn_slice = df1.iloc[list(idx.values()[i])]
</code></pre>
","5869388","","","0","687","Randy","2016-02-01 19:16:42","6","15","0","0","49011261","49053835","2018-02-27 14:39:50","0","425","<p>I have a list of person IDs, and for each ID, I want to extract all available information from two different dataframes. In addition, the types of information also have IDs, and I only want specific information IDs for each person ID. Here's how I'm currently doing this:</p>

<pre><code>    new_table = []
    for i in range(ranges):

        slice = pd.concat([df1[sp.logical_and(df1.person.values == persons[i],
                                                   df1['info_id'].isin(info_ids))],
                df2[sp.logical_and(df2.person.values == persons[i],
                                      df2['info_id'].isin(info_ids))]], ignore_index=True)

        if len(list(set(slice['info_ids']))) &lt; amount_of_info_needed:
                    continue
        else:
            full_time_range = max(slice['age_days']) - min(slice['age_days']) 
            if full_time_range &lt;= 1460:
                new_table.append(slice)
            else:
                window_end = min(slice['age_days']) + 1460
                slice = slice[slice.age_days &lt; window_end+1]
                if len(list(set(slice['info_id']))) &lt; amount_of_info_needed:
                    continue
                else:
                    new_table.append(slice)
    #return new_table
    new_table = pd.concat(new_table, axis=0)
    new_table = new_table.groupby(['person', 'info_id']).agg(np.mean).reset_index()
    new_table.to_sql('person_info_within4yrs', engine, if_exists='append', index=False, 
                 dtype={'person': types.NVARCHAR(32), 'value': types.NVARCHAR(4000)})
</code></pre>

<p>I read about not using pd.concat in a loop because of quadratic time, but I tried converting the dataframes to arrays and slicing and concatenating those, but that went even slower than using pd.concat. After profiling each line with %lprun, all of the time is being consumed with the pd.concat/logical_and operation in the loop. This code is also faster than using .loc with both dataframes and concatenating two slices together. After the if-else blocks, I append to a list and at the end, turn the list into a dataframe. </p>

<p>Edit: Here is an example of what I'm doing. The goal is to slice from both dataframes by person_id and info_id, combine the slices, and append the combined slice to a list, which I will then turn back into a dataframe and export to a SQL table. The if-else blocks are relevant too, but from my profiling they take barely any time at all so I'm not going to describe them in detail. </p>

<pre><code>df1.head()
    person  info_id value   age_days
0   000012eae6ea403ca564e87b8d44d0bb    0   100.0   28801
1   000012eae6ea403ca564e87b8d44d0bb    0   100.0   28803
2   000012eae6ea403ca564e87b8d44d0bb    0   100.0   28804
3   000012eae6ea403ca564e87b8d44d0bb    0   100.0   28805
4   000012eae6ea403ca564e87b8d44d0bb    0   100.0   28806

df2.head()
    person  info_id value   age_days
0   00000554787a3cb38131c3c38578cacf    4v  97.0    12726
1   00000554787a3cb38131c3c38578cacf    14v 180.3   12726
2   00000554787a3cb38131c3c38578cacf    9v  2.0 12726
3   00000554787a3cb38131c3c38578cacf    3v  20.0    12726
4   00000554787a3cb38131c3c38578cacf    0v  71.0    12726
</code></pre>
","5869388","5869388","2018-03-01 16:00:15","Fastest way to combine two slices from two pandas dataframes in a loop?","<python><pandas>","1","3","3219"
"49053866","2018-03-01 16:05:26","0","","<p>To your first question, it looks like the author is calculating two different things here - you're correct in saying this is redundant. Simply running <code>df['views_count'].sum()</code> would return the same values as the final line. </p>

<p>For the second question, when you preform a <code>groupby().sum()</code>, pandas returns a dataframe with the index being the keys that were used in the group - in this case, the index values would be <code>asin</code> and <code>views_count</code>. <code>reset_index()</code> will recreate a default index starting at 0, so that <code>views_count</code> and <code>asin</code> can be accessed and treated like normal columns. A better way of doing this might be: </p>

<pre><code>#To get total views:
sum_views_count = df['views_count'].sum()

#To get views by page:
unique_page_views = df.groupby(['asin', 'views_count']).sum()

#To get the original dataframe structure back
unique_page_views = unique_page_views.reset_index()
</code></pre>

<p>see <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html"" rel=""nofollow noreferrer"">https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html</a> and <a href=""https://pandas.pydata.org/pandas-docs/stable/indexing.html"" rel=""nofollow noreferrer"">https://pandas.pydata.org/pandas-docs/stable/indexing.html</a> for details.</p>
","7465457","","","0","1386","Gasvom","2017-01-24 18:44:17","141","2","9","0","49053494","49053774","2018-03-01 15:48:50","0","84","<p>For my task, I need to understand some Python Pandas Code in order to make some modification and reimplement it using another programming language(Java).
I took some online tutorials, but still have issues with Pandas. For example, this lines:</p>

<pre><code>uniq_page_df = df.groupby([""asin"", ""views_count""])
uniq_page_df = uniq_page_df.sum().reset_index()
sum_views_count = int(uniq_page_df[""views_count""].sum())
</code></pre>

<p>In this part, as I understand, author tries to calculate total views count. So my question is, why do we need to group by and calculate sum for each group(line 2) and then calculate overall sum(line 3)? Why we cannot calculate it without grouping by? Or I didn’t understand this part of code correctly.</p>

<p>Another question is, why do we need to <code>reset_index()</code> after calculating <code>sum()</code> on line 2?</p>

<p><strong>UPDATE</strong>: all columns in data frame are: asin, product_group, category_description, views_count</p>
","8541082","8541082","2018-03-01 16:09:47","Sum of grouped by data in Pandas (Python)","<python><pandas><dataframe>","2","0","985"
"49053921","2018-03-01 16:08:27","0","","<p>Try doing this:</p>

<pre><code>df.column_name = df.column_name.astype(float)
</code></pre>

<p>For reference see <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.astype.html"" rel=""nofollow noreferrer"">this</a></p>
","9210028","","","0","250","TrinTragula","2018-01-12 16:38:11","135","10","21","0","49053783","49054096","2018-03-01 16:01:47","3","748","<p>The main problem I have right now is that <a href=""https://github.com/pandas-dev/pandas/issues/13157"" rel=""nofollow noreferrer"">DataFrame.quantile() doesn't work with Decimals</a>.</p>

<p>I can convert my Dataframe to floats by using <code>df.convert_objects(convert_numeric=True)</code>, but this generates a deprecation warning and the suggested replacement <code>infer_objects()</code> doesn't work.</p>

<p>As an alternative, I could use <code>Dataframe.round</code> on my input data instead of converting them to Decimals. I assume that this should be safe for direct comparisons (I am indexing on a column to subtract two dataframes from each other, e.g. <code>df1.set_index('Time') - df2.set_index('Time')</code>) but I can't be certain.</p>
","9237121","","","How should I convert a Dataframe full of decimals to floats?","<python><pandas><dataframe>","3","0","753"
"49053920","2018-03-01 16:08:27","1","","<p>Okay, so I checked a little to update my rusty memory of pymongo, and here is what I found.</p>

<p>The correct query should be : </p>

<pre><code>db.ncollec.find({ 'status':""ok"", 
                  'articles.title' : { '$exists' : 'True' },
                  'articles.description' : { '$exists' : 'True' } })
</code></pre>

<p>Now, if you do this :</p>

<pre><code>query = { 'status' : ""ok"",
          'articles.title' : { '$exists' : 'True' },
          'articles.description' : { '$exists' : 'True' } }
for item in db.ncollect.find(query):
    print item
</code></pre>

<p>And that it doesn't show anything, the query is correct, but you don't have the right database, or the right tree, or whatever.</p>

<p>But I assure you, that with the database you showed me, that if you do...</p>

<pre><code>query = { 'status' : ""ok"",
          'articles.title' : { '$exists' : 'True' },
          'articles.description' : { '$exists' : 'True' } }
for item in db.ncollect.find(query):
    save.write(item[0]['title'])
    save.write(item[0]['description'])
</code></pre>

<p>It'll do what you wished to do in the first place.</p>

<p>Now, the key <code>item[0]</code> might not be good, but for this, I can't really be of any help since it is was you are showing on the screen. :)</p>

<hr>

<p>Okay, now. I have found something for you that is a bit more complicated, but is cool :)
But I'm not sure if it'll work for you. I suspect you're giving us a wrong tree, since when you do <code>.find( {'status' : 'ok'} )</code>, it doesn't return anything, and it should return <strong>all</strong> the documents with a <code>'status' : 'ok'</code>, and since you have lots...</p>

<p>Anyways, here is the query, that you should use with <strong><code>.aggregate()</code></strong> method, instead of <code>.find()</code> :</p>

<pre><code>elem = { '$match' : { 'status' : 'ok', 'articles.title' : { '$exists' : 'True'}, 'articles.description' : { '$exists' : 'True'}} }
[ elem, { '$unwind' : '$articles' }, elem ]
</code></pre>

<p>If you want an explanation as to how this works, I invite you to <a href=""https://stackoverflow.com/questions/3985214/retrieve-only-the-queried-element-in-an-object-array-in-mongodb-collection"">read this page</a>. </p>

<p>This query will return ONLY the elements in your array that have a title, and a description, with a status OK. If an element doesn't have a title, or a description, it will be ignored.</p>
","8003790","8003790","2018-03-02 08:28:20","6","2437","IMCoins","2017-05-12 15:45:09","2382","354","179","6","49051507","49053920","2018-03-01 14:10:25","0","51","<p>Here is my sample mongodb database </p>

<p><a href=""https://i.stack.imgur.com/iYdvY.png"" rel=""nofollow noreferrer"">database image for one object</a></p>

<p>The above is a database with an array of articles. I fetched only one object for simplicity purposes. </p>

<p><a href=""https://i.stack.imgur.com/rcp5N.png"" rel=""nofollow noreferrer"">database image for multiple objects ( max 20 as it's the size limit )</a></p>

<p>I have about 18k such entries.
I have to extract the <strong>description</strong> and <strong>title</strong> tags present inside the (articles and 0) subsections. 
The find() method is the question here.. i have tried this : </p>

<pre><code>for i in db.ncollec.find({'status':""ok""}, { 'articles.0.title' : 1 , 'articles.0.description' : 1}):
    for j in i:
        save.write(j)
</code></pre>

<p>After executing the code, the file <em>save</em> has this : </p>

<p>_id<br>
articles<br>
_id<br>
articles</p>

<p>and it goes on and on.. </p>

<p>Any help on how to print what i stated above? </p>

<p>My entire code for reference : </p>

<pre><code>    import json
    import newsapi
    from newsapi import NewsApiClient
    import pymongo
    from pymongo import MongoClient

    client = MongoClient()
    db = client.dbasenews
    ncollec = db.ncollec


    newsapi = NewsApiClient(api_key='**********')
    source = open('TextsExtractedTemp.txt', 'r')
    destination = open('NewsExtracteddict.txt', ""w"")
    for word in source:
        if word == '\n':
            continue
        all_articles = newsapi.get_everything(q=word, language='en', page_size=1)
        print(all_articles)
        json.dump(all_articles, destination)
        destination.write(""\n"")
        try:
            ncollec.insert(all_articles)
        except:
            pass
</code></pre>
","9405893","9405893","2018-03-02 03:48:38","How to use find() nested documents for two levels or more?","<python><sql><database><mongodb>","1","7","1795"
"49053930","2018-03-01 16:09:12","3","","<p>sst only supports Python 2 even though pip will let you install it for Python 3. The error <code>NameError: name 'StandardError' is not defined</code> is from sst trying to use the built in exception StandardError which was removed in Python 3. To resolve this, you can either use a different module (which I would recommend) or downgrade to Python 2.7.</p>
","2714050","","","0","361","Daniel O'Brien","2013-08-24 17:26:46","73","13","28","0","49053105","49053930","2018-03-01 15:30:30","1","1815","<p>I'm currently developing a website with the SST - Web Test Framework (i'm very beginner) but I have a problem with python</p>

<p>I used this Link: <a href=""https://pypi.python.org/pypi/sst/0.2.2"" rel=""nofollow noreferrer"">https://pypi.python.org/pypi/sst/0.2.2</a></p>

<p>I m using - Python 3.6.4 and SST - Web Test Framework- Latest Version: 0.2.4</p>

<p>My Code is:</p>

<pre><code>from sst.actions import *
go_to('http://www.google.com/')
</code></pre>

<p>Error is:</p>

<pre><code>C:\Python\scrapy-master\Projects&gt;python proxyhar.py
Traceback (most recent call last):
File ""proxyhar.py"", line 1, in &lt;module&gt;
from sst.actions import *
File ""C:\Python\lib\site-packages\sst\actions.py"", line 104, in &lt;module&gt;
class EndTest(StandardError):
NameError: name 'StandardError' is not defined
</code></pre>

<p>Anyone suggest me how to resolve this.</p>

<p>Thank you</p>
","2218510","","","Python : NameError: name 'StandardError' is not defined","<python><sst>","1","7","889"
"49053968","2018-03-01 16:11:06","0","","<p>Or try this:</p>

<pre><code>for c in df:
    df[c] = pd.to_numeric(df[c])
</code></pre>
","6694255","","","0","92","Marcus V.","2016-08-09 06:59:52","2703","118","399","73","49053783","49054096","2018-03-01 16:01:47","3","748","<p>The main problem I have right now is that <a href=""https://github.com/pandas-dev/pandas/issues/13157"" rel=""nofollow noreferrer"">DataFrame.quantile() doesn't work with Decimals</a>.</p>

<p>I can convert my Dataframe to floats by using <code>df.convert_objects(convert_numeric=True)</code>, but this generates a deprecation warning and the suggested replacement <code>infer_objects()</code> doesn't work.</p>

<p>As an alternative, I could use <code>Dataframe.round</code> on my input data instead of converting them to Decimals. I assume that this should be safe for direct comparisons (I am indexing on a column to subtract two dataframes from each other, e.g. <code>df1.set_index('Time') - df2.set_index('Time')</code>) but I can't be certain.</p>
","9237121","","","How should I convert a Dataframe full of decimals to floats?","<python><pandas><dataframe>","3","0","753"
"49053997","2018-03-01 16:13:00","0","","<p>You can use <code>np.where</code> with a numpy array. For your example:</p>

<pre><code>i = np.arange(23411)
label = np.where(i&lt;=7, 0, np.where(i&lt;=42, 1, 2))
</code></pre>
","4199257","","","0","181","fernandezcuesta","2014-10-30 16:14:57","1676","95","162","11","49052612","49052682","2018-03-01 15:06:59","0","62","<p>I have an empty list called 'label', where depending on which bucket is more appropriate, it will fill the 'label' list with 0,1,or 2. </p>

<p>'label' is associated to the 3 'buckets':</p>

<pre><code># Bucket 0: 0 -7 Days --------------------------&gt; 0
# Bucket 1: 1 - 6 Weeks (8 - 42 Days) ----------&gt; 1
# Bucket 2: 7+ Weeks (49+ Days) ----------------&gt; 2
</code></pre>

<p>I have another list has a length of 23411. This list's contents consist of 0 days to 1099 days. So based on this list's contents, it should populate the 'label' list. </p>

<p>I have tried this <code>for-loop</code> &amp; <code>if-else</code> statement to do what I want, however it is giving me a <code>IndexError: list assignment index out of range</code>:</p>

<pre><code>label = []
for i in range(23411):
    if ageNew[i] &lt;= 7:
        label[i] = 0
    elif ageNew[i] &lt;= 42:
        label[i] = 1
    else:
        label[i] = 2
</code></pre>

<p>For example:</p>

<pre><code>list: [0, 8, 14, 14, 45, 1056, 1]
label: [0, 1, 1, 1, 2, 2, 0]
</code></pre>
","8778033","8778033","2018-03-01 15:36:35","Making a list based on a criteria of another list","<python><list><for-loop><if-statement>","5","2","1049"
"49053998","2018-03-01 16:13:03","1","","<p>Python 3 has changed how this expression should be written.  <a href=""https://docs.python.org/3/reference/compound_stmts.html#the-try-statement"" rel=""nofollow noreferrer"">From the documentation</a>, it is now <code>except OSError as e</code>.</p>

<p>Note that in Python 2, <a href=""https://docs.python.org/2.7/reference/compound_stmts.html#the-try-statement"" rel=""nofollow noreferrer"">both comma and <code>as</code> were permitted</a>.</p>
","1079354","","","1","444","Makoto","2011-12-03 20:07:05","87085","18638","14499","15300","49053865","49053998","2018-03-01 16:05:25","-1","2291","<p>I'm currently developing a website with the SST - Web Test Framework (i'm very beginner) but I have a problem with python</p>

<p>I used this Link: <a href=""https://pypi.python.org/pypi/sst/0.2.2"" rel=""nofollow noreferrer"">https://pypi.python.org/pypi/sst/0.2.2</a></p>

<p>I m using - Python 3.6.4 and SST - Web Test Framework- Latest Version: 0.2.4</p>

<p>My Code is:</p>

<pre><code>from sst.actions import *
go_to('http://www.google.com/')
</code></pre>

<p>Error is:</p>

<pre><code>C:\Python\scrapy-master\Projects&gt;python proxyhar.py
Traceback (most recent call last):
File ""proxyhar.py"", line 1, in &lt;module&gt;
from sst.actions import *
File ""C:\Python\lib\site-packages\sst\actions.py"", line 274, in &lt;module&gt;
except OSError, e:
              ^
SyntaxError: invalid syntax
</code></pre>

<p>Anyone suggest me how to resolve this.</p>

<p>Thank you</p>
","2218510","5851928","2018-03-01 16:10:29","Python : except OSError, e:","<python><sst>","1","1","875"
"49054004","2018-03-01 16:13:15","0","","<p>This method of moving cv2.pyd no longer works with the recent version of Anaconda. Instead I did a reinstall and typed this into the Anaconda terminal:</p>

<pre><code>conda install -c conda-forge opencv 
</code></pre>

<p>Make sure your PATH is correct and that your <em>computer</em> terminal recognizes conda.</p>

<p><a href=""https://anaconda.org/conda-forge/opencv"" rel=""nofollow noreferrer"">https://anaconda.org/conda-forge/opencv</a></p>
","394842","","","0","448","Mia","2010-07-17 20:22:38","585","285","155","2","48751340","49054004","2018-02-12 16:40:58","0","2396","<p>I've followed this tutorial exactly (up to the copy and paste part):
<a href=""http://mathalope.co.uk/2015/05/07/opencv-python-how-to-install-opencv-python-package-to-anaconda-windows/"" rel=""nofollow noreferrer"">http://mathalope.co.uk/2015/05/07/opencv-python-how-to-install-opencv-python-package-to-anaconda-windows/</a></p>

<p>For whatever reason, even after copying the cv2.pyd file and pasting it into the Anaconda3 site-packages folder, I still am unable to get import cv to work.
When I call import cv, I keep getting this error:</p>

<pre><code>runfile('C:/Users/Mia/.spyder-py3/temp.py', wdir='C:/Users/Mia/.spyder-py3')
Traceback (most recent call last):

  File ""&lt;ipython-input-1-8ac32963ba13&gt;"", line 1, in &lt;module&gt;
    runfile('C:/Users/Mia/.spyder-py3/temp.py', wdir='C:/Users/Mia/.spyder-py3')

  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 710, in runfile
    execfile(filename, namespace)

  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 101, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""C:/Users/Mia/.spyder-py3/temp.py"", line 3, in &lt;module&gt;
    import cv2

ImportError: DLL load failed: The specified module could not be found.
</code></pre>

<p>It doesn't seem to recognize cv2.pyd even though it is in the Anaconda3 folder, is this due to an update or am I going about this the wrong way? I am not the admin of this computer and I believe Anaconda, python, and openCV were installed for all users, though I am not sure this makes a difference. </p>

<p>To be clear, there is not a folder labeled Anaconda, just Anaconda3. I figured this would  not make a difference, but now I am not too sure.</p>
","394842","394842","2018-03-05 16:20:53","OpenCV unable to import into Spyder","<python><opencv>","1","0","1763"
"49054058","2018-03-01 16:15:39","1","","<p>Just pass the actual objects as a tuple, without unpacking them:</p>

<pre><code>csv_que = Queue() 

# put arguments to the que which will be written later  
def write_row_to_que(self,*args, **kwargs):
    csv_que.put((args, kwargs))

# send each argument in the que to the write_row function with the arguments 
#from the que
def csv_writer_func():
    while True:
        args, kwargs = csv_que.get()
        write_row(args, kwargs)
</code></pre>
","4042267","","","1","452","Graipher","2014-09-15 11:02:12","5186","486","1152","21","49053956","49054177","2018-03-01 16:10:28","0","158","<p>So i have been using the *args **kwargs functionality in python for a while and I came across a problem that I can't seem to find a solution to in the documentation/here on stackoverflow. </p>

<p>I have a multithreaded job which sends requests to the server in parallel, and then does some analysis on the JSON that is returned. I need to write to a csv file a line for each request-response pair. </p>

<p>because this is done in parallel, it will be problematic to write to the csv in the threaded job function. The solution I came up with is to put the analysis result in a que as well and then make a function to grab it from the analysis from the que and write it to the csv in order. </p>

<p>Now to the the real problem:
the function that I have to write to the csv takes arguments and keyword arguments, but the que doesn't know how to handle that. </p>

<p>Is there a way to put *args **kwargs in a que then getting them one by one and passing them to another function? </p>

<p>I want something that would look like this:</p>

<pre><code>csv_que = Queue() 

# put arguments to the que which will be written later  
def write_row_to_que(self,*args, **kwargs):
    csv_que.put(*args, **kwargs)

# send each argument in the que to the write_row function with the arguments 
#from the que
def csv_writer_func():
    while True:
        args, kwargs = csv_que.get()
        write_row(args, kwargs)
</code></pre>

<p>I dont know if this is the right way to go about solving this but I would love to hear some thought and if this functionality (to pass arguments to a que and then pull them from it) is possible. </p>
","7217896","","","python *args **kwargs used in a que","<python><multithreading><python-2.7><kwargs>","2","0","1625"
"49054096","2018-03-01 16:17:24","5","","<p>You can apply <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_numeric.html"" rel=""noreferrer""><code>pd.to_numeric</code></a> to an entire dataframe:</p>

<pre><code>df = df.apply(pd.to_numeric, downcast='float')
</code></pre>
","9209546","","","2","254","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49053783","49054096","2018-03-01 16:01:47","3","748","<p>The main problem I have right now is that <a href=""https://github.com/pandas-dev/pandas/issues/13157"" rel=""nofollow noreferrer"">DataFrame.quantile() doesn't work with Decimals</a>.</p>

<p>I can convert my Dataframe to floats by using <code>df.convert_objects(convert_numeric=True)</code>, but this generates a deprecation warning and the suggested replacement <code>infer_objects()</code> doesn't work.</p>

<p>As an alternative, I could use <code>Dataframe.round</code> on my input data instead of converting them to Decimals. I assume that this should be safe for direct comparisons (I am indexing on a column to subtract two dataframes from each other, e.g. <code>df1.set_index('Time') - df2.set_index('Time')</code>) but I can't be certain.</p>
","9237121","","","How should I convert a Dataframe full of decimals to floats?","<python><pandas><dataframe>","3","0","753"
"49054121","2018-03-01 16:18:42","2","","<p>You can carefully pick the elements of the shape that you know to have a ""best of both worlds"" result:</p>

<pre><code>def my_get_shape(tensor):
    if tensor.shape.ndims is None:
        # Fully dynamic
        return tf.shape(tensor)
    if tensor.shape.is_fully_defined():
        # Fully static
        return tensor.shape
    # Partially static
    dyn_shape = tf.shape(tensor)
    shape = []
    for i, d in enumerate(tensor.shape):
        shape.append(d.value if d.value is not None else dyn_shape[i])
    return shape

def my_function(x, y):
    x_shape = my_get_shape(x)  # Or just tf.shape(x)! - see edit
    a = tf.reshape(y, x_shape)
    b = tf.zeros(x_shape)
    num_x_values = x_shape[0]
    c = tf.reshape(y, [num_x_values, 4])
    d = tf.zeros([num_x_values, 4])
    return a, b, c, d

# Fully static
with tf.Graph().as_default():
    x = tf.placeholder(tf.float32, [2, 4])
    y = tf.placeholder(tf.float32, [8])
    a, b, c, d = my_function(x, y)
print('a:', a.shape, ', b:', b.shape, ', c:', c.shape, ', d:', d.shape)
# a: (2, 4) , b: (2, 4) , c: (2, 4) , d: (2, 4)

# Fully dynamic
with tf.Graph().as_default():
    x = tf.placeholder(tf.float32)
    y = tf.placeholder(tf.float32)
    a, b, c, d = my_function(x, y)
print('a:', a.shape, ', b:', b.shape, ', c:', c.shape, ', d:', d.shape)
# a: &lt;unknown&gt; , b: &lt;unknown&gt; , c: (?, 4) , d: (?, 4)

# Partially static
with tf.Graph().as_default():
    x = tf.placeholder(tf.float32, [None, 4])
    y = tf.placeholder(tf.float32)
    a, b, c, d = my_function(x, y)
print('a:', a.shape, ', b:', b.shape, ', c:', c.shape, ', d:', d.shape)
# a: (?, 4) , b: (?, 4) , c: (?, 4) , d: (?, 4)
</code></pre>

<p><em>EDIT:</em></p>

<p>Actually, replacing <code>my_get_shape</code> with <code>tf.shape</code> in the previous snippet works exacly the same. It seems that <code>tf.shape</code> should be the default (being careful not to cram the graph with it) unless you explicitly want to keep dimensions undefined.</p>

<p>I have investigated a bit, and I couldn't work the whole thing out completely. I don't know if this is useful, but here are some things I found out. Apparently TensorFlow has, at C++ level (it seems it used to be in Python before, but not anymore), a ""shape inference"" mechanism. If you look, for example, in <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/array_ops.cc"" rel=""nofollow noreferrer""><code>tensorflow/core/ops/array_ops.cc</code></a>) you will see that every operation declaration includes a <code>.SetShapeFn</code> at the end, which is a function that uses <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/shape_inference.h"" rel=""nofollow noreferrer""><code>InferenceContext</code></a> to try to guess the output shape of the operation. This class can, among other things , check whether values in a tensor are already known, which is true for example for <code>tf.shape</code> when the given tensor is static or for <code>tf.fill</code> (and related like <code>tf.ones</code>) with known values. The resolution of the shape inference algorithm is what is set as tensor shape in Python, and it can be called directly (although I don't see how it can be useful) through <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/common_shapes.py"" rel=""nofollow noreferrer""><code>call_cpp_shape_fn</code></a>:</p>

<pre><code>from tensorflow.python.framework.common_shapes import call_cpp_shape_fn
with tf.Graph().as_default():
    print(call_cpp_shape_fn(tf.reshape(tf.placeholder(tf.float32), tf.fill([2], 3)).op))
    # Shows this:
    # {
    #   'shapes': [dim { size: 3 } dim { size: 3 }],
    #   'handle_data': [None],
    #   'inputs_needed': b'\x12\x01\x01'
    # }
    print(call_cpp_shape_fn(tf.reshape(tf.placeholder(tf.float32), (2 * tf.fill([2], 3))).op))
    # Shows this:
    # {
    #   'shapes': [dim { size: -1 } dim { size: -1 }],
    #   'handle_data': [None],
    #   'inputs_needed': b'\x12\x01\x01'
    # }
</code></pre>

<p>You can see that, while <code>tf.fill([2], 3)</code> was correctly inspected, TensorFlow didn't work out that <code>2 * tf.fill([2], 3)</code> is <code>[6, 6]</code>, presumably because statically keeping track of operations like multiplication, even if operands are known constants, was deemed too expensive.</p>

<p>What I haven't found out is where do ops declare that their values can be statically known, or where/how these values are retrieved exactly. It seems that, for example, for <code>tf.shape</code>, it is able to specifically pick known values and leave the rest as undefined.</p>
","1782792","1782792","2018-03-01 17:56:53","3","4657","jdehesa","2012-10-29 11:43:40","37080","2442","2562","26","49038854","49054121","2018-02-28 21:27:18","2","877","<p>I'm trying to write a chunk of reusable code that reads the shape of one tensor and then uses the resulting object to define the shape of other tensors. I have a choice of reading the dynamic shape of the tensor with <code>tf.shape(tensor)</code> or the static shape of the tensor with <code>tensor.get_shape()</code>. The toy example looks like this (with the two different strategies):</p>

<pre><code>def my_function_strategy_1(x, y):
    x_shape = tf.shape(x)
    a = tf.reshape(y, x_shape)
    b = tf.zeros(x_shape)
    num_x_values = x_shape[0]
    c = tf.reshape(y, [num_x_values, 4])
    d = tf.zeros([num_x_values, 4])
    return a, b, c, d

def my_function_strategy_2(x, y):
    x_shape = x.get_shape()
    a = tf.reshape(y, x_shape)
    b = tf.zeros(x_shape)
    num_x_values = x_shape[0]
    c = tf.reshape(y, [num_x_values, 4])
    d = tf.zeros([num_x_values, 4])
    return a, b, c, d
</code></pre>

<p>I want to use this chunk of code in different graphs. Sometimes the shape of the input tensors will be known and sometimes they will be unknown:</p>

<pre><code>graph_A = tf.Graph()
with graph_A.as_default():
    x = tf.placeholder(tf.float32, [2, 4])
    y = tf.placeholder(tf.float32, [8])
    a, b, c, d = my_function(x, y)

with graph_B.as_default():
    x = tf.placeholder(tf.float32)
    y = tf.placeholder(tf.float32)
    a, b, c, d = my_function(x, y)
</code></pre>

<p>The behavior I want is: (A) When the shapes of the input tensors are known (as in <code>graph_A</code>), I want TensorFlow to calculate all of the shapes in the graph at graph creation time (so it can efficiently allocate resources, etc.), and (B) When the shapes of the input tensors are unknown (as in <code>graph_B</code>), I want the TensorFlow to wait until runtime to calculate all of the shapes in the graph.</p>

<p>The <code>strategy_1</code> version of the function <em>almost</em> does this. It achieves (B), but it doesn't quite achieve (A) because TensorFlow leaves the shape of some tensors unknown. For example, in the toy example above, the shapes of <code>a</code>, <code>b</code>, and <code>c</code> are calculated at graph creation time, but the shape of <code>d</code> is left unknown (even though <code>d</code> uses very similar operations). You can check this by printing <code>a.get_shape()</code>, <code>b.get_shape()</code>, etc.</p>

<p>Conversely, the <code>strategy_2</code> version of the function achieves (A) for all tensors in the graph, but doesn't achieve (B) because TensorFlow (understandably) throws an exception when it tries to use the (unknown) static shape of the input tensor to shape other tensors.</p>

<p>Is there a way to achieve both (A) and (B) in a single function? How/why does the <code>strategy_1</code> version work for most tensors in the graph, but not all?</p>
","4440436","4440436","2018-03-01 15:58:34","Determining tensor shapes at time of graph creation in TensorFlow","<python><tensorflow>","1","9","2816"
"49054150","2018-03-01 16:20:04","2","","<p>It seems you are trying to write to either Letter size or Tabloid size according to the <a href=""http://xlsxwriter.readthedocs.io/page_setup.html#set_print_scale"" rel=""nofollow noreferrer"">documentation</a> </p>

<p>Your sizes correspond to the indices 1 &amp; 3</p>

<p>Try:</p>

<p><code>worksheet.set_paper(1)</code></p>

<p>Or</p>

<p><code>worksheet.set_paper(3)</code></p>

<p>Update: If you are trying to render the image on to screen, that would not work. In which case, you would need to use <code>worksheet.set_zoom(&lt;someIntegerVal&gt;)</code></p>
","1560708","","","0","564","Shahan M","2012-07-29 08:13:07","138","38","79","2","49053919","","2018-03-01 16:08:21","0","65","<p>Is there any way we can render data into excel/spreadsheet similar to page size 8""x11"" and 11""x17"" format using python.</p>

<p>On python- xlsxwriter package, using worksheet.set_paper() we have the option to set the page size using pagesetup function, but this is not rendering the output in 8""x11"" or 11""x17"" format.</p>

<p>Requirement - Need to render account details from table to excel sheet. As this sheet has more columns, user has to scroll right to view entire data. In order to reduce scrolling, an option is provided in a UI pop up to view data either in page size 8""x11"" and 11""x17"" before rendering data into excel.</p>

<p>I know,through excel we can reduce the zoom size &lt; 100, so that data can be viewed in single page. My question - is there any way we can reduce the size of cell data similar to 8""x11"" and 11""x17"" page layout without zoom effect in python?</p>

<p>Screenshot for reference
<a href=""https://i.stack.imgur.com/FTDWn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FTDWn.png"" alt=""Budget plan""></a>  </p>
","929894","929894","2018-03-02 09:05:07","can i export excel data in 8""x11"" and 11""x17"" size format using python","<python><xlsxwriter>","1","3","1064"
"49054177","2018-03-01 16:21:09","1","","<p>This mod should be enough to get you started:</p>

<pre><code>def write_row_to_que(self,*args, **kwargs):
    csv_que.put( (args, kwargs) )
</code></pre>

<p>Put the parameters into a tuple and the <code>get()</code> method at the other end will retrieve them.</p>

<pre><code>args, kwargs = csv_que.get()
</code></pre>

<p>This line will retrieve the items, but:</p>

<ol>
<li><code>args</code> will be a tuple of the unnamed arguments.</li>
<li><code>kwargs</code> will be a dictionary of the keyword arguments originally supplied.</li>
</ol>
","4834","","","0","548","quamrana","2008-09-05 20:27:56","15246","2075","2510","88","49053956","49054177","2018-03-01 16:10:28","0","158","<p>So i have been using the *args **kwargs functionality in python for a while and I came across a problem that I can't seem to find a solution to in the documentation/here on stackoverflow. </p>

<p>I have a multithreaded job which sends requests to the server in parallel, and then does some analysis on the JSON that is returned. I need to write to a csv file a line for each request-response pair. </p>

<p>because this is done in parallel, it will be problematic to write to the csv in the threaded job function. The solution I came up with is to put the analysis result in a que as well and then make a function to grab it from the analysis from the que and write it to the csv in order. </p>

<p>Now to the the real problem:
the function that I have to write to the csv takes arguments and keyword arguments, but the que doesn't know how to handle that. </p>

<p>Is there a way to put *args **kwargs in a que then getting them one by one and passing them to another function? </p>

<p>I want something that would look like this:</p>

<pre><code>csv_que = Queue() 

# put arguments to the que which will be written later  
def write_row_to_que(self,*args, **kwargs):
    csv_que.put(*args, **kwargs)

# send each argument in the que to the write_row function with the arguments 
#from the que
def csv_writer_func():
    while True:
        args, kwargs = csv_que.get()
        write_row(args, kwargs)
</code></pre>

<p>I dont know if this is the right way to go about solving this but I would love to hear some thought and if this functionality (to pass arguments to a que and then pull them from it) is possible. </p>
","7217896","","","python *args **kwargs used in a que","<python><multithreading><python-2.7><kwargs>","2","0","1625"
"49054290","2018-03-01 16:26:14","2","","<p>You are using the <a href=""https://www.tensorflow.org/programmers_guide/datasets#creating_an_iterator"" rel=""nofollow noreferrer"">initializable iterator</a> of <code>tf.Data</code> to feed data to your model. This means that you can parametrize the dataset in terms of placeholders, and then call an initializer op for the iterator to prepare it for use.</p>

<p>In case you use the initializable iterator, or any other iterator from <code>tf.Data</code> to feed inputs to your model, you should not use the <code>feed_dict</code> argument of <code>sess.run</code> to try to do data feeding. Instead, define your model in terms of the outputs of <code>iterator.get_next()</code> and omit the <code>feed_dict</code> from <code>sess.run</code>.</p>

<p>Something along these lines:</p>

<pre><code>iterator = dataset.make_initializable_iterator()
image_batch, label_batch = iterator.get_next()

# use get_next outputs to define model
model = Model(config, image_batch, label_batch) 

# placeholders fed in while initializing the iterator
sess.run(iterator.initializer, 
            feed_dict={images_placeholder: images,
                       labels_placeholder: labels})

for step in xrange(steps):
     # iterator will feed image and label in the background
     sess.run(model.optimize) 
</code></pre>

<p>The iterator will feed data to your model in the background, additional feeding via <code>feed_dict</code> is not necessary.</p>
","5471520","5471520","2018-03-02 09:23:53","4","1439","mikkola","2015-10-21 12:30:32","2565","397","1248","528","49053569","49054290","2018-03-01 15:52:06","3","726","<p>I am trying to feed minibatches of numpy arrays to my model, but I'm stuck with batching. Using 'tf.train.shuffle_batch' raises an error because the 'images' array is larger than 2 GB. I tried to go around it and create placeholders, but when I try to feed the the arrays they are still represented by tf.Tensor objects. My main concern is that I defined the operations under the model class and the objects don't get called before running the session. Does anyone have an idea how to handle this issue?</p>

<pre><code>def main(mode, steps):
  config = Configuration(mode, steps)



  if config.TRAIN_MODE:

      images, labels = read_data(config.simID)

      assert images.shape[0] == labels.shape[0]

      images_placeholder = tf.placeholder(images.dtype,
                                                images.shape)
      labels_placeholder = tf.placeholder(labels.dtype,
                                                labels.shape)

      dataset = tf.data.Dataset.from_tensor_slices(
                (images_placeholder, labels_placeholder))

      # shuffle
      dataset = dataset.shuffle(buffer_size=1000)

      # batch
      dataset = dataset.batch(batch_size=config.batch_size)

      iterator = dataset.make_initializable_iterator()

      image, label = iterator.get_next()

      model = Model(config, image, label)

      with tf.Session() as sess:

          sess.run(tf.global_variables_initializer())

          sess.run(iterator.initializer, 
                   feed_dict={images_placeholder: images,
                          labels_placeholder: labels})

          # ...

          for step in xrange(steps):

              sess.run(model.optimize)
</code></pre>
","7007828","7007828","2018-03-01 18:13:39","Tensorflow: create minibatch from numpy array > 2 GB","<python><tensorflow><training-data><tensorflow-datasets><mini-batch>","1","5","1693"
"49054292","2018-03-01 16:26:19","1","","<p>If you are on Linux,</p>

<ol>
<li>Clone the project :<a href=""https://github.com/cmusatyalab/openface"" rel=""nofollow noreferrer"">https://github.com/cmusatyalab/openface</a> </li>
<li>cd openface</li>
<li>python setup.py install</li>
<li>Then create an empty file named <code>__init__.py</code> inside the openface/ directory</li>
<li>Try running the demo command : ./demos/compare.py images/examples/{lennon*,clapton*}</li>
</ol>

<p><strong>Note</strong>: If the demo fails due to dependency issue, try to install those dependencies. Like in my case I had to install following as well</p>

<pre><code>luarocks install torch
luarocks install nn
luarocks install dpnn
</code></pre>
","3832614","","","0","685","appsdownload","2014-07-12 16:00:14","391","78","21","1","45102130","","2017-07-14 11:43:00","3","2940","<p>I installed openface using the <a href=""https://www.learnopencv.com/install-dlib-on-ubuntu/"" rel=""nofollow noreferrer"">link</a></p>

<p>But when i am importing openface in python it is giving an error </p>

<pre><code>./util/align-dlib.py ./home/admin1/Dhoni/ align outerEyesAndNose    ./aligned-images/ --size 96
Traceback (most recent call last):
File ""./util/align-dlib.py"", line 24, in &lt;module&gt;
import openface
ImportError: No module named openface
</code></pre>

<p>Please help me!!!!!</p>
","6477776","860421","2018-05-11 06:14:59","Error in importing openface","<python>","2","1","504"
"49054330","2018-03-01 16:27:52","0","","<p>Sholudn't Calculation be a string? When you do:</p>

<pre><code>Calculation=info4/0.1
</code></pre>

<p>you're dividing a StringVariable by 0.1. You should convert to a number, do the math, and then convert to String again</p>

<p>Actually, I'd suggest not using ""£"" or ""$"" or ""%"" on numeric fields and not using StringValue() for values that are clearly not intended to store Strings (if you want to do math to it, then it's not a String)</p>

<p>As for the csv file, check the Python's own <a href=""https://docs.python.org/2/library/csv.html"" rel=""nofollow noreferrer"">csv module</a>.</p>

<p>Quick example here</p>

<pre><code>import csv
with open('eggs.csv', 'wb') as csvfile:
    spamwriter = csv.writer(csvfile, delimiter=' ',
                            quotechar='|', quoting=csv.QUOTE_MINIMAL)
    spamwriter.writerow(['Spam'] * 5 + ['Baked Beans'])
    spamwriter.writerow(['Spam', 'Lovely Spam', 'Wonderful Spam'])
</code></pre>
","2403469","2403469","2018-03-01 16:39:11","3","943","Halogen II","2013-05-20 22:48:59","15","7","5","0","49053858","","2018-03-01 16:05:01","-1","25","<p>The below code is supposed to be a stock management system for a business so the user is able to change the price of goods that have stayed too long within the business (unable to sell)</p>

<pre><code>from tkinter import*
from tkinter import Tk, StringVar, ttk
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
import random
import datetime
import time;
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
start = Tk()
start.geometry(""100x600+0+0"")
start.title (""R.E.D Inventory Control System"")


#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Heading = Frame(start, width = 1000, height = 100, bd = 10, relief = 'raise')
Heading.pack(side = TOP)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
LowerHeading = Frame(start, width = 500, height  = 100, bd = 20, relief = 'raise')
LowerHeading.pack(side = BOTTOM)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
LMiddle = Frame(start, width = 500, height = 1000, bd = 12, relief = 'raise')
LMiddle.pack(side = LEFT)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
RMiddle = Frame(start, width = 500, height = 1000, bd = 12, relief = 'raise')
RMiddle.pack(side=RIGHT)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Title = Label(Heading, font=('arial',40,'bold'), text = ""R.E.D Inventory Control System"", bd = 10, width = 40, anchor = 'w')
          #justify = 'center')
Title.grid(row=0,column=0)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
info1=StringVar()
info2=StringVar()
info3=StringVar()
info4=StringVar()
info5=StringVar()
info6=StringVar()
info7=StringVar()
info8=StringVar()


info1.set("""")
info2.set("""")
info3.set("""")
info4.set("""")
info5.set("""")
info6.set("""")
info7.set("""")
info8.set("""")
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
def Product(event):
    if (info1.get()==""ID01""):
        info2.set(""Dress"")
        info3.set(""03/08/2016"")
        info4.set(""£8"")
        info5.set(""74"")
        info6.set(""Spring"")
        if (info7.get()==""10%""):
                Calculation=info4/0.1
                info8.set(Calculation)
</code></pre>

<p>1) The above code doesn't work as when the user clicks ""10%"" on the GUI the new price variable is supposed to change accordingly. Not only for 10% but for the other values too.</p>

<pre><code>    elif (info1.get()==""ID02""):
        info2.set(""Shoes"")
        info3.set(""25/03/2017"")
        info4.set(""£4"")
        info5.set(""24"")
        info6.set(""Spring"")
        if (info7.get()==""10%""):
                Calculation=info4/0.1
                info8.set(Calculation)
    elif (info1.get()==""ID03""):
        info2.set(""Belt"")
        info3.set(""16/08/2017"")
        info4.set(""£1.50"")
        info5.set(""36"")
        info6.set(""Spring"")
        if (info7.get()==""10%""):
                Calculation=info4/0.1
                info8.set(Calculation)
    elif (info1.get()==""ID04""):
        info2.set(""Blazer"")
        info3.set(""18/05/2016"")
        info4.set(""£18"")
        info5.set(""96"")
        info6.set(""Spring"")
        if (info7.get()==""10%""):
                Calculation=info4/0.1
                info8.set(Calculation)
    elif (info1.get()==""ID05""):
        info2.set(""Skirt"")
        info3.set(""27/06/2017"")
        info4.set(""£5"")
        info5.set(""47"")
        info6.set(""Spring"")
        if (info7.get()==""10%""):
                Calculation=info4/0.1
                info8.set(Calculation)

#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
ProductID = Label(LMiddle, font=('arial',12,'bold'),text = ""Product ID"", bd = 10, width = 15, anchor = 'w')
ProductID.grid(row=0,column=0)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
ProductsID = ttk.Combobox(LMiddle, textvariable = info1 ,state='readonly', font=('arial',12,'bold'),  width =20)
ProductsID['value']=('','ID01','ID02','ID03','ID04','ID05')
ProductsID.current(0)
ProductsID.grid(row=0,column=1)
ProductsID.bind(""&lt;&lt;ComboboxSelected&gt;&gt;"", Product)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Description1 = Label(LMiddle, font=('arial',12,'bold'),text =""Description"", bd = 10, width = 15, anchor = 'w')
Description1.grid(row=2,column=0)
Description2 = Label(LMiddle, font=('arial',12,'bold'), textvariable = info2, bd = 10, width = 18, relief = 'sunken')
Description2.grid(row=2,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
DateStockBought1 = Label(LMiddle, font=('arial',12,'bold'), text =""Date Stock Bought"", bd = 10, width = 15, anchor = 'w')
DateStockBought1.grid(row=3,column=0)
DateStockBought2 = Label(LMiddle, font=('arial',12,'bold'), textvariable = info3, bd = 10, width = 18, relief = 'sunken')
DateStockBought2.grid(row=3,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Price1 = Label(LMiddle, font=('arial',12,'bold'), text =""Price"", bd = 10, width = 15, anchor = 'w')
Price1.grid(row=4,column=0)
Price2 = Label(LMiddle, font=('arial',12,'bold'), textvariable = info4, bd = 10, width = 18, relief = 'sunken')
Price2.grid(row=4,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
AmountLeft1 = Label(RMiddle, font=('arial',12,'bold'), text =""Amount Left"", bd = 10, width = 15, anchor = 'w')
AmountLeft1.grid(row=1,column=0)
AmountLeft2 = Label(RMiddle, font=('arial',12,'bold'), textvariable = info5,bd = 10, width = 18, relief = 'sunken')
AmountLeft2.grid(row=1,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
CurrentSeason1 = Label(RMiddle, font=('arial',12,'bold'), text =""CurrentSeason"", bd = 10, width = 15, anchor = 'w')
CurrentSeason1.grid(row=2,column=0)
CurrentSeason2 = Label(RMiddle, font=('arial',12,'bold'), textvariable = info6, bd = 10, width = 18, relief = 'sunken')
CurrentSeason2.grid(row=2,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
Discount1 = Label(RMiddle, font=('arial',12,'bold'),text = ""Discount"", bd = 10, width = 15, anchor = 'w')
Discount1.grid(row=3,column=0)

Discount1 = ttk.Combobox(RMiddle , textvariable=info7, state='readonly', font=('arial',12,'bold'),  width =20)
Discount1['value']=('','10%','20%','30%','40%','50%')
Discount1.current(0)
Discount1.grid(row=3,column=1)
Discount1.bind(""&lt;&lt;ComboboxSelected&gt;&gt;"", Product)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
NewPrice1 = Label(RMiddle, font=('arial',12,'bold'), text =""New Price"", bd = 10, width = 15, anchor = 'w')
NewPrice1.grid(row=4,column=0)
NewPrice2 = Label(RMiddle, font=('arial',12,'bold'),textvariable = info8, bd = 10, width = 18, relief = 'sunken')
NewPrice2.grid(row=4,column=1)
#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
LH=Label(LowerHeading, font=('arial',12,'bold'), text =""Update"", bd = 10, width = 15, anchor = 'w')
LH.grid(row=1,column=0)
</code></pre>

<p>2) How do i put all the information within a csv file? So the user can change the price of the products?</p>

<pre><code>#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#
start.mainloop()
</code></pre>
","8490800","","","How do i change what the the values contain within the variables such as using a percentage?","<python><tkinter>","1","1","9431"
"49054336","2018-03-01 16:28:07","0","","<p>A colleague helped to fix this. It turns out the problem was that line was not an integer. this was fixed by replacing the for loop as follows:</p>

<pre><code>for line in range(0,len(SMAs)): 
</code></pre>

<p>Thank you for all help.</p>
","9424172","","","0","242","CavendishCambridge","2018-02-28 14:36:12","6","1","0","0","49032480","","2018-02-28 14:57:36","1","31","<p>The if statement is as follows:</p>

<pre><code>for line in result
    if result &lt; 0 and test == 1:
        test = 0
        print('patient result ', (TestAmount/SMAs.amount[line] - 1))
</code></pre>

<p>There are a sequence of these but the issue is in the if statement. When I run the code I get an error saying 
<code>""ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().""</code></p>

<p>I understand that this means that I cannot have the if statement criteria as I have them with pandas but do not know how to correct it. Is it possible to condition an if statement on two things when using a pandas DataFrame?</p>

<p>I am very new to coding and am very unfamiliar with terminology. I am hoping to write a program to analyse lab data once and then hopefully not have to do too much more with it.</p>
","9424172","9424172","2018-02-28 15:05:39","I require two comparisons to be true for an if statement but pandas gives an error. How can I rewrite the statement in a way pandas will accept?","<python><pandas><dataframe>","2","3","866"
"49054393","2018-03-01 16:30:55","2","","<p>This should do the trick</p>

<pre><code>df.set_index(['user', 'report']).groupIDs.apply(pd.Series).stack().reset_index(['user', 'report'], name='groupIDs')
</code></pre>
","2817602","","","0","174","Demetri Pananos","2013-09-26 01:47:37","2557","325","151","34","49054198","","2018-03-01 16:22:00","2","50","<p>I have a dataframe like this:</p>

<pre><code>user    groupIDs                report
user2   [31501, 31502, 31503]   blogpost
jim     [31501, 31502, 31503]   book
jane    [31600]                 article
jim     [31501, 31502, 31503]   book
peter   [31501, 31502, 31503]   blogpost
user1   [31501, 31502]          blogpost
user1   [31501, 31502]          blogpost
john    [31600]                 tweet
</code></pre>

<p><code>groupIDs</code> column contains lists of integers.</p>

<p>I need to turn this dataframe into:</p>

<pre><code>user    groupIDs    report
user2   31501       blogpost
user2   31502       blogpost
user2   31503       blogpost
jim     31501       book
jim     31502       book
jim     31503       book
jane    31600       article
...
</code></pre>

<p>That is, turn every row with multiple IDs into a list of this row's copies each with one of the ids in the original list.</p>

<p><code>groupby</code> with use of this column complains about it not being hashable for obvious reasons.</p>
","2022518","","","""Splat"" rows with lists into multiple rows (pandas)","<python><pandas>","2","0","1016"
"49054413","2018-03-01 16:31:47","0","","<p>'The problem is solved. 
I had ""/usr/lib/python2.7/dist-packages"" in my PYTHONPATH.
So there was a version mismatch between protobufs and it was solved by typing 'unset PYTHONPATH' before starting to import tensorflow.</p>
","7545335","","","0","226","azzz","2017-02-10 10:33:45","46","89","5","0","48934848","","2018-02-22 18:32:52","1","1137","<p>I am getting headache with tensorflow installations...</p>

<p>I have CUDA 8, CUdnn 6 and UBUNTU 16.04, python 2.7</p>

<p>I want now to install yensorflow. I have followed what they have explained for installation on the website but I have version ismatches of libraries.
As I am using caffe, I do not want to change those versions. So I have to go for older versions of tensorflow it seems.</p>

<p>But I can not find a good way to install it. Every time it is just failuare. I am very tired now.</p>

<p>I go like this:
1- download tensorflow r1.4 from here:
<a href=""https://github.com/tensorflow/tensorflow/tree/r1.4"" rel=""nofollow noreferrer"">https://github.com/tensorflow/tensorflow/tree/r1.4</a></p>

<p>2- My 'LD_LIBRARY_PATH' is:</p>

<pre><code>    :/usr/local/cuda-8.0/lib64/:/usr/local/cuda/lib64:/home/aa/torch/install/lib:/usr/lib/
</code></pre>

<p>3- The I run successfully this:</p>

<pre><code> $ sudo apt-get install python-pip python-dev python-virtualenv # for Python 2.7
</code></pre>

<p>4- and this:</p>

<pre><code>$ virtualenv --system-site-packages targetDirectory # for Python 2.7
</code></pre>

<p>5- I activate the environment</p>

<pre><code>$ source ~/tensorflow/bin/activate
</code></pre>

<p>6- and this</p>

<pre><code>(tensorflow)$ easy_install -U pip
</code></pre>

<p>Till here, everything is fine.</p>

<p>7- and when I run this line</p>

<pre><code>pip install --upgrade tensorflow-gpu  
</code></pre>

<p>It finished successfully with this message:</p>

<pre><code>Successfully installed absl-py-0.1.10 numpy-1.14.1 protobuf-3.5.1 setuptools-38.5.1 six-1.11.0 tensorflow-gpu-1.5.0 tensorflow-tensorboard-1.5.1 werkzeug-0.14.1 wheel-0.30.0
</code></pre>

<p>But then I cannot import it in python and this message is given:</p>

<pre><code> Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/home/aa/tensorflow/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in &lt;module&gt;
from tensorflow.python import *
  File ""/home/aa/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in &lt;module&gt;
from tensorflow.python import pywrap_tensorflow
   File ""/home/aa/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in &lt;module&gt;
raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/aa/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in &lt;module&gt;
from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/aa/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in &lt;module&gt;
_pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/aa/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace above this error message when asking for help.
</code></pre>

<p>I think I should go for older versions.</p>

<p>I did install older versions
but then when I test installation in python I see this messages:</p>

<pre><code>&gt;&gt;&gt; import tensorflow
  Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/home/aa/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in &lt;module&gt;
from tensorflow.python import *
  File ""/home/aa/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 52, in &lt;module&gt;
from tensorflow.core.framework.graph_pb2 import *
  File ""/home/aa/.local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in &lt;module&gt;
from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2
  File ""/home/aa/.local/lib/python2.7/site-packages/tensorflow/core/framework/node_def_pb2.py"", line 16, in &lt;module&gt;
from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/home/aa/.local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in &lt;module&gt;
from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/home/aa/.local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in &lt;module&gt;
from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2
  File ""/home/aa/.local/lib/python2.7/site-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 22, in &lt;module&gt;
serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tB/\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01\xf8\x01\x01\x62\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'


&gt;&gt;&gt; import tensorflow
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/home/aa/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in &lt;module&gt;
from tensorflow.python import *
  File ""/home/aa/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in &lt;module&gt;
from tensorflow.python import pywrap_tensorflow
ImportError: cannot import name pywrap_tensorflow
</code></pre>
","7545335","3938208","2018-05-04 16:18:32","how to install older versions of tensor flow","<python><tensorflow>","3","8","5918"
"49054414","2018-03-01 16:31:52","2","","<p>This line:</p>

<pre><code>c.executescript(""INSERT INTO books (title,text,tags) ""
                ""VALUES (col[0],col[1],col[2])"")
</code></pre>

<p>Is not a valid SQL. Now since <code>c</code> is defined as a cursor, you can run <code>execute</code> from it directly instead of <code>executescript</code>, which the latter is suppose to create a cursor from a connection and execute a SQL. Just replace that line with the following should work:</p>

<pre><code>c.execute(""INSERT INTO books (title,text,tags) ""
          ""VALUES (?,?,?)"", col)
</code></pre>

<p>The SQL above uses a ""qmark style"" placeholder, which takes actual value from the parameter list that follows it.</p>
","9214517","","","1","683","adrtam","2018-01-14 02:33:36","3918","166","19","13","49054275","49054425","2018-03-01 16:25:34","0","1085","<p>I have this simple code which I can't make work.</p>

<pre><code>import sqlite3

conn = sqlite3.connect('db\\books')
c = conn.cursor()

col = []

title = input('title')
text = input('text')
tags = input('tags')

col.append(title)
col.append(text)
col.append(tags)

c.executescript(""INSERT INTO books (title,text,tags) ""
                ""VALUES (col[0],col[1],col[2])"")
</code></pre>

<p>The db code (connection and normal insert) works but the problem rise when I want to do what you see above.</p>

<p>The goal I would like to achieve is to let the user insert the data into db (all strings). I don't know if this is the right way to do this...</p>

<p>How can I do this ?</p>

<p>Thanks</p>
","8368351","","","Insert values from list into table (Python, sqlite3)","<python><list><sqlite>","2","0","696"
"49054425","2018-03-01 16:32:41","2","","<p>One option is to change your last line to:</p>

<pre><code>c.execute(""INSERT INTO books (title,text,tags) VALUES (?,?,?)"", (col[0], col[1], col[2]))
</code></pre>

<p>And then commit and close the connection if you're done making changes:</p>

<pre><code>conn.commit()
conn.close()
</code></pre>
","6866811","","","4","299","thesilkworm","2016-09-22 20:17:18","3845","151","1210","248","49054275","49054425","2018-03-01 16:25:34","0","1085","<p>I have this simple code which I can't make work.</p>

<pre><code>import sqlite3

conn = sqlite3.connect('db\\books')
c = conn.cursor()

col = []

title = input('title')
text = input('text')
tags = input('tags')

col.append(title)
col.append(text)
col.append(tags)

c.executescript(""INSERT INTO books (title,text,tags) ""
                ""VALUES (col[0],col[1],col[2])"")
</code></pre>

<p>The db code (connection and normal insert) works but the problem rise when I want to do what you see above.</p>

<p>The goal I would like to achieve is to let the user insert the data into db (all strings). I don't know if this is the right way to do this...</p>

<p>How can I do this ?</p>

<p>Thanks</p>
","8368351","","","Insert values from list into table (Python, sqlite3)","<python><list><sqlite>","2","0","696"
"49054434","2018-03-01 16:33:01","-1","","<pre><code>import itertools

/////


i = 0
for item1, item2 in itertools.izip_longest(listone,listtwo):
    listthree[i] = dict(item1, **item2)
    i += 1
</code></pre>

<p>I'd recommend having a look at itertools though as there are more efficient ways of doing this and there may be a method for this.</p>

<p>Also this is assuming the lists are the same size.</p>

<p>See the answer below for more on iterating</p>

<p><a href=""https://stackoverflow.com/questions/1663807/how-to-iterate-through-two-lists-in-parallel"">How to iterate through two lists in parallel?</a></p>

<p><a href=""https://stackoverflow.com/a/1663826/5990760"">https://stackoverflow.com/a/1663826/5990760</a></p>
","5990760","","","0","685","SPRS1994","2016-02-27 16:20:26","1","5","0","0","49053435","49053663","2018-03-01 15:45:42","1","220","<p>I have a list of dictionaries as follows</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611}, 
 {'grade': '2', 'past_student_sum': 1631}, 
 {'grade': '3', 'past_student_sum': 1598}, 
 {'grade': '1', 'current_student_sum': 1611}, 
 {'grade': '2', 'current_student_sum': 1631}, 
 {'grade': '3', 'current_student_sum': 1598}]
</code></pre>

<p>I got this list by combining 2 query sets in the following fashion:</p>

<pre><code>grade_list = list(past_enrollments) + list(current_enrollments)
</code></pre>

<p>Is there a better alternatives to combine these in such a way to get a list that looks like this:</p>

<pre><code>[{'grade': '1', 'past_student_sum': 1611, 'current_student_sum': 1621},
 {'grade': '2', 'past_student_sum': 1511, 'current_student_sum': 1521}]
</code></pre>
","6168639","6906028","2018-03-01 15:49:43","Group a large list of dictionaries by key value in django","<python><django>","6","2","788"
"49054457","2018-03-01 16:34:15","1","","<p>Firstly you should try to check whether you can import PyPDF2 library from a python console.</p>

<p>Run from your native console:</p>

<pre><code>python3 -c ""import PyPDF2""
</code></pre>

<p>If no error message occurs, the problem is not in the library.</p>

<p>Check a path of python interpreter that is used by PyCharm.</p>

<p>Navigate inside PyCharm:</p>

<pre><code>Ctrl-Alt-S &gt; Build, Execution Deployment &gt; Console &gt; Python Console
</code></pre>

<p>The path should be to <code>/usr/bin/</code>folder.</p>

<p>If not - change it to a path of the desirable python interpreter that is inside <code>/usr/bin/</code> folder. </p>

<p>I hope this helps!</p>

<p>Will be good if someone can add a way to solve this type of problem in Windows environment. </p>
","7295475","3272592","2018-03-02 10:56:54","0","774","Kyrylo","2016-12-14 08:48:47","368","29","11","2","49052983","49054457","2018-03-01 15:24:30","1","3832","<p>I'm using a script to run Odoo11 via pycharm in ubuntu (openerp_openserver script) </p>

<p><a href=""https://i.stack.imgur.com/1sG83.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1sG83.png"" alt=""script""></a></p>

<p>When i try to run the program , it fails at some point , when it import pdf module and i have this error :</p>

<p><code>ImportError No Module Named 'PyPDF2'</code> as you can see in this Image</p>

<p><a href=""https://i.stack.imgur.com/CeglL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CeglL.png"" alt=""enter image description here""></a></p>

<p>I Already installed PyPDF2 via this command (i have python3.5 already installed) :</p>

<pre><code>sudo apt-get install python3-pypdf2
</code></pre>

<p><a href=""https://i.stack.imgur.com/gouZd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gouZd.png"" alt=""enter image description here""></a></p>

<p>So im wondering , what is the problem , why pycharm cannot find and import pypdf2?</p>

<p>Thanks</p>

<p><strong>EDIT :</strong></p>

<p>When i Try to import PyPDF2 using the Python command , i dont have error
<a href=""https://i.stack.imgur.com/NsW3k.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NsW3k.png"" alt=""enter image description here""></a></p>
","6276360","6276360","2018-03-01 15:35:45","Odoo 11 : ImportError No Module Named 'PyPDF2'","<python><python-3.x><pycharm><ubuntu-16.04><odoo-11>","2","6","1303"
"49054488","2018-03-01 16:35:51","2","","<p>While <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.get_loc.html"" rel=""nofollow noreferrer""><code>pandas.Index.get_loc()</code></a> will only work if you have a single key, the following paradigm will also work getting the <code>iloc</code> of multiple elements:</p>

<pre><code>np.argwhere(condition).flatten()   # array of all iloc where condition is True
</code></pre>

<p>In your case, picking the latest element where <code>df.index &lt; '2000-01-04'</code>:</p>

<pre><code>np.argwhere(df.index &lt; '2000-01-04').flatten()[-1]  # returns 2
</code></pre>
","3104974","","","0","595","ascripter","2013-12-15 17:33:30","3124","521","1394","217","34897014","34897532","2016-01-20 10:07:07","14","15657","<p>I have an indexed pandas dataframe. By searching through its index, I find a row of interest. How do I find out the iloc of this row?</p>

<p>Example:</p>

<pre><code>dates = pd.date_range('1/1/2000', periods=8)
df = pd.DataFrame(np.random.randn(8, 4), index=dates, columns=['A', 'B', 'C', 'D'])
df
                   A         B         C         D
2000-01-01 -0.077564  0.310565  1.112333  1.023472
2000-01-02 -0.377221 -0.303613 -1.593735  1.354357
2000-01-03  1.023574 -0.139773  0.736999  1.417595
2000-01-04 -0.191934  0.319612  0.606402  0.392500
2000-01-05 -0.281087 -0.273864  0.154266  0.374022
2000-01-06 -1.953963  1.429507  1.730493  0.109981
2000-01-07  0.894756 -0.315175 -0.028260 -1.232693
2000-01-08 -0.032872 -0.237807  0.705088  0.978011

window_stop_row = df[df.index &lt; '2000-01-04'].iloc[-1]
window_stop_row
Timestamp('2000-01-08 00:00:00', offset='D')
#which is the iloc of window_stop_row?
</code></pre>
","11464","11464","2016-01-20 10:25:39","How do i find the iloc of a row in pandas dataframe?","<python><pandas><dataframe>","4","8","934"
"49054489","2018-03-01 16:35:52","1","","<p>You can use <a href=""https://docs.python.org/3/library/stdtypes.html#str.strip"" rel=""nofollow noreferrer""><code>string.strip()</code></a>, which (with no arguments) removes any whitespace from the start and end of a string:</p>

<pre><code>for r in rows:
    print(r.strip())
</code></pre>

<p>If you want to remove only newlines, you can pass that character as an argument to <code>strip</code>:</p>

<pre><code>for r in rows:
    print(r.strip('\n'))
</code></pre>

<hr>

<p>For a clean solution, you could use a generator to wrap <code>open</code>, like this:</p>

<pre><code>def open_no_newlines(*args, **kwargs):
    with open(*args, **kwargs) as f:
        for line in f:
            yield line.strip('\n')
</code></pre>

<p>You can then use <code>open_no_newlines</code> like this:</p>

<pre><code>for line in open_no_newlines('myfile.csv', mode='r'):
    print(line)
</code></pre>
","6445069","6445069","2018-03-01 16:44:06","4","892","Phydeaux","2016-06-09 11:15:54","2150","165","730","164","49054468","","2018-03-01 16:34:49","1","102","<p>Using the python <code>open</code> built-in function in this way:</p>

<pre><code>with open('myfile.csv', mode='r') as rows:
    for r in rows:
        print(r.__repr__())
</code></pre>

<p>I obtain this ouput</p>

<pre><code>'col1,col2,col3\n'
'fst,snd,trd\n'
'1,2,3\n'
</code></pre>

<p>I don't want the <code>\n</code> character. Do you know some efficient way to remove that char (in place of the obvious <code>r.replace('\n','')</code>)?</p>
","3211950","","","open a new line separated text file in python","<python><string><csv>","2","4","450"
"49054512","2018-03-01 16:36:56","3","","<p>from <a href=""https://docs.pytest.org/en/latest/fixture.html#conftest-py-sharing-fixture-functions"" rel=""nofollow noreferrer"">pytest doc</a> and <a href=""https://docs.pytest.org/en/latest/writing_plugins.html#conftest-py-plugins"" rel=""nofollow noreferrer"">about plugins in pytest</a> :</p>

<blockquote>
  <p>Local conftest.py plugins contain directory-specific hook
  implementations. Hook Session and test running activities will invoke
  all hooks defined in conftest.py files closer to the root of the
  filesystem</p>
</blockquote>

<p>so, in order for your test to know the fixture, it should be higher in the hierarchy.
i.e. put your shared fixtures under the root folder, <code>/tumble/conftest.py</code></p>
","1716131","","","0","720","Avishay Cohen","2012-10-03 05:48:25","850","95","107","35","49053928","49054512","2018-03-01 16:09:09","1","852","<p>I am building a python package, using <code>pytest</code> for all unit testing. My package is composed of several modules, with various submodules under each module. The unit tests are within the <code>test</code> folder of each module (e.g., <code>./tumble/tumble/math/test/test_multiply.py</code> or <code>./tumble/tumble/science/test/test_divide.py</code>)</p>

<p>I have some fixtures that I want to share across all of the modules &amp; submodules. Because of this, I want place them in a central location, <code>./tumble/tumble/test</code> in this example, and not have duplicate fixtures in each submodule (<code>math/test</code> and <code>science/test</code>). </p>

<p>If I place <code>conftest.py</code> within the <code>test</code> folder in each submodule, everything works as expected. However, I have the same fixtures in two locations, which isn't ideal.</p>

<p>When I place my fixtures in a central location, I am able to see them when I use the command <code>pytest --fixtures</code>, however, when I run <code>pytest</code>, it tells me <code>fixture not found</code> and the fixture is not listed in the <code>available fixtures</code>. </p>

<p>Do I need to move all of my unit tests under the <code>test</code> folder, or is there something that I can do to keep unit tests within the submodules, but fixtures in a central location?</p>

<pre><code>tumble
+-- setup.py
+-- README.md
+-- tumble
|   +-- math
|   |   +-- __init__.py
|   |   +-- multiply.py
|   |   +-- test
|   |   +-- __init__.py
|   |   |   +-- test
|   |   |   |   +-- __init__.py
|   |   |   |   +-- test_multiply.py
|   +-- science
|   |   +-- __init__.py
|   |   +-- divide.py
|   |   +-- test
|   |   +-- __init__.py
|   |   |   +-- test
|   |   |   |   +-- __init__.py
|   |   |   |   +-- test_divide.py
|   +-- test
|   |   +-- __init__.py
|   |   +-- conftest.py
</code></pre>

<p><strong>multiply.py</strong></p>

<pre><code>def multipy(x, y):
    return x * y
</code></pre>

<p><strong>conftest.py</strong></p>

<pre><code>import pytest

@pytest.fixture()
def numbers():
    return (1, 5, 10)
</code></pre>

<p><strong>test_multiply.py</strong></p>

<pre><code>import tumble
import pytest

assert tumble.multiply(numbers[0], numbers[1]) == 5   
</code></pre>
","3420371","3420371","2018-03-01 16:15:47","Keeping pytest fixtures in one location and using them across submodules","<python><unit-testing><pytest><fixtures>","1","3","2261"
"49054534","2018-03-01 16:38:09","0","","<p>I guess that this module is kept in path where python does not look for when resolving for package. One thing you can do is add path where this folder is kept to PYTHONPATH environment variable so that python can detect it and import won't fail.</p>

<p>Execute below command on Linux platform:</p>

<pre><code>export PYTHONPATH = $PYTHONPATH:/path/to/module
</code></pre>
","8756315","","","3","376","Sunnysinh Solanki","2017-10-11 03:50:15","448","51","19","4","49053839","","2018-03-01 16:04:29","0","150","<p>I have a package structure as follows:</p>

<pre><code>package
  __init__.py
  subpackageA
      api.py
      __init__.py
  subpackageB
      action.py
      start.py
      __init__.py
</code></pre>

<p>The main package only serves to expose one class in subpackageB start.py called Schedule.  All other classes are used internally and cant be exposed.</p>

<p>Therefore my package/__init__.py is as follows:</p>

<pre><code>from package.subpackageB.start import Schedule
</code></pre>

<p>However, when I try to import package, i get the following error:</p>

<pre><code>ImportError: No module named 'package.subpackageB'
</code></pre>

<p>What am I doing wrong here?</p>

<p><strong>Update</strong></p>

<p>So after a bit of toiling I realised that my approach was probably wrong for what I was trying to achieve.</p>

<p>I changed it so that api.py, action.py and start.py are no longer in sub packages, but within the main package only.  I then reworked action.py so that its contents where part of start.py.</p>

<p>What this enabled me to do was to use the __all__ parameter to only import the Schedule module I wanted from start.py</p>

<p>As I use api.py it will also be imported by start.py, but this isn't a big issue for now so the new approach works for me.</p>

<pre><code>package
  __init__.py
  api.py
  start.py (action.py contents now part of start.py)
</code></pre>
","268247","268247","2018-03-02 08:26:34","Cannot import subpackage using __init__.py","<python><python-3.x>","1","7","1387"
"49054587","2018-03-01 16:41:15","0","","<p>In general, <strong>you can't</strong>.</p>

<p>Because you don't have the information needed to solve the problem.</p>

<p>If you have to know that a file was completely transferred/created/written/whatever successfully, the <em>creator</em> has to send you a signal somehow, because only the creator has that information.  From the receiving side, there's in general no way to infer that a file has been completely transferred.  You can try to <em>guess</em>, but that's all it is.  You can't in general tell a complete transfer from one where the connection was lost, for example.</p>

<p>So you need a signal of some sort from the sender.</p>

<p>One common way is to use a rename operation from something like <code>filename.xfr</code> to <code>filename</code>, or from an ""in work"" directory to the one you're watching.  Since most operating systems implement such rename operations atomically, if the sender only does the rename when the transfer is successfully done, you'll only process complete files that have been successfully transferred.</p>

<p>Another common signal is to send a ""done"" flag file, such as sending <code>filename.done</code> once <code>filename</code> has been successfully sent.</p>

<p>Since you don't control the sender, you can't <em>reliably</em> solve this problem by watching for files.</p>
","4756299","","","0","1332","Andrew Henle","2015-04-06 21:37:33","22773","2721","3563","134","49054134","","2018-03-01 16:19:29","1","50","<p>An application A (out of my control) writes a file into a directory.
After the file is written I want to back it up somewhere else with a python script of mine.</p>

<p>Question: how may I be sure that the file is completed or that instead the application A is still writing the file so that I should wait until its completion? I am worried I could copy a partial file....</p>

<p>I wanted to use this function <code>shutil.copyfile(src,dst)</code> but I don't know if it is safe or I should check the file to copy in some other way.</p>
","5313884","5851928","2018-03-01 16:20:34","How to make sure a file is completed before copying it?","<python><file><copy>","1","7","541"
"49054598","2018-03-01 16:41:37","1","","<pre><code>train_pct_index = int(0.8 * len(X))
X_train, X_test = X[:train_pct_index], X[train_pct_index:]
y_train, y_test = y[:train_pct_index], y[train_pct_index:]
</code></pre>

<p>It's one of those situations where it's just better not to involve <code>sklearn</code> helpers. Very straightforward, readable, and not dependent on knowing internal options of <code>sklearn</code> helpers, which code readers may not have experience with.</p>
","567620","","","0","444","ely","2011-01-07 23:55:27","44893","4128","1562","318","49054538","49054598","2018-03-01 16:38:13","0","940","<p>I need to split my dataset into training and testing. 
I need the last 20% of the values for testing and the first 80% for training. 
I have currently used the 'train_test_split()' but it picks the data randomly instead of the last 20%. How can I get the last 20% for testing and the first 80% for training?
My code is as follows:</p>

<pre><code>numpy_array = df.as_matrix()
X = numpy_array[:, 1:26]
y = numpy_array[:, 0]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20) #I do not want the data to be random.
</code></pre>

<p>Thanks</p>
","3259776","3259776","2018-03-01 16:44:03","How to split the data set without train_test_split()?","<python><arrays><numpy><scikit-learn>","2","1","565"
"49054602","2018-03-01 16:41:42","0","","<p>This works for me:</p>

<pre><code>options = Options()
prefs = {'download.prompt_for_download': False,
        'download.default_directory': download_dir,
        'download.directory_upgrage': True,
        'profile.default_content_settings.popups': 0,
        }
options.add_experimental_option('prefs', prefs)
</code></pre>

<p>p.s. Sorry, i couldn't comment, so I ask here: How do you pass your preferences?</p>
","9424384","","","2","417","Alexey Dolgopolov","2018-02-28 15:24:30","471","35","2","1","49053624","49054602","2018-03-01 15:54:35","0","415","<p>I'm trying to download a couple of files in a test that are randomly generated on the back-end with a unique name</p>

<p>I use this preferences that I pass to the chrome driver both directly or in a selenium hub</p>

<pre><code>CHROME_PREFERENCES = {
    ""profile.default_content_settings.popups"": 0,
    ""download.prompt_for_download"": ""false"",
    ""download.directory_upgrade"": ""true"",
    ""download.default_directory"": ""/mnt/hgfs/down/"",
    ""profile.default_content_setting_values.notifications"": 2,
    ""profile.default_content_setting_values.automatic_downloads"": 1
}
</code></pre>

<p>But Chrome keeps asking me for the download location every time that I make the get call to the download URL from the driver, rendering the automation useless...</p>

<p>I also tried, using bool values as True / False instead of ""true"" / ""false""</p>
","8448263","","","Chrome keep asking me for a download location on Selenium Hub/Driver on Python","<python><google-chrome><selenium><selenium-chromedriver>","1","0","846"
"49054604","2018-03-01 16:41:44","3","","<p>Two ways</p>

<p>1) after fetching one record, <code>curs2.description</code> will contain names and types:</p>

<pre><code>&gt;&gt;&gt; curs.execute(""declare cu cursor for select a, a*2 as b from generate_series(1,10) x(a);"") 
&gt;&gt;&gt; curs2 = cnn.cursor('cu')

&gt;&gt;&gt; curs2.description

&gt;&gt;&gt; curs2.fetchone()
(1, 2)

&gt;&gt;&gt; curs2.description
(Column(name='a', type_code=23, display_size=None, internal_size=4, precision=None, scale=None, null_ok=None),
 Column(name='b', type_code=23, display_size=None, internal_size=4, precision=None, scale=None, null_ok=None))
</code></pre>

<p>2) inspect the postgres system catalog:</p>

<pre><code>=# create function my_thing(p1 int, p2 int, out o1 int, out o2 int) returns setof record language sql as $$select a, a*2 from generate_series(p1,p2) x(a)$$;
CREATE FUNCTION

=# select * from my_thing(3,5);
 o1 | o2 
----+----
  3 |  6
  4 |  8
  5 | 10

=# select proargmodes, proargnames, proallargtypes from pg_proc where proname = 'my_thing';
 proargmodes |  proargnames  | proallargtypes 
-------------+---------------+----------------
 {i,i,o,o}   | {p1,p2,o1,o2} | {23,23,23,23}
</code></pre>

<p>See <a href=""https://www.postgresql.org/docs/current/static/catalog-pg-proc.html"" rel=""nofollow noreferrer"">pg_proc docs</a> for the meaning of the fields.</p>
","10138","","","0","1330","piro","2008-09-15 21:23:14","10013","677","143","33","49020718","49054604","2018-02-28 01:42:56","1","846","<p>I'm trying to get a list of column names after calling my postgres stored proc via psycopg2 in python...</p>

<p>Here's my code</p>

<pre><code># create a connection to the database
conn = psycopg2.connect(...)

# create a cursor object for execution
curs = conn.cursor()
curs.callproc('usp_my_stored_proc', ['mySP'])

# now open a new cursor &amp; ""steal"" the recordset from the previous cursor
curs2 = conn.cursor('mySP')

# close cursor &amp; connection
curs2.close()
curs.close()
conn.close()
</code></pre>

<p>Now I want to print out the columns of my stored proc and make them headers for my CSV file - I've search and I haven't found any leads...</p>

<p>Advice / Help is definitely welcome...</p>
","1566703","","","Get a list of column names from a psycopg2 cursor executing stored proc?","<python><python-3.x><postgresql><cursor><psycopg2>","1","0","708"
"49054612","2018-03-01 16:42:07","1","","<p>I think this Stackoverflow topic answers your question :</p>

<p><a href=""https://stackoverflow.com/questions/43838052/how-to-get-a-non-shuffled-train-test-split-in-sklearn"">How to get a non-shuffled train_test_split in sklearn</a></p>

<p>And especially this piece of text :</p>

<blockquote>
  <p>in scikit-learn version 0.19, you can pass the parameter shuffle=False to train_test_split to obtain a non-shuffled split.</p>
</blockquote>

<p>From the documentation : </p>

<blockquote>
  <p>shuffle : boolean, optional (default=True)</p>
  
  <p>Whether or not to shuffle the data before splitting. If shuffle=False then >stratify must be None.</p>
</blockquote>

<p>Please tell me if I didn't understand your question correctly </p>
","7786148","","","0","739","gcharbon","2017-03-29 13:33:05","580","36","37","5","49054538","49054598","2018-03-01 16:38:13","0","940","<p>I need to split my dataset into training and testing. 
I need the last 20% of the values for testing and the first 80% for training. 
I have currently used the 'train_test_split()' but it picks the data randomly instead of the last 20%. How can I get the last 20% for testing and the first 80% for training?
My code is as follows:</p>

<pre><code>numpy_array = df.as_matrix()
X = numpy_array[:, 1:26]
y = numpy_array[:, 0]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20) #I do not want the data to be random.
</code></pre>

<p>Thanks</p>
","3259776","3259776","2018-03-01 16:44:03","How to split the data set without train_test_split()?","<python><arrays><numpy><scikit-learn>","2","1","565"
"49054632","2018-03-01 16:43:23","1","","<p>There's probably a million (easy) ways to do this, but as it took me more than a minute to think about this, I thought I'd share my solution:</p>

<pre><code>def row_based_idx(num_rows, num_cols, idx):
    return np.arange(1, num_rows*num_cols + 1).reshape((num_rows, num_cols)).transpose().flatten()[idx-1]
</code></pre>

<p>With this, one can simply do</p>

<pre><code>row_based_plot_idx = row_based_idx(num_rows, num_cols, col_based_plot_idx)
plt.subplot(num_rows, num_cols, row_based_plot_idx)
</code></pre>

<p>Just hoping this saves somebody a minute. Surely, there are better solutions available.</p>
","2207840","","","0","611","jhin","2013-03-25 14:11:43","2304","120","481","5","49054631","49054741","2018-03-01 16:43:23","2","1223","<p>By default, matplotlib subplots are filled by row, not by column. To clarify, the commands</p>

<pre><code>plt.subplot(nrows=3, ncols=2, idx=2)
plt.subplot(nrows=3, ncols=2, idx=3)
</code></pre>

<p>first plot into the upper right plot of the 3x2 plot grid (idx=2), and then into the middle left plot (idx=3). </p>

<p>Sometimes it may be desirable for whatever reason to fill the subplots by row, not by column (for example, because directly consecutive plots belong together and are easier interpretable when positioned below each other, rather than next to each other). How can this be achieved?</p>
","2207840","","","Fill matplotlib subplots by column, not row","<python><matplotlib>","2","0","606"
"49054636","2018-03-01 16:43:35","3","","<p>Change your computer name so it only has valid ASCII characters</p>
","5682919","","","0","71","jsanchezs","2015-12-15 16:05:44","1216","185","566","10","49054463","49054730","2018-03-01 16:34:31","-1","1878","<p>Im new to django, i started a project inside a virtualenv and whenever i try to runserver i get this message:</p>

<pre><code>Performing system checks...

System check identified no issues (0 silenced).
March 01, 2018 - 13:22:34
Django version 2.0.2, using settings 'PollApp.settings'
Starting development server at http://127.0.0.1:8000/
Quit the server with CTRL-BREAK.
Unhandled exception in thread started by &lt;function check_errors.
&lt;locals&gt;.wrapper at 0x03BBF7C8&gt;
Traceback (most recent call last):
  File ""C:\Users\Sebastian\Desktop\Desarrollo\HelloWorld1\lib\site-
packages\django\utils\autoreload.py"", line 225, in wrapper
    fn(*args, **kwargs)
  File ""C:\Users\Sebastian\Desktop\Desarrollo\HelloWorld1\lib\site-
packages\django\core\management\commands\runserver.py"", line 143, in 
inner_run
    ipv6=self.use_ipv6, threading=threading, server_cls=self.server_cls)
  File ""C:\Users\Sebastian\Desktop\Desarrollo\HelloWorld1\lib\site-
packages\django\core\servers\basehttp.py"", line 163, in run
    httpd = httpd_cls(server_address, WSGIRequestHandler, ipv6=ipv6)
  File ""C:\Users\Sebastian\Desktop\Desarrollo\HelloWorld1\lib\site-
packages\django\core\servers\basehttp.py"", line 66, in __init__
    super().__init__(*args, **kwargs)
  File ""c:\users\sebastian\appdata\local\programs\python\python36-
32\Lib\socketserver.py"", line 453, in __init__
    self.server_bind()
  File ""c:\users\sebastian\appdata\local\programs\python\python36-
32\Lib\wsgiref\simple_server.py"", line 50, in server_bind
    HTTPServer.server_bind(self)
  File ""c:\users\sebastian\appdata\local\programs\python\python36-
32\Lib\http\server.py"", line 138, in server_bind
    self.server_name = socket.getfqdn(host)
  File ""c:\users\sebastian\appdata\local\programs\python\python36-
32\Lib\socket.py"", line 673, in getfqdn
    hostname, aliases, ipaddrs = gethostbyaddr(name)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe1 in position 7: 
invalid continuation byte
</code></pre>

<p>I dont realy know where to start solving this error, i have a WAMP server installed, should i check if im using the 8000 port?</p>
","7474170","","","django manage.py runserver fails to run","<python><django><virtualenv>","2","1","2121"
"49054705","2018-03-01 16:46:52","2","","<p><code>beam.Map</code> is useful with one-to-one transformation, but here you need <code>beam.FlatMap</code> that does one-to-many transformation.</p>

<p><code>word_dicts</code> needs to return a list of tuples (see below) and <code>beam.Map(word_dicts)</code> can be replaced by <code>beam.FlatMap(word_dicts)</code>.</p>

<pre><code>def word_dicts(row):
  words = row['sentence'].split(' ')
  return [(word, row['value']) for word in words]
</code></pre>

<p>The rest should be very similar to <a href=""https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/wordcount.py"" rel=""nofollow noreferrer""><code>wordcount</code></a> example.
You can apply <code>beam.GroupByKey</code> and <code>beam.Map(lambda kv : (kv[0], sum(kv[1])))</code>. You can also do <code>beam.CombineValues(lambda x,y : x + y)</code>.</p>
","1017693","1017693","2018-03-02 18:34:08","1","836","Jiayuan Ma","2011-10-28 03:51:49","1558","129","5","4","49054032","","2018-03-01 16:14:24","0","320","<p>I have a PCollection of dictionaries:</p>

<pre><code>{'sentence': 'foo bar', 'value' : 5 }
{'sentence': 'one bar', 'value' : 2 }
</code></pre>

<p>I would like to space split the sentences, give the same value for each word of the sentence, and then aggregate by word with sum function. My desired output is:</p>

<pre><code>{'word': 'foo', 'value' : 5}
{'word': 'bar', 'value' : 7}
{'word': 'one', 'value' : 2}
</code></pre>

<p>I defined a function that splits the sentence and returns a list of dicts for each sentence:</p>

<pre><code>def word_dicts(row):
 words = row['sentence'].split(' ')
 return [{'word' : word, 'value' : row['value'] } for word in words]
</code></pre>

<p>I put this function in a <code>beam.Map</code>, then i'm using <code>beam.CombineGlobally(beam.combiners.ToListCombineFn())</code> to get a list of all lists of dictoinaries </p>

<pre><code>[[{'word': 'foo', 'value' : 5},{'word': 'bar', 'value' : 5}],[{'word': 'foo', 'value' : 5},{'word': 'one', 'value' : 2}]]
</code></pre>

<p>And then i'm stuck because i can't see how to Partition this list and do the Combine to get the final results.</p>

<p>Do you know a simplest way to do this? </p>

<p>Thanks in advance</p>
","6107966","","","split sentences and combine words in Apache Beam","<python><apache-beam>","1","0","1207"
"49054730","2018-03-01 16:48:12","2","","<p>According to known issues bellow, your best solution will be changing your host name.
I don't WAMP is causing this, unless they are running on the same PORT!</p>

<p><a href=""https://code.djangoproject.com/ticket/19357"" rel=""nofollow noreferrer"">https://code.djangoproject.com/ticket/19357</a></p>

<p><a href=""https://bugs.python.org/issue26227"" rel=""nofollow noreferrer"">https://bugs.python.org/issue26227</a></p>

<p><a href=""https://stackoverflow.com/questions/25324014/error-while-running-django-app"">Error while running Django app</a></p>
","5601726","","","0","548","Gal Silberman","2015-11-24 22:07:39","2591","337","1053","17","49054463","49054730","2018-03-01 16:34:31","-1","1878","<p>Im new to django, i started a project inside a virtualenv and whenever i try to runserver i get this message:</p>

<pre><code>Performing system checks...

System check identified no issues (0 silenced).
March 01, 2018 - 13:22:34
Django version 2.0.2, using settings 'PollApp.settings'
Starting development server at http://127.0.0.1:8000/
Quit the server with CTRL-BREAK.
Unhandled exception in thread started by &lt;function check_errors.
&lt;locals&gt;.wrapper at 0x03BBF7C8&gt;
Traceback (most recent call last):
  File ""C:\Users\Sebastian\Desktop\Desarrollo\HelloWorld1\lib\site-
packages\django\utils\autoreload.py"", line 225, in wrapper
    fn(*args, **kwargs)
  File ""C:\Users\Sebastian\Desktop\Desarrollo\HelloWorld1\lib\site-
packages\django\core\management\commands\runserver.py"", line 143, in 
inner_run
    ipv6=self.use_ipv6, threading=threading, server_cls=self.server_cls)
  File ""C:\Users\Sebastian\Desktop\Desarrollo\HelloWorld1\lib\site-
packages\django\core\servers\basehttp.py"", line 163, in run
    httpd = httpd_cls(server_address, WSGIRequestHandler, ipv6=ipv6)
  File ""C:\Users\Sebastian\Desktop\Desarrollo\HelloWorld1\lib\site-
packages\django\core\servers\basehttp.py"", line 66, in __init__
    super().__init__(*args, **kwargs)
  File ""c:\users\sebastian\appdata\local\programs\python\python36-
32\Lib\socketserver.py"", line 453, in __init__
    self.server_bind()
  File ""c:\users\sebastian\appdata\local\programs\python\python36-
32\Lib\wsgiref\simple_server.py"", line 50, in server_bind
    HTTPServer.server_bind(self)
  File ""c:\users\sebastian\appdata\local\programs\python\python36-
32\Lib\http\server.py"", line 138, in server_bind
    self.server_name = socket.getfqdn(host)
  File ""c:\users\sebastian\appdata\local\programs\python\python36-
32\Lib\socket.py"", line 673, in getfqdn
    hostname, aliases, ipaddrs = gethostbyaddr(name)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe1 in position 7: 
invalid continuation byte
</code></pre>

<p>I dont realy know where to start solving this error, i have a WAMP server installed, should i check if im using the 8000 port?</p>
","7474170","","","django manage.py runserver fails to run","<python><django><virtualenv>","2","1","2121"
"49054741","2018-03-01 16:48:54","6","","<p>You can create the 3x2 array of axes using:</p>

<pre><code>fig, axes = plt.subplots(nrows=3, ncols=2)
</code></pre>

<p>If you transpose this array, then flatten you can plot column wise, rather than row wise:</p>

<pre><code>fig, axes = plt.subplots(nrows=3, ncols=2)

for ax in axes.T.flatten():
    ax.plot([1,2,3])
</code></pre>
","5851928","","","1","337","DavidG","2016-01-28 12:17:14","13142","1875","1418","8903","49054631","49054741","2018-03-01 16:43:23","2","1223","<p>By default, matplotlib subplots are filled by row, not by column. To clarify, the commands</p>

<pre><code>plt.subplot(nrows=3, ncols=2, idx=2)
plt.subplot(nrows=3, ncols=2, idx=3)
</code></pre>

<p>first plot into the upper right plot of the 3x2 plot grid (idx=2), and then into the middle left plot (idx=3). </p>

<p>Sometimes it may be desirable for whatever reason to fill the subplots by row, not by column (for example, because directly consecutive plots belong together and are easier interpretable when positioned below each other, rather than next to each other). How can this be achieved?</p>
","2207840","","","Fill matplotlib subplots by column, not row","<python><matplotlib>","2","0","606"
"49054749","2018-03-01 16:49:21","0","","<p>If you just want to find words which appear in both of triggerlist and citylist, you can run</p>

<pre><code>triggerlist = [""hotel"", ""venue""]
citylist = [""hotel"", ""austria"", ""germany"", ""switzerland"", ""spain""]
word = [""hotel""]

for w in word:
    if w in triggerlist and w in citylist:
        print(w)
        print('SUCCESS')
</code></pre>

<p>Also note that Python evaluates boolean conditions lazily
<a href=""https://docs.python.org/3/reference/expressions.html#boolean-operations"" rel=""nofollow noreferrer"">https://docs.python.org/3/reference/expressions.html#boolean-operations</a> </p>
","3582729","","","3","595","Guangyang Li","2014-04-28 19:29:22","963","32","388","99","49054567","","2018-03-01 16:39:54","-2","62","<p>I am looking for a way to connect two lists and two conditions... My way doesn't work and I have no idea how to get it right.</p>

<p>What I want:</p>

<p>Find terms of triggerlist in file. 
If the have been found, find citylist terms. 
Only if this combination is found, print success</p>

<p>All my following approaches do not work…   </p>

<pre><code>triggerlist = [""hotel"", ""venue""]
citylist = [""austria"", ""germany"", ""switzerland"", ""spain""]

with open(filename, 'r') as myself:
    for word in words(myself):

    for i in triggerlist and citylist:
          if i in word:
              print ('SUCCESS')

    for i in triggerlist:
          if i in word and triggerlist:
              print ('SUCCESS')

    for i in triggerlist:
          if i in word 
             if i in triggerlist:
             print ('SUCCESS')
</code></pre>

<p>UPDATE:</p>

<p>As it seems I was not clear enough (but I thought I was), here another brief description of what I want:</p>

<pre class=""lang-html prettyprint-override""><code>textfromfile = [""A log line of text containing several words""]
triggerlist = [""hotel"", ""venue""]
citylist = [""austria"", ""germany"", ""switzerland"", ""spain""]

if word from triggerlist is in textfromfile:
    print 'nice'

if word from triggerlist AND word from citylist is in textfromfile:
    print 'what I want'
</code></pre>

<p>Is it now better to understand what I want?</p>
","8359429","8359429","2018-03-01 19:39:03","Two lists + two conditions","<python>","4","8","1397"
"49054787","2018-03-01 16:51:04","1","","<p>I recently encountered the same problem and my investigation led me to write on the <a href=""https://groups.google.com/forum/#!topic/django-users/wrNj3VHQkqc"" rel=""nofollow noreferrer"">django-users group</a> (short answer is django-channels does NOT manage session deletion, just waiting for it to expire).</p>

<p>I came up doing it myself since the session won't be useful once the WebSocket client is disconnected:</p>

<pre><code>from channels.sessions import session_for_reply_channel

@channel_session_user
def ws_disconnect(message):
    ...
    session = session_for_reply_channel(message.reply_channel.name)
    session.delete(session.session_key)
</code></pre>

<p>Hope this will work for you.</p>
","2076612","","","0","711","Nicolas Ferrari","2013-02-15 18:32:38","38","7","4","0","48320946","","2018-01-18 12:06:09","1","596","<p>I followed the somewhat outdated guide here:
<a href=""https://blog.heroku.com/in_deep_with_django_channels_the_future_of_real_time_apps_in_django"" rel=""nofollow noreferrer"">https://blog.heroku.com/in_deep_with_django_channels_the_future_of_real_time_apps_in_django</a></p>

<p>And successfully setup django app with channels:</p>

<pre><code>&gt; cat requirements.txt 
..
Django==1.10.6
asgi-redis==1.4.3
asgiref==1.1.2
channels==1.1.8
django-redis-cache==1.7.1
daphne==1.4.2
..

&gt; cat Procfile 
web: daphne Landia.asgi:channel_layer --port $PORT --bind 0.0.0.0
worker: python manage.py runworker

CHANNEL_LAYERS = {
    ""default"": {
        ""BACKEND"": ""asgi_redis.RedisChannelLayer"",
        ""CONFIG"": {
            ""hosts"": [os.environ.get('REDIS_URL', 'redis://localhost:6379')],
        },
        ""ROUTING"": ""Landia.routing.channel_routing"",
    },
}
</code></pre>

<p>The problem being is that the redis memory consumption starts at 2M, and gradually, very slowly, over 48 hours or so grows to 50MB when the provisioned space is exhausted and my server essentially starts throwing 5XX.</p>

<p>It can be fixed by flushing redis.</p>

<p>I assuming the channels/redis are not discarding the replies it sends out.</p>

<p><a href=""https://i.stack.imgur.com/bxJSH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bxJSH.png"" alt=""Screenshot with redis mem usage""></a></p>

<p>Any ideas how to fix, or at least debug this problem?</p>

<p>I also use redis for session storage, which I think is the source of leak:</p>

<pre><code>&gt; heroku redis:cli
&gt; info
...
# Keyspace
db0:keys=119,expires=119,avg_ttl=49389233
db1:keys=7749,expires=7749,avg_ttl=1192828136
&gt; select 1
&gt; keys *
...
7757) :1:django.contrib.sessions.cachechnb5cafa749ec3b1b8b6fc20903750f
7758) :1:django.contrib.sessions.cachechn975ee5d806f3b27d6492e3fad8218
7759) :1:django.contrib.sessions.cachechn659906572f30ed388e655b75fbf87
</code></pre>

<p>Here's the django channels session setup:</p>

<pre><code>CHANNEL_SESSION_ENGINE = 'django.contrib.sessions.backends.cache'

CACHES = {
    'default': {
        'BACKEND': 'redis_cache.RedisCache',
        'LOCATION': os.environ.get('REDIS_URL', 'redis://localhost:6379')
    },
}
</code></pre>

<p>And usage in consumers.py</p>

<pre><code>@allowed_hosts_only
@channel_session_user_from_http
def ws_connect(message):
    ...


@channel_session_user
def ws_receive(message):
   ...


@channel_session_user
def ws_disconnect(message):
    ...
</code></pre>

<p>Is there a way to clean the session info being stored in redis on disconnect, or at least set up sensible TTL for the redis keys?</p>
","2008221","2008221","2018-01-18 19:34:29","Django channels with redis setup on heroku leaking memory","<python><django><heroku><memory-leaks><django-channels>","1","0","2645"
"49054788","2018-03-01 16:51:05","1","","<p>You can use <code>re.sub()</code> to remove all lowercase letters and spaces.</p>

<p><strong>Regex</strong>: <a href=""https://regex101.com/r/wev2VQ/1"" rel=""nofollow noreferrer""><code>[a-z ]+</code></a></p>

<p>Details:</p>

<ul>
<li><code>[]+</code> Match a single character present in the list between one and
unlimited times</li>
</ul>

<p><strong>Python code</strong>:</p>

<pre><code>re.sub(r'[a-z ]+', '', theatre)
</code></pre>

<p>Output: <code>RCCS14</code></p>

<p><a href=""https://ideone.com/eCkgmv"" rel=""nofollow noreferrer"">Code demo</a></p>
","6101071","","","1","558","Srdjan M.","2016-03-22 21:01:48","2679","264","505","18","49054634","49054897","2018-03-01 16:43:28","3","445","<p>I have a string as follows: <br>
<code>theatre = 'Regal Crown Center Stadium 14'</code></p>

<p>I would like to break this into an acronym based on the first letter in each word but also include both numbers:<br>
desired output = <code>'RCCS14'</code><br></p>

<p>My code attempts below:<br>
<code>acronym = """".join(word[0] for word in theatre.lower().split())
 acronym = """".join(word[0].lower() for word in re.findall(""(\w+)"", theatre))
 acronym = """".join(word[0].lower() for word in re.findall(""(\w+ | \d{1,2})"", theatre))
 acronym = re.search(r""\b(\w+ | \d{1,2})"", theatre)</code><br></p>

<p>In which I wind up with something like: <code>rccs1</code> but can't seem to capture that last number. There could be instances when the number is in the middle of the name as well: <code>'Regal Crown Center 14 Stadium'</code> as well. TIA!</p>
","6938318","","","Python create acronym from first characters of each word and include the numbers","<python><regex><elements><capture>","4","1","844"
"49054800","2018-03-01 16:51:31","0","","<p>this is a typical case of async programming for which Python is not very well equipped. Luckily there is the asyncio library. If you install that, you can call your function with async await pattern. That way you will be able to await server results before calling new one. </p>

<p>Here is a good explanation:
<a href=""https://www.blog.pythonlibrary.org/2016/07/26/python-3-an-intro-to-asyncio/"" rel=""nofollow noreferrer"">https://www.blog.pythonlibrary.org/2016/07/26/python-3-an-intro-to-asyncio/</a></p>
","4462086","","","0","510","Imre_G","2015-01-16 14:53:30","1312","113","119","14","49054681","","2018-03-01 16:45:35","0","95","<p>I have a Node.js server continuously receiving python client's POST request to call a backend service. Promise is used in Node server's REST router to call the backend service and then return the results to the client.</p>

<p>On node.js:</p>

<pre><code> router.post(""/result/"", jsonParser, function (req, res) {
   callService(req.body)
     .then(function(result) {
        res.json({
          result: result
        });
     }, function (error) {
        res.status(400);
     });
 }

 var callService = function(input) {
    return new Promise((resolve,reject) =&gt; {
      //do something;
      resolve(result);
    }
 }
</code></pre>

<p>The client is sending request messages in order (e.g. reading a file line by line) and saving results in another file line by line. </p>

<p>In client.py:</p>

<pre><code>for line in read_file:
        time.sleep(0.5)
        start_new_thread(request_to_server_and_write_to_file, (line))
</code></pre>

<p>However since the backend processing speed varies due to the complexity of each request message, the result returned to the client <strong>are not in the same order</strong> as the requests sent.</p>

<p>What should I do to make this result in the same order as the requests?</p>
","9425335","","","POST request and get response in order (NodeJS, python client)","<python><node.js><promise>","1","0","1236"
"49054838","2018-03-01 16:53:32","0","","<p>If I understand your question correctly, you are looking to see if any of the triggerlist words are also in the citylist?  If this is the case you can do this very efficiently by converting them to sets and look for the intersection:</p>

<pre><code>triggerlist = [""hotel"", ""venue""]
citylist = [""hotel"", ""austria"", ""germany"", ""switzerland"", ""spain""]
word = ""hotel""

if word in set(triggerlist) &amp; set(citylist):
    print('SUCCESS')
</code></pre>

<p>If you are reading from a file of words: (note this answer is incomplete if there are more than one word per line, but you can figure out the rest).</p>

<pre><code>triggerlist = [""hotel"", ""venue""]
citylist = [""hotel"", ""austria"", ""germany"", ""switzerland"", ""spain""]
intersection_set = set(triggerlist) &amp; set(citylist)

with open(filename, 'r') as myself:
    for word in myself:
        if word in intersection_set:
            print('SUCCESS')
</code></pre>

<h2>Update</h2>

<p>Given the new information.  You can convert your trigger and city list to sets to compare the overlap (&amp;) very efficiently.  You can put your second check inside of the first one rather than perform them independently.</p>

<pre><code>triggers = set([""hotel"", ""venue""])
cities = set([""austria"", ""germany"", ""switzerland"", ""spain""])

with open('filename', 'r') as myfile:
    for line in myfile:
        word_set = set(line.split())
        if bool(word_set &amp; triggers):
            print 'nice' # condition 1 satisfied
            if bool(word_set &amp; cities):
                print 'what I want' # condition 1 and 2 satisfied
</code></pre>

<p>I haven't tested this code, mind you, but it should be straightforward to get it working.</p>
","4904821","4904821","2018-03-02 16:20:04","1","1688","David Ferris","2015-05-15 17:28:32","756","128","1474","3","49054567","","2018-03-01 16:39:54","-2","62","<p>I am looking for a way to connect two lists and two conditions... My way doesn't work and I have no idea how to get it right.</p>

<p>What I want:</p>

<p>Find terms of triggerlist in file. 
If the have been found, find citylist terms. 
Only if this combination is found, print success</p>

<p>All my following approaches do not work…   </p>

<pre><code>triggerlist = [""hotel"", ""venue""]
citylist = [""austria"", ""germany"", ""switzerland"", ""spain""]

with open(filename, 'r') as myself:
    for word in words(myself):

    for i in triggerlist and citylist:
          if i in word:
              print ('SUCCESS')

    for i in triggerlist:
          if i in word and triggerlist:
              print ('SUCCESS')

    for i in triggerlist:
          if i in word 
             if i in triggerlist:
             print ('SUCCESS')
</code></pre>

<p>UPDATE:</p>

<p>As it seems I was not clear enough (but I thought I was), here another brief description of what I want:</p>

<pre class=""lang-html prettyprint-override""><code>textfromfile = [""A log line of text containing several words""]
triggerlist = [""hotel"", ""venue""]
citylist = [""austria"", ""germany"", ""switzerland"", ""spain""]

if word from triggerlist is in textfromfile:
    print 'nice'

if word from triggerlist AND word from citylist is in textfromfile:
    print 'what I want'
</code></pre>

<p>Is it now better to understand what I want?</p>
","8359429","8359429","2018-03-01 19:39:03","Two lists + two conditions","<python>","4","8","1397"
"49054897","2018-03-01 16:56:32","2","","<p><a href=""https://regex101.com/r/rNDktx/2"" rel=""nofollow noreferrer"">See regex in use here</a></p>

<pre><code>(?:(?&lt;=\s)|^)(?:[a-z]|\d+)
</code></pre>

<ul>
<li><code>(?:(?&lt;=\s)|^)</code> Ensure what precedes is either a space or the start of the line</li>
<li><code>(?:[a-z]|\d+)</code> Match either a single letter or one or more digits</li>
</ul>

<p>The <code>i</code> flag (<code>re.I</code> in python) allows <code>[a-z]</code> to match its uppercase variants.</p>

<p><a href=""https://tio.run/##FYs9C8IwFAD3/IpHl@ShBkQnsXTo5KqjVQgm2ki@eImI0v8e63Qc3KVPGWPY1Gp9ilSADGME7Ux5iz5ZZwQ1otuJbt8OGacrznJWq@9lGvQCm@W/PCDL88OP5qEc9BTfAXoTiiE4FaXty8N6yxlLZEMRnMtntEGQvNuglXMiIyKr9Qc"" rel=""nofollow noreferrer"">See code in use here</a></p>

<pre><code>import re

r = re.compile(r""(?:(?&lt;=\s)|^)(?:[a-z]|\d+)"", re.I)
s = 'Regal Crown Center Stadium 14'

print(''.join(r.findall(s)))
</code></pre>

<p>The code above finds all instances where the regex matches and joins the list items into a single string.</p>

<p>Result: <code>RCCS14</code></p>
","3600709","3600709","2018-03-01 17:06:11","1","1051","ctwheels","2014-05-04 05:37:24","14809","1524","401","133","49054634","49054897","2018-03-01 16:43:28","3","445","<p>I have a string as follows: <br>
<code>theatre = 'Regal Crown Center Stadium 14'</code></p>

<p>I would like to break this into an acronym based on the first letter in each word but also include both numbers:<br>
desired output = <code>'RCCS14'</code><br></p>

<p>My code attempts below:<br>
<code>acronym = """".join(word[0] for word in theatre.lower().split())
 acronym = """".join(word[0].lower() for word in re.findall(""(\w+)"", theatre))
 acronym = """".join(word[0].lower() for word in re.findall(""(\w+ | \d{1,2})"", theatre))
 acronym = re.search(r""\b(\w+ | \d{1,2})"", theatre)</code><br></p>

<p>In which I wind up with something like: <code>rccs1</code> but can't seem to capture that last number. There could be instances when the number is in the middle of the name as well: <code>'Regal Crown Center 14 Stadium'</code> as well. TIA!</p>
","6938318","","","Python create acronym from first characters of each word and include the numbers","<python><regex><elements><capture>","4","1","844"
"49054899","2018-03-01 16:56:37","0","","<p>I can't comment since I don't have enough reputation, but <em>S. Jovan</em> answer isn't satisfying since it assumes that each word starts with a capital letter and that each word has one and only one capital letter. </p>

<pre><code>re.sub(r'[a-z ]+', '', ""Regal Crown Center Stadium YB FIEUBFB DBUUFG FUEH  14"")
</code></pre>

<p>will returns <code>'RCCSYBFIEUBFBDBUUFGFUEH14'</code></p>

<p>However <em>ctwheels</em> answers will be able to work in this case :</p>

<pre><code>r = re.compile(r""\b(?:[a-z]|\d+)"", re.I)
s = 'Regal Crown Center Stadium YB FIEUBFB DBUUFG FUEH  14'

print(''.join(r.findall(s)))
</code></pre>

<p>will print </p>

<pre><code>RCCSYFDF14
</code></pre>
","7786148","","","2","685","gcharbon","2017-03-29 13:33:05","580","36","37","5","49054634","49054897","2018-03-01 16:43:28","3","445","<p>I have a string as follows: <br>
<code>theatre = 'Regal Crown Center Stadium 14'</code></p>

<p>I would like to break this into an acronym based on the first letter in each word but also include both numbers:<br>
desired output = <code>'RCCS14'</code><br></p>

<p>My code attempts below:<br>
<code>acronym = """".join(word[0] for word in theatre.lower().split())
 acronym = """".join(word[0].lower() for word in re.findall(""(\w+)"", theatre))
 acronym = """".join(word[0].lower() for word in re.findall(""(\w+ | \d{1,2})"", theatre))
 acronym = re.search(r""\b(\w+ | \d{1,2})"", theatre)</code><br></p>

<p>In which I wind up with something like: <code>rccs1</code> but can't seem to capture that last number. There could be instances when the number is in the middle of the name as well: <code>'Regal Crown Center 14 Stadium'</code> as well. TIA!</p>
","6938318","","","Python create acronym from first characters of each word and include the numbers","<python><regex><elements><capture>","4","1","844"
"49054939","2018-03-01 16:59:12","0","","<p>In the following line:</p>

<pre><code>test = train.fillna(0)
</code></pre>

<p>you are assigning (overwriting) <code>test</code> variable with the ""train"" data ...</p>
","5741205","","","2","172","MaxU","2016-01-03 18:59:33","137626","9897","9013","520","49050243","","2018-03-01 12:58:26","-2","77","<p>Below is what i have done so far.</p>

<pre><code>#importing the necessary modules
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import RidgeCV
from sklearn.linear_model import LassoCV
from sklearn.linear_model import ElasticNetCV
from sklearn.ensemble import RandomForestRegressor

filepath = r""C:\Users...Kaggle data\house prediction iowa\house_predtrain (3).csv""
train = pd.read_csv(filepath)
print(train.shape)

filepath2 = r""C:\Users...Kaggle data\house prediction iowa\house_predtest (1).csv""
test = pd.read_csv (filepath2)
print(test.shape)

#first we raplace all the NANs by 0 in botht the train and test data
train = train.fillna(0) 
test = test.fillna(0)    #error one
train.dtypes.value_counts()

#isolating all the object/categorical feature and converting them to numeric features

encode_cols = train.dtypes[train.dtypes == np.object]
encode_cols2 = test.dtypes[test.dtypes == np.object]

#print(encode_cols)

encode_cols = encode_cols.index.tolist()
encode_cols2 = encode_cols2.index.tolist()
print(encode_cols2)

# Do the one hot encoding
train_dummies = pd.get_dummies(train, columns=encode_cols)
test_dummies = pd.get_dummies(test, columns=encode_cols2)

#align your test and train data (error2)
train, test = train_dummies.align(test_dummies, join = 'left', axis = 1)
print(train.shape)
print(test.shape)

#Now working with Floats features

numericals_floats = train.dtypes == np.float
numericals = train.columns[numericals_floats]
print(numericals)

#we check for skewness in the float data

skew_limit = 0.35
skew_vals = train[numericals].skew()

skew_cols = (skew_vals
             .sort_values(ascending=False)
             .to_frame()
             .rename(columns={0:'Skewness'}))

skew_cols

#Visualising them above data before and after log transforming
%matplotlib inline

field = 'GarageYrBlt'
fig, (ax_before, ax_after) = plt.subplots(1, 2, figsize=(10,5))
train[field].hist(ax=ax_before)
train[field].apply(np.log1p).hist(ax=ax_after)

ax_before.set (title = 'Before np.log1p', ylabel = 'frequency', xlabel = 'Value')
ax_after.set (title = 'After np.log1p', ylabel = 'frequency', xlabel = 'Value')

fig.suptitle('Field: ""{}""'.format (field));
#note how applying log transformation on GarageYrBuilt does not do much 

print(skew_cols.index.tolist()) #returns a list of the values

for i in skew_cols.index.tolist():
    if i == ""SalePrice"":           #we do not want to transform the feature to be predicted
        continue
    train[i] = train[i].apply(np.log1p)
    test[i]  = test[i].apply(np.log1p)

feature_cols = [x for x in train.columns if x != ('SalePrice')]

X_train = train[feature_cols]
y_train = train['SalePrice']

X_test  = test[feature_cols]


y_test  = train['SalePrice']
print(X_test.shape)
print(y_train.shape)
print(X_train.shape)

#now to the most fun part. Feature engineering is over!!!
#i am going to use linear regression, L1 regularization, L2 regularization and ElasticNet(blend of L1 and L2)
#first up, Linear Regression
alphas =[0.00005, 0.0005, 0.005, 0.05, 0.5, 0.1, 0.3, 1, 3, 5, 10, 25, 50, 100]    #i choosed this
l1_ratios = np.linspace(0.1, 0.9, 9)

#LinearRegression
linearRegression = LinearRegression().fit(X_train, y_train)
prediction1 = linearRegression.predict(X_test)
LR_score = linearRegression.score(X_train, y_train)
print(LR_score)

#ridge
ridgeCV = RidgeCV(alphas=alphas).fit(X_train, y_train)
prediction2 = ridgeCV.predict(X_test)
R_score = ridgeCV.score(X_train, y_train)
print(R_score)

#lasso
lassoCV = LassoCV(alphas=alphas, max_iter=1e2).fit(X_train, y_train)
prediction3 = lassoCV.predict(X_test)
L_score = lassoCV.score(X_train, y_train)
print(L_score)

#elasticNetCV
elasticnetCV = ElasticNetCV(alphas=alphas, l1_ratio=l1_ratios, max_iter=1e2).fit(X_train, y_train)
prediction4 = elasticnetCV.predict(X_test)
EN_score = elasticnetCV.score(X_train, y_train)
print(EN_score)

from sklearn.ensemble import RandomForestRegressor
randfr = RandomForestRegressor()
randfr = randfr.fit(X_train, y_train)
prediction5 = randfr.predict(X_test)
print(prediction5.shape)
RF_score = randfr.score(X_train, y_train)
print(RF_score)

#putting it lall together

rmse_vals = [LR_score, R_score, L_score, EN_score, RF_score]

labels = ['Linear', 'Ridge', 'Lasso', 'ElasticNet', 'RandomForest']

rmse_df = pd.Series(rmse_vals, index=labels).to_frame()
rmse_df.rename(columns={0: 'SCORES'}, inplace=1)
rmse_df

\\KaggleHouse_submission_1 = pd.DataFrame({'Id': test.Id, 'SalePrice': prediction5})
KaggleHouse_submission_1 = KaggleHouse_submission_1
print(KaggleHouse_submission_1.shape)
</code></pre>

<p>In the kaggle house prediction there is a train dataset and a test dataset. here is the link to the actual data <a href=""https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"" rel=""nofollow noreferrer"">link</a>. The output dataframe size should be a 1459 X 2 but mine is 1460 X 2 for some reason. I am not sure why this is happening. Any feedbacks is highly appreciated.  </p>
","6774204","6774204","2018-03-02 12:34:28","Why is my output dataframe shape not 1459 x 2 but 1460 x 2","<python><pandas><machine-learning><scikit-learn><kaggle>","2","3","5093"
"49054963","2018-03-01 17:00:26","0","","<p>This is what I think you are looking to achieve:</p>

<pre><code>import pandas as pd, numpy as np

df.loc[df['b_s'] == 'sell', 'total'] *= -1

df = df.groupby(['city', 'zone'], as_index=False)['total'].sum()

df['b_s'] = np.where(df['total'] &gt;= 0, 'buy', 'sell')

#       city  zone  total  b_s
# 0  bristol     1    100  buy
# 1  cardiff     1    500  buy
# 2  cardiff     2    100  buy
</code></pre>
","9209546","","","0","408","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49054338","49054963","2018-03-01 16:28:10","-3","351","<p>Hi, I want to know if it's possible to do the following calculation in a panda data frame in python. I have a single data frame with the below columns</p>

<pre><code>      city  zone   b_s  total
0  cardiff     1   buy   1000
1  cardiff     1  sell    500
2  cardiff     2   buy    100
3  bristol     1   buy    200
4  bristol     1  sell    100
</code></pre>

<p></p><p></p>
What I need if possible is, when City and Zone match and there is both a Buy and Sell for that pair, then do a calculation. So in the above case I would like to do a calculation only on Cardiff Zone 1 and Bristol Zone 1 (as Cardiff Zone 2 only has one line). The calculation is to aggregate the two, so if there is more sells than buys, I only want the sell line but want to do Total Sell - Total Buy to get a net of the two.</p></p>

<p><p> Output would be </p><p>
Cardiff | 1 | Buy | 500 </p><p>
Cardiff | 2 | Buy | 100 </p><p>
Bristol | 1 | Buy | 100 </p></p>
","6494381","7954504","2018-03-01 16:53:44","Aggregate rows in a Pandas Data Frame based off two columns","<python><pandas>","1","0","943"
"49054991","2018-03-01 17:01:35","2","","<p>Did you mean:</p>

<pre><code>json_arr.append(mails['data']['from'][0]['id'])
json_arr.append(mails['data']['to'][0]['id'])
</code></pre>
","4834","","","2","141","quamrana","2008-09-05 20:27:56","15246","2075","2510","88","49054909","","2018-03-01 16:57:09","0","32","<p>How do I go about extracting more than one JSON key at a time given this script - the script cycles through a list of message ids and extracts the JSON response. I only want to extract certain keys from the response.   </p>

<pre><code>import urllib3
import json
import csv
from progressbar import ProgressBar
import time

pbar = ProgressBar()
base_url = 'https://api.pipedrive.com/v1/mailbox/mailMessages/'
fields = {""include_body"": ""1"", ""api_token"": ""token""}

json_arr = []
http = urllib3.PoolManager()
with open('ten.csv', newline='') as csvfile:
    for x in pbar(csv.reader(csvfile, delimiter=' ', quotechar='|')):
            r = http.request('GET', base_url + """".join(x), fields=fields)
            mails = json.loads(r.data.decode('utf-8'))
            json_arr.append(mails['data']['from'][0]['id'])

print(json_arr)
</code></pre>

<p>This works as intended. But I want to do the following.</p>

<pre><code>json_arr.append(mails(['data']['from'][0]['id'],['data']['to'][0]['id'])
</code></pre>

<p>Which results in TypeError: list indices must be integers or slices, not str</p>
","9289113","","","Extracting multiple nested JSON keys at a time","<python><json>","2","1","1091"
"49055000","2018-03-01 17:02:04","0","","<p>Your class subclasses <code>logging.Logger</code>, so you should not call <code>getLogger</code> or manipulate a logger as an attribute. Rather, the logger <em>is <code>self</code></em> inside the class, and should be adjusted directly:</p>

<pre><code>import logging
import sys


print(""imported module {}"".format(__name__))


class PyLogger(logging.Logger):
    """"""Wrapper for logging.Logger to redirect its message to                                                                                   
    sys.stdout or sys.stderr accordingly """"""

    def __init__(self, *args):
        super(PyLogger, self).__init__(self, *args)

        #####
        # self *is* the logger!                                                                                                                          
        self.setLevel(logging.DEBUG)

        # build Formatter                                                                                                                      
        formatter = logging.Formatter(fmt=""%(asctime)s:%(name)s   %(message)s"")

        # build StreamHandler for sys.stderr                                                                                                   
        error = logging.StreamHandler(stream=sys.stderr)
        error.setLevel(logging.CRITICAL)
        error.setFormatter(formatter)

        #####
        # Assign the handler to self
        self.addHandler(error)

        # build StreamHandler for sys.stdin                                                                                                    
        out = logging.StreamHandler(stream=sys.stdout)
        out.setFormatter(formatter)
        out.setLevel(logging.WARNING)

        #####
        # Assign the handler to self
        self.addHandler(out)


def main():
    logger = PyLogger()
    # help(logger)                                                                                                                             
    logger.info(""INFO"")
    logger.warning(""WARN"")
    logger.critical(""CRIT"")


if __name__ == ""__main__"":
    main()
</code></pre>

<p>This displays the following, as expected:</p>

<pre><code>ely@eschaton:~/programming$ python test_logger.py 
imported module __main__
2018-03-01 11:59:41,896:&lt;__main__.PyLogger object at 0x7fa236aa4a50&gt;   WARN
2018-03-01 11:59:41,896:&lt;__main__.PyLogger object at 0x7fa236aa4a50&gt;   CRIT
2018-03-01 11:59:41,896:&lt;__main__.PyLogger object at 0x7fa236aa4a50&gt;   CRIT
</code></pre>

<p>Notice how the critical message trips two different output handlers, so it appears twice (once because it satisfied warning level, once for critical level).</p>

<p>In your original code, notice that you are creating a variable called <code>logger</code> inside of <code>__init__</code>, but this not assigned to <code>self</code> or anything. This variable gets destroyed when it goes out of scope of the <code>__init__</code> function, and so the assignment of any handlers is meaningless. Plus, because handlers weren't assigned to <code>self</code>, but the object that <code>self</code> is referencing <em>is</em> the logger that will be called later on, that is why you see the error about no handlers.</p>
","567620","567620","2018-03-01 17:09:02","6","3216","ely","2011-01-07 23:55:27","44893","4128","1562","318","49054556","49055000","2018-03-01 16:39:17","2","377","<p>I´m just starting to learn Python and have encountered a Problem that I´m not able to solve.
I want to redirect every level above CRITICAL to sys.stderr and everything above WARNING to sys.stdout.
I came up with this script...</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>import logging
import sys


print(""imported module {}"".format(__name__))


class PyLogger(logging.Logger):
    """"""Wrapper for logging.Logger to redirect its message to
    sys.stdout or sys.stderr accordingly """"""

    def __init__(self, *args):
        super(PyLogger, self).__init__(self, *args)

        # get Logger
        logger = logging.getLogger()
        logger.setLevel(logging.DEBUG)

        # build Formatter
        formatter = logging.Formatter(fmt=""%(asctime)s:%(name)s   %(message)s"")

        # build StreamHandler for sys.stderr
        error = logging.StreamHandler(stream=sys.stderr)
        error.setLevel(logging.CRITICAL)
        error.setFormatter(formatter)
        logger.addHandler(error)

        # build StreamHandler for sys.stdin
        out = logging.StreamHandler(stream=sys.stdout)
        out.setFormatter(formatter)
        out.setLevel(logging.WARNING)
        logger.addHandler(out)


def main():
    logger = PyLogger()
    # help(logger)
    logger.info(""INFO"")


if __name__ == ""__main__"":
    main()</code></pre>
</div>
</div>
</p>

<p>When running this scrip directly I get the following error:</p>

<pre><code>No handlers could be found for logger ""&lt;__main__.PyLogger object at 0x105f23c50&gt;""
</code></pre>

<p>I´ve googled around and many people said that a logging.basicConfig() would do the job but that didn´t worked for me.</p>

<p>Maybe someone of you guys could help me out.
Thanks!</p>
","7169757","","","Redirecting Loggers`messages to sys.stdout and sys.stderr","<python><redirect><logging><stdout><stderr>","1","2","1917"
"49055001","2018-03-01 17:02:05","1","","<pre><code>b = np.cumsum(a)

print(b)
</code></pre>

<p>You are not storing the output of <code>np.cumsum()</code></p>
","5337505","","","0","119","Siladittya","2015-09-15 10:19:18","415","125","154","24","49054927","49055004","2018-03-01 16:58:19","1","459","<p>Here is my code:</p>

<pre><code>import numpy as np

a = [4,6,12]

np.cumsum(a)

print(a)
</code></pre>

<p>Instead of getting <code>[4,10,22]</code>, I am still getting <code>[4,6,12]</code>. I am confused. So if <code>cumsum()</code> is not the way to do accumulation sum, what I should do then? Thanks.</p>
","1277239","","","numpy cumsum( ) not working?","<python><arrays><numpy><sum>","2","4","313"
"49055004","2018-03-01 17:02:18","1","","<p>The <a href=""https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.cumsum.html"" rel=""nofollow noreferrer"">docstring of <code>numpy.cumsum</code></a> says:</p>

<blockquote>
  <p>Return the cumulative sum of the elements along the given axis.</p>
</blockquote>

<p>So that means it returns a new array. It does not modify the existing array.</p>
","1552748","","","0","361","Paul H","2012-07-25 20:00:07","36143","3414","1711","16","49054927","49055004","2018-03-01 16:58:19","1","459","<p>Here is my code:</p>

<pre><code>import numpy as np

a = [4,6,12]

np.cumsum(a)

print(a)
</code></pre>

<p>Instead of getting <code>[4,10,22]</code>, I am still getting <code>[4,6,12]</code>. I am confused. So if <code>cumsum()</code> is not the way to do accumulation sum, what I should do then? Thanks.</p>
","1277239","","","numpy cumsum( ) not working?","<python><arrays><numpy><sum>","2","4","313"
"49055035","2018-03-01 17:04:12","4","","<p>Xarray maps Python 2's <code>str</code>/<code>bytes</code> type to NetCDF's <code>NC_CHAR</code> type. Both these types represent single byte character data (generally ASCII) so this makes a certain amount of sense.</p>

<p>To get a netCDF string <code>NC_STRING</code>, you need to pass pass <code>unicode</code> data (<code>str</code> on Python 3). You can get this by explicitly coercing your timestamp column to unicode, either with <code>.astype(unicode)</code> or by passing <code>{'dtype': unicode}</code> in <code>encoding</code>.</p>
","809705","","","2","546","shoyer","2011-06-22 05:09:10","5745","450","245","4","48959201","49055035","2018-02-24 03:54:06","1","455","<p>I am converting a text file to netCDF format using xarray. When I am using netCDF4 format and Python3, it is storing string variables as strings but when I use Python2 it stores them as n-dimensional character arrays. I have tried to set dtype='str' in encoding and that didn't make any difference. Is there a way to make these variables to have string data-type using Python2? Any thoughts would be appreciated.</p>

<p>Here is my code:</p>

<pre><code>import pandas as pd
import xarray as xr

column_names = ['timestamp', 'air_temp', 'vtempdiff', 'rh', 'pressure', 'wind_dir', 'wind_spd']

df = pd.read_csv(args.input_file, skiprows = 1, header=None, names = column_names)
ds = xr.Dataset.from_dataframe(df)

encoding = {'timestamp': {'dtype': 'str'},
            'air_temp': {'_FillValue': 9.96921e+36, 'dtype': 'f4'}
            }

ds.to_netcdf(op_file.nc, format = 'NETCDF4', unlimited_dims={'time':True}, encoding = encoding)
</code></pre>

<p>When I do ncdump of the op_file.nc using Python3.6, I get:</p>

<pre><code>netcdf op_file {
dimensions:
    time = UNLIMITED ; // (24 currently)
variables:
    string timestamp(time) ;
    float air_temp(time) ;
    .
    .
    .
</code></pre>

<p>And when I use Python2.7, I get:</p>

<pre><code>netcdf op_file {
dimensions:
    time = UNLIMITED ; // (24 currently)
    string20 = 20 ;
variables:
    char timestamp(time, string20) ;
        timestamp:_Encoding = ""utf-8"" ;
    float air_temp(time) ;
    .
    .
    .
</code></pre>

<p>The sample input file looks like this:</p>

<pre><code># Fields: stamp,AGO-4.air_temp,AGO-4.vtempdiff,AGO-4.rh,AGO-4.pressure,AGO-4.wind_dir,AGO-4.wind_spd
2016-11-30T00:00:00Z,-36.50,,56.00,624.60,269.00,5.80
2016-11-30T01:00:00Z,-35.70,,55.80,624.70,265.00,5.90
</code></pre>
","9326176","9326176","2018-02-28 09:11:21","xarray - store strings as 'string' data-type instead of 'char' (n-dimensional character arrays) for Python2.7","<python><netcdf><python-xarray><netcdf4><xarray>","1","1","1769"
"49055046","2018-03-01 17:04:31","2","","<p>If you are trying to read and parse csv file, Python's csv module might serve better:</p>

<pre><code>import csv
reader = csv.reader(open('myfile.csv', 'r'))
for row in reader:
    print(', '.join(row))
</code></pre>

<p>Although you cannot change the line terminator for reader here, it ends a row with either '\r' or '\n', which works for your case.</p>

<p><a href=""https://docs.python.org/3/library/csv.html#csv.Dialect.lineterminator"" rel=""nofollow noreferrer"">https://docs.python.org/3/library/csv.html#csv.Dialect.lineterminator</a></p>

<p>Again, for most of the cases, I don't think you need to parse csv file manually. There are a few issues/reasons that makes csv module easier for you: field containing separator, field containing newline character, field containing quote character, etc.</p>
","3582729","","","0","808","Guangyang Li","2014-04-28 19:29:22","963","32","388","99","49054468","","2018-03-01 16:34:49","1","102","<p>Using the python <code>open</code> built-in function in this way:</p>

<pre><code>with open('myfile.csv', mode='r') as rows:
    for r in rows:
        print(r.__repr__())
</code></pre>

<p>I obtain this ouput</p>

<pre><code>'col1,col2,col3\n'
'fst,snd,trd\n'
'1,2,3\n'
</code></pre>

<p>I don't want the <code>\n</code> character. Do you know some efficient way to remove that char (in place of the obvious <code>r.replace('\n','')</code>)?</p>
","3211950","","","open a new line separated text file in python","<python><string><csv>","2","4","450"
"49055055","2018-03-01 17:04:51","0","","<p>The answer already posted looks good but I'll share the one-liner equivalent, using <code>extend()</code> instead of <code>append()</code>:</p>

<pre><code>json_arr.extend([mails['data']['from'][0]['id'], mails['data']['to'][0]['id']])
</code></pre>
","6866811","","","0","253","thesilkworm","2016-09-22 20:17:18","3845","151","1210","248","49054909","","2018-03-01 16:57:09","0","32","<p>How do I go about extracting more than one JSON key at a time given this script - the script cycles through a list of message ids and extracts the JSON response. I only want to extract certain keys from the response.   </p>

<pre><code>import urllib3
import json
import csv
from progressbar import ProgressBar
import time

pbar = ProgressBar()
base_url = 'https://api.pipedrive.com/v1/mailbox/mailMessages/'
fields = {""include_body"": ""1"", ""api_token"": ""token""}

json_arr = []
http = urllib3.PoolManager()
with open('ten.csv', newline='') as csvfile:
    for x in pbar(csv.reader(csvfile, delimiter=' ', quotechar='|')):
            r = http.request('GET', base_url + """".join(x), fields=fields)
            mails = json.loads(r.data.decode('utf-8'))
            json_arr.append(mails['data']['from'][0]['id'])

print(json_arr)
</code></pre>

<p>This works as intended. But I want to do the following.</p>

<pre><code>json_arr.append(mails(['data']['from'][0]['id'],['data']['to'][0]['id'])
</code></pre>

<p>Which results in TypeError: list indices must be integers or slices, not str</p>
","9289113","","","Extracting multiple nested JSON keys at a time","<python><json>","2","1","1091"
"49055061","2018-03-01 17:05:01","1","","<p>I seem to have fixed the learning problem! 
My network error is now steadily decreasing as I train it!
I was using the wrong trainer. As I am using a recurrent neural network, I should not have been using the back propagation trainer. I am now using the RPropMinusTrainer.
To fix, the following line:</p>

<pre><code>trainer = BackpropTrainer(net, ds, verbose = True, momentum = 0.01)
</code></pre>

<p>Was changed to</p>

<pre><code>trainer = RPropMinusTrainer(net, dataset=ds, verbose = True)
</code></pre>
","6629225","","","0","512","FatUglyProud","2016-07-23 14:17:32","72","29","42","0","48966371","49055061","2018-02-24 18:43:44","1","73","<p>Neural networking noob here.<br>
I am using PyBrain to try and create a network that learns music.<br>
My dataset consists of about a hundred songs where the input for the network is two notes and the target is the next two notes.<br>
Each note is represented by an int for the note/chord combination, an int for octave of the note and a float for the duration of the note.<br>
My network looks like this:</p>

<pre><code>    net = RecurrentNetwork()
    net.addInputModule(LinearLayer(6, name='in'))
    net.addModule(LSTMLayer(50, name='hidden1'))
    net.addModule(LSTMLayer(50, name='hidden2'))
    net.addOutputModule(LinearLayer(6, name='out'))
    net.addConnection(FullConnection(net['in'], net['hidden1'], name='c1'))
    net.addConnection(FullConnection(net['hidden1'], net['hidden2'], name='c3'))
    net.addRecurrentConnection(FullConnection(net['hidden2'], net['hidden1'], name='c4'))
    net.addConnection(FullConnection(net['hidden2'], net['out'], name='c5'))
    net.sortModules()
</code></pre>

<p>With a dataset and trainer like so:</p>

<pre><code>ds = SupervisedDataSet(6, 6)
trainer = BackpropTrainer(net, ds, verbose = True, momentum = 0.01)
</code></pre>

<p>My problem is, when I train the network, I get a huge error back (E.G. 24569847209.8) which never seems to go down, it changes with each epoch but it always hovers around the same number.</p>

<p>After the network is trained it creates a song by taking two random notes as input, then generating the target, then passing the target back as an input, and repeating this over and over until it has a full song. But I find all it ever does is just write output over and over again, like it just learns one fixed target.</p>

<p>I'm really not sure what's wrong with what I have that is causing this.If there is some information I should include please let me know.</p>
","6629225","6629225","2018-02-25 17:02:47","Neural Network Error Rate Does Not Progress","<python><neural-network><lstm><recurrent-neural-network><pybrain>","1","5","1851"
"49055068","2018-03-01 17:05:22","0","","<pre><code>import re
theatre = 'Regal Crown Center Stadium 14'
r = re.findall(""\s(\d+|\S)"", ' '+theatre)
print(''.join(r))
</code></pre>

<p>Gives me <code>RCCS14</code></p>
","5095849","","","0","174","Amaro Vita","2015-07-08 21:03:14","432","27","8","24","49054634","49054897","2018-03-01 16:43:28","3","445","<p>I have a string as follows: <br>
<code>theatre = 'Regal Crown Center Stadium 14'</code></p>

<p>I would like to break this into an acronym based on the first letter in each word but also include both numbers:<br>
desired output = <code>'RCCS14'</code><br></p>

<p>My code attempts below:<br>
<code>acronym = """".join(word[0] for word in theatre.lower().split())
 acronym = """".join(word[0].lower() for word in re.findall(""(\w+)"", theatre))
 acronym = """".join(word[0].lower() for word in re.findall(""(\w+ | \d{1,2})"", theatre))
 acronym = re.search(r""\b(\w+ | \d{1,2})"", theatre)</code><br></p>

<p>In which I wind up with something like: <code>rccs1</code> but can't seem to capture that last number. There could be instances when the number is in the middle of the name as well: <code>'Regal Crown Center 14 Stadium'</code> as well. TIA!</p>
","6938318","","","Python create acronym from first characters of each word and include the numbers","<python><regex><elements><capture>","4","1","844"
"49055076","2018-03-01 17:05:58","1","","<p>What you are describing is generally referred to as ""variable aggregation.""  As you indicate, there are four basic steps:</p>

<ol>
<li>Identify the linear equality equations you want to remove</li>
<li>Compute the substitution map</li>
<li>Deactivate the equality constraints that you want to remove</li>
<li>Substitute variables on all remaining constraints</li>
</ol>

<p>It sounds like you have 1 and 2 under control.  For 3, assuming you identified a Constraint <code>m.c</code> you want to deactivate, you just need to call <code>m.c.deactivate()</code>.</p>

<p>For 4, you will want to generate new expressions for the remaining Constraint ""<code>body</code>"" expressions (variables only appear in the body and not in the lower/upper bounds).  For current Pyomo releases (through 5.4.x), you can perform variable substitution by leveraging the <code>clone_expression()</code>.  You need to generate a ""substitution map"": a dict that maps the <code>id()</code> of the variables you want to the new expression you want to use.  For example:</p>

<pre><code>from pyomo.core.base.expr import clone_expression

m = ConcreteModel()
m.y = Var([1,2,3])
m.eta = Var([1,2])
# ...
m.c = Constraint(expr=m.y[1]**2 + m.y[3]**2 &lt;= 4)
# ...

substitution_map = {
    id(m.y[1]): 1 - m.eta[1],
    id(m.y[2]): m.eta[1],
    id(m.y[3]): m.eta[2],
}
m.c = (m.c.lower, clone_expression(m.c.body, substitute=substitution_map), m.c.upper)
</code></pre>

<p>Finally, the disclaimers:</p>

<ol>
<li>Setting the constraint with this syntax should work with recent Pyomo releases (I tested back through 5.1)</li>
<li>This approach technically violates one of the assumptions in the current Pyomo expression system (it generates potentially ""entangled"" expressions: expressions that share common sub-trees).  While not ""good"", it shouldn't cause troubles, unless you do additional transformations / expression manipulation.</li>
<li>Pyomo 5.5 will have a new expression system that will likely have a different mechanism for manipulating / substituting variables.</li>
</ol>
","6749874","","","4","2062","jsiirola","2016-08-23 21:46:13","1106","134","5","0","49028165","49055076","2018-02-28 11:09:39","1","601","<p>I want to eliminate linear equality constraints on integral variables in a pyomo model by substitution. For instance, I wish to transform the model </p>

<p><a href=""https://i.stack.imgur.com/zkBoy.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zkBoy.gif"" alt=""enter image description here""></a></p>

<p>by substituting </p>

<p><a href=""https://i.stack.imgur.com/pnuI3.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pnuI3.gif"" alt=""enter image description here""></a> ( * ) </p>

<p>to </p>

<p><a href=""https://i.stack.imgur.com/9g2EG.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9g2EG.gif"" alt=""enter image description here""></a></p>

<p>Is there a way to perfom such a substitution in a pyomo model? I will be able to obtain ( * ) by computing the solution space of the corresponding system of linear diophantine equations in the form <code>y = const_vec + susbtitution_matrix * eta</code>, where in our example we have </p>

<pre><code>const_vec = np.array([1,0,0])
substitution_matrix = np.array([[-1,0],
                                [1,0],
                                [0,1]])
</code></pre>
","7889571","","","Eliminate equality constraints in a pyomo model","<python><mathematical-optimization><pyomo>","1","4","1168"
"49055077","2018-03-01 17:06:01","3","","<p>Nope.  The scoping rules are part of a language's basic definition.  To change this, you'd have to alter the compiler to exclude items higher on the context stack, but still within the user space.  You obviously don't want to limit <em>all</em> symbols outside the function's context, as you've used one in your example: the external function <code>print</code>.  :-)</p>
","4785185","","","0","375","Prune","2015-04-14 00:37:53","54183","8845","3232","13592","49054993","49055085","2018-03-01 17:01:40","5","539","<p>Is there a way to limit function so that it would only have access to local variable and passed arguments?</p>

<p>For example, consider this code</p>

<pre><code>a = 1
def my_fun(x):
    print(x)
    print(a)
my_fun(2)
</code></pre>

<p>Normally the output will be</p>

<pre><code>2
1
</code></pre>

<p>However, I want to limit <code>my_fun</code> to local scope so that <code>print(x)</code> would work but throw an error on <code>print(a)</code>. Is that possible?</p>
","951894","","","Limit Python function scope to local variables only","<python><function><scope><global-variables>","2","2","475"
"49055085","2018-03-01 17:06:29","1","","<p>I feel like I should preface this with: <strong>Do not actually do this.</strong></p>

<p>You (sort of) can with functions, but you will also disable calls to all other global methods and variables, which I do not imagine you would like to do.</p>

<p>You can use the following decorator to have the function act like there are no variables in the global namespace:</p>

<pre><code>import types
noglobal = lambda f: types.FunctionType(f.__code__, {})
</code></pre>

<p>And then call your function:</p>

<pre><code>a = 1
@noglobal
def my_fun(x):
    print(x)
    print(a)
my_fun(2)
</code></pre>

<p>However this actually results in a different error than you want, it results in:</p>

<blockquote>
  <p>NameError: name 'print' is not defined</p>
</blockquote>

<p>By not allowing globals to be used, you cannot use <code>print()</code> either.</p>

<p>Now, you could pass in the functions that you want to use as parameters, which would allow you to use them inside the function, but this is not a good approach and it is much better to just keep your globals clean.</p>

<pre><code>a = 1
@noglobal
def my_fun(x, p):
    p(x)
    p(a)
my_fun(2, print)
</code></pre>

<p>Output:</p>

<pre><code>2
NameError: name 'a' is not defined
</code></pre>
","3483203","3483203","2018-03-01 17:11:42","0","1248","user3483203","2014-04-01 00:22:53","39972","4672","2822","1887","49054993","49055085","2018-03-01 17:01:40","5","539","<p>Is there a way to limit function so that it would only have access to local variable and passed arguments?</p>

<p>For example, consider this code</p>

<pre><code>a = 1
def my_fun(x):
    print(x)
    print(a)
my_fun(2)
</code></pre>

<p>Normally the output will be</p>

<pre><code>2
1
</code></pre>

<p>However, I want to limit <code>my_fun</code> to local scope so that <code>print(x)</code> would work but throw an error on <code>print(a)</code>. Is that possible?</p>
","951894","","","Limit Python function scope to local variables only","<python><function><scope><global-variables>","2","2","475"
"49055095","2018-03-01 17:06:54","1","","<p><code>np.array</code> won't 'flatten' an object dtype array.  You have to use some sort of concatenate.</p>

<p>Make an array of arrays.  Notice that I have play some games to get around <code>np.array's</code> preference to create a 3d array:</p>

<pre><code>In [5]: arr = np.empty((3,), dtype=object)
In [6]: arr
Out[6]: array([None, None, None], dtype=object)
In [7]: arr[:] = [np.zeros((2,3)) for _ in range(3)]
In [8]: arr
Out[8]: 
array([array([[0., 0., 0.],
       [0., 0., 0.]]),
       array([[0., 0., 0.],
       [0., 0., 0.]]),
       array([[0., 0., 0.],
       [0., 0., 0.]])], dtype=object)
</code></pre>

<p>Another <code>np.array</code> call doesn't do anything</p>

<pre><code>In [9]: np.array(arr)
Out[9]: 
array([array([[0., 0., 0.],
       [0., 0., 0.]]),
       array([[0., 0., 0.],
       [0., 0., 0.]]),
       array([[0., 0., 0.],
       [0., 0., 0.]])], dtype=object)
</code></pre>

<p><code>stack</code> treats the <code>arr</code> as a list, and joins the elements on a new axis.  <code>concatenate</code> joins them on an existing axis.</p>

<pre><code>In [10]: np.stack(arr)
Out[10]: 
array([[[0., 0., 0.],
        [0., 0., 0.]],

       [[0., 0., 0.],
        [0., 0., 0.]],

       [[0., 0., 0.],
        [0., 0., 0.]]])
In [11]: np.concatenate(arr, axis=0)
Out[11]: 
array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]])
</code></pre>

<p>If one or more of elements of <code>arr</code> differed in shape, then this would not work.</p>

<p><code>np.array((np.zeros((2,3)), np.zeros((3,2))))</code> creates an object array effortlessly - and possibly is a mistake.  It cannot be <code>stacked</code>.</p>
","901925","","","1","1711","hpaulj","2011-08-19 06:44:39","130801","8991","3044","37","49054126","49055095","2018-03-01 16:19:12","-2","33","<p>I have an array of M samples
and each sample has a shape of: (11, 64)
So theoretically my main array should have a shape of (M, 11, 64)
but all I get is (m,) as the shape</p>

<p>I tried np.array(main_array) but that doesn't do anything. 
I was wondering if there was anyway to make numpy realize the dimensionality of the data that its using. </p>

<p>The way I get the data is by using pandas in the following fashion:</p>

<pre><code>main_array = data['source_info'].apply(func_to_create_2d_array_for_each_row).values
</code></pre>
","7971022","7971022","2018-03-01 16:21:07","Creating a 3D numpy array of from a prexisting iterable that has the appropriate shape","<python><arrays><pandas><numpy><multidimensional-array>","1","8","538"
"49055098","2018-03-01 17:07:10","3","","<p>I often load the dict into a pandas DataFrame then use the plot function of the DataFrame. <br>
Here is the one-liner:</p>

<pre><code>pandas.DataFrame(D, index=['quantity']).plot(kind='bar')
</code></pre>

<p><a href=""https://i.stack.imgur.com/EApgV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EApgV.png"" alt=""resulting plot""></a></p>
","1935611","","","0","362","anilbey","2012-12-28 23:37:48","800","127","1193","9","16010869","16014873","2013-04-15 08:34:47","74","109616","<p>Is there any way to plot a bar plot using <code>matplotlib</code> using data directly from a dict? </p>

<p>My dict looks like this: </p>

<pre><code>D = {u'Label1':26, u'Label2': 17, u'Label3':30}
</code></pre>

<p>I was expecting </p>

<pre><code>fig = plt.figure(figsize=(5.5,3),dpi=300)
ax = fig.add_subplot(111)
bar = ax.bar(D,range(1,len(D)+1,1),0.5)
</code></pre>

<p>to work, but it does not. </p>

<p>Here is the error:</p>

<pre><code>&gt;&gt;&gt; ax.bar(D,range(1,len(D)+1,1),0.5)
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/usr/local/lib/python2.7/site-packages/matplotlib/axes.py"", line 4904, in bar
    self.add_patch(r)
  File ""/usr/local/lib/python2.7/site-packages/matplotlib/axes.py"", line 1570, in add_patch
    self._update_patch_limits(p)
  File ""/usr/local/lib/python2.7/site-packages/matplotlib/axes.py"", line 1588, in _update_patch_limits
    xys = patch.get_patch_transform().transform(vertices)
  File ""/usr/local/lib/python2.7/site-packages/matplotlib/patches.py"", line 580, in get_patch_transform
    self._update_patch_transform()
  File ""/usr/local/lib/python2.7/site-packages/matplotlib/patches.py"", line 576, in _update_patch_transform
    bbox = transforms.Bbox.from_bounds(x, y, width, height)
  File ""/usr/local/lib/python2.7/site-packages/matplotlib/transforms.py"", line 786, in from_bounds
    return Bbox.from_extents(x0, y0, x0 + width, y0 + height)
TypeError: coercing to Unicode: need string or buffer, float found
</code></pre>
","1862909","355230","2019-04-29 20:27:13","Plot a bar using matplotlib using a dictionary","<python><matplotlib><plot>","6","7","1523"
"49055108","2018-03-01 17:08:06","7","","<p>Use <a href=""https://www.tensorflow.org/api_docs/python/tf/stack"" rel=""noreferrer""><code>tf.stack</code></a> on the last axis:</p>

<pre><code>tf.InteractiveSession()

tf.stack([x1, x2], axis=-1).eval()

#array([[[  1.,   7.],
#        [  2.,   8.],
#        [  3.,   9.]],

#       [[  4.,  10.],
#        [  5.,  11.],
#        [  6.,  12.]]], dtype=float32)
</code></pre>
","4983450","","","0","378","Psidom","2015-06-07 13:40:28","137976","6288","3736","111","49055062","49055108","2018-03-01 17:05:03","3","1197","<p>I have two tensors as below:</p>

<pre><code>x1 = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
x2 = tf.constant([[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]])
</code></pre>

<p>How should I merge and transform x1 and x2, so that I can have a tensor like below:</p>

<pre><code>[[[1.0, 7.0]
  [2.0, 8.0]
  [3.0, 9.0]]

 [[4.0, 10.0]
  [5.0, 11.0]
  [6.0, 12.0]]
]
</code></pre>
","1118236","","","tensorflow merge and zip two tensors","<python><matrix><tensorflow><tensor>","1","0","375"
"49055111","2018-03-01 17:08:12","0","","<p>When you read csv in pandas, read it like below: <code>pd.read_csv(file_name,parse_dates=True)</code></p>

<p>parse_dates=True converts data to date format if it has date.</p>
","8756315","","","0","179","Sunnysinh Solanki","2017-10-11 03:50:15","448","51","19","4","49054893","","2018-03-01 16:56:21","-1","19","<p>i have a csv file. that have a column named DOB. but when i want to change the data type into date type.  its gave error. 
here is the code</p>

<p><code>b['DOB'] =  pd.to_datetime(b['DOB'], format='%Y-%m-%d')</code></p>
","9430091","9209546","2018-03-01 16:57:26","convert object column into date type column using python","<python><pandas><datetime><null>","1","3","224"
"49055142","2018-03-01 17:09:51","1","","<pre><code>'''
=====================================
Rotating 3D voxel animation of PYTHON
=====================================

Demonstrates using ``ax.voxels`` with uneven coordinates
'''
import matplotlib.pyplot as plt
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.animation as manimation
from math import copysign

def explode(data):
    size = np.array(data.shape)*2
    data_e = np.zeros(size - 1, dtype=data.dtype)
    data_e[::2, ::2, ::2] = data
    return data_e

def voxel_face(corns, dm, nf):
    '''
    Grab the corner coordinates of one voxel face

    Parameters
    ----------
    corns : np.indices array of corners for one voxel
    dm : (dimension), values can be  0(x), 1(y), 2(z)
    nf : (near/far face), values can be 0(near), 1(far)
    '''

    lc = corns.copy() #local copy so we don't swap original
    if dm == 1 : #swap y into x and correct ordering
        lc[0], lc[1] = corns[1].transpose(1,0,2), corns[0].transpose(1,0,2)
    if dm == 2 : #swap z into x and correct ordering
        lc[0], lc[2] = corns[2].transpose(2,1,0), corns[0].transpose(2,1,0)

    ret = np.zeros((3,2,2))
    xc1 = lc[0,nf,0,0] #hold x dim constant
    ret[0,:] = np.array([[xc1, xc1], [xc1, xc1]])
    yc1, yc2 = lc[1,0,0:2,0]
    ret[1,:] = np.array([[yc1, yc2], [yc1, yc2]])
    zc1, zc2 = lc[2,0,0,0:2]
    ret[2,:] = np.array([[zc1, zc1], [zc2, zc2]])

    if dm != 0 : #swap x back into desired dimension
        ret[0], ret[dm] = ret[dm].copy(), ret[0].copy()
    return ret


# build PYTHON letters
n_voxels = np.zeros((4, 4, 5), dtype=bool)
letters = [None]*6
letter_faces = np.zeros((6,2),dtype=int)

#P
n_voxels[0, 0, :] = True
n_voxels[:, 0, -3] = True
n_voxels[:, 0, -1] = True
n_voxels[-1, 0, -2] = True
letters[0] = np.array(np.where(n_voxels)).T
letter_faces[0] = [1, 0] #close y face
n_voxels[...] = False
#Y
n_voxels[-1, 0, -3:] = True
n_voxels[-1, -1, :] = True
n_voxels[-1, :, -3] = True
n_voxels[-1, :, 0] = True
letters[1] = np.array(np.where(n_voxels)).T
letter_faces[1] = [0, 1] #far x face
n_voxels[...] = False
#T
n_voxels[:, 0, -1] = True
n_voxels[1:3, :, -1] = True
letters[2] = np.array(np.where(n_voxels)).T
letter_faces[2] = [2, 1] #far z face
n_voxels[...] = False
#H
n_voxels[0, 0, :] = True
n_voxels[0, -1, :] = True
n_voxels[0, :, 2] = True
letters[3] = np.array(np.where(n_voxels)).T
letter_faces[3] = [0, 0] #close x face
n_voxels[...] = False
#O
n_voxels[0, 1:3, 0] = True
n_voxels[-1, 1:3, 0] = True
n_voxels[1:3, 0, 0] = True
n_voxels[1:3, -1, 0] = True
letters[4] = np.array(np.where(n_voxels)).T
letter_faces[4] = [2, 0] #close z face
n_voxels[...] = False
#N
n_voxels[0, -1, :] = True
n_voxels[-1, -1, :] = True
n_voxels[1, -1, 1:3] = True
n_voxels[2, -1, 2:4] = True
letters[5] = np.array(np.where(n_voxels)).T
letter_faces[5] = [1, 1] #far y face
n_voxels[...] = False

fcol = np.full(n_voxels.shape, '#7A88CC60')
ecol = np.full(n_voxels.shape,  '#7D84A6')
filled = np.ones(n_voxels.shape)

# upscale the above voxel image, leaving gaps
filled_2 = explode(filled)
fcolors_2 = explode(fcol)
ecolors_2 = explode(ecol)

# Shrink the gaps
corn = np.indices(np.array(filled_2.shape) + 1).astype(float) // 2
ccorn = 0.05 #close corner
fcorn = 1.0 - ccorn
corn[0,0::2, :, :] += ccorn
corn[1,:, 0::2, :] += ccorn
corn[2,:, :, 0::2] += ccorn
corn[0,1::2, :, :] += fcorn
corn[1,:, 1::2, :] += fcorn
corn[2,:, :, 1::2] += fcorn


fig = plt.figure()
ax = fig.gca(projection='3d')
ax.axis(""off"")

#Plot the voxels
x, y, z = corn
ax.voxels(x, y, z, filled_2, facecolors=fcolors_2, edgecolors=ecolors_2)

#Plot the letter square faces
jj=0
for j in [x for x in letters if x is not None]:

    locf = np.empty((j.shape[0],3,2,2)) #local face

    ji = 0
    for i in j:
        i = i * 2 #skip empty voxels
        loc = corn[:,i[0]:i[0]+2,i[1]:i[1]+2,i[2]:i[2]+2] #local corners
        locf[ji] = voxel_face(loc, letter_faces[jj,0], letter_faces[jj,1])
        ax.plot_surface(locf[ji,0],locf[ji,1],locf[ji,2],color='#ffe500a0',
                        shade=False)
        ji += 1

    jj += 1


#Views:        PY,  P, Y,  T,   H,   O,  N,  PY
view_elev = [  5,   0, 0, 90,   0, -90,  0,   5]
view_azim = [-60, -90, 0, 90, 180, 180, 90, -60]
#'''
FFMpegWriter = manimation.writers['ffmpeg']
metadata = dict(title='Movie Test', artist='Matplotlib',
                comment='Movie support!')
writer = FFMpegWriter(fps=25, metadata=metadata)

with writer.saving(fig, ""pythonRot2.mp4"", 100):

    for j in range(20):
        ax.view_init(view_elev[0], view_azim[0])
        plt.draw()
        writer.grab_frame()

    for i in range(1,len(view_elev)):

        de = (view_elev[i] - view_elev[i-1])
        da = (view_azim[i] - view_azim[i-1])

        if abs(da) &gt;= 180 : #unecessary in this config
            da -= copysign(360, da)
        if abs(de) &gt;= 180 :
            de -= copysign(360, de)

        if i != 1 :
            steps = 60
        else :
            steps = 10
        da = da / steps
        de = de / steps

        for j in range(10): #Pause on direct view of a letter
            ax.view_init(view_elev[i-1], view_azim[i-1])
            plt.draw()
            writer.grab_frame()
        for j in range(steps): #Rotate to next letter
            ax.view_init(view_elev[i-1] + j*de,
                         view_azim[i-1] + j*da)
            plt.draw()
            writer.grab_frame()
#'''
</code></pre>

<p><img src=""https://i.imgur.com/DOQUH82.gif"" alt=""output""></p>
","2977541","","","1","5468","mTesseracted","2013-11-11 01:24:30","63","8","12","0","48833850","49055142","2018-02-16 19:47:32","1","454","<p><img src=""https://numfocus.org/wp-content/uploads/2016/07/numpy-logo-300.png"" alt=""numfocus numpy logo""></p>

<p>I want to reproduce this image using matplotlib. The example docs have a <a href=""https://matplotlib.org/devdocs/gallery/mplot3d/voxels_numpy_logo.html"" rel=""nofollow noreferrer"" title=""numpy logo"">numpy logo</a>, but all the voxel cubes are homogenous in color. 
<img src=""https://matplotlib.org/devdocs/_images/sphx_glr_voxels_numpy_logo_001.png"" alt=""matplotlib example""></p>

<p>I could imagine perhaps making a separate surface plot for each face I want to change but that seems impractical. Here's the code for the example docs numpy logo:</p>

<pre><code>import matplotlib.pyplot as plt
import numpy as np
from mpl_toolkits.mplot3d import Axes3D


def explode(data):
    size = np.array(data.shape)*2
    data_e = np.zeros(size - 1, dtype=data.dtype)
    data_e[::2, ::2, ::2] = data
    return data_e

# build up the numpy logo
n_voxels = np.zeros((4, 3, 4), dtype=bool)
n_voxels[0, 0, :] = True
n_voxels[-1, 0, :] = True
n_voxels[1, 0, 2] = True
n_voxels[2, 0, 1] = True
facecolors = np.where(n_voxels, '#FFD65DC0', '#7A88CCC0')
edgecolors = np.where(n_voxels, '#BFAB6E', '#7D84A6')
filled = np.ones(n_voxels.shape)

# upscale the above voxel image, leaving gaps
filled_2 = explode(filled)
fcolors_2 = explode(facecolors)
ecolors_2 = explode(edgecolors)

# Shrink the gaps
x, y, z = np.indices(np.array(filled_2.shape) + 1).astype(float) // 2
x[0::2, :, :] += 0.05
y[:, 0::2, :] += 0.05
z[:, :, 0::2] += 0.05
x[1::2, :, :] += 0.95
y[:, 1::2, :] += 0.95
z[:, :, 1::2] += 0.95

fig = plt.figure()
ax = fig.gca(projection='3d')
ax.voxels(x, y, z, filled_2, facecolors=fcolors_2, edgecolors=ecolors_2)

plt.show()
</code></pre>
","2977541","2977541","2018-02-16 20:00:59","matplotlib: changing a single voxel face color","<python><matplotlib>","1","4","1749"
"49055161","2018-03-01 17:10:59","3","","<p>Use <code>add</code> to add list of customers to new booking:</p>

<pre><code>booking = Booking.object.create(tour_ref=""ref"")
customers = list(Customer.objects.filter(email=""email@mail.com""))
booking.customers.add(customers)
</code></pre>

<p>or you can add booking to specific customer using reverse lookup <code>booking_set</code> and <code>create</code>:</p>

<pre><code>booking = Booking.object.create(tour_ref=""ref"")
customer.booking_set.create(tour_ref=""ref"")
</code></pre>
","641249","","","0","483","neverwalkaloner","2011-03-02 13:25:37","28058","1244","1934","0","49054950","49055161","2018-03-01 16:59:59","0","41","<p>Is there any way to create an object in a model using a ManyToManyField?</p>

<p>Here are the models:</p>

<pre><code>class Booking(models.Model):
    tour_ref = models.CharField(max_length=30)
    customers = models.ManyToManyField(Customer)

class Customer(models.Model):
    name = models.CharField(max_length=40)
    email = models.EmailField()
</code></pre>

<p>The task is to create a new Booking object. But how do I do this using specific customers from the Customer table? (I would be identifying them by email). (Obviously more than one customer would be likely).</p>

<p>Many thanks!</p>
","7576477","","","Django / Python - Using ManyToMany field In Object Creation","<python><django><django-models>","1","1","602"
"49055173","2018-03-01 17:11:17","0","","<p>Your last column isn't being parsed as floats, but strings.</p>

<p>To fix this, try casting to numeric before summing:</p>

<pre><code>import locale

locale.setlocale(locale.LC_NUMERIC, '')

df['2017'] = df['2017'].map(locale.atoi)
</code></pre>

<p>Better still, try reading in the data as numeric data. For example:</p>

<pre><code>df = pd.read_csv('file.csv', sep='\t', thousands=',')
</code></pre>
","9209546","9209546","2018-03-01 17:50:18","4","406","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49054969","49055173","2018-03-01 17:00:37","0","318","<p>The program I have written generally has done what I've wanted it to do - for the most part. To add totals of each column. My dataframe uses the csv file format. My code is below:</p>

<pre><code>import pandas as pd
import matplotlib.pyplot


class ColumnCalculation:
""""""This houses the functions for all the column manipulation calculations""""""

def max_electricity(self):
    df.set_index('Date', inplace=True)
    df.loc['Total'] = df.sum()
    print(df)


df = pd.read_csv(""2011-onwards-city-elec-consumption.csv"")
ColumnCalculation.max_electricity(df)
</code></pre>

<p>Also my dataset (I didn't know how to format it properly)</p>

<p><a href=""https://i.stack.imgur.com/AoGBP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AoGBP.png"" alt=""dataset""></a></p>

<p>The code nicely adds up all totals into a total column at the bottom of each column, except when it comes to the last column(2017)(image below):<a href=""https://i.stack.imgur.com/CcHWk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CcHWk.png"" alt=""enter image description here""></a></p>

<p>I am not sure the program does is, I've tried to use different formatting options like <code>.iloc</code> or <code>.ix</code> but it doesn't seem to make a difference. I have also tried adding each column individually (below):</p>

<pre><code>def max_electricity(self):
    df.set_index('Date', inplace=True)
    df.loc['Total', '2011'] = df['2011'].sum()
    df.loc['Total', '2012'] = df['2012'].sum()
    df.loc['Total', '2013'] = df['2013'].sum()
    df.loc['Total', '2014'] = df['2014'].sum()
    df.loc['Total', '2015'] = df['2015'].sum()
    df.loc['Total', '2016'] = df['2016'].sum()
    df.loc['Total', '2017'] = df['2017'].sum()
    print(df)
</code></pre>

<p>But I receive an error, as I assume this would be too much? I've tried to figure this out for a good hour and a bit. </p>
","","","2018-03-01 17:08:25","Sum all columns in each column in csv using Pandas","<python><pandas><dataframe>","1","0","1892"
"49055207","2018-03-01 17:13:07","1","","<p>Finally, I figured it out. I can't put </p>

<pre><code>if __name__ == '__main__':
    main()
</code></pre>

<p>in the <code>__init__</code>, it never work, which caused me try to run it directly and failed by <code>ImportError: cannot import name 'hello'</code>. When <code>__init__</code> is <code>__main__</code>, it cannot import substuffs, but it works if called from outside, for example, from submodule2, <code>submodule1.main()</code> still available. So this issue looks doesn't impact to user now. Thanks for <code>@progmatico</code>, you answers help me a lot to understand how those functions work together, very appreciate!</p>
","3593261","","","1","644","user3593261","2014-05-01 15:36:54","308","54","14","1","48890084","","2018-02-20 16:40:30","6","574","<p>I'm having a multiple sub-modules python project, for example ""myproject"" which has two submodules ""submodule1"" and ""submodule2"" underneath.</p>

<p>Project structure</p>

<pre><code>Example1/
|-- submodule1/
|   |-- __init__.py
|   |-- hello.py
...
|-- submodule2/
|   |-- __init__.py
...
</code></pre>

<p>And I have a <code>hello.py</code> under <code>submodule1</code> which has contents:</p>

<pre><code>import datetime

def greeting():
    print(""hello world! - "" + datetime.datetime.now().strftime(""%Y-%m-%d %H:%M:%S""))
</code></pre>

<p>The content for <code>submodule1</code>'s <code>__init__.py</code> is:</p>

<pre><code>def main():
    import hello
    hello.greeting()

if __name__ == '__main__':
    main()
</code></pre>

<p>I'm able to import <code>hello.py</code> and call <code>greeting()</code> function successfully here.</p>

<p>Now, I installed <code>submodule1</code> as a package to python, and then created <code>submodule2</code>, and tried to call <code>submodule1</code> within <code>submodule2</code> by put the following code in the <code>__init__.py</code> under <code>submodule2</code>:</p>

<pre><code>import submodule1

def main():
    submodule1.main()

if __name__ == '__main__':
    main()
</code></pre>

<p>It failed by message: </p>

<pre><code>....in main submodule1.main()
    ModuleNotFoundError: No module named 'hello'
</code></pre>

<p>I think the <code>hello</code> shouldn't be exposed to outside, but how am I able to let my <code>submodule1</code> works? I'm using python3</p>

<p>========</p>

<p>setup.py is:</p>

<pre><code>from setuptools import setup, find_packages

with open('requirements.txt') as f:
    requirements = f.read().splitlines()

__version__ = ""0.0.2""

setup(
    version=__version__
    name = ""mymodules"",
    packages = find_packages(exclude=['tests', '*.tests', '*.tests.*']),
    install_requires=requirements,
)
</code></pre>
","3593261","7857466","2018-02-21 15:55:34","Module can't be found when called from outside","<python><python-3.x>","3","8","1903"
"49055232","2018-03-01 17:14:25","0","","<p>If I am interpreting your question correctly, you have a web control that provides a ""search"" field which will progressively filter a list based on the content of the field.  So, as you type ""python"", your list will get reduced to just the items that match ""python"".  in this case you'll want to use your code, but add an additional wait for the item in the list that matches.  something like this:</p>

<pre><code>WebDriverWait(self.browser, 5).until(
            expected_conditions.presence_of_element_located((By.ID, ""name"")))
query = driver.find_element_by_id('name') 
query.send_keys('python')
options_list = some_code_to_find_your_options_list
target_option = WebDriverWait(options_list, 5).until(expected_conditions.presense_of_element_located((By.XPATH, ""[text()[contains(.,'python')]]"")))
driver.find_element_by_id(""button"").click()
</code></pre>

<p>This all assumes that the button selects the chosen item.</p>
","4321213","","","1","926","Breaks Software","2014-12-03 17:40:24","1428","239","122","7","49051111","","2018-03-01 13:49:24","3","2173","<p>I have a question regarding the send_keys function. How can I make the test wait for the entire content of send_keys to be entered? I can not use time.sleep, so I tried:</p>

<pre><code>WebDriverWait(self.browser, 5).until(
            expected_conditions.presence_of_element_located((By.ID, ""name"")))
query = driver.find_element_by_id('name') 
query.send_keys('python')
driver.find_element_by_id(""button"").click()
</code></pre>

<p>the app clicks the button before the action completes send_keys
thank you for an answer</p>
","9429143","","","python selenium send_keys wait","<python><selenium><selenium-webdriver><wait><sendkeys>","3","5","528"
"49055288","2018-03-01 17:17:34","1","","<p>Presumably the graph you exported contains a <code>decode_csv</code> op to read inputs. How quotes are handled will depend on the setting to the parameter <code>use_quote_delim</code>. To illustrate, consider the following:</p>

<pre><code>import tensorflow as tf

data = ['some text', '""some text""']
with tf.Session() as sess:
  use_delim = tf.decode_csv(data, [['']], use_quote_delim=True)
  dont = tf.decode_csv(data, [['']], use_quote_delim=False)
  out = sess.run([use_delim, dont])
  print(""use"", out[0])
  print(""dont"", out[1])

&gt;&gt;&gt; ('use', [array(['some text', 'some text'], dtype=object)])
&gt;&gt;&gt; ('dont', [array(['some text', '""some text""'], dtype=object)])
</code></pre>

<p>To get the behavior you are expecting, you want your exported model to set <code>use_quote_delim=True</code> (which is the default).</p>
","1399222","","","1","841","rhaertel80","2012-05-16 17:06:13","7109","1105","76","1","49046956","","2018-03-01 09:52:58","1","95","<p>I have trained a CNN model for predicting 0/1 values and using google ml-engine local predict for testing it. My test file contains 2 lines:</p>

<pre><code>some text
""some text""
</code></pre>

<p>and I know that this should give me 1 and 1 as predicted result. But output is 1 and 0. So double quotes matter for some reason.
While training pandas.read_csv is used for vocabulary creation. </p>

<pre><code>pd.read_csv(filename, header=None, sep=',', names=['source', 'title'],encoding='utf-8', na_filter=False,engine='python')
</code></pre>

<p>For prediction following command is used:</p>

<pre><code>gcloud ml-engine local predict --model-dir=.... --text-instances=... --format=json
</code></pre>

<p>Am I missing some parameter while reading csv for training or is this google ml-engine's issue?</p>
","963973","","","Tensorflow + google ml-engne local predict: How CSV quotes should be processed?","<python><pandas><tensorflow><google-cloud-ml>","2","0","808"
"49055327","2018-03-01 17:19:49","3","","<p>Using <code>itertools</code> you can do this:</p>

<pre><code>from itertools import product

list(map(''.join, product('0123456789', repeat=2)))

# ['00', '01', '02', '03', '04', '05', '06', '07', ...]
</code></pre>
","9209546","5079316","2018-03-01 21:29:09","3","219","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49055208","49055327","2018-03-01 17:13:13","0","132","<p>I've this code, and i'm trying to put all results of itertools in one single list 
: <code>l = ['00','01','02','03'..]</code> , instead of that i'm getting a list on every single line <code>['0', '0']  ['0', '1'] ['0', '2'] ['0', '3']</code> </p>

<pre><code>import itertools

for r in itertools.product('0123456789', repeat=2):
    print list(r)
</code></pre>
","9134855","9209546","2018-08-08 17:12:07","Put results of itertools in one single list","<python><list><itertools><cartesian-product>","2","8","364"
"49055342","2018-03-01 17:20:56","1","","<p>Taking up on Marcus' suggestion, I tried but unable to install scikit-learn dev version, but have found something similar called <a href=""https://pypi.python.org/pypi/category_encoders/1.2.6"" rel=""nofollow noreferrer"">category_encoders</a>.</p>

<p>Changing the code into this works:</p>

<pre><code>from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer
import category_encoders as CateEncoder

# Class that identifies Column type
class Columns(BaseEstimator, TransformerMixin):
    def __init__(self, names=None):
        self.names = names
    def fit (self, X, y=None, **fit_params):
        return self
    def transform(self, X):
        return X[self.names]

# Separate target from training features
y = df['MED']
X = df.drop('MED', axis=1)

X_selected = X.filter(['num1', 'num2', 'cate1', 'cate2'])

# from the selected X, further choose categorical only
X_selected_cat = X_selected.filter(['cate1', 'cate2']) # hand selected since some cat var has value 0, 1

# Find the numerical columns, exclude categorical columns
X_num_cols = X_selected.columns[X_selected.dtypes.apply(lambda c: np.issubdtype(c, np.number))] # list of numeric column names, automated here
X_cat_cols = X_selected_cat.columns # list of categorical column names, previously hand-slected

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_selected, y, 
                                                    test_size=0.5, 
                                                    random_state=567, 
                                                    stratify=y)

# Pipeline
pipe = Pipeline([
    (""features"", FeatureUnion([
        ('numeric', make_pipeline(Columns(names=X_num_cols),StandardScaler())),
        ('categorical', make_pipeline(Columns(names=X_cat_cols),CateEncoder.BinaryEncoder()))
    ])),
    ('LR_model', LogisticRegression()),
])
</code></pre>
","3635544","","","0","1973","KubiK888","2014-05-14 07:27:27","1466","352","134","3","49018652","","2018-02-27 22:00:37","1","887","<p>I have looked up for the right tutorials and Q/A on stackoverflow for the last few days without finding the right guide, primarily because examples showing use case of LabelBinarizer or OneHotEncoder don't show how it's incorporated into pipeline, and vice versa.</p>

<p>I have a dataset with 4 variables:</p>

<pre><code>num1    num2    cate1    cate2
3       4       Cat      1
9       23      Dog      0
10      5       Dog      1
</code></pre>

<p>num1 and num2 are numeric variables, cate1 and cate2 are categorical variables. I understand I need to encode the categorical variables somehow before fitting a ML algorithm, but I am not quite sure how to do that in pipeline after multiple tries.</p>

<pre><code>from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer

# Class that identifies Column type
class Columns(BaseEstimator, TransformerMixin):
    def __init__(self, names=None):
        self.names = names
    def fit (self, X, y=None, **fit_params):
        return self
    def transform(self, X):
        return X[self.names]

# Separate target from training features
y = df['MED']
X = df.drop('MED', axis=1)

X_selected = X.filter(['num1', 'num2', 'cate1', 'cate2'])

# from the selected X, further choose categorical only
X_selected_cat = X_selected.filter(['cate1', 'cate2']) # hand selected since some cat var has value 0, 1

# Find the numerical columns, exclude categorical columns
X_num_cols = X_selected.columns[X_selected.dtypes.apply(lambda c: np.issubdtype(c, np.number))] # list of numeric column names, automated here
X_cat_cols = X_selected_cat.columns # list of categorical column names, previously hand-slected

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_selected, y, 
                                                    test_size=0.5, 
                                                    random_state=567, 
                                                    stratify=y)

# Pipeline
pipe = Pipeline([
    (""features"", FeatureUnion([
        ('numeric', make_pipeline(Columns(names=X_num_cols),StandardScaler())),
        ('categorical', make_pipeline(Columns(names=X_cat_cols)))
    ])),
    ('LR_model', LogisticRegression()),
])
</code></pre>

<p>This gives me error <code>ValueError: could not convert string to float: 'Cat'</code></p>

<p>Replacing the last 4th line with this</p>

<pre><code>('categorical', make_pipeline(Columns(names=X_cat_cols),OneHotEncoder()))
</code></pre>

<p>will give me the same <code>ValueError: could not convert string to float: 'Cat'</code>.</p>

<p>Replacing the last 4th line with this</p>

<pre><code>('categorical', make_pipeline(Columns(names=X_cat_cols),LabelBinarizer(),OneHotEncoder()))
])),
</code></pre>

<p>will give me a different error <code>TypeError: fit_transform() takes 2 positional arguments but 3 were given</code>.</p>

<p>Replacing the last 4th line with this </p>

<pre><code>('numeric', make_pipeline(Columns(names=X_num_cols),LabelBinarizer())),
</code></pre>

<p>will give me this error <code>TypeError: fit_transform() takes 2 positional arguments but 3 were given</code>.</p>
","3635544","3635544","2018-02-27 22:57:36","How to combine LabelBinarizer and OneHotEncoder in pipeline in python for categorical variables?","<python><machine-learning><scikit-learn><preprocessor><feature-extraction>","2","5","3217"
"49055357","2018-03-01 17:21:55","1","","<p>This is the OP. I was able to fix the issue, and wanted to post my solution here in case it would help others. </p>

<p>Essentially I believe it occurred because Python2 is default on my machine, but pip is by default pointing to resources pertaining to Python3, or something like that. Doing <code>pip2 --version</code> instead provided the expected response.</p>
","5482356","","","0","368","user5482356","2015-10-24 02:48:00","168","23","16","0","49019136","","2018-02-27 22:40:09","0","1222","<p>I'm using terminal on mac, and anytime I attempt to use pip, I get the following error message telling me that it cannot find a module named zlib:</p>

<hr>

<pre><code>$ pip --version

Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/packages/__init__.py"", line 27, in &lt;module&gt;
    from . import urllib3
  File ""/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/packages/urllib3/__init__.py"", line 8, in &lt;module&gt;
    from .connectionpool import (
  File ""/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/packages/urllib3/connectionpool.py"", line 42, in &lt;module&gt;
    from .response import HTTPResponse
  File ""/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/packages/urllib3/response.py"", line 3, in &lt;module&gt;
    import zlib
ModuleNotFoundError: No module named 'zlib'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.5/bin/pip"", line 7, in &lt;module&gt;
    from pip import main
  File ""/usr/local/lib/python3.6/site-packages/pip/__init__.py"", line 21, in &lt;module&gt;
    from pip._vendor.requests.packages.urllib3.exceptions import DependencyWarning
  File ""/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/__init__.py"", line 62, in &lt;module&gt;
    from .packages.urllib3.exceptions import DependencyWarning
  File ""/usr/local/lib/python3.6/site-packages/pip/_vendor/requests/packages/__init__.py"", line 29, in &lt;module&gt;
    import urllib3
  File ""/usr/local/lib/python3.6/site-packages/urllib3/__init__.py"", line 8, in &lt;module&gt;
    from .connectionpool import (
  File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 36, in &lt;module&gt;
    from .response import HTTPResponse
  File ""/usr/local/lib/python3.6/site-packages/urllib3/response.py"", line 3, in &lt;module&gt;
    import zlib

ModuleNotFoundError: No module named 'zlib'
</code></pre>

<hr>

<p>I've read several SO posts with the same error message, and have tried their solutions, including attempting to install zlib using homebrew, which fails, and updating my Xcode developer tools. I also installed pip earlier using <code>python get-pip.py</code>, and it said it installed successfully. </p>

<p>The reason I need pip is to install a package for use on python 2.7, but doing <code>$ pip install ""package-name""</code> produces the same error as above. I have both Python 2 and 3 installed on my machine, if that helps. I'm kind of new to pip and using the command line in general, and I'm super confused; if anyone could help me out I'd really appreciate it.</p>
","5482356","9232626","2018-02-28 02:03:49","""No module named zlib"" error anytime I use pip","<python><python-2.7><pip>","1","2","2715"
"49055370","2018-03-01 17:22:42","0","","<pre><code>PATH_TO_TEST_IMAGES_DIR = 'test_images'
TEST_IMAGE_PATHS = []
for ext in ('*.png', '*.jpeg'):
    TEST_IMAGE_PATHS.extend(glob(join(PATH_TO_TEST_IMAGES_DIR, ext)))
</code></pre>

<p>solves the issue</p>
","4663377","","","0","214","Ajinkya","2015-03-12 14:43:37","636","194","93","3","49040059","49055370","2018-02-28 22:58:08","1","353","<p>I have the following script wherein I add the path to the images in TEST_IMAGE_PATHS. My input is ""test_images"" folder. In ""test_images"" folder images are named as image0, image1, image2 etc.</p>

<p>Script to add images in test_images to the path is:</p>

<pre><code>PATH_TO_TEST_IMAGES_DIR = 'test_images'
TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpeg'.format(i)) for i in range(5, 7) ]
</code></pre>

<p>This script outputs:
<a href=""https://i.stack.imgur.com/jjms4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jjms4.png"" alt=""enter image description here""></a></p>

<p>How do I modify this script such that: </p>

<ol>
<li><p>I can input any type of images(not just limited to jpeg) as mentioned above. Type of image include JPG, png, jpg, etc</p></li>
<li><p>Images should not be named as image0, image1, image2, image3, image4, image5, image6 etc. It should not be restricted to this naming convention and should pick up all the images in the 'test_images' folder</p></li>
</ol>

<p>I referred <a href=""https://stackoverflow.com/questions/10377998/how-can-i-iterate-over-files-in-a-given-directory"">How can I iterate over files in a given directory?</a>. as suggested, however this link explains how to reference files in the folder and add them to the path. My question has to do with modifications to do to the file after being added to the path. I am able to add files to the path using above script. I need to attach multiple extensions of images. to the existing path</p>
","4663377","4663377","2018-03-01 16:40:52","Python script to add path to the images","<python><python-3.x>","1","3","1535"
"49055377","2018-03-01 17:23:12","0","","<pre><code>def lenumerate(s, flip=False): ## Default value is False if not provided
    a = (text.split())
    b = ([len(x) for x in text.split()])
    c = list(zip(a,b))

    if list: ## Reverse the pairs if you want to
        c = list(zip(b, a))

    return c

text = ""But then of course African swallows are nonmigratory""
l = lenumerate(text)
print(l)      
</code></pre>
","7908770","","","0","376","Adi219","2017-04-23 09:50:18","3109","540","642","43","49055336","49055381","2018-03-01 17:20:18","0","31","<p>Beginner here, looking for some help with python!</p>

<p>Right now, I have a function defined that returns a list of lists:</p>

<pre><code>def lenumerate(s):
    a = (text.split())
    b = ([len(x) for x in text.split()])
    c = list(zip(a,b))
    print
    return c

text = ""But then of course African swallows are nonmigratory""
l = lenumerate(text)
print(l)        
</code></pre>

<p>And it prints out: </p>

<pre><code>[('But', 3), ('then', 4), ('of', 2), ('course', 6), ('African', 7), ('swallows', 8), ('are', 3), ('nonmigratory', 12)]
</code></pre>

<p>Now, I want to write a second version of the function that takes as second argument a boolean (i.e. True or False) called flip. The default value for flip shall be False. </p>

<p>I can reverse the order such that 'nonmigratory' appears at the beginning, but that's not what I want. I want the order preserved, just flipping to (3, ""But') all the way through.</p>

<p>I appreciate any help you can offer!</p>
","9424264","9209546","2018-03-07 00:19:54","Adding on to function with bool in python","<python><python-3.x><function><boolean>","3","2","974"
"49055381","2018-03-01 17:23:29","2","","<p>Here's one solution:</p>

<pre><code>def lenumerate(s, flip=False):
    a = text.split()
    b = map(len, a)
    c = zip(a, b) if not flip else zip(b, a)
    return list(c)

text = ""But then of course African swallows are nonmigratory""
l = lenumerate(text, True)
print(l)

# [(3, 'But'), (4, 'then'), (2, 'of'), (6, 'course'), (7, 'African'), (8, 'swallows'), (3, 'are'), (12, 'nonmigratory')]
</code></pre>

<p><strong>Explanation</strong></p>

<ul>
<li>You only need to apply <code>split()</code> once.</li>
<li>You can feed <code>map</code> directly into <code>zip</code>. This means more work is done lazily, rather than building unnecessary lists.</li>
<li>Python supports lazy ternary statements for one-line <code>if</code> / <code>else</code> constructs.</li>
<li>A <code>print</code> statement with no argument is not useful and can be removed.</li>
</ul>
","9209546","9209546","2018-03-01 17:29:13","0","868","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49055336","49055381","2018-03-01 17:20:18","0","31","<p>Beginner here, looking for some help with python!</p>

<p>Right now, I have a function defined that returns a list of lists:</p>

<pre><code>def lenumerate(s):
    a = (text.split())
    b = ([len(x) for x in text.split()])
    c = list(zip(a,b))
    print
    return c

text = ""But then of course African swallows are nonmigratory""
l = lenumerate(text)
print(l)        
</code></pre>

<p>And it prints out: </p>

<pre><code>[('But', 3), ('then', 4), ('of', 2), ('course', 6), ('African', 7), ('swallows', 8), ('are', 3), ('nonmigratory', 12)]
</code></pre>

<p>Now, I want to write a second version of the function that takes as second argument a boolean (i.e. True or False) called flip. The default value for flip shall be False. </p>

<p>I can reverse the order such that 'nonmigratory' appears at the beginning, but that's not what I want. I want the order preserved, just flipping to (3, ""But') all the way through.</p>

<p>I appreciate any help you can offer!</p>
","9424264","9209546","2018-03-07 00:19:54","Adding on to function with bool in python","<python><python-3.x><function><boolean>","3","2","974"
"49055402","2018-03-01 17:24:55","1","","<pre><code>&gt;&gt;&gt; from collections import defaultdict
... 
... 
... def solution(lst):
...     result = []
...     seen = defaultdict(int)
...     for num in lst:
...         seen[num] += 1
...         result.append(seen[num])
...     return result
... 
&gt;&gt;&gt; solution([88, 88, 27, 0, 88])
[1, 2, 1, 1, 3]
&gt;&gt;&gt; solution([8, 1, 2, 3, 1, 3, 3, 1, 2, 99])
[1, 1, 1, 1, 2, 2, 3, 3, 2, 1]
</code></pre>

<p>Without imports:</p>

<pre><code>&gt;&gt;&gt; def solution(lst):
...     result = []
...     seen = {}
...     for num in lst:
...         try:
...             seen[num] += 1
...         except KeyError:
...             seen[num] = 1
...         result.append(seen[num])
...     return result
... 
&gt;&gt;&gt; solution([88, 88, 27, 0, 88])
[1, 2, 1, 1, 3]
&gt;&gt;&gt; solution([8, 1, 2, 3, 1, 3, 3, 1, 2, 99])
[1, 1, 1, 1, 2, 2, 3, 3, 2, 1]
</code></pre>
","8079103","8079103","2018-03-01 17:32:20","2","880","G_M","2017-05-29 00:31:33","3102","440","139","287","49055298","49055417","2018-03-01 17:18:02","3","47","<p>Sorry, I'm pretty sure that somebody else may have asked this question already but I did not find it. I'd like to keep track the number of times I've seen this specific item like </p>

<p>Input : </p>

<pre><code>[88,88,27,0,88]
</code></pre>

<p>Desired Output :</p>

<pre><code>[1,2,1,1,3]
</code></pre>

<p>I'm looking for something especially good in terms of performance.
I'm ok with Numpy or Pandas solutions.</p>
","4383566","4383566","2018-03-01 17:34:59","Counter occurrences within the same item in python","<python><group-by><counter>","4","3","423"
"49055403","2018-03-01 17:24:55","3","","<p>Here is a simple way using a list comprehension:</p>

<pre><code>x = [8,1,2,3,1,3,3,1,2,99]
y = [x[:i].count(el) + 1 for i, el in enumerate(x)]
print(y)
</code></pre>

<p>Output:</p>

<pre><code>[1, 1, 1, 1, 2, 2, 3, 3, 2, 1]
</code></pre>
","3483203","","","3","243","user3483203","2014-04-01 00:22:53","39972","4672","2822","1887","49055298","49055417","2018-03-01 17:18:02","3","47","<p>Sorry, I'm pretty sure that somebody else may have asked this question already but I did not find it. I'd like to keep track the number of times I've seen this specific item like </p>

<p>Input : </p>

<pre><code>[88,88,27,0,88]
</code></pre>

<p>Desired Output :</p>

<pre><code>[1,2,1,1,3]
</code></pre>

<p>I'm looking for something especially good in terms of performance.
I'm ok with Numpy or Pandas solutions.</p>
","4383566","4383566","2018-03-01 17:34:59","Counter occurrences within the same item in python","<python><group-by><counter>","4","3","423"
"49055405","2018-03-01 17:24:59","0","","<p>The best way to interact programmatically with gdb is to simply use gdb's Python layer to do things.  Then you can communicate with it any way that is convenient -- say, by sending JSON messages to it, and having your Python code in gdb respond.</p>

<p>However, the more classic way is to use gdb's MI (""Machine Interface""), which is a mode gdb provides where its output is structured in a way that is more readily parsed.</p>

<p>Googling for ""ruby gdb MI"" shows some plausible libraries, like <a href=""https://github.com/mcarpenter/rubug"" rel=""nofollow noreferrer"">this one</a>, or <a href=""https://github.com/eqv/gdb-mi-parser"" rel=""nofollow noreferrer"">this one</a>.</p>
","1442050","","","1","679","Tom Tromey","2012-06-07 11:15:04","16698","1053","16","3","49017606","","2018-02-27 20:42:57","0","44","<p>is there any support for ruby to invoke and control gdb. I need gdb control from ruby to send gdb commands for c/c++ debugging sessions.  i need the tool mentioned in the question  given the link below for ruby</p>

<p><a href=""https://stackoverflow.com/questions/3482869/invoke-and-control-gdb-from-python"">Invoke and control GDB from Python</a> </p>
","2100829","","","invoke and control gdb from ruby","<python><ruby><gdb>","1","0","355"
"49055417","2018-03-01 17:25:43","2","","<pre><code>lst = [8,1,2,3,1,3,3,1,2,99]

cnt = {}
res = []

for x in lst:
    cnt[x] = cnt.get(x,0)+1
    res += [cnt[x]]

print(res)
</code></pre>

<p>Output</p>
","5095849","","","1","163","Amaro Vita","2015-07-08 21:03:14","432","27","8","24","49055298","49055417","2018-03-01 17:18:02","3","47","<p>Sorry, I'm pretty sure that somebody else may have asked this question already but I did not find it. I'd like to keep track the number of times I've seen this specific item like </p>

<p>Input : </p>

<pre><code>[88,88,27,0,88]
</code></pre>

<p>Desired Output :</p>

<pre><code>[1,2,1,1,3]
</code></pre>

<p>I'm looking for something especially good in terms of performance.
I'm ok with Numpy or Pandas solutions.</p>
","4383566","4383566","2018-03-01 17:34:59","Counter occurrences within the same item in python","<python><group-by><counter>","4","3","423"
"49055422","2018-03-01 17:26:16","1","","<p>Try executing it as raw string. I have added <code>""r""</code> at the start of cmd_3</p>

<p><strong>Ex:</strong></p>

<pre><code>cmd_3= r'''cat temp_1.cat | awk -F '[=]' '{printf(""%s,"",$2);} END {printf(""\n"");}' '''
call(cmd_3, shell=True)
</code></pre>
","532312","","","1","257","Rakesh","2010-12-06 13:07:54","56694","5302","758","1508","49055354","49055422","2018-03-01 17:21:44","0","137","<p>The script in python is like below:</p>

<pre><code>cmd_3='''cat temp_1.cat | awk -F '[=]' '{printf(""%s,"",$2);} END {printf(""\n"");}' '''
call(cmd_3, shell=True)
</code></pre>

<p>It returns: awk: line 1: runaway string constant "" ...</p>

<p>Thanks!</p>
","9225401","9225401","2018-03-01 17:23:33","How to execute awk command with format claming in python script?","<python><awk>","1","3","257"
"49055444","2018-03-01 17:27:33","1","","<p>Using <code>funcy.merge</code>:</p>

<pre><code>from funcy import merge

x, y = map(lambda d: {hash(frozenset(c.keys())):c for c in d}, (a['configurations'], b['configurations']))
merged = list(merge(x, y).values())

print(json.dumps(merged, indent=4))
</code></pre>

<p>Result:</p>

<pre><code>[
    {
        ""this-needs-to-stay"": {
            ""properties"": {
                ""some_property"": ""EXISTING""
            }
        }
    },
    {
        ""this-needs-to-be-updated"": {
            ""properties"": {
                ""this.would.stay"": ""CHANGED"",
                ""this.would.be.added"": ""ADDED""
            }
        }
    },
    {
        ""this-would-be-added"": {
            ""properties"": {
                ""some-property"": ""ADDED""
            }
        }
    }
]   
</code></pre>
","2022518","2022518","2018-03-01 17:34:30","0","794","LetMeSOThat4U","2013-01-29 16:57:17","2841","278","111","4","49053777","","2018-03-01 16:01:33","1","193","<p>I have two json files which contain all kinds of levels of properties. I want to write a python script that will replace existing properties and add missing ones, but keep all the other ones in place.</p>

<p>In my attempts until now the entire ""configurations"" array of the original file is overwritten, including all properties. All examples I could find show merge for objects without arrays. Any help would be appreciated.</p>

<p>Original:</p>

<pre><code>{
  ""configurations"": [
    {
      ""this-needs-to-stay"": {
        ""properties"": {
          ""some_property"": ""EXISTING""
        }
      }
    },
    {
      ""this-needs-to-be-updated"": {
        ""properties"": {
          ""this.would.stay"": ""EXISTING"",
          ""this.wont.be.overwritten"": ""EXISTING""
        }
      }
    }
  ],
  ""other-values-1"": [
    {
      ""components"": [
        {
          ""name"": ""EXISTING""
        }
      ],
      ""name"": ""somename""
    }
  ],
  ""other-values-2"": {
    ""randomProperties"": {
      ""type"": ""random""
    },
    ""and_so_on"": ""you_get_the_point""
  }
}
</code></pre>

<p>Additional data that should be added to original:</p>

<pre><code>{
  ""configurations"" : [
    {
      ""this-would-be-added"": {
        ""properties"": {
          ""some-property"": ""ADDED""
        }
      }
    },
    {
      ""this-needs-to-be-updated"": {
        ""properties"": {
          ""this.would.stay"": ""CHANGED"",
          ""this.would.be.added"": ""ADDED""
        }
      }
    }
  ]
}
</code></pre>

<p>Result is a merging of the two on the property level:</p>

<pre><code>{
  ""configurations"": [
    {
      ""this-would-be-added"": {
        ""properties"": {
          ""some-property"": ""ADDED""
        }
      }
    },
    {
      ""this-needs-to-stay"": {
        ""properties"": {
          ""some_property"": ""EXISTING""
        }
      }
    },
    {
      ""this-needs-to-be-updated"": {
        ""properties"": {
          ""this.would.stay"": ""CHANGED"",
          ""this.would.be.added"": ""ADDED""
          ""this.wont.be.overwritten"": ""EXISTING""
        }
      }
    }
  ],
  ""other-values-1"": [
    {
      ""components"": [
        {
          ""name"": ""EXISTING""
        }
      ],
      ""name"": ""somename""
    }
  ],
  ""other-values-2"": {
    ""randomProperties"": {
      ""type"": ""random""
    },
    ""and_so_on"": ""you_get_the_point""
  }
}
</code></pre>
","1081960","","","How to merge json objects containing arrays using python?","<python><json><merge><array-merge>","3","0","2328"
"49055460","2018-03-01 17:28:56","0","","<p>Even if you can get <code>pad</code> to work, it would be faster to insert <code>a</code> into a blank <code>b</code>.  <code>pad</code> is setup for complex padding patterns, and does the job iteratively - row by row, column by column.</p>

<pre><code>In [29]: a = np.full((2,3),'#')
In [30]: a
Out[30]: 
array([['#', '#', '#'],
       ['#', '#', '#']], dtype='&lt;U1')
In [31]: b = np.full((4,5),'?')
In [32]: b
Out[32]: 
array([['?', '?', '?', '?', '?'],
       ['?', '?', '?', '?', '?'],
       ['?', '?', '?', '?', '?'],
       ['?', '?', '?', '?', '?']], dtype='&lt;U1')
In [33]: b[1:-1,1:-1] = a
In [34]: b
Out[34]: 
array([['?', '?', '?', '?', '?'],
       ['?', '#', '#', '#', '?'],
       ['?', '#', '#', '#', '?'],
       ['?', '?', '?', '?', '?']], dtype='&lt;U1')
</code></pre>

<hr>

<p>Here's the clever <code>pad_with</code> solution, with an added print so we can see how often it is called:</p>

<pre><code>In [36]: def pad_with(vector, pad_width, iaxis, kwargs):
    ...:     ...:     print(vector)
    ...:     ...:     pad_value = kwargs.get('padder', '?')
    ...:     ...:     vector[:pad_width[0]] = pad_value
    ...:     ...:     vector[-pad_width[1]:] = pad_value
    ...:     ...:     return vector
    ...: 
In [37]: np.pad(a,1,pad_with)
['' '' '' '']
['' '#' '#' '']
['' '#' '#' '']
['' '#' '#' '']
['' '' '' '']
['?' '?' '?' '?' '?']
['' '#' '#' '#' '']
['' '#' '#' '#' '']
['?' '?' '?' '?' '?']
Out[37]: 
array([['?', '?', '?', '?', '?'],
       ['?', '#', '#', '#', '?'],
       ['?', '#', '#', '#', '?'],
       ['?', '?', '?', '?', '?']], dtype='&lt;U1')
</code></pre>
","901925","901925","2018-03-01 17:34:10","0","1607","hpaulj","2011-08-19 06:44:39","130801","8991","3044","37","49049852","49050076","2018-03-01 12:34:58","1","798","<p>I have created a 2d Numpy string array like so:</p>

<pre><code>a = np.full((2, 3), '#', dtype=np.unicode)
print(a)
</code></pre>

<p>The output is:    </p>

<pre><code>array([['#', '#', '#'], ['#', '#', '#']], dtype=`'&lt;U1'`)
</code></pre>

<p>I would like to pad it with '?' on all sides with a width of 1. I'm expecting output as:</p>

<pre><code>array([
['?', '?', '?', '?', '?'],
['?', '#', '#', '#', '?'],
['?', '#', '#', '#', '?'],
['?', '#', '#', '#', '?'],
['?', '?', '?', '?', '?']],
dtype=`'&lt;U1')
</code></pre>

<p>I tried the following:</p>

<pre><code>b = np.pad(a, ((1, 1), (1, 1)), 'constant', constant_values=(('?', '?'), ('?', '?')))
</code></pre>

<p>But that gives the following error:</p>

<pre><code>File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
File ""/usr/lib/python3/dist-packages/numpy/lib/arraypad.py"", line 1357, in pad
    cast_to_int=False)
File ""/usr/lib/python3/dist-packages/numpy/lib/arraypad.py"", line 1069, in _normalize_shape
    return tuple(tuple(axis) for axis in arr.tolist())
AttributeError: 'tuple' object has no attribute 'tolist'
</code></pre>

<p>Similar code works for integers. What am I doing wrong for strings?</p>
","6695849","1000551","2018-03-01 12:41:43","Numpy string array pad with string","<python><string><python-3.x><numpy>","2","2","1173"
"49055510","2018-03-01 17:32:03","0","","<p>That link is not JSON but a python <code>dict</code>.</p>

<p>You can make it a valid JSON string using <code>dumps</code>:</p>

<p><code>json_string = json.dumps(your_dict_variable)</code></p>

<p>And then make it a dict (which it already is) using <code>loads</code>:</p>

<p><code>json.loads(json_string)</code></p>
","4225229","","","1","322","JacobIRR","2014-11-07 02:07:43","4780","861","1957","38","49054888","","2018-03-01 16:56:11","0","29","<p>I have the following json string :</p>

<pre><code>{u'debug': {u'version': 3.1}, u'status': u'OK', u'results': {u'api_timestamp': u'1439552208', u'totalCommentsFound': 9300, u'totalCommentsReturned': 25, u'comments': [{u'assetID': 3425398, u'replies': [], u'lft': 9, u'assetURL': u'http://wordplay.blogs.nytimes.com/2015/03/31/why-i-moved-to-florida/', u'parentID': 14580714, u'commentID': 14581040, u'rgt': 10, u'userDisplayName': u'John', u'createDate': u'1427860827', u'userID': 12857582, u'replyCount': 0, u'commentTitle': u'&lt;br/&gt;', u'status': u'approved', u'approveDate': u'1427860868', u'userTitle': u'NULL', u'editorsSelection': 0, u'statusID': 2, u'userURL': u'NULL', u'userLocation': u'Chicago', u'commentType': u'userReply', u'updateDate': u'1427860868', u'commentSequence': 14581040, u'commentBody': u""Yea, Martin, but what does the wife know. She doesn't like It's a Wonderful Life and doesn't even know Bert and Ernie were the cop and the cab driver. She just knows Bert and Ernie as muppets who used to baby sit for her."", u'recommendationCount': 1}, [...]
</code></pre>

<p><a href=""https://pastebin.com/qZ5hKB4j"" rel=""nofollow noreferrer"">Full JSON Data File</a></p>

<pre><code>obj = json.loads(line)
</code></pre>

<p>I am unable to use <code>json.loads(mystring)</code> as it throws an error. What should I do?</p>
","6765462","1392490","2018-03-02 12:35:41","Unable to load json data as strings inside it are in unicode","<python><json>","2","3","1343"
"49055515","2018-03-01 17:32:27","0","","<p><a href=""https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists"" rel=""nofollow noreferrer"">Python functions can be called with a single list of arguments</a>, instead of multiple individual arguments.</p>

<p>We can use this to make one set of arguments and one reversed set of arguments, depending on the state of <code>flip</code></p>

<pre><code>def lenumerate(s, flip=False):
    words = text.split()
    word_lengths = [len(x) for x in text.split()]
    args = [words, word_lengths] if flip else [word_lengths, words]
    return list(zip(*args))


text = ""But then of course African swallows are nonmigratory""

print(lenumerate(text))
print(lenumerate(text, True))
</code></pre>

<p>prints</p>

<pre><code>[(3, 'But'), (4, 'then'), (2, 'of'), (6, 'course'), (7, 'African'), (8, 'swallows'), (3, 'are'), (12, 'nonmigratory')]
[('But', 3), ('then', 4), ('of', 2), ('course', 6), ('African', 7), ('swallows', 8), ('are', 3), ('nonmigratory', 12)]
</code></pre>

<p>Notes</p>

<ul>
<li>The parentheses you were using were superfluous</li>
<li>Try to use speaking variable names, not <code>a</code> and <code>b</code></li>
</ul>

<p>Python's <em>list comprehensions</em> make it possible to avoid writing a function in the first place. The above function could be written as:</p>

<pre><code>result = [(word, len(word)) for word in text.split()]
print(result)
</code></pre>
","18771","","","0","1399","Tomalak","2008-09-19 11:44:16","271209","22506","7280","284","49055336","49055381","2018-03-01 17:20:18","0","31","<p>Beginner here, looking for some help with python!</p>

<p>Right now, I have a function defined that returns a list of lists:</p>

<pre><code>def lenumerate(s):
    a = (text.split())
    b = ([len(x) for x in text.split()])
    c = list(zip(a,b))
    print
    return c

text = ""But then of course African swallows are nonmigratory""
l = lenumerate(text)
print(l)        
</code></pre>

<p>And it prints out: </p>

<pre><code>[('But', 3), ('then', 4), ('of', 2), ('course', 6), ('African', 7), ('swallows', 8), ('are', 3), ('nonmigratory', 12)]
</code></pre>

<p>Now, I want to write a second version of the function that takes as second argument a boolean (i.e. True or False) called flip. The default value for flip shall be False. </p>

<p>I can reverse the order such that 'nonmigratory' appears at the beginning, but that's not what I want. I want the order preserved, just flipping to (3, ""But') all the way through.</p>

<p>I appreciate any help you can offer!</p>
","9424264","9209546","2018-03-07 00:19:54","Adding on to function with bool in python","<python><python-3.x><function><boolean>","3","2","974"
"49055528","2018-03-01 17:33:21","1","","<p>You can only pass an array to LabelEncoder object's fit method but you are passing a matrix to it (X_train). Find the columns which has categorical values in X_train and pass it to the LabelEncoder like,</p>

<pre><code>le = le.fit(X_train[:, 0]) // to encode the first column
X_train[:, 0] = le.transform(X_train[:, 0]) // to convert to numerical
</code></pre>

<p>You can do both fit and transform in the same call using,</p>

<pre><code>X_train[:, 0] = le.fit_transform(X[:, 0])
</code></pre>
","9429907","","","2","499","Suba Selvandran","2018-03-01 16:00:06","183","17","11","2","49050357","","2018-03-01 13:05:51","0","45","<pre><code>import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
#mydataset = pd.read_csv('AttributeDataset.csv')
names =
['Dress_ID','Style','Price','Rating','Size','Season','NeckLine', 
'SleeveLength','waiseline','Material','FabricType','Decoration','Pattern 
Type','Recommendaation']
dataframe = pd.read_csv('AttributeDataset.csv',names=names)
print(dataframe.shape)
array = dataframe.values
X = array[:,:-1]
Y = array[:,-1]

from sklearn.cross_validation import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
le.fit(X_train)`
</code></pre>

<p>For this code, we are unable to fit the data. When we compile this code the following error occurs:</p>

<pre><code>Traceback (most recent call last):

  File ""&lt;ipython-input-29-3df12e017cba&gt;"", line 1, in &lt;module&gt;
    le.fit(X)

  File ""C:\ProgramData\Anaconda3\lib\site-packages\sklearn\preprocessing    \label.py"", line 95, in fit
y = column_or_1d(y, warn=True)

  File ""C:\ProgramData\Anaconda3\lib\site-packages\sklearn\utils\validation.py"", line 614, in column_or_1d
    raise ValueError(""bad input shape {0}"".format(shape))

ValueError: bad input shape (501, 13).
</code></pre>

<p>Can anyone help me in solving this issue? And explain to us how to preprocess the data and convert it from categorical to numerical values.</p>
","9428947","7366707","2018-03-01 14:49:26","Related to preprocessing data in sklearn using python","<python>","1","0","1416"
"49055542","2018-03-01 17:34:20","1","","<p>the problem is caused because the children are not stuck in the constructor of the parent, it does it an instant later so search_box will be None in the constructor, the solution is to execute it an instant after finishing the constructor with the help of Clock:</p>

<pre><code>from kivy.clock import Clock


class DisplayPage(Screen):
    search_box= ObjectProperty()
    label_maening=StringProperty()
    label_synonym=StringProperty()
    label_ant=StringProperty()
    label_sentence=StringProperty()


    def __init__(self, **kwargs):
        super(DisplayPage,self).__init__(**kwargs)
        Clock.schedule_once(self.callback)

    def callback(self, dt):
        with open('vocab_words.json') as rfile:
            data=json.load(rfile)

        word=self.search_box.text               #the error occurred here 

        for value in data:
            if value['word']==word:
                self.label_maening=value['meaning']
                self.label_synonym=value['synonym']
                self.label_ant=value['antonyms']
                self.label_sentence=value['sentence']
</code></pre>
","6622587","","","0","1111","eyllanesc","2016-07-21 23:29:11","114264","27275","2584","21000","49053729","49055542","2018-03-01 15:59:12","0","78","<p>I am making an application.as far as I know I am doing thingd correctly but still getting this error</p>

<blockquote>
  <p>word=self.search_box.text 
   AttributeError: 'NoneType' object has no attribute 'text'</p>
</blockquote>

<p>I have checked for typos and other common mistakes still its not working.</p>

<p>heres the code-</p>

<pre><code>import kivy
kivy.require('1.10.0')

from kivy.uix.stacklayout import StackLayout
from kivy.uix.floatlayout import FloatLayout
from kivy.uix.boxlayout import BoxLayout
from kivy.uix.label import Label 
from kivy.app import App
from kivy.uix.popup import Popup  
from kivy.uix.screenmanager import ScreenManager, Screen 
from kivy.lang import Builder 
from kivy.properties import ObjectProperty
from kivy.uix.textinput import TextInput
from kivy.properties import StringProperty


import json

Builder.load_file('VocabularyJournal.kv')

class MenuPage(Screen):
    pass

class DisplayPage(Screen):
    search_box= ObjectProperty()
    label_maening=StringProperty()
    label_synonym=StringProperty()
    label_ant=StringProperty()
    label_sentence=StringProperty()


    def __init__(self, **kwargs):
        super(DisplayPage,self).__init__(**kwargs)
        with open('vocab_words.json') as rfile:
            data=json.load(rfile)

        word=self.search_box.text               #the error occurred here 

        for value in data:
            if value['word']==word:
                self.label_maening=value['meaning']
                self.label_synonym=value['synonym']
                self.label_ant=value['antonyms']
                self.label_sentence=value['sentence']


class WordInsertPage(Screen):
    pass


class NewWordPage(Screen):
    word_box = ObjectProperty()
    meaning_box = ObjectProperty()
    synonym_box = ObjectProperty()
    ant_box = ObjectProperty()
    sentence_box = ObjectProperty()


    def saving_data(self):

        with open('vocab_words.json') as rfile:
            data=json.load(rfile)


        entry={'word': self.word_box.text, 'meaning': self.meaning_box.text, 'synonym': self.synonym_box.text, 'antonyms': self.ant_box.text, 'sentence': self.sentence_box.text}
        data.append(entry)


        with open('vocab_words.json','w') as wfile:
            json.dump(data,wfile,indent=4)


class FlashCard(Screen):
    pass

class WordGroups(Screen):
    pass

class Manager(ScreenManager):
    pass

class VocabularyJournalApp(App):
    def build(self):
        return Manager()

object = VocabularyJournalApp()
object.run()
</code></pre>

<p>heres the kv code-        </p>

<pre><code>&lt;Manager&gt;:
    MenuPage:
        name: 'menu'
    WordInsertPage:
        name: 'insertword'
    NewWordPage:
        name: 'newword'
    FlashCard:
        name: 'flashcard'
    WordGroups:
        name: 'wordgroup'
    DisplayPage:
        name: 'display'

&lt;MenuPage&gt;:
    Label: 
        text: ""Vocabulary Journal""
        size_hint: .90,.10

    StackLayout:
        orientation: 'tb-rl'
        spacing: 10
        padding: 10

        Button:
            text: 'Search'
            size_hint: None,.20
            width: 130
            background_down:'darkgrey.png'
            on_press: root.manager.current='insertword'
        Button:
            text: 'New Word'
            size_hint: None,.20
            width: 130
            background_down:'darkgrey.png'
            on_press: root.manager.current='insertword'
        Button:
            text: 'Flash Cards'
            size_hint: None,.20
            width: 130
            background_down:'darkgrey.png'
            on_press: root.manager.current='flashcard'

        Button:
            text: 'Word Groups'
            size_hint: None,.20
            width: 130
            background_down:'darkgrey.png'
            on_press: root.manager.current='wordgroup'

&lt;WordInsertPage&gt;:

    FloatLayout:

        Button: 
            text: ""New Word""
            on_press: root.manager.current='newword'
            font_size: 30
            color: 0,0,0,1
            size_hint: .2, .1
            pos_hint: {""center_x"": .5, ""center_y"": 0.3}
            background_down: 'darkgrey.png'
        Button:
            text: ""search word""
            on_press: root.manager.current='display'
            font_size: 30
            color: 0,0,0,1
            size_hint: .2, .1
            pos_hint: {""center_x"": .5, ""center_y"": 0.5}
            background_down: 'darkgrey.png'
        Button:
            text: 'Flash Cards'
            on_press: root.manager.current=""flashcard""
            font_size: 30
            color: 0,0,0,1
            size_hint: .2, .1
            pos_hint: {""center_x"": .5, ""center_y"": 0.7}
            background_down: 'darkgrey.png'



&lt;NewWordPage&gt;:
    id: refer_to_it
    word_box: word_input
    meaning_box: meaning_input
    synonym_box: Synonym_input
    ant_box: ant_input
    sentence_box: sentence_input
    StackLayout:
        orientation: 'tb-rl'
        spacing: 10
        padding: 90
        TextInput:
            text: ""write your word here""
            color: 1,1,1,1
            id: word_input
            width: 300
            size_hint: None, .10

        TextInput:
            text: ""write meaning of your word here""
            color: 1,1,1,1
            id: meaning_input
            width: 600
            size_hint: None, .20

        TextInput:
            text: ""write Synonyms of your word here""
            color: 1,1,1,1
            id: Synonym_input
            width: 600
            size_hint: None, .20

        TextInput:
            text: ""write antonyms of your text here""
            color: 1,1,1,1
            id: ant_input
            width: 600
            size_hint: None, .20

        TextInput:
            text: ""write a sentence based on your word here""
            color: 1,1,1,1
            id: sentence_input
            width: 600
            size_hint: None, .20

        Button:
            text: 'Save'
            size_hint: None,.10
            width: 130
            background_down:'darkgrey.png'
            on_press: refer_to_it.saving_data()     

&lt;DisplayPage&gt;:
    search_box: search_text  # search_box is the reference to the textinput in py file
    BoxLayout:
        size_hint_y: None
        height: '48dp'

        TextInput:
            text:'enter the word you wanna search here'
            id: search_text


        ToggleButton:
            id: tog
            text: 'Horizontal'
            group: 'accordion'
            state: 'down'

        ToggleButton:
            text: 'Vertical'
            group: 'accordion'

    Accordion:
        orientation: 'horizontal' if tog.state == 'down' else 'vertical'    

        AccordionItem:
            title:'meaning'

            Label:
                text: root.label_maening
                text_size: self.width, None

        AccordionItem:
            title:'Synonym'

            Label:
                text: root.label_synonym
                text_size: self.width, None

        AccordionItem:
            title:'Antonym'

            Label:
                text: root.label_ant
                text_size: self.width, None

        AccordionItem:
            title:'Sentence'

            Label:
                text: root.label_sentence
                text_size: self.width, None
</code></pre>
","9355642","6622587","2018-03-01 17:12:14","in __init__ word=self.search_box.text AttributeError: 'NoneType' object has no attribute 'text'","<python><kivy>","1","3","7335"
"49055552","2018-03-01 17:34:52","0","","<p>This should do what you want</p>

<pre><code># clean the string of ""white chars""
num = num.replace("" "", """").replace(""\n"", """").replace(""\r"", """")
# now ""num"" has actually 5000 chars/digits, so
# you either you do it like this, but might be wrong
s = sum(int(num[i:i + 150]) for i in xrange(0, len(num), 150))
# or if you want the sum only the numbers with 150 digits, skipping the last chunk
s = sum(int(num[i:i + 150]) if i + 150 &lt; len(num) else 0 for i in xrange(0, len(num), 150))
# but actually ... seeing that you need only the first 10 digits ... it does not matter
# the last 50-digit number doesn't have enough ""power"" to change those digits (at least with this input)
print str(s)[:10]
# ==&gt; 1944206193 
</code></pre>
","4020610","4020610","2018-03-01 18:26:17","0","734","Lohmar ASHAR","2014-09-08 20:06:58","1193","75","31","4","49055073","","2018-03-01 17:05:36","0","73","<p>I am trying to solve a problems that involves a number with around 5100 digits. The question asks to find all the 150 digit numbers inside the 5100 digits and sum them together. The question wants you to give the first ten digits of the resulting sum. Its a Euler Project Problem and here is the link:<a href=""https://projecteuler.net/problem=13"" rel=""nofollow noreferrer"">https://projecteuler.net/problem=13</a>. </p>

<p>My solution keeps giving me this error - ValueError: invalid literal for int() with base 10: '37107287533902102798797998220837590246510135740250\n46376937677490009712648124896970078050417018260538\n743249861995247410594742333095130581237266173096'. </p>

<p>Here is my code: </p>

<pre><code>num = """"""37107287533902102798797998220837590246510135740250
46376937677490009712648124896970078050417018260538
74324986199524741059474233309513058123726617309629
91942213363574161572522430563301811072406154908250
23067588207539346171171980310421047513778063246676
89261670696623633820136378418383684178734361726757
28112879812849979408065481931592621691275889832738
44274228917432520321923589422876796487670272189318
47451445736001306439091167216856844588711603153276
70386486105843025439939619828917593665686757934951
62176457141856560629502157223196586755079324193331
64906352462741904929101432445813822663347944758178
92575867718337217661963751590579239728245598838407
58203565325359399008402633568948830189458628227828
80181199384826282014278194139940567587151170094390
35398664372827112653829987240784473053190104293586
86515506006295864861532075273371959191420517255829
71693888707715466499115593487603532921714970056938
54370070576826684624621495650076471787294438377604
53282654108756828443191190634694037855217779295145
36123272525000296071075082563815656710885258350721
45876576172410976447339110607218265236877223636045
17423706905851860660448207621209813287860733969412
81142660418086830619328460811191061556940512689692
51934325451728388641918047049293215058642563049483
62467221648435076201727918039944693004732956340691
15732444386908125794514089057706229429197107928209
55037687525678773091862540744969844508330393682126
18336384825330154686196124348767681297534375946515
80386287592878490201521685554828717201219257766954
78182833757993103614740356856449095527097864797581
16726320100436897842553539920931837441497806860984
48403098129077791799088218795327364475675590848030
87086987551392711854517078544161852424320693150332
59959406895756536782107074926966537676326235447210
69793950679652694742597709739166693763042633987085
41052684708299085211399427365734116182760315001271
65378607361501080857009149939512557028198746004375
35829035317434717326932123578154982629742552737307
94953759765105305946966067683156574377167401875275
88902802571733229619176668713819931811048770190271
25267680276078003013678680992525463401061632866526
36270218540497705585629946580636237993140746255962
24074486908231174977792365466257246923322810917141
91430288197103288597806669760892938638285025333403
34413065578016127815921815005561868836468420090470
23053081172816430487623791969842487255036638784583
11487696932154902810424020138335124462181441773470
63783299490636259666498587618221225225512486764533
67720186971698544312419572409913959008952310058822
95548255300263520781532296796249481641953868218774
76085327132285723110424803456124867697064507995236
37774242535411291684276865538926205024910326572967
23701913275725675285653248258265463092207058596522
29798860272258331913126375147341994889534765745501
18495701454879288984856827726077713721403798879715
38298203783031473527721580348144513491373226651381
34829543829199918180278916522431027392251122869539
40957953066405232632538044100059654939159879593635
29746152185502371307642255121183693803580388584903
41698116222072977186158236678424689157993532961922
62467957194401269043877107275048102390895523597457
23189706772547915061505504953922979530901129967519
86188088225875314529584099251203829009407770775672
11306739708304724483816533873502340845647058077308
82959174767140363198008187129011875491310547126581
97623331044818386269515456334926366572897563400500
42846280183517070527831839425882145521227251250327
55121603546981200581762165212827652751691296897789
32238195734329339946437501907836945765883352399886
75506164965184775180738168837861091527357929701337
62177842752192623401942399639168044983993173312731
32924185707147349566916674687634660915035914677504
99518671430235219628894890102423325116913619626622
73267460800591547471830798392868535206946944540724
76841822524674417161514036427982273348055556214818
97142617910342598647204516893989422179826088076852
87783646182799346313767754307809363333018982642090
10848802521674670883215120185883543223812876952786
71329612474782464538636993009049310363619763878039
62184073572399794223406235393808339651327408011116
66627891981488087797941876876144230030984490851411
60661826293682836764744779239180335110989069790714
85786944089552990653640447425576083659976645795096
66024396409905389607120198219976047599490197230297
64913982680032973156037120041377903785566085089252
16730939319872750275468906903707539413042652315011
94809377245048795150954100921645863754710598436791
78639167021187492431995700641917969777599028300699
15368713711936614952811305876380278410754449733078
40789923115535562561142322423255033685442488917353
44889911501440648020369068063960672322193204149535
41503128880339536053299340368006977710650566631954
81234880673210146739058568557934581403627822703280
82616570773948327592232845941706525094512325230608
22918802058777319719839450180888072429661980811197
77158542502016545090413245809786882778948721859617
72107838435069186155435662884062257473692284509516
20849603980134001723930671666823555245252804609722
53503534226472524250874054075591789781264330331690""""""

def sumLarge(num2):
    sumFinal = 0
    i = 0
    while i &lt; len(num2):
        currentElem = num2[i: i+150]
        sumFinal += int(currentElem)
        i += 150
    return sumFinal

print(sumLarge(num))
</code></pre>

<p>I think the error is arising because there are line breaks in the number string. I am not sure how to remove them. I know one way I could probably avoid this problem is to put the entire number on one line. However, I would like to avoid doing that. So is there away to succinctly remove the line breaks?</p>
","8922261","","","Adding numbers with large digits in python and how to avoid issues with line breaks","<python><python-3.x><numbers><line-breaks><string-math>","1","5","6366"
"49055574","2018-03-01 17:36:19","0","","<p>If you use <code>maxResults=0</code>, <code>search_issues</code> will do the pagination for you to retrieve all records for the search request.</p>
","9430322","","","0","151","Shrike","2018-03-01 17:30:55","1","0","0","0","48689762","","2018-02-08 16:02:40","0","470","<p>I want to gather all jira issues via REST API.</p>

<p>My current code gets the first 100 rows of data because atlassian limits 100 rows per request.</p>

<p>Now, I have more than 500 rows but I don't know how to get them all instead of only 100 rows:</p>

<pre><code>from collections import Counter
from jira import JIRA
import csv


jira = JIRA(basic_auth=('foo@gmail.com', 'mypassw'), options={'server': 'https://myjira.atlassian.net'})

daten = [issue.key + ';' + str(issue.fields.status) + ';' + issue.fields.summary + ';' + str(issue.fields.customfield_10121) + ';' + '\n' for issue in jira.search_issues('project=dt', maxResults=100)]

daten_enc = u''.join((daten)).encode('utf-8').strip()

print daten_enc
</code></pre>

<p>Output is e.g.:</p>

<ul>
<li><p>DT-1469;Done;My Summary;ServiceDesk 1;</p></li>
<li><p>DT-1468;Done;My Summary;ServiceDesk 2;</p></li>
<li><p>DT-1467;Done;My Summary;ServiceDesk 3;</p></li>
</ul>

<p>So, it is possible to add a jql query in </p>

<pre><code>jira.search_issues('project=dt &amp; issuekey &lt; issue.key', maxResults=100)
</code></pre>

<p>But issue.key should be the last row of 100 rows (e.g. DT-1476).</p>

<p>I need to count 100 rows and then take the last issue.key to add in the above jql query </p>

<pre><code>(jira.search_issues('project=dt &amp; issuekey &lt; issue.key.variable', maxResults=100)
</code></pre>
","5770447","","","Python: How to loop an API request to skip limit","<python><jira-rest-api><python-jira>","1","4","1372"
"49055577","2018-03-01 17:36:44","5","","<p>I up-voted the previous answer as it gave me the insight to verify the data and inputs to the <code>fit_generator</code> function and find out what the root cause of the issue actually was.  In summary, in cases where my dataset was small, I calculated <code>validation_steps</code> and <code>steps_per_epoch</code> which turned out to be zero (0) which caused the error.</p>

<p>I suppose the better longer-term answer, perhaps for the Keras team, is to cause an error/exception in <code>fit_generator</code> when these values are zero, which would probably lead to a better understanding about how to address this issue.</p>
","3011570","4388776","2019-06-22 18:12:12","0","630","Eric Broda","2013-11-20 04:25:54","1922","179","46","5","49035200","49035538","2018-02-28 17:19:12","4","6334","<p>I am training a Keras (Tensorflow backend, Python, on MacBook) and am getting an error in the early stopping callback in fit_generator function.  The error is as follows:</p>

<pre><code>RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are:
  (self.monitor, ','.join(list(logs.keys()))),
RuntimeWarning: Can save best model only with val_acc available, skipping.

'skipping.' % (self.monitor), RuntimeWarning
[local-dir]/lib/python3.6/site-packages/keras/callbacks.py:497: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are:
  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning
[local-dir]/lib/python3.6/site-packages/keras/callbacks.py:406: RuntimeWarning: Can save best model only with val_acc available, skipping.
  'skipping.' % (self.monitor), RuntimeWarning)
Traceback (most recent call last):
  :
  [my-code]
  :
  File ""[local-dir]/lib/python3.6/site-packages/keras/legacy/interfaces.py"", line 91, in wrapper
return func(*args, **kwargs)
  File ""[local-dir]/lib/python3.6/site-packages/keras/engine/training.py"", line 2213, in fit_generator
callbacks.on_epoch_end(epoch, epoch_logs)
  File ""[local-dir]/lib/python3.6/site-packages/keras/callbacks.py"", line 76, in on_epoch_end
callback.on_epoch_end(epoch, logs)
  File ""[local-dir]/lib/python3.6/site-packages/keras/callbacks.py"", line 310, in on_epoch_end
self.progbar.update(self.seen, self.log_values, force=True)
AttributeError: 'ProgbarLogger' object has no attribute 'log_values'
</code></pre>

<p>My code is as follows (which looks OK):</p>

<pre><code>:
ES = EarlyStopping(monitor=""val_loss"", min_delta=0.001, patience=3, mode=""min"", verbose=1)
:
self.model.fit_generator(
        generator        = train_batch,
        validation_data  = valid_batch,
        validation_steps = validation_steps,
        steps_per_epoch  = steps_per_epoch,
        epochs           = epochs,
        callbacks        = [ES],
        verbose          = 1,
        workers          = 3,
        max_queue_size   = 8)
</code></pre>

<p>The error message appears to relate to the early stopping callback but the callback looks OK.  Also the error states that the val_loss is not appropriate, but I am not sure why... one more unusual thing about this is that the error only occurs when I use smaller data sets.</p>

<p>Any help is appreciated.</p>
","3011570","","","Keras early stopping callback error, val_loss metric not available","<python><tensorflow><keras>","5","0","2423"
"49055605","2018-03-01 17:38:31","2","","<p>You can only assign multiple variables dynamically if the number of outputs is certain. If you assign the result of <code>confusion_matrix</code> to a single variable, you can then check its contents in a loop and assign the contents conditionally:</p>

<p><code>returned = confusion_matrix(y_true, y_predict).ravel()</code></p>

<pre><code>for var in returned:
    #... do stuff with each item in the returned collection
</code></pre>

<p>You could also just check its length and if it is 4, you can proceed as usual:</p>

<pre><code>if len(returned) == 4:
    tn, fp, fn, tp = returned
</code></pre>
","4225229","","","0","605","JacobIRR","2014-11-07 02:07:43","4780","861","1957","38","49055410","","2018-03-01 17:25:10","1","1100","<p>I'm trying to use the <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"" rel=""nofollow noreferrer"">confusion_matrix</a> function, as follows:</p>

<pre><code>tn, fp, fn, tp = confusion_matrix(y_true, y_predict).ravel()
</code></pre>

<p><code>y_true</code> and <code>y_predict</code> are both lists. When I return their shape, I get: <code>(71,)</code>.</p>

<p>I'm however getting the following error for the above statement:</p>

<pre><code>ValueError: too many values to unpack
</code></pre>

<p>I'm not sure if it is because of the second (empty) dimension in <code>(71,)</code>? I'm not sure how to remove it if it is the issue here.</p>

<p>Any thoughts?</p>

<p>Thanks.</p>
","588855","","","confusion_matrix - too many values to unpack","<python><list><scikit-learn><confusion-matrix>","1","2","730"
"49055618","2018-03-01 17:39:26","1","","<p>One option to construct an edited odb is to use the ""odbcombine"" Abaqus plugin. I believe this plugin is an officially supported Abaqus product. </p>

<p>The plugin can be imported from the abaqus_plugins folder by</p>

<pre><code>sys.path.insert('r'/abaqus_main/6.14-1/code/python2.7/lib/abaqus_plugins/odbCombine')
import odbCombineKernel
odbCombineKernel.combineOdbs(jobName='myjob',
                             configName='myconfig.xml', 
                             loadODB=1) 
</code></pre>

<p>For this command to work it requires an XML input file. The XML file must be configured with something like: </p>

<pre><code>&lt;?xml version=""1.0"" ?&gt;
&lt;OdbInput&gt;
    &lt;MasterOdb Name=""oldjob.odb""/&gt;
&lt;/OdbInput&gt;
</code></pre>

<p>If you only specify a Master Odb, you don't need additional odb's to combine. Then the odbcombine tool works as an odb filter rather than a combiner. </p>
","3203246","","","0","910","johnzilla","2014-01-16 15:52:51","153","24","109","1","49055487","","2018-03-01 17:30:47","1","945","<p>So in the Abaqus Scripting Interface there is no direct way to delete data off an odb file or to duplicate an odb with some data removed from the database. </p>

<p>So how can we edit the odb to remove unwanted output? </p>
","3203246","3203246","2018-03-01 17:39:34","Abaqus Python: How can I edit or remove data from an odb output database","<python><abaqus>","2","0","227"
"49055630","2018-03-01 17:40:14","1","","<p>one with generators:</p>

<pre><code>def return_count(l):
    cnt = {}
    for x in l:
        cnt[x] = cnt.get(x, 0) + 1
        yield cnt[x]

print(list(return_count([8, 1, 2, 3, 1, 3, 3, 1, 2, 99])))
</code></pre>
","1132603","","","0","220","Totoro","2012-01-05 16:22:26","641","55","9","0","49055298","49055417","2018-03-01 17:18:02","3","47","<p>Sorry, I'm pretty sure that somebody else may have asked this question already but I did not find it. I'd like to keep track the number of times I've seen this specific item like </p>

<p>Input : </p>

<pre><code>[88,88,27,0,88]
</code></pre>

<p>Desired Output :</p>

<pre><code>[1,2,1,1,3]
</code></pre>

<p>I'm looking for something especially good in terms of performance.
I'm ok with Numpy or Pandas solutions.</p>
","4383566","4383566","2018-03-01 17:34:59","Counter occurrences within the same item in python","<python><group-by><counter>","4","3","423"
"49055635","2018-03-01 17:40:38","1","","<p>The xpath has a problem.  this should work:</p>

<pre><code>browser.find_element_by_xpath(""//span[@id='ui-id-3']/following-sibling::button"").click()
</code></pre>

<p>To get to the span below it, you could use:</p>

<pre><code>browser.find_element_by_xpath(""//span[@id='ui-id-3']/following-sibling::button/span"")
</code></pre>

<p>by the way, if you're more comfortable with CSS, the equivalent paths would be:</p>

<pre><code>div#ui-id-3 &gt; button
div#ui-id-3 &gt; button span:nth-of-type(1)
</code></pre>
","4321213","","","2","512","Breaks Software","2014-12-03 17:40:24","1428","239","122","7","49054985","49055635","2018-03-01 17:01:28","0","1651","<p>I need to close a popup window from the website itself by pressing the ""X"" window on the top right. Here is the shortened, relevant part of my code:</p>

<pre><code>chromedriver = r'C:\Users\do\Desktop\chromedriver.exe'
browser = webdriver.Chrome(chromedriver)
url = 'Fake.com'

browser.get(url) 
browser.find_element_by_id('imgAttachmentsImg').click()
# I need to close out the window after this
</code></pre>

<p>The issue is that there are no unique identifiers for the ""X"" button itself. However, the pop up itself does have a unique identifier. I just need to be able to flow it down to the X button.</p>

<p>Info from the page:</p>

<pre><code>1. V&lt;div class=""ui-dialog ui-widget ui-widget-content ui-corner-all ui-front ui-draggable ui-resizable"" tabindex=""-1"" role=""dialog"" aria-describedby=""attachmentsDialogOverview"" aria-labelledby=""ui-id-3"" style=""position: absolute; height: auto; width: auto; top: 239px; left: 102px; display: block;""&gt;
  2. &lt;div class=""ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix""&gt;
    3. &lt;span id=""ui-id-3"" class=""ui-dialog-title""&gt;Attachments&lt;/span&gt;
   4. V&lt;button type=""button"" class=""ui-button ui-widget ui-state-default ui-corner-all ui-button-icon-only ui-dialog-titlebar-close"" role=""button"" aria-disabled=""false"" title=""close""&gt;
       5. &lt;span class=""ui-button-icon-primary ui-icon ui-icon-closethick""&lt;/span&gt;
       6. &lt;span class=""ui-button-text""&gt;close&lt;/span&gt;&lt;/button&gt;
</code></pre>

<p>I am new to using Python and Selenium. I switched over from VBA and still don't exactly understand all the syntax yet, so I do make mistakes! I did find a bandaid solution by just having sendkeys press Escape. But I am trying to actually understand how to actually solve this. I am not sure what errors I made with my solution:</p>

<pre><code>browser.find_element_by_xpath(""//span[@id, 'ui-id-3']/following-sibling::button"").click()
</code></pre>

<p>Questions</p>

<ol>
<li><p>Why did my solution not work?</p></li>
<li><p>How would I locate ""ui-id-3""(on line 3) and get to the element on Line 4 to click it?</p></li>
<li><p>How would I locate ""ui-id-3""(on line 3) and get to the element on <strong>Line 5</strong> to click it? (just so I know how to move across multiple elements)</p></li>
</ol>

<hr>

<p>Relevant links I looked over:</p>

<p><a href=""https://stackoverflow.com/questions/41127120/following-sibling-python-selenium"">Following-Sibling Python Selenium</a></p>

<p><a href=""https://stackoverflow.com/questions/23887592/find-next-sibling-element-in-python-selenium"">Find next sibling element in Python Selenium?</a></p>

<p><a href=""https://stackoverflow.com/questions/8923721/using-xpath-selector-following-siblingtext-in-selenium-python"">Using XPath Selector &#39;following-sibling::text()&#39; in Selenium (Python)</a></p>

<p><a href=""https://stackoverflow.com/questions/30948860/python-selenium-webdriver-get-div-value-if-sibling-contains-string"">Python + Selenium WebDriver - Get div value if sibling contains string</a></p>

<p><a href=""https://stackoverflow.com/questions/45697705/what-is-the-correct-syntax-for-using-a-variable-and-following-sibling-in-python"">What is the correct syntax for using a variable and following-sibling in Python Selenium?</a></p>
","9358196","","","Python/Selenium - Getting the element after an element","<python><selenium><siblings>","1","7","3295"
"49055679","2018-03-01 17:43:14","0","","<p>This might help. I am first reading the raw content from the text and then using the <code>literal_eval</code>to convert it to a python dictionary object.</p>

<p><strong>Demo</strong></p>

<pre><code>import ast
import json
p = ""PATH_TO/json_data.txt""
with open(p, ""r"") as infile:
    data = infile.read()

data = ast.literal_eval(data)
print data['debug']
</code></pre>

<p><strong>Output</strong>:</p>

<pre><code>{u'version': 3.1}
</code></pre>
","532312","","","1","451","Rakesh","2010-12-06 13:07:54","56694","5302","758","1508","49054888","","2018-03-01 16:56:11","0","29","<p>I have the following json string :</p>

<pre><code>{u'debug': {u'version': 3.1}, u'status': u'OK', u'results': {u'api_timestamp': u'1439552208', u'totalCommentsFound': 9300, u'totalCommentsReturned': 25, u'comments': [{u'assetID': 3425398, u'replies': [], u'lft': 9, u'assetURL': u'http://wordplay.blogs.nytimes.com/2015/03/31/why-i-moved-to-florida/', u'parentID': 14580714, u'commentID': 14581040, u'rgt': 10, u'userDisplayName': u'John', u'createDate': u'1427860827', u'userID': 12857582, u'replyCount': 0, u'commentTitle': u'&lt;br/&gt;', u'status': u'approved', u'approveDate': u'1427860868', u'userTitle': u'NULL', u'editorsSelection': 0, u'statusID': 2, u'userURL': u'NULL', u'userLocation': u'Chicago', u'commentType': u'userReply', u'updateDate': u'1427860868', u'commentSequence': 14581040, u'commentBody': u""Yea, Martin, but what does the wife know. She doesn't like It's a Wonderful Life and doesn't even know Bert and Ernie were the cop and the cab driver. She just knows Bert and Ernie as muppets who used to baby sit for her."", u'recommendationCount': 1}, [...]
</code></pre>

<p><a href=""https://pastebin.com/qZ5hKB4j"" rel=""nofollow noreferrer"">Full JSON Data File</a></p>

<pre><code>obj = json.loads(line)
</code></pre>

<p>I am unable to use <code>json.loads(mystring)</code> as it throws an error. What should I do?</p>
","6765462","1392490","2018-03-02 12:35:41","Unable to load json data as strings inside it are in unicode","<python><json>","2","3","1343"
"49055725","2018-03-01 17:46:41","0","","<p>that cgi script is returning html for a full page, and doesn't require post.  It probably is not meant for the ajax call you are trying to do.  try putting a simple link in the main html file to start</p>

<pre><code>&lt;a href='/cgi-bin/test1.py'&gt;
  &lt;img style=""height: 63px""src=""http://images.clipartpanda.com/stop-sign-clipart-119498958977780800stop_sign_right_font_mig_.svg.hi.png""&gt;
&lt;/a&gt;
</code></pre>

<p>If you want to switch to a post, maybe a simple form could also do it.</p>

<pre><code>&lt;form method='post' action='/cgi-bin/test1.py'&gt;
  &lt;input type=""submit"" value=""stop""&gt;
&lt;/form&gt;
</code></pre>

<p>I think the ajax call might have the wrong path in it, and a few other issues.  This might work.  If the alert says 200, it ran.</p>

<pre><code>function bot_stop() {
  var xmlhttp = new XMLHttpRequest();
  xmlhttp.onreadystatechange = function() {
    if (this.readyState == 4) {
      alert(this.status);
    }
  };
  xmlhttp.open('POST','/cgi-bin/test1.py',true);
  xmlhttp.send(null);
}
</code></pre>

<p>If you are only accessing the script by ajax, you can change it so it just prints a simple ""OK"" instead of the full html page.  Something like this...</p>

<pre><code>#! /usr/bin/python
import os

# TODO: maybe check that this is a post and not a get before restarting
os.system(""sudo service motion stop"")
os.system(""sudo service motion stop"")
os.system(""sudo motion"")
os.system(""sudo service motion start"")

print ""Content-type: text/plain""
print """"
print ""OK""
</code></pre>

<p>--------------- next issue-----------</p>

<p>you might not be able to run those commands with sudo if the server user doesn't have permissions set up.  Python isn't really needed in the above script, so it can be replaced by this:</p>

<pre><code>#! /bin/bash
sudo service motion stop
sudo service motion stop
sudo motion
sudo service motion start

echo Content-type: text/plain
echo
echo OK
</code></pre>

<p>to see what user you are running these scripts as maybe point the browser at the script (called /var/www/cgi-bin/whoami.sh)
(when you create new scripts remember to <code>chmod +x &lt;scriptname&gt;</code>)</p>

<pre><code>#! /bin/bash
echo Content-type: text/plain
echo
whoami
</code></pre>

<p>and then point the browser at <a href=""http://192.168.1.24/cgi-bin/whoami.sh"" rel=""nofollow noreferrer"">http://192.168.1.24/cgi-bin/whoami.sh</a></p>

<p>to see what happens when you try to sudo a different command try this</p>

<pre><code>#! /bin/bash
echo Content-type: text/plain
echo
sudo echo 1
echo 2
</code></pre>

<p>if sudo is the issue, on the command line you can <code>sudo su &lt;whatever user you get from the whoami script&gt;</code> and see what happens when you try the script as them.</p>

<p>---- and if sudo permissions are the problem ---</p>

<p>a solution could be to put the four restart commands into their own script, and give the lighttpd user sudo permissions to run that script without a password like this: <a href=""https://serverfault.com/questions/294661/how-to-grant-sudo-rights-only-to-specific-script-files"">https://serverfault.com/questions/294661/how-to-grant-sudo-rights-only-to-specific-script-files</a>.  (or find another way to make those commands work without sudo - could be the subject of another question)</p>

<hr>

<p><code>#!</code> is backwards in the code above.</p>

<p>When you run cgi scripts on the command line to test them, try running them like this</p>

<pre><code>./test1.py
</code></pre>

<p>not</p>

<pre><code>python test1.py
</code></pre>

<p>and that will help make sure that the interpreter and permissions are set up correctly.  You may have to fix the permissions like this <code>chmod +x test1.py</code></p>

<p>In some cases the server will use this information to run the script.  In other cases I case you configure the interpreter for the extension and none of this part matters.</p>
","5203563","5203563","2018-03-14 06:32:27","9","3897","Alex028502","2015-08-07 20:09:18","1372","140","215","6","49055394","","2018-03-01 17:24:21","1","87","<p>This issue is I call a function to run and I’m not sure if it’s running. I have site hosted on a raspberry pi using lighttpd and some .cgi and .py located in the /var/www/cgi-bin. When I go to the that location ie 192.168.1.24/cgi-bin/test1.py it runs but when I click the button that should trigger the event I don’t seem to get anything. Also in the script are system commands but they don’t seem to work either. </p>

<p>HTML code:</p>

<pre><code>&lt;button style=""height: 75px; width: 85px"" onclick=""bot_stop()""&gt;
&lt;img style=""height: 63px""src=""http://images.clipartpanda.com/stop-sign-
clipart-119498958977780800stop_sign_right_font_mig_.svg.hi.png""&gt;
&lt;/button&gt;

&lt;script&gt;
var xmlhttp;
function bot_stop()
{
xmlhttp.open('POST','CGI-Executables/test1.py',true);
xmlhttp.send(null);
}
&lt;/script&gt;
</code></pre>

<p>CGI Code:</p>

<pre><code>!#/usr/bin/python
import os

print  ""Content-type: text/html\r\n\r\n""
print  ""&lt;html&gt;""
print  ""&lt;head&gt;&lt;title&gt; code is executing&lt;/title&gt;&lt;/head&gt;""
os.system(""sudo service motion stop"")
os.system(""sudo service motion stop"")
os.system(""sudo motion"")
os.system(""sudo service motion start"")
print  ""&lt;p&gt; code ran &lt;/p&gt;""
print  ""&lt;/html&gt;""
</code></pre>
","5976546","4225229","2018-03-01 17:44:42","How to know if CGI code ran effectively?","<python><raspberry-pi><lighttpd>","1","4","1258"
"49055730","2018-03-01 17:47:05","2","","<p>Yes! You can use the set_tick_params() method to do this. Here's an example for setting up a histogram to work as you described:</p>

<pre><code>hist.xaxis.set_ticks_position('both')  # Adding ticks to both top and bottom
hist.xaxis.set_tick_params(direction='in', which='top')  # The bottom will maintain the default of 'out'
</code></pre>
","7947967","","","0","344","Brandon Schabell","2017-05-01 15:57:42","459","44","14","2","34955160","","2016-01-22 20:14:07","3","1904","<p>Is there a way to make the direction of the tick marks on the bottom of the xaxis point outward, but the top ones point inward, using matplotlib?</p>
","5434336","","","Direction of tick marks in matplotlib","<python><matplotlib><graph><plot>","2","0","153"
"49055750","2018-03-01 17:48:33","2","","<p>Use <code>from_</code> instead of <code>from</code> since <code>from</code> is a keyword in python used for imports.</p>
","4225229","4225229","2018-03-01 17:58:49","4","124","JacobIRR","2014-11-07 02:07:43","4780","861","1957","38","49055680","49055750","2018-03-01 17:43:25","1","42","<p>I have set up a Twilio app that I want to send updates to people, but I don't want to respond to individual text. I just want them to call if there is a question. I have everything working but I want to show incoming text if one gets sent, just to make sure I don't miss a question. I am using python/flask. I have my template set up and I can get it to show me all my messages, and even who the message went to, but I can't get it to show who the message was from.</p>

<pre><code>{% for msg in msgs %}
    {% if msg.direction == 'inbound' %}
        &lt;p&gt; {{ msg.from }} : {{ msg.body }} &lt;/p&gt;
    {% endif %}
{% endfor %}
</code></pre>

<p>This will show all my messages but won't show anything else. If I change it to {{ msg.to }} it will show who the message is to. I have also tried to request in my app.</p>

<pre><code>numbs = request.form[""From""]
</code></pre>

<p>And then iterate over it in my template using a for loop, but no such luck. </p>
","9211026","","","Can't get twilio to show 'from' data but it will show 'to' data","<python><flask><twilio><twilio-api>","1","0","967"
"49055765","2018-03-01 17:49:20","0","","<p>with open(""list1.txt"") as f:
    doIHaveToCopyTheLine = False
    '''open output file in write mode'''
    with open(""output.txt"", 'w') as f1:
        '''iterate line by line'''
        for line in f:
            if 'tests/file/myword' in line:
                doIHaveToCopyTheLine = True
            elif doIHaveToCopyTheLine:
                f1.write(line)</p>

<p>f1.close()
f.close()</p>
","7387934","","","0","395","kishor kumar Jha","2017-01-07 14:35:56","161","29","0","0","15343743","15343861","2013-03-11 16:33:39","25","134866","<p>I would like to copy certain lines of text from one text file to another. In my current script when I search for a string it copies everything afterwards, how can I copy just a certain part of the text? E.g. only copy lines when it has ""tests/file/myword"" in it?</p>

<p>current code:</p>

<pre><code>#!/usr/bin/env python
f = open('list1.txt')
f1 = open('output.txt', 'a')

doIHaveToCopyTheLine=False

for line in f.readlines():

    if 'tests/file/myword' in line:
        doIHaveToCopyTheLine=True

    if doIHaveToCopyTheLine:
        f1.write(line)

f1.close()
f.close()
</code></pre>
","1803391","395737","2013-03-11 16:45:29","Copying from one text file to another using Python","<python><text-files>","7","3","593"
"49055777","2018-03-01 17:49:48","0","","<p>I ran into the same problem while installing scrapy. The solution for me was a little bit different, not the file pip_vendor\pkg_resources__init__.py, but the \pip\compat__init__.py, I've changed line 75 to mbcs, and then pip installed scrapy successfully! </p>

<p>After that, I changed that line back to utf-8. </p>
","6167839","","","0","321","Fabio Mendes Soares","2016-04-06 15:57:30","31","6","6","0","45830222","","2017-08-23 03:36:26","0","534","<p><a href=""https://i.stack.imgur.com/sooVG.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/sooVG.jpg"" alt=""enter image description here""></a></p>

<pre><code>C:\Users\Administrator&gt;pip3 install scrapy
Collecting scrapy
Using cached Scrapy-1.4.0-py2.py3-none-any.whl
Requirement already satisfied: pyOpenSSL in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from scrapy)
Requirement already satisfied: service-identity in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from scrapy)
Requirement already satisfied: lxml in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from scrapy)
Requirement already satisfied: six&gt;=1.5.2 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from scrapy)
Requirement already satisfied: w3lib&gt;=1.17.0 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from scrapy)
Collecting Twisted&gt;=13.1.0 (from scrapy)
Using cached Twisted-17.5.0.tar.bz2
Requirement already satisfied: cssselect&gt;=0.9 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from scrapy)
Requirement already satisfied: queuelib in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from scrapy)
Requirement already satisfied: parsel&gt;=1.1 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from scrapy)
Collecting PyDispatcher&gt;=2.0.5 (from scrapy)
Requirement already satisfied: cryptography&gt;=1.9 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from pyOpenSSL-&gt;scrapy)
Requirement already satisfied: attrs in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from service-identity-&gt;scrapy)
Requirement already satisfied: pyasn1 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from service-identity-&gt;scrapy)
Requirement already satisfied: pyasn1-modules in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from service-identity-&gt;scrapy)
Requirement already satisfied: zope.interface&gt;=4.0.2 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from Twisted&gt;=13.1.0-&gt;scrapy)
Requirement already satisfied: constantly&gt;=15.1 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from Twisted&gt;=13.1.0-&gt;scrapy)
Requirement already satisfied: incremental&gt;=16.10.1 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from Twisted&gt;=13.1.0-&gt;scrapy)
Requirement already satisfied: Automat&gt;=0.3.0 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from Twisted&gt;=13.1.0-&gt;scrapy)
Requirement already satisfied: hyperlink&gt;=17.1.1 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from Twisted&gt;=13.1.0-&gt;scrapy)
Requirement already satisfied: idna&gt;=2.1 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from cryptography&gt;=1.9-&gt;pyOpenSSL-&gt;scrapy)
Requirement already satisfied: cffi&gt;=1.7 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from cryptography&gt;=1.9-&gt;pyOpenSSL-&gt;scrapy)
Requirement already satisfied: asn1crypto&gt;=0.21.0 in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from cryptography&gt;=1.9-&gt;pyOpenSSL-&gt;scrapy)
Requirement already satisfied: setuptools in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from zope.interface&gt;=4.0.2-&gt;Twisted&gt;=13.1.0-&gt;scrapy)
Requirement already satisfied: pycparser in c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages (from cffi&gt;=1.7-&gt;cryptography&gt;=1.9-&gt;pyOpenSSL-&gt;scrapy)
Building wheels for collected packages: Twisted
Running setup.py bdist_wheel for Twisted ... error
Failed building wheel for Twisted
Running setup.py clean for Twisted
Failed to build Twisted
Installing collected packages: Twisted, PyDispatcher, scrapy
Running setup.py install for Twisted ... error
</code></pre>

<hr>

<pre><code>Exception:
    Traceback (most recent call last):
    File ""c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages\pip\compat\__init__.py"",
line 73, in console_to_str
        return s.decode(sys.__stdout__.encoding)
    UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 2: invalid continuation byte
</code></pre>

<p>During handling of the above exception, another exception occurred:</p>

<pre><code>Traceback (most recent call last):
    File ""c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages\pip\commands\install.py"",
line 342, in run
        prefix=options.prefix_path,
    File ""c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages\pip\req\req_set.py"",
line 784, in install
        **kwargs
    File ""c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages\pip\req\req_install.py"",
line 878, in install
        spinner=spinner,
    File ""c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages\pip\utils\__init__.py"",
line 676, in call_subprocess
        line = console_to_str(proc.stdout.readline())
    File ""c:\users\administrator\appdata\local\programs\python\python36-32\lib\site-packages\pip\compat\__init__.py"",
line 75, in console_to_str
        return s.decode('utf_8')
    UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd5 in position 2: invalid continuation byte
</code></pre>
","8503561","2509078","2017-08-23 06:59:05","a error happened while pip was installing scrapy","<python><scrapy>","1","2","5844"
"49055787","2018-03-01 17:50:29","0","","<p>Above code each and every iteration you are creating a list. To take the elements to one list create an empty list append items to list in each array. Actually you don't need <code>itertool</code> for this...</p>

<pre><code>strng =  '0123456789'
num = []
for r in strng :
    num.append(r)

print(num)
</code></pre>

<p>But if you really want to use <code>itertools</code>, you can use this.</p>

<pre><code>import itertools as iter
num = []
for r in iter.chain('0123456789') :
    num.append(r)

print(num)
</code></pre>
","5975253","","","2","526","Govinda","2016-02-24 14:58:49","96","29","20","0","49055208","49055327","2018-03-01 17:13:13","0","132","<p>I've this code, and i'm trying to put all results of itertools in one single list 
: <code>l = ['00','01','02','03'..]</code> , instead of that i'm getting a list on every single line <code>['0', '0']  ['0', '1'] ['0', '2'] ['0', '3']</code> </p>

<pre><code>import itertools

for r in itertools.product('0123456789', repeat=2):
    print list(r)
</code></pre>
","9134855","9209546","2018-08-08 17:12:07","Put results of itertools in one single list","<python><list><itertools><cartesian-product>","2","8","364"
"49055858","2018-03-01 17:54:45","0","","<pre><code>#copy the iter_block_items function from https://github.com/python-openxml/python-docx/issues/276
from os import scandir
totaltext= []
for filename in scandir(directory):
    sentences = []
    x = filename.path
    cable = Document(x)
    for item in iter_block_items(cable):
        sentences.append(item.text if isinstance(item, Paragraph) else '&lt;table&gt;') 
totaltext.append(sentences) 
</code></pre>

<p>You can then just run a script to delete all instances of ""&lt; table >"" using re.sub</p>
","8445518","","","0","514","eluth","2017-08-10 12:47:47","29","27","6","0","48526167","","2018-01-30 16:27:08","0","314","<p>I have a docx file that I need to extract all of the text from. The docx also has tables which I want to disregard/delete.</p>

<p>My current code is:</p>

<pre><code>import docx2txt
from docx.api import Document
import docx

#initialize the new columns
ctext = list(textdb['txt'])
ctable = list(textdb['tables'])

#call in the file
x = &lt;docx_filepath&gt;
document = Document(x)
tables = document.tables

#see the actual text of tables
for table in document.tables:
    for row in table.rows:
        for cell in row.cells:
            print (cell.text)

#tells the count of how many tables are in the docx
tablelength = str(len(tables))
ctable.append(tablelength.replace(""'"",""""))

#process the actual text (this includes the table text right now)
text2 = docx2txt.process(x)
ctext.append(text2.replace(""'"",""""))        

#write values back to the list
textdb['txt'] = ctext
textdb['tables'] = ctable
</code></pre>

<p>I want all of the table text out of the file. Right now each table will show up as an individual element within python (EX:  docx.table.Table at 0x1d303c4f2b0)</p>

<p>Any help would be great - thanks,</p>
","8445518","8445518","2018-03-01 17:55:00","Python - delete tables from docx file","<python><python-3.x><docx>","1","1","1130"
"49055864","2018-03-01 17:55:09","4","","<blockquote>
  <p>In continuation of  Mikhail post. </p>
</blockquote>

<p>Assume that you already have <code>feature_names</code> from <code>vectorizer.get_feature_names()</code> and after that you have called <code>svd.fit(X)</code></p>

<p>Now you can also extract sorted best feature names using the following code:</p>

<pre><code>best_fearures = [feature_names[i] for i in svd.components_[0].argsort()[::-1]]
</code></pre>

<p>The above code, try to return the arguement of descending sort of <code>svd.components_[0]</code> and find the relative index from <code>feature_names</code> (all of the features) and construct the <code>best_features</code> array.
Then you can see for example the 10 best features:</p>

<pre><code>In[21]: best_features[:10]

Out[21]: 
['manag',
 'develop',
 'busi',
 'solut',
 'initi',
 'enterprise',
 'project',
 'program',
 'process',
 'plan']
</code></pre>
","1361125","","","0","895","imanzabet","2012-04-27 12:46:42","1139","49","32","1","44633571","44642933","2017-06-19 14:43:53","3","2070","<p>I have the following code</p>

<pre><code>import pandas as pd
import numpy as np
from sklearn.decomposition import TruncatedSVD
df = df = pd.DataFrame(np.random.randn(1000, 25), index=dates, columns=list('ABCDEFGHIJKLMOPQRSTUVWXYZ'))

def reduce(dim):
    svd = sklearn.decomposition.TruncatedSVD(n_components=dim, n_iter=7, random_state=42)
    return svd.fit(df)

fitted = reduce(5)
</code></pre>

<p>how do i get the column names from <code>fitted</code>?</p>
","3599638","3599638","2017-06-19 14:50:11","How can I get the feature names from sklearn TruncatedSVD object?","<python><pandas><scikit-learn><sklearn-pandas>","2","2","466"
"49055867","2018-03-01 17:55:24","0","","<p>Here's one way:</p>

<pre><code>df3 = df2[df2['col2'] != ''].sort_values('date', ascending=False).drop_duplicates('name')

#   col2                 date name
# 2    4  2018-02-28 19:55:29  bil
</code></pre>

<p>However, the dataframe you provided and output you desire seem to be inconsistent.</p>
","9209546","9209546","2018-03-01 18:12:28","2","301","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49055771","49055867","2018-03-01 17:49:35","0","37","<p>I am trying to get one result per 'name' with all of the latest data, unless the column is blank. In R I would have used group_by, sorted by timestamp and selected the latest value for each column. I tried to do that here and got very confused. Can someone explain how to do this in Python? In the example below my goal is:</p>

<pre><code>   col2                 date name
1    4  2018-03-27 15:55:29  bil #latest timestamp with the latest non-blank col4 value
</code></pre>

<p>Heres my code so far:</p>

<pre><code>d = {'name':['bil','bil','bil'],'date': ['2018-02-27 14:55:29', '2018-03-27 15:55:29', '2018-02-28 19:55:29'], 'col2': [3,'', 4]}
df2 = pd.DataFrame(data=d)
print(df2)

grouped = df2.groupby(['name']).sum().reset_index()
print(grouped)
sortedvals=grouped.sort_values(['date'], ascending=False)
print(sortedvals)
</code></pre>
","1634753","9209546","2018-04-18 23:39:52","How to combine groupby and sort in pandas","<python><python-3.x><pandas><sorting><group-by>","1","0","847"
"49055875","2018-03-01 17:55:59","0","","<p>Have you tried:</p>

<pre><code>query = (Test.a == 123) | (Test.b == 456)
list( Test.scan(query))
</code></pre>
","279691","","","0","115","Betamoo","2009-12-24 13:21:33","6748","682","850","7","48089051","","2018-01-04 05:13:10","0","578","<p>I am using PynamoDB and trying to genrate a dynamic query/scan on attributes from a flask request.  Assuming the following model:</p>

<pre><code>class Test(Model):
    class Meta:
        table_name = ""test""
        region = ""us-west-2""
    a = NumberAttribute(hash_key=True)
    b = NumberAttribute(range_key=True)
    c = UnicodeAttribute()
</code></pre>

<p>I have this bolted to Flask, so that when a user sends a request with query arguments such as <code>?a=123&amp;b=456</code> I can turn this into a filter within PynamoDB to return results which match records with those two filters.</p>

<p>The following works for a single attribute:</p>

<pre><code>&gt;&gt;&gt; query = operator.eq(Test.a, 123)
&gt;&gt;&gt; list(Test.scan(query))
[Test&lt;4426599961&gt;]
</code></pre>

<p>I am looking to be able to bolt this onto a dynamic number of attributes (beyond a,b and c for example)</p>

<p>I tried turning this into a tuple, but that seems to break with the following error:</p>

<pre><code>&gt;&gt;&gt; query = (operator.eq(Test.a, 123), operator.eq(Test.b, 456))
&gt;&gt;&gt; list(Test.scan(*query))
</code></pre>

<p>but I get the following error:</p>

<pre><code>Invalid type for parameter Segment, value: b = {'N': '1'}, type: &lt;class 'pynamodb.expressions.condition.Comparison'&gt;, valid types: &lt;type 'int'&gt;, &lt;type 'long'&gt;
</code></pre>

<p>Any ideas on how I can construct a dynamic filter to pass into the PynamoDB scan method?</p>
","9171107","400617","2018-01-04 05:55:39","Python PynamoDB - Creating dynamic queries with Flask","<python><amazon-dynamodb>","2","0","1467"
"49055880","2018-03-01 17:56:22","1","","<p>First lets convert the dictionary of lists into a dictionary of sets.</p>

<pre><code>SystemDictu4 = {'System 1': ['test1@test.com', 'test2@test.com', 'test5@test.com'],
                'System 2': ['test1@test.com', 'test7@test.com', 'test55@test.com'],
                'System 3': ['test1@test.com', 'test23@test.com', 'test55@test.com'],
                'System 4': ['test1@test.com', 'test23@test.com', 'test55@test.com']}
System = {k,set(v) for k,v in SystemDictu4.items()}
</code></pre>

<p>I recommend using a set since you will only need a single instance of each email address per system key. Once we have the larger system converted to a dictionary of sets, then we can use the nature of a set to unite the information from other systems.</p>

<pre><code>def add_dict(SystemDictFrom, SystemDictTo, number_of_systems):
    for system in sorted(SystemDictFrom, key = lambda a: len(SystemDictFrom.get(a)))[:number_of_systems]:
        if system in SystemDictTo:
            SystemDictTo[system].union(SystemDictFrom[system])
        else:
            SystemDictTo[system] = SystemDictFrom[system]
</code></pre>

<p>In the function above, I'm using SystemDictFrom as the dictionary of lists or sets that will add values to the larger dictionary, SystemDictTo. </p>

<p>You might call that function with the following:</p>

<pre><code># This will add the three least populated systems from SystemDicto3 to SystemDictu4
add_dict(SystemDicto3, SystemDictu4, 3)
</code></pre>
","6233386","6233386","2018-03-01 20:12:32","8","1481","Mike Peder","2016-04-21 03:40:45","604","60","66","8","49055559","49055880","2018-03-01 17:35:37","0","80","<p>I am looking to append list items from one nested dictionary to another (From SystemDicto3 to SystemDictu4). They both have the same kind of content, the system number (Keys) and which emails (Values) fall under that system number. So far I have the following code (snippet of full code):</p>

<pre><code>#Gets the key/system with the lowest amount of values/emails, set = to SysMin
SysLength = defaultdict(list)
for x in SystemDict:
    length = len(SystemDict[x])
    SysLength[x].append(length) 
SysMin = min(SysLength, key=SysLength.get)

for system in SystemDicto3: #Iterates through systems
    for item in SystemDicto3[system]: #iterates through emails within systems
        if item in system != SystemDictu4[system]: #if the email isn't in the dict, add it
            SystemDictu4.append(item)
</code></pre>

<p>I want to iterate over the SystemDicto3 dictionary emails (dfo3 dataframe was used to create this dictionary), adding the contents to the alreay populated SystemDictu4 dictionary based on which system it is in and prioritizing the system with the lowest count. </p>

<p>For example if the email ""test1@test.com"" is in (SystemDicto3):</p>

<pre><code> ['System 1']
 ['System 3']
 ['System 5'] 
 ['System 7'] 
</code></pre>

<p>I want to append that email to the three lowest SystemDictu4 systems. So if the length in SystemDictu4 is as follows: </p>

<pre><code>system 1 = 100 
system 3 = 40 
system 5 = 200 
system 7 = 90
</code></pre>

<p>I want to append that email to systems 1, 3, and 7.</p>

<p>I have not included my full code, as it may complicate the question. Any help will be appreciated, and thank you for taking the time to read this!</p>

<p>The dictionaries look like the below code. There can be up to 60 systems, and 1000s of emails in each and the same email can show up across different systems, and my goal is to add the emails from the second dictionary to the first. the expected output would be a one populated dictionary, and one dictionary containing emails that were not sent to the first one. </p>

<pre><code>    {'System 1':                         test1@test.com
                                       test2@test.com
                                       test5@test.com

'System 2':                                test1@test.com
                                           test7@test.com
                                           test55@test.com

 'System 3':                              test1@test.com
                                          test23@test.com
                                          test55@test.com

'System 4':                                test1@test.com
                                           test23@test.com
                                           test55@test.com   }
</code></pre>
","9200498","9200498","2018-03-01 18:16:27","Append select items from one nested dictionary to another","<python><pandas><dictionary><nested><append>","1","0","2770"
"49055890","2018-03-01 17:56:56","1","","<p>When you load a tmx file in cocos2d-python you get a Resource object, this includes more data about the map than just the layers. And important there also is that a map can have multiple layers.</p>

<p>The ScrollingManager requires a layer object, not a resource object. To get the layer you want to add out of Resource object you can access it like a dictionary, like so:</p>

<pre><code>MapLayer = load(""themap.tmx"")[""The name of the layer""]
</code></pre>

<p>Here's a modification of your example with my own test map that works:</p>

<pre><code>import cocos
from cocos.tiles import load
from cocos.layer import ScrollingManager
from cocos.director import director
from cocos.scene import Scene

director.init()

loaded_tmx = load(""test.tmx"")

MapLayer = loaded_tmx[""Tile Layer 1""]

scroller = ScrollingManager()

scroller.add(MapLayer)

director.run(Scene(scroller))
</code></pre>

<p>As a forewarning though, the current version of TMX file handling in cocos2d-python does not properly handle the most current version of the TMX file format. I've had to make some modifications to get it to work.</p>
","1181617","","","0","1110","Koraken","2012-01-31 23:59:29","54","21","15","0","43690830","","2017-04-29 01:08:48","1","125","<pre><code>import cocos
from cocos.tiles import load
from cocos.layer import ScrollingManager
from cocos.director import director
from cocos.scene import Scene

director.init()

MapLayer = load(""themap.tmx"")

scroller = ScrollingManager()

scroller.add(MapLayer)

director.run(Scene(scroller))
</code></pre>

<p>Just started using cocos and trying to figure out Tilemaps. Getting ridiculous errors and would appreciate some help.</p>
","7939134","1181617","2018-03-02 16:46:00","Cocos2d Python - AttributeError: 'Resource' object has no attribute 'set_view'","<python><cocos2d-python>","1","1","434"
"49055894","2018-03-01 17:57:17","3","","<p>You can using <code>shift</code> </p>

<pre><code>df['New']=df.sort_values(['id','yr']).groupby('id').data.shift()
df
Out[793]: 
    data  id  yr   New
0   1-87   1  87   NaN
1   1-88   1  88  1-87
2   1-89   1  89  1-88
3   2-54   2  54  2-53
4   2-55   2  55  2-54
5   2-53   2  53   NaN
6   3-87   3  87   NaN
7   4-87   4  87  4-86
8   5-89   5  89   NaN
9   3-90   3  90  3-87
10  3-91   3  91  3-90
11  3-92   3  92  3-91
12  4-86   4  86   NaN
</code></pre>
","7964527","","","2","468","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49055769","49055894","2018-03-01 17:49:29","0","37","<p>I have a DataFrame that contains many years worth of data. I want to make a couple columns containing the previous years' data from the same DataFrame. Here's an example:</p>

<pre><code>df = pd.DataFrame({'id': [1,1,1,2,2,2,3,4,5,3,3,3,4],
                   'yr': [87,88,89,54,55,53,87,87,89,90,91,92,86],
                   'data': '1-87 1-88 1-89 2-54 2-55 2-53 3-87 4-87 5-89 3-90 3-91 3-92 4-86'.split()})
    data  id  yr
0   1-87   1  87
1   1-88   1  88
2   1-89   1  89
3   2-54   2  54
4   2-55   2  55
5   2-53   2  53
6   3-87   3  87
7   4-87   4  87
8   5-89   5  89
9   3-90   3  90
10  3-91   3  91
11  3-92   3  92
12  4-86   4  86
</code></pre>

<p>I'd like to add on another column that shows the previous years' data for that id number. like this:</p>

<pre><code>    data  id  yr  last_year_data
0   1-87   1  87  NaN 
1   1-88   1  88  1-87
2   1-89   1  89  1-88
3   2-54   2  54  2-53
4   2-55   2  55  2-54
5   2-53   2  53  NaN
6   3-87   3  87  NaN
7   4-87   4  87  4-86
8   5-89   5  89  NaN
9   3-90   3  90  NaN
10  3-91   3  91  3-90
11  3-92   3  92  3-91
12  4-86   4  86  NaN
</code></pre>

<p>I tried to do this with a merge but I got Nan's all the way down in the 2nd half of the merge. Here's my code for that:</p>

<pre><code>df['last_year'] = df['yr'].apply(lambda x: x-1 if x &gt; 0 else None)
df_test = df.merge(df, how='left',indicator=False,left_on=['id','yr'],right_on=['id','last_year'])
</code></pre>

<p>I know there's a better way to do this, but I'm not sure what it is. can you help?</p>
","3071728","","","Python Pandas self merge on previous data","<python><python-3.x><pandas>","1","0","1543"
"49055946","2018-03-01 18:00:20","0","","<p>In the items of <code>configurations</code> in you sample data, looks like you are using items' only key as a unique key in the array. Therefore, we can convert the list into a dict by using that unique key.</p>

<p>That is turning
<code>[{""ID_1"": ""VALUE_1""}, {""ID_2"": ""VALUE_2""}]</code>
into <code>{""ID_1"": ""VALUE_1"", ""ID_2"": ""VALUE_2""}</code></p>

<p>Then, we just want to merge those two dict. Here I use <code>{**a, **b}</code> to merge them. For this part, you can take a look at <a href=""https://stackoverflow.com/questions/38987/how-to-merge-two-dictionaries-in-a-single-expression"">How to merge two dictionaries in a single expression?</a></p>

<p>So </p>

<pre><code>{""ID_1"": ""value_1"", ""ID_2"": ""value_2""}
</code></pre>

<p>and </p>

<pre><code>{""ID_2"": ""new_value_2"", ""ID_3"": ""new_value_3""}
</code></pre>

<p>would be merged as</p>

<pre><code>{""ID_1"": ""value_1"", ""ID_2"": ""new_value_2"", ""ID_3"": ""new_value_3""}
</code></pre>

<p>Once they are merged, convert the result dict back into list and that's the final result.</p>

<pre><code>[{""ID_1"": ""value_1""}, {""ID_2"": ""new_value_2""}, {""ID_3"": ""new_value_3""}]
</code></pre>

<p>Codes:</p>

<pre><code>def list_to_dict(l):
    return {list(item.keys())[0]: list(item.values())[0] for item in l}

def list_item_merge(a, b):
    return [{k: v} for k, v in {**list_to_dict(a), **list_to_dict(b)}.items()]

list_item_merge(original['configurations'], additional['configurations'])
</code></pre>
","3582729","3582729","2018-03-01 18:11:05","0","1449","Guangyang Li","2014-04-28 19:29:22","963","32","388","99","49053777","","2018-03-01 16:01:33","1","193","<p>I have two json files which contain all kinds of levels of properties. I want to write a python script that will replace existing properties and add missing ones, but keep all the other ones in place.</p>

<p>In my attempts until now the entire ""configurations"" array of the original file is overwritten, including all properties. All examples I could find show merge for objects without arrays. Any help would be appreciated.</p>

<p>Original:</p>

<pre><code>{
  ""configurations"": [
    {
      ""this-needs-to-stay"": {
        ""properties"": {
          ""some_property"": ""EXISTING""
        }
      }
    },
    {
      ""this-needs-to-be-updated"": {
        ""properties"": {
          ""this.would.stay"": ""EXISTING"",
          ""this.wont.be.overwritten"": ""EXISTING""
        }
      }
    }
  ],
  ""other-values-1"": [
    {
      ""components"": [
        {
          ""name"": ""EXISTING""
        }
      ],
      ""name"": ""somename""
    }
  ],
  ""other-values-2"": {
    ""randomProperties"": {
      ""type"": ""random""
    },
    ""and_so_on"": ""you_get_the_point""
  }
}
</code></pre>

<p>Additional data that should be added to original:</p>

<pre><code>{
  ""configurations"" : [
    {
      ""this-would-be-added"": {
        ""properties"": {
          ""some-property"": ""ADDED""
        }
      }
    },
    {
      ""this-needs-to-be-updated"": {
        ""properties"": {
          ""this.would.stay"": ""CHANGED"",
          ""this.would.be.added"": ""ADDED""
        }
      }
    }
  ]
}
</code></pre>

<p>Result is a merging of the two on the property level:</p>

<pre><code>{
  ""configurations"": [
    {
      ""this-would-be-added"": {
        ""properties"": {
          ""some-property"": ""ADDED""
        }
      }
    },
    {
      ""this-needs-to-stay"": {
        ""properties"": {
          ""some_property"": ""EXISTING""
        }
      }
    },
    {
      ""this-needs-to-be-updated"": {
        ""properties"": {
          ""this.would.stay"": ""CHANGED"",
          ""this.would.be.added"": ""ADDED""
          ""this.wont.be.overwritten"": ""EXISTING""
        }
      }
    }
  ],
  ""other-values-1"": [
    {
      ""components"": [
        {
          ""name"": ""EXISTING""
        }
      ],
      ""name"": ""somename""
    }
  ],
  ""other-values-2"": {
    ""randomProperties"": {
      ""type"": ""random""
    },
    ""and_so_on"": ""you_get_the_point""
  }
}
</code></pre>
","1081960","","","How to merge json objects containing arrays using python?","<python><json><merge><array-merge>","3","0","2328"
"49056137","2018-03-01 18:13:04","0","","<p>I guess that «quadratic surface» would be a more correct term than «plane». </p>

<p>And the problem is to fit z = a<em>x^2 + b</em>y^2 + c<em>x</em>y + d<em>x + e</em>y + f
to given set of points P.</p>

<p>To do that via optimization you need to formulate residual function (for instance, vertical distance). </p>

<p>For each 3D points p from P residual is </p>

<p>|p_2 – a<em>p_0^2 + b</em>p_1^2 + c*p_0*p_1 + d<em>p_0 + e</em>p_1 + f|</p>

<p>You need to minimize all residuals, i.e. sum of square of them, variating parameters a…f. </p>

<p>The following code technically should solve above problem. But fitting the problem is multi-extremal and such routine may fail to find right set of parameters without good starting point or globalization of search. </p>

<pre><code>import numpy
import scipy.optimize

P = numpy.random.rand(3,10) # given point set

def quadratic(x,y, a, b, c, d, e, f): 
  #fit quadratic surface
  return a*x**2 + b*y**2 + c*x*y + d*x + e*y + f

def residual(params, points):
  #total residual
  residuals = [
    p[2] - quadratic(p[0], p[1],
    params[0], params[1], params[2], params[3], params[4], params[5]) for p in points]

  return numpy.linalg.norm(residuals)

result = scipy.optimize.minimize(residual, 
                                 (1, 1, 0, 0, 0, 0),#starting point
                                 args=P)
</code></pre>
","3219777","","","0","1371","Askold Ilvento","2014-01-21 14:59:57","446","27","96","2","49054841","49056137","2018-03-01 16:53:41","0","613","<p>I am trying to fit a quadratic plane to a cloud of data points in python. My plane function is of the form</p>

<pre><code>   f(x,y,z) = a*x**2 + b*y**2 + c*x*y + d*x + e*y + f - z
</code></pre>

<p>Currently, my data points do not have errors associated with them, however, some errors can be assumed if necessary. Following suggestions from <a href=""https://stackoverflow.com/questions/35118419/wrong-result-for-best-fit-plane-to-set-of-points-with-scipy-linalg-lstsq/35118683"">here</a>, I work out the vertical distance from a point p0=(x0,y0,z0) (which correspond to my data points) to a point on the plane p=(x,y,z) following <a href=""http://mathworld.wolfram.com/Point-PlaneDistance.html"" rel=""nofollow noreferrer"">this method</a>. I then end up with</p>

<pre><code>def vertical_distance(params,p0):
    *** snip ***
    nominator = f + a*x**2 + b*y**2 + c*x*y - x0*(2*a*x-c*y-d) - y0*(2*b*y-c*x-e) + z0
    denominator = sqrt((2*a*x+c*y+d)**2 + (2*b*y+c*x+e)**2 + (-1)**2)
    return nominator/denominator
</code></pre>

<p>Ultimately, I think it is the vertical_distance function that I need to minimise. I can happily feed a list of starting parameters (params) and the array of data points to it in two dimensions, however, I am unsure on how to achieve this in 3D. ODR pack seems to only allow data containing x,y or two dimensions. Furthermore, how do I implement the points on the plane (p) into the minimising routine? I guess that during the fit operations the points vary according to the parameter optimisation and thus the exact equation of the plane at that very moment.</p>
","6228774","","","Fitting ""quadratic"" surface to data points in 3D","<python><python-2.7><math><3d><data-fitting>","1","1","1598"
"49056202","2018-03-01 18:17:33","1","","<p>This is one method. It takes a few lines, but building a new dataframe is often more efficient.</p>

<pre><code>from itertools import chain

df = pd.DataFrame([['user2', [31501, 31502, 31503], 'blogpost']],
                  columns=['user', 'groupIDs', 'report'])

lens = list(map(len, df['groupIDs']))

df_out = pd.DataFrame({'user': np.repeat(df['user'].values, lens),
                       'groupIDs': list(chain.from_iterable(df['groupIDs'].values)),
                       'report': np.repeat(df['report'].values, lens)})

#    groupIDs    report   user
# 0     31501  blogpost  user2
# 1     31502  blogpost  user2
# 2     31503  blogpost  user2
</code></pre>
","9209546","","","0","671","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49054198","","2018-03-01 16:22:00","2","50","<p>I have a dataframe like this:</p>

<pre><code>user    groupIDs                report
user2   [31501, 31502, 31503]   blogpost
jim     [31501, 31502, 31503]   book
jane    [31600]                 article
jim     [31501, 31502, 31503]   book
peter   [31501, 31502, 31503]   blogpost
user1   [31501, 31502]          blogpost
user1   [31501, 31502]          blogpost
john    [31600]                 tweet
</code></pre>

<p><code>groupIDs</code> column contains lists of integers.</p>

<p>I need to turn this dataframe into:</p>

<pre><code>user    groupIDs    report
user2   31501       blogpost
user2   31502       blogpost
user2   31503       blogpost
jim     31501       book
jim     31502       book
jim     31503       book
jane    31600       article
...
</code></pre>

<p>That is, turn every row with multiple IDs into a list of this row's copies each with one of the ids in the original list.</p>

<p><code>groupby</code> with use of this column complains about it not being hashable for obvious reasons.</p>
","2022518","","","""Splat"" rows with lists into multiple rows (pandas)","<python><pandas>","2","0","1016"
"49056229","2018-03-01 18:19:35","1","","<p>The positions of a widget that is not the toplevel are relative to your parent, but in your case none has a parent, the solution is to pass the <code>self</code> to him as a parent.</p>

<pre><code>def setupUi(self):
    pg4titleLbl = QtGui.QLabel(self)
    [...]   
    HomePageLink = QtGui.QPushButton(self)
    [...]  
    enterUsernameLbl = QtGui.QLabel(self)
    [...]  
    usernameInput = QtGui.QLineEdit(self)
    [...]  
    createEmailLbl = QtGui.QLabel(self)
    [...]  
    createEmailInput = QtGui.QLineEdit(self)
    [...]  
    createPaswordLbl = QtGui.QLabel(self)
    [...]  
    createPasswordInput = QtGui.QLineEdit(self)
    [...]  
    confirmPasswordLbl = QtGui.QLabel(self)
    [...]  
    confirmPasswordInput = QtGui.QLineEdit(self)
    [...]  
    registerButton = QtGui.QPushButton(self)
    [...]  
</code></pre>

<p><a href=""https://i.stack.imgur.com/TqPAi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/TqPAi.png"" alt=""enter image description here""></a></p>
","6622587","6622587","2018-03-01 18:31:48","5","1011","eyllanesc","2016-07-21 23:29:11","114264","27275","2584","21000","49055933","49056229","2018-03-01 17:59:43","1","320","<p>I'm currently having a problem with my program where when I run the program, a blank window will show.</p>

<p>It will show up with the title I set. However, the labels, line edits and buttons fail to show. I'm new to <code>PYQT4</code> and <code>OOP</code> so I'm not too sure if I have used the correct class or even if I need to set the object name for every item.</p>

<pre><code>import sys
from PyQt4 import QtCore, QtGui
import mysql.connector

class RegisterPage(QtGui.QMainWindow):
  def __init__(self):
    super(RegisterPage, self).__init__()
    self.setupUi()

    self.setGeometry(0,0,640,480)
    self.setWindowTitle(""Register"")

  def setupUi(self):

    #this part of the code is for the title of the of the register page
    pg4titleLbl = QtGui.QLabel()
    pg4titleLbl.setGeometry(QtCore.QRect(250, 50, 150, 40))
    font = QtGui.QFont()
    font.setPointSize(26)
    font.setBold(True)
    font.setWeight(75)
    pg4titleLbl.setFont(font)
    pg4titleLbl.setObjectName(""pg4titleLbl"")
    pg4titleLbl.setText(""Register"")

    #this part of the code is the button to take the user back to the homepage
    HomePageLink = QtGui.QPushButton()
    HomePageLink.setGeometry(QtCore.QRect(0, 170, 60, 120))
    HomePageLink.setObjectName(""HomePageLink"")
    HomePageLink.setText(""Home"")

    #this part of the code is to let the users know they need to enter a username
    enterUsernameLbl = QtGui.QLabel()
    enterUsernameLbl.setGeometry(QtCore.QRect(90, 130, 190, 40))
    font = QtGui.QFont()
    font.setPointSize(16)
    enterUsernameLbl.setFont(font)
    enterUsernameLbl.setObjectName(""enterUsernameLbl"")
    enterUsernameLbl.setText(""Choose a username:"")

    #this part of the code is there so the user can input their username they want to create
    usernameInput = QtGui.QLineEdit()
    usernameInput.setGeometry(QtCore.QRect(290, 140, 260, 30))
    usernameInput.setObjectName(""UsernameInput"")

    #this part of the code is to let the user know that they need to enter an email
    createEmailLbl = QtGui.QLabel()
    createEmailLbl.setGeometry(QtCore.QRect(130, 180, 160, 40))
    font = QtGui.QFont()
    font.setPointSize(16)
    createEmailLbl.setFont(font)
    createEmailLbl.setObjectName(""createEmailLbl"")
    createEmailLbl.setText(""Create an Email:"")

    #this part of the code is there so the user can input their email they want to use
    createEmailInput = QtGui.QLineEdit()
    createEmailInput.setGeometry(QtCore.QRect(290, 190, 260, 30))
    createEmailInput.setObjectName(""createEmailInput"")

    #this part of the code is to let the user know that they need to make a password
    createPaswordLbl = QtGui.QLabel()
    createPaswordLbl.setGeometry(QtCore.QRect(100, 230, 200, 40))
    font = QtGui.QFont()
    font.setPointSize(16)
    createPaswordLbl.setFont(font)
    createPaswordLbl.setObjectName(""createPaswordLbl"")
    createPaswordLbl.setText(""Choose a Password:"")

    #this part of the code is there so the user can input the password they want to create
    createPasswordInput = QtGui.QLineEdit()
    createPasswordInput.setGeometry(QtCore.QRect(290, 240, 260, 30))
    createPasswordInput.setObjectName(""createPasswordInput"")

    #this part of the of the code is to let the user know that they need to re-enter the password they just created
    confirmPasswordLbl = QtGui.QLabel()
    confirmPasswordLbl.setGeometry(QtCore.QRect(110, 280, 200, 40))
    font = QtGui.QFont()
    font.setPointSize(16)
    confirmPasswordLbl.setFont(font)
    confirmPasswordLbl.setObjectName(""confirmPasswordLbl"")
    confirmPasswordLbl.setText(""Confirm password:"")

    #this part of the code is there so the user can re-enter the password they just create
    confirmPasswordInput = QtGui.QLineEdit()
    confirmPasswordInput.setGeometry(QtCore.QRect(290, 290, 260, 30))
    confirmPasswordInput.setObjectName(""confirmPasswordInput"")

    #this button is used so the user can input there data into the system
    registerButton = QtGui.QPushButton()
    registerButton.setGeometry(QtCore.QRect(260, 350, 110, 30))
    registerButton.setObjectName(""registerButton"")
    registerButton.setText(""Register"")


    def register():
        if createPasswordInput.text()==confirmPasswordInput.text():
            password=confirmPasswordInput.text()
        else:
            msg = QtGui.QMessageBox.information(self, 'Message', 'Inputted passwords are not the same', QtGui.QMessageBox.Ok)
        email=createEmailInput.text()
        username=usernameInput.text()
        if password=="""" or email=="""" or username=="""":
            msg = QtGui.QMessageBox.information(self, 'Message', 'please fill in all boxes', QtGui.QMessageBox.Ok)
        else:
            cnx = mysql.connector.connect(user='scott', password='password',host='127.0.0.1',database='employees')
            add_user = (""INSERT INTO draughtsUsers ""
           ""(username, passsword, email) ""
           ""VALUES (%s, %s, %s)"")
            cursor=cnx.cursor()
            userData=(username,password,email)
            cursor.execute(add_user, userData)
            userId= cursor.lastrowid
            cnx.commit()
            cursor.close()
            cnx.close()


    #this button will take the user back to the login page if they already have an account
    loginPageLink = QtGui.QPushButton()
    loginPageLink.setGeometry(QtCore.QRect(390, 420, 240, 30))
    loginPageLink.setStyleSheet(""QPushButton { border: 0px;\n} QPushButton:hover {color:rgb(0,0,225);}"")
    loginPageLink.setObjectName(""loginPageLink"")
    loginPageLink.setText(""If you already have an account, login here"")


if __name__ == ""__main__"":
  app = QtGui.QApplication(sys.argv)
  window = RegisterPage()
  window.show()
  sys.exit(app.exec_())
</code></pre>
","9430297","355230","2018-03-19 01:50:05","Blank window using PyQt4","<python><pyqt><pyqt4><qwidget><qmainwindow>","1","1","5742"
"49056314","2018-03-01 18:24:49","0","","<p>firstly u have to import numpy library (refer code for making a numpy array)
<code>shape</code> only gives the output only if the variable is attribute of numpy library .in other words it must be a np.array or any other data structure of numpy.
Eg.</p>

<pre><code>`&gt;&gt;&gt; import numpy
&gt;&gt;&gt; a=numpy.array([[1,1],[1,1]])
&gt;&gt;&gt; a.shape
(2, 2)`
</code></pre>
","8794168","","","1","380","yunus","2017-10-18 07:25:24","1137","70","20","4","21015674","21015708","2014-01-09 09:01:47","47","223696","<p>how to create an array to numpy array?</p>

<pre><code>def test(X, N):
    [n,T] = X.shape
    print ""n : "", n
    print ""T : "", T



if __name__==""__main__"":

    X = [[[-9.035250067710876], [7.453250169754028], [33.34074878692627]], [[-6.63700008392334], [5.132999956607819], [31.66075038909912]], [[-5.1272499561309814], [8.251499891281128], [30.925999641418457]]]
    N = 200
    test(X, N)
</code></pre>

<p>I am getting error as </p>

<pre><code>AttributeError: 'list' object has no attribute 'shape'
</code></pre>

<p>So, I think I need to convert my X to numpy array?</p>
","778942","2225682","2016-02-21 13:38:32","'list' object has no attribute 'shape'","<python><list><numpy>","7","0","583"
"49056402","2018-03-01 18:31:00","2","","<p>The error message states that you should be using integers. Your division by 2 currently results in a float. You can cast it into an integer using <code>int()</code>:</p>

<pre><code>A = [1,2,3,4,5,6]
B = A[:int(len(A)/2)]
C = A[int(len(A)/2):]

print(B)
print(C)
</code></pre>

<p>Out:</p>

<pre><code>[1, 2, 3]
[4, 5, 6]
</code></pre>
","6735980","6735980","2018-03-01 18:44:13","2","340","Dennis Soemers","2016-08-19 17:30:31","5427","446","1354","36","49056343","49056406","2018-03-01 18:27:12","0","41","<p>I like to split an array into first half and its second half. I tried following code, but it does not work:</p>

<pre><code>A = [1,2,3,4,5,6]
B = A[:len(A)/2]
C = A[len(A)/2:]
</code></pre>

<p>The error message says:</p>

<pre><code>TypeError: slice indices must be integers or None or have an __index__ method
</code></pre>

<p>Supposedly, I should get </p>

<pre><code>B = [0,1,2]

C = [3,4,5]
</code></pre>

<p>I am wondering how I should do it? Thanks</p>
","1277239","","","separate an array into two halves","<python><arrays><numpy>","3","0","464"
"49056406","2018-03-01 18:31:11","4","","<p>You are doing float-math - use integer division:</p>

<pre><code>A = [1,2,3,4,5,6]
B = A[:len(A)//2]
C = A[len(A)//2:]

print(A,B,C)
</code></pre>

<p>Output:</p>

<pre><code>([1, 2, 3, 4, 5, 6], [1, 2, 3], [4, 5, 6])
</code></pre>

<p>Have a look at the operators here:  <a href=""https://docs.python.org/3/library/stdtypes.html?highlight=floor%20division#numeric-types-int-float-complex"" rel=""nofollow noreferrer"">numeric-types-int-float-complex</a></p>
","7505395","7505395","2018-03-01 18:36:31","0","458","Patrick Artner","2017-02-02 10:46:51","30736","5120","3506","4713","49056343","49056406","2018-03-01 18:27:12","0","41","<p>I like to split an array into first half and its second half. I tried following code, but it does not work:</p>

<pre><code>A = [1,2,3,4,5,6]
B = A[:len(A)/2]
C = A[len(A)/2:]
</code></pre>

<p>The error message says:</p>

<pre><code>TypeError: slice indices must be integers or None or have an __index__ method
</code></pre>

<p>Supposedly, I should get </p>

<pre><code>B = [0,1,2]

C = [3,4,5]
</code></pre>

<p>I am wondering how I should do it? Thanks</p>
","1277239","","","separate an array into two halves","<python><arrays><numpy>","3","0","464"
"49056445","2018-03-01 18:34:20","3","","<p>try this</p>

<pre><code>A = [1,2,3,4,5,6]
half = len(A)//2
B = A[:half]
C = A[half:]
</code></pre>
","9430579","","","1","103","Boko Moko","2018-03-01 18:28:36","31","2","1","0","49056343","49056406","2018-03-01 18:27:12","0","41","<p>I like to split an array into first half and its second half. I tried following code, but it does not work:</p>

<pre><code>A = [1,2,3,4,5,6]
B = A[:len(A)/2]
C = A[len(A)/2:]
</code></pre>

<p>The error message says:</p>

<pre><code>TypeError: slice indices must be integers or None or have an __index__ method
</code></pre>

<p>Supposedly, I should get </p>

<pre><code>B = [0,1,2]

C = [3,4,5]
</code></pre>

<p>I am wondering how I should do it? Thanks</p>
","1277239","","","separate an array into two halves","<python><arrays><numpy>","3","0","464"
"49056478","2018-03-01 18:36:11","3","","<p>You can use:</p>

<pre><code>a[i.T[0], i.T[1]]
</code></pre>

<p>In case you have more dimensions, you can use:</p>

<pre><code>a[tuple(i.T)]
</code></pre>
","8605791","8605791","2018-03-01 18:45:46","0","159","llllllllll","2017-09-13 21:41:23","14078","1653","562","12957","49056388","49056478","2018-03-01 18:30:02","0","40","<p>If I have a 2D array of indices:</p>

<pre><code>i = np.array([[0, 0], [1, 1]])
</code></pre>

<p>And a 2D array I want to index:</p>

<pre><code>a = np.array([[1, 2], [3, 4]])
</code></pre>

<p>How can I index the array to get a 1D array like the following?</p>

<pre><code>np.array([1, 4])
</code></pre>
","2422432","","","2D index of numpy array using array indexing","<python><arrays><numpy><multidimensional-array>","2","0","309"
"49056497","2018-03-01 18:37:11","2","","<p><code>plt.plot(x, y)</code> accepts two parameters, as shown.  try: </p>

<p><code>x = [10, 20, 40, 80, 160]
plt.plot(x, predictions)
</code></p>

<p><a href=""https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html"" rel=""nofollow noreferrer"">https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html</a></p>
","8766025","","","0","323","ChootsMagoots","2017-10-12 14:46:59","523","126","84","33","49056405","","2018-03-01 18:31:09","-2","20","<p>I'm using <code>matplotlib</code> to graph the relationship between a variable <code>N</code> and some <code>Y</code> values.  Here's my code:</p>

<pre><code>plt.title(""My Graph"")
plt.xlabel(""Values of N"")
plt.ylabel(""Estimated Y Values"")
plt.plot(predictions)
plt.show()
</code></pre>

<p>And I get:</p>

<p><a href=""https://i.stack.imgur.com/ZrXQQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZrXQQ.png"" alt=""enter image description here""></a></p>

<p>This is great, except for the x-axis labels.  My <code>predictions</code> list has 5 values in it, corresponding to values of <code>N = 10, N = 20, N = 40, N = 80, N = 160</code>.</p>

<p>How can I change the x-axis to reflect this (so the first Y value is directly above <code>N = 10</code>, second Y values i directly above <code>N = 20</code>, etc)?  I do want to keep the interpolation between data points, so I don't want a scatterplot.</p>

<p>Thanks!</p>
","1316501","","","Matplotlib: Unsure how to set new x-axis","<python><matplotlib>","1","0","942"
"49056521","2018-03-01 18:38:42","1","","<p>I found a solution. Read this <a href=""http://ipywidgets.readthedocs.io/en/stable/examples/Widget%20Asynchronous.html#Updating-a-widget-in-the-background"" rel=""nofollow noreferrer"">doc</a> for details.</p>

<p>You use the <code>threading</code> library to make your update function (in my case the timer that updates every second) run separately so you can still execute other code cells. </p>

<p>Also, I tried doing a couple <code>%%timeit</code> 's on simple test functions like this:</p>

<p><code>[x*=x for i in range(20)]</code> </p>

<p>And it looks like having this timer widget running in the background didn't cause a significant increase in execution time.</p>
","7185934","7185934","2018-03-02 00:03:02","0","675","David Skarbrevik","2016-11-20 16:34:00","134","45","29","0","49056028","","2018-03-01 18:05:28","0","511","<p>I made this timer widget that works the way I want, but it locks up the notebook so I can't execute other code cells at the same time.</p>

<p>Here's an example of what I mean:</p>

<p><a href=""https://i.stack.imgur.com/1LYPf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1LYPf.png"" alt=""enter image description here""></a></p>

<p><strong>Any ideas for getting the widget to execute in the background?</strong></p>

<p>In case it helps, here is the code that makes the above widget:</p>

<pre class=""lang-python prettyprint-override""><code>import ipywidgets as widgets
from IPython.display import display, Javascript
from traitlets import Unicode, validate
import time

class Timer(widgets.DOMWidget):
    _view_name = Unicode('HelloView').tag(sync=True)
    _view_module = Unicode('hello').tag(sync=True)
    _view_module_version = Unicode('0.1.0').tag(sync=True)
    value = Unicode('00:00:00').tag(sync=True)

    def timeit(self, b, limit=180):
        #display(self)
        hours = 0
        mins = 0
        secs = 0
        for i in range(1,(limit*60+1)):
            if i%60 == 0:
                if i%3600 == 0:
                    secs = 0
                    mins = 0
                    hours += 1
                else:
                    secs = 0
                    mins += 1
            else:
                secs += 1
            time.sleep(1)
            self.value = '{hour:02}:{minute:02}:{second:02}'.format(hour=hours,minute=mins,second=secs)


def display_timer(timer):
    button = widgets.Button(description=""Start Timer"", button_style='info')
    display(button)
    display(timer)
    button.on_click(timer.timeit)
</code></pre>
","7185934","","","Ipython Widgets (how to make a timer)","<python><jupyter-notebook><ipython-parallel><ipywidgets>","1","0","1681"
"49056572","2018-03-01 18:41:49","0","","<p>I think it will work if you change
<code>form['title'].initial = checkin_type.title</code>
to
<code>form.cleaned_data['title'] = checkin_type.title</code></p>
","2740177","","","1","162","HenryM","2013-09-02 14:27:13","3257","656","178","9","49055570","","2018-03-01 17:36:05","0","43","<p>I'm trying to create a dynamic form which pre-populates the <a href=""https://docs.djangoproject.com/en/2.0/ref/forms/fields/#initial"" rel=""nofollow noreferrer""><code>initial</code></a> attribute of a certain field (<code>title</code>) when another field (<code>checkin_type</code>) is selected from a drop-down menu. </p>

<p>I'm using Django's generic <a href=""https://docs.djangoproject.com/en/2.0/ref/class-based-views/generic-editing/#createview"" rel=""nofollow noreferrer""><code>CreateView</code></a>, and the way I'd like to go about it is by overriding the view's <code>post()</code> method such that if it receives an AJAX request (which is triggered by a jQuery <code>.change()</code> in the aforementioned drop-down menu and contains the <code>id</code> of the selection option), it updates the <code>initial</code> property of the form's <code>title</code>.</p>

<p>Here is the view I've tried so far (in <code>views.py</code>):</p>

<pre><code>from django.views import generic
from .models import CheckIn, CheckInType


class CheckInCreate(generic.CreateView):
    model = CheckIn
    fields = '__all__'

    def post(self, request, *args, **kwargs):
        if request.is_ajax():
            checkin_type = CheckInType.objects.get(pk=request.POST['id'])
            form = self.get_form()
            form['title'].initial = checkin_type.title
            self.object = CheckIn.objects.create(checkin_type=checkin_type)
            return self.render_to_response(self.get_context_data(form=form))
        else:
            return super().post(request, *args, **kwargs)
</code></pre>

<p>Here is how the AJAX request is made in the form's template, called <code>templates/dashboard/checkin_form.html</code> in accordance with Django's naming convention (<code>dashboard</code> is the name of the app):</p>

<pre><code>&lt;script src=""https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js""&gt;&lt;/script&gt;
&lt;script src=""https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js""&gt;&lt;/script&gt;
&lt;script&gt;
    $(document).ready(function(){
        var csrftoken = Cookies.get('csrftoken');

        function csrfSafeMethod(method) {
            // these HTTP methods do not require CSRF protection
            return (/^(GET|HEAD|OPTIONS|TRACE)$/.test(method));
        }
        $.ajaxSetup({
            beforeSend: function(xhr, settings) {
                if (!csrfSafeMethod(settings.type) &amp;&amp; !this.crossDomain) {
                    xhr.setRequestHeader(""X-CSRFToken"", csrftoken);
                }
            }
        });

        $("".auto-submit"").change(function() {
            $.post({
                url: ""{% url 'checkin-create' %}"",
                data: {id: $("".auto-submit option:selected"").val()}
            })
        });
    });
&lt;/script&gt;


&lt;form action="""" method=""post""&gt;{% csrf_token %}
    {% for field in form %}
        &lt;div class=""{% if field.name == 'checkin_type' %}auto-submit{% endif %}""&gt;
            {{ field.errors }}
            {{ field.label_tag }}
            {{ field }}
        &lt;/div&gt;
    {% endfor %}
    &lt;input type=""submit"" value=""Send message"" /&gt;
&lt;/form&gt;
</code></pre>

<p>Here are the corresponding models (in <code>models.py</code>):</p>

<pre><code>from django.db import models


class CheckInType(models.Model):
    title = models.CharField(blank=True, max_length=255)
    description = models.TextField(blank=True)

    def __str__(self):
        return self.title


class CheckIn(models.Model):
    checkin_type = models.ForeignKey(CheckInType, null=True, on_delete=models.CASCADE)
    title = models.CharField(blank=True, max_length=255)
    description = models.TextField(blank=True)

    notes = models.TextField(blank=True)

    # Scheduling
    requested_date = models.DateField(blank=True, null=True)
    completed_date = models.DateField(blank=True, null=True)
</code></pre>

<p>The problem is that when I select an option from the drop-down menu for <code>checkin_type</code>, I see no change in the form:</p>

<p><a href=""https://i.stack.imgur.com/ufao8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ufao8.png"" alt=""enter image description here""></a></p>

<p>I would have expected the <code>Title</code> field to become pre-populated with '1-week check-in' in this example. Any ideas why this is not working?</p>
","995862","","","How to update a ModelForm's initial values dynamically?","<python><django><django-forms><django-templates><django-generic-views>","1","2","4378"
"49056612","2018-03-01 18:44:20","0","","<p>You just need a simple indexing:</p>

<pre><code>In [11]: a[i[:, 0], i[:, 1]]
Out[11]: array([1, 4])
</code></pre>

<p>The first column of <code>i</code> is number of rows and the second one denotes the column number.</p>
","2867928","","","0","225","Kasramvd","2013-10-10 16:10:31","83554","6938","4534","1304","49056388","49056478","2018-03-01 18:30:02","0","40","<p>If I have a 2D array of indices:</p>

<pre><code>i = np.array([[0, 0], [1, 1]])
</code></pre>

<p>And a 2D array I want to index:</p>

<pre><code>a = np.array([[1, 2], [3, 4]])
</code></pre>

<p>How can I index the array to get a 1D array like the following?</p>

<pre><code>np.array([1, 4])
</code></pre>
","2422432","","","2D index of numpy array using array indexing","<python><arrays><numpy><multidimensional-array>","2","0","309"
"49056646","2018-03-01 18:46:20","3","","<p>As of Python 3.6, DDL, or Data Defitinion Language statements, like <code>CREATE TABLE</code>, do not start a transaction. This means that any such statement is automatically committed the moment you execute one.</p>

<p>See the <a href=""https://docs.python.org/3/library/sqlite3.html#controlling-transactions"" rel=""nofollow noreferrer""><em>Controlling transactions</em> section</a>:</p>

<blockquote>
  <p>By default, the <code>sqlite3</code> module opens transactions implicitly before a Data Modification Language (DML) statement (i.e. <code>INSERT</code>/<code>UPDATE</code>/<code>DELETE</code>/<code>REPLACE</code>).</p>
  
  <p>[...]</p>
  
  <p><em>Changed in version 3.6</em>: <code>sqlite3</code> used to implicitly commit an open transaction before DDL statements. This is no longer the case.</p>
</blockquote>

<p>This means that you'll have to start a transaction <em>explicitly</em> if you want DDL statements to be part of a transaction.</p>

<p>Using the connection as a context manager still only issues a <em>commit</em> or <em>rollback</em> when exiting, it does not <em>start</em> a transaction; instead the first DML statement encountered will start one. If you want DDL to be part of a transaction, add a <code>begin</code> statement at the top:</p>

<pre><code>try:
    with con:
        con.execute('begin')  # explicit, rather than implicit, transaction start
        con.execute('create table foo (id integer primary key)')
        con.execute('insert into foo values (1)')
        con.execute('insert into foo values (1)')
except sqlite3.Error:
    print('transaction failed')
</code></pre>
","100297","100297","2018-03-01 18:54:07","0","1620","Martijn Pieters","2009-05-03 14:53:57","770256","252083","5762","19510","49056545","49056646","2018-03-01 18:40:13","1","336","<p><a href=""https://docs.python.org/3/library/sqlite3.html#using-the-connection-as-a-context-manager"" rel=""nofollow noreferrer"">According to the documentation</a>,</p>

<blockquote>
  <p>Connection objects can be used as context managers that automatically commit or rollback transactions. In the event of an exception, the transaction is rolled back; otherwise, the transaction is committed:</p>
</blockquote>

<p>I understand that everything within a <code>with</code> statement should be an atomic transaction. Now consider this code</p>

<pre><code>import sqlite3
con = sqlite3.connect(':memory:')

try:
  with con:
    con.execute('create table foo (id integer primary key)')
    con.execute('insert into foo values (1)')
    con.execute('insert into foo values (1)')
except sqlite3.Error:
  print('transaction failed')

try:
  rec = con.execute('select count(*) from foo')
  print('number of records: {}'.format(rec.fetchone()[0]))
except sqlite3.Error as e:
  print(e)
</code></pre>

<p>which returns</p>

<pre class=""lang-none prettyprint-override""><code>transaction failed
number of records: 0
</code></pre>

<p>On one hand, the transaction failed, due to the duplicated value. On the other hand, table <code>foo</code> exists, even though it is empty, which means that the first insert has been rolled back. Shouldn't the table creation be rolled back as well?</p>

<p>Doing the transaction ""by hand"" produces the expected result:</p>

<pre><code>import sqlite3
con = sqlite3.connect(':memory:')

con.execute('begin')
try:
  con.execute('create table foo (id integer primary key)')
  con.execute('insert into foo values (1)')
  con.execute('insert into foo values (1)')
  con.execute('commit')
except sqlite3.Error:
  con.execute('rollback')
  print('transaction failed')

try:
  rec = con.execute('select count(*) from foo')
  print('number of records: {}'.format(rec.fetchone()[0]))
except sqlite3.Error as e:
  print(e)
</code></pre>

<p>returns </p>

<pre class=""lang-none prettyprint-override""><code>transaction failed
no such table: foo
</code></pre>

<p>Why the discrepency?</p>
","1735003","100297","2018-03-01 19:56:49","transactions of an sqlite3 connection used as a context manager are not atomic","<python><sqlite>","1","0","2096"
"49056655","2018-03-01 18:46:38","0","","<p>If that is your full code then you forgot to import the json library</p>

<pre><code>import json
def application(environ, start_response):
    headers = [('Content-Type', 'application/json')]
    start_response('200 OK', headers)
    test = json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])
    test1 = test.encode('utf-8')      
    return [test1]
</code></pre>
","8993438","","","0","368","LordTlacoyo","2017-11-22 21:47:32","1","1","0","0","43619492","","2017-04-25 19:35:31","1","1712","<p>I use <code>uwsgi</code> for serving my web content and it works well when it comes to usual html pages:</p>

<pre><code>return [b'&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;Hello, world!&lt;/body&gt;&lt;/html&gt;']
</code></pre>

<p>But when I want to return <code>json</code>:</p>

<pre><code>headers = [('content-type', 'application/json')]
test = json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])
test1 = bytearray(test, 'utf8')

start_response('200 OK', headers)
return [test1]
</code></pre>

<p>the webserver returns nothing...there is no error, just empty response body... anybody could explain me why?</p>

<p>thanks and greetings!</p>
","4958604","4958604","2017-04-25 19:51:37","Python 3 wsgi - json response","<python><json><response><uwsgi><wsgi>","3","3","655"
"49056663","2018-03-01 18:47:12","4","","<p>The claim from the documentation refers to reducing sums, i.e:</p>

<pre><code>&gt;&gt;&gt; a + b
1    NaN
3    9.0
4    NaN
dtype: float64
&gt;&gt;&gt; (a + b).sum()
9.0 # nans treated as zero...
</code></pre>

<p>Not vectorized sums. You'll have to do this explicitely:</p>

<pre><code>&gt;&gt;&gt; (a + b).fillna(0)
1    0.0
3    9.0
4    0.0
dtype: float64
</code></pre>

<p>As for the promotion to <code>float</code>, that is a common <code>pandas</code> gotcha, which you can read about <a href=""http://pandas.pydata.org/pandas-docs/version/0.19/gotchas.html#nan-integer-na-values-and-na-type-promotions"" rel=""nofollow noreferrer"">here</a></p>

<p>Given your problem description, i.e. summarizing value counts across columns, you <em>may</em> want to add a <code>fill_value</code> to the addition, which the <code>pd.Series.add</code> method lets you do:</p>

<pre><code>&gt;&gt;&gt; a.add(b, fill_value=0)
1    2.0
3    9.0
4    6.0
dtype: float64
</code></pre>

<p>Note, unfortunately, it still does type-promotion due to <code>NaN</code>s. If it is an issue you can easily fix it:</p>

<pre><code>&gt;&gt;&gt; a.add(b, fill_value=0).astype(np.int)
1    2
3    9
4    6
dtype: int64
</code></pre>
","5014455","5014455","2018-03-01 18:54:04","5","1208","juanpa.arrivillaga","2015-06-16 08:18:23","42745","9720","6722","648","49056567","49056663","2018-03-01 18:41:34","0","2842","<p>I want to sum Pandas Series objects, but I get weird results that seem not to be what the documentation says.</p>

<p>In Pandas 0.19.2, the following code:</p>

<pre><code>a = pd.Series({1: 2, 3: 4})
b = pd.Series({3: 5, 4: 6})
print(a + b)
</code></pre>

<p>gives me,</p>

<pre><code>1    NaN
3    9.0
4    NaN
dtype: float64
</code></pre>

<p>however, the <a href=""https://pandas.pydata.org/pandas-docs/stable/missing_data.html"" rel=""nofollow noreferrer"">documentation</a> says:</p>

<blockquote>
  <p>When summing data, NA (missing) values will be treated as zero</p>
</blockquote>

<p>This seems to treat them as NaN rather than zeros.  I was expecting the output:</p>

<pre><code>1    2.0
3    9.0
4    6.0
dtype: float64
</code></pre>

<p>In my case the Series comes from <code>value_counts()</code> over several columns and I wanted to use <code>sum()</code> but it gives me NaN for all rows that don't have values in all columns, which is wrong.  There should be an integer for every row.</p>

<p>Another mystery for me is why the result has dtype float:</p>

<pre><code>a.dtype, b.dtype, (a+b).dtype
</code></pre>

<p>gives,</p>

<pre><code>(dtype('int64'), dtype('int64'), dtype('float64'))
</code></pre>

<p>which is quite surprising to me.</p>

<p>Edit: if I make sure that <code>a</code> and <code>b</code> have the same rows, then the resulting dtype is <code>int64</code>.  So the change to float is clearly just to allow for the NaN value, which is a bit shocking.</p>

<p>Edit 2: Fix mistake in the expected output.</p>
","5945965","5945965","2018-03-01 18:52:55","How to sum with missing values in Pandas?","<python><pandas>","1","7","1540"
"49056741","2018-03-01 18:51:20","1","","<p>The problem is that value is converted to the type that is saved, in your case it is an integer that takes the following values <code>Qt::Checked</code>, <code>Qt::PartiallyChecked</code> and <code>Qt::Checked</code>, the solution is to compare them with those values.</p>

<pre><code>def setData(self, index, value, role=QtCore.Qt.DisplayRole):
    row = index.row()
    if index.column() == self.column and role == QtCore.Qt.CheckStateRole:
        if value == QtCore.Qt.Checked:
            self.checkboxes[row] = True
        else:
            self.checkboxes[row] = False
        self.dataChanged.emit(index, index, [QtCore.Qt.CheckStateRole])
        return True
    else:
        return False
</code></pre>

<p>To select or deselect we use the following method</p>

<pre><code>    self.table_model3.dataChanged.connect(self.on_data_changed)

def on_data_changed(self, topleft, bottomRight, roles):
    if QtCore.Qt.CheckStateRole in roles:
        row = topleft.row()
        isChecked = topleft.data(QtCore.Qt.CheckStateRole) == QtCore.Qt.Checked
        flag = QtCore.QItemSelectionModel.Select if isChecked else QtCore.QItemSelectionModel.Deselect
        for col in range(self.table_model3.columnCount()):
            ix = self.table_model3.index(row, col)
            self.tableView3.selectionModel().select(ix, flag)
</code></pre>
","6622587","6622587","2018-03-03 22:21:54","11","1347","eyllanesc","2016-07-21 23:29:11","114264","27275","2584","21000","49056306","49056741","2018-03-01 18:24:27","0","216","<p>Am having a QTableView that shows data from an sqlite database. Apparently, am creating a checkbox on all available rows of data. The problem is that the checkboxes are not checkable and when clicked show the following error.</p>

<pre><code>if value.toBool():
    AttributeError: 'int' object has no attribute 'toBool'
</code></pre>

<p>Below is the code that i got but not giving my required result. I would like to highlight the row whose checkbox has been clicked.</p>

<pre><code>    self.table_model3 = CheckboxSqlModel(0)
    self.table_model3.setQuery(""SELECT Name, Email FROM Individuals"")
    self.tableView3.setModel(self.table_model3)
    self.tableView3.horizontalHeader().setStretchLastSection(True)
    self.tableView3.setShowGrid(False)
    self.table_model3.setHeaderData(0, QtCore.Qt.Horizontal, ""All"")
    self.table_model3.setHeaderData(1, QtCore.Qt.Horizontal, ""Client Name"")
    self.table_model3.setHeaderData(2, QtCore.Qt.Horizontal, ""Email Address"")
    self.tableView3.setStyleSheet('QHeaderView:section{Background-color:#cdcdcd; font-family: Arial Narrow; font-size: 15px; height: 30px;}')
    self.table_model3.insertColumn(0)
    self.tableView3.setColumnWidth(0, 30)


class CheckboxSqlModel(QtSql.QSqlQueryModel):
    def __init__(self, column):
        super(CheckboxSqlModel, self).__init__()
        self.column = column
        self.checkboxes = list() #List of checkbox states
        self.first = list() #Used to initialize checkboxes

    #Make column editable
    def flags(self, index):
        flags = QtSql.QSqlQueryModel.flags(self, index)
        if index.column() == self.column:
            flags |= QtCore.Qt.ItemIsUserCheckable
        return flags

    def data(self, index, role=QtCore.Qt.DisplayRole):
        row = index.row()
        if index.column() == self.column and role == QtCore.Qt.CheckStateRole:
            #Used to initialize
            if row not in self.first :
                index = self.createIndex(row, self.column)
                self.first.append(row)
                self.checkboxes.append(False)
                return QtCore.Qt.Unchecked
            #if checked
            elif self.checkboxes[row]:
                return QtCore.Qt.Checked
            else:
                return QtCore.Qt.Unchecked
        else:
            return QtSql.QSqlQueryModel.data(self, index, role)

    def setData(self, index, value, role=QtCore.Qt.DisplayRole):
        row = index.row()
        if index.column() == self.column and role == QtCore.Qt.CheckStateRole:
            if value.toBool():
                self.checkboxes[row] = True
            else:
                self.checkboxes[row] = False
            self.dataChanged.emit(index, index)
            return True
        else:
            return False
</code></pre>
","7260203","6622587","2018-03-01 18:34:19","How to create a qcheckbox on a qtableview that gets data from an sqlite database","<python><pyqt><pyqt4><qtableview><qcheckbox>","1","0","2796"
"49056760","2018-03-01 18:52:42","1","","<p>Issue resolved. I used ssh - t for remote login to overcome the sudo tty issues and used below one..</p>

<p>import os</p>

<p>os.system(sudo chown xxxx) </p>
","9406145","","","0","162","Gundu Rao Kuruba","2018-02-24 15:34:39","16","0","0","0","48994802","","2018-02-26 18:27:38","-1","274","<p>there are few servers running with python 2.4.3 where pexpect is not working.. Is there any way to place sudo password for sudo chown </p>
","9406145","","","How to use sudo chown command in python?","<python><passwords><sudo>","1","0","142"
"49056767","2018-03-01 18:53:09","0","","<p>I found out that it closes without crashing if I type in the terminal ctrl+c instead of ctrl+z as I did before.</p>
","4807022","","","0","119","Leonardo Barazza","2015-04-19 13:37:16","25","15","1","0","48531314","49056767","2018-01-30 22:06:37","0","44","<p>I'm trying to create a simple program using universe by openai but every time I close the VNC, the python launcher doesn't respond anymore and I have to force quit it. What can I do to solve this? Thanks</p>
","4807022","4807022","2018-03-01 18:53:41","Python launcher not responding after closing VNC (mac)","<python><vnc><openai-gym>","1","0","211"
"49056813","2018-03-01 18:55:57","2","","<p>String formatting helps:</p>

<pre><code>def present_board(board):
    print('Nim:')
    for i, elem in enumerate(board, 1):
        print('{}:'.format(i), elem * 'X ')

present_board([4, 3, 1, 2])
</code></pre>

<p>Output:</p>

<pre><code>Nim:
1: X X X X 
2: X X X 
3: X 
4: X X 
</code></pre>

<p>I addition, <code>enumerate</code> helps your increment your counter automatically. </p>

<h3>Python 3.6+ only</h3>

<p>Use a f-string:</p>

<pre><code>def present_board(board):
    print('Nim:')
    for i, elem in enumerate(board, 1):
        print(f'{i}:', elem * 'X ')

present_board([4, 3, 1, 2])
</code></pre>
","837534","837534","2018-03-01 19:01:53","1","617","Mike Müller","2011-07-10 10:47:45","59443","2890","1608","51","49056718","49056813","2018-03-01 18:50:06","-2","34","<p>I tried searching this but the solutions either didn't fit what I needed (<code>sep=""""</code>) or work (+). My code is as follows:</p>

<pre><code>present_board([4, 3, 1, 2])

def present_board(board):
    print('Nim:')
    i = 1
    for elem in board:
        print(i,'\b'':',elem * 'X ')
        i += 1
    pass
</code></pre>

<p>I want it to print like:</p>

<pre><code>1: X X X X
</code></pre>

<p>instead of:</p>

<pre><code>1 : X X X X 
</code></pre>
","9007273","837534","2018-03-01 18:59:05","Remove certain spaces in print statement","<python><python-3.x>","1","2","460"
"49056817","2018-03-01 18:56:15","0","","<p>The 2nd line of the output has a clue to the problem - ""Using cached ...""</p>

<p>You can skip the cache using the <strike><code>--skip-cache</code></strike> <code>--no-cache-dir</code> option to <code>pip install</code> or request an upgrade using the <code>-U</code> option</p>

<p>edit: updated comment with the correct option (although, seems like that wasn't the problem in this specific case).</p>
","262108","262108","2018-03-07 14:23:08","1","407","lonetwin","2010-01-29 20:11:13","596","26","88","4","49056702","49057691","2018-03-01 18:49:01","0","41","<p>I have a package that I am trying to install via <code>pip install allen-bradley-toolkit</code>. The package is failing with the following reason.</p>

<p><a href=""https://i.stack.imgur.com/VTpKY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VTpKY.png"" alt=""enter image description here""></a></p>

<p>The problem seems to related to the fact that pip is trying to install <code>1.0a1.post0</code> instead of the latest release version <code>2.0.0</code>.  Does anyone have any ideas on what to do about this.  Perhaps there is something wrong in my deployment script.  You can view the <a href=""https://github.com/cmseaton42/Allen-Bradley-Toolkit"" rel=""nofollow noreferrer"">Github</a> Library here to see how I am deploying to PyPi. </p>

<p>There is an issue opened on the GitHub Tracker <a href=""https://github.com/cmseaton42/Allen-Bradley-Toolkit/issues/2"" rel=""nofollow noreferrer"">#2</a> that you can also reference for more info.</p>

<p>NOTE: The package seems to install fine on my win10 machine.  But I am unable to get it to install on a win7 VM.</p>

<p>Ive also tried installing with the following commands:</p>

<ul>
<li><code>pip install --no-cache-dir allen-bradley-toolkit</code></li>
<li><code>pip install allen-bradley-toolkit==2.0.0</code> -> this ones throws a 'doesnt exist error`</li>
</ul>
","7496355","7496355","2018-03-01 19:08:15","Pip installing wrong version on win7,","<python><python-2.7><pip><package>","2","0","1337"
"49056838","2018-03-01 18:57:41","0","","<p>Check out <a href=""https://knowledgebase.progress.com/articles/Article/How-to-configure-the-11-6-OpenEdge-64-bit-ODBC-driver-on-Ubuntu-14-04-to-retrieve-data-from-an-OpenEdge-database"" rel=""nofollow noreferrer"">this site</a>, I used this documentation to get python3 on a Debian 9 machine connected by ODBC to a remote 10.1c DB. I used the python turbodbc library to manage the connection in python. This should work in python 2.7 as long as it is 64 bit. </p>

<p>Progress Note: This documentation recommends you install ""libstdc++5"" BEFORE you install the ODBC software. Also make sure that $DLC is set properly. </p>

<p>turbodbc Note: i had to install ""libboost-all-dev"" and ""unixodbc-dev"" for turbodbc to install.</p>

<p>good luck </p>
","3084737","","","0","745","Jay42","2013-12-09 22:29:14","164","50","77","0","43501180","","2017-04-19 16:24:20","0","257","<p>I can get pyodbc to connect to Progress DB from Windows using a DSN without any problems.</p>

<p>However I need to get it to work from Linux (Centos 6) and although I've downloaded and attempted to install the driver from progress.com, I cannot figure out how to configure the Linux system using the docs from progress.com.  I'm no Linux sysadmin, but not completely lost.</p>

<p>revised 4/22: how do you configure odbc.ini in Centos 6 and will freetds talk to databases other than Sybase and MSSQL that they list in their docs?</p>

<p>I apologize if my initial post was inappropriate, I think my frustration was showing thru.</p>

<p>Thanks,</p>

<p>Fred.</p>
","6026191","6026191","2017-04-23 02:26:44","Linux Python 2.7 odbc Connection to Progress Open Edge DB","<python><linux><odbc><openedge><progress-db>","1","1","667"
"49056856","2018-03-01 18:58:53","2","","<p>I found an answer to my own question...</p>

<ol>
<li>Enable compression for each variable</li>
<li>For column <code>e</code>, specify that <code>dtype</code> is ""character"" (i.e. <code>S1</code>)</li>
</ol>

<p>Before saving the .nc file, add the following code:</p>

<pre><code>encoding = {'a':{'zlib':True},
            'b':{'zlib':True},
            'c':{'zlib':True},
            'd':{'zlib':True},
            'e':{'zlib':True, 'dtype':'S1'}}
ds.to_netcdf('ds.nc',format='NETCDF4',engine='netcdf4',encoding=encoding)
</code></pre>

<p>The new results are:</p>

<pre><code>&gt;&gt;&gt; csv = 1688902 bytes
&gt;&gt;&gt;  nc = 1066182 bytes
&gt;&gt;&gt; nc/csv = 0.6312870729029867
</code></pre>

<p>Note that it still takes a bit of time to save the .nc file.</p>
","2654962","","","1","771","Diego","2013-08-06 00:46:52","24","4","0","0","49053692","","2018-03-01 15:57:28","0","310","<p>I have many large .csv files that I want to convert to .nc (i.e. netCDF files) using <a href=""http://xarray.pydata.org/en/stable/index.html"" rel=""nofollow noreferrer"">xrray</a>. However, I found that saving the .nc files takes a very long time, and the resulting .nc files are much larger (4x to 12x larger) than the original .csv files.</p>

<p>Below is sample code to show how the same data produces .nc files that are about 4 times larger than when saved in .csv</p>

<pre><code>import pandas as pd
import xarray as xr
import numpy as np
import os

# Create pandas DataFrame 
df = pd.DataFrame(np.random.randint(low=0, high=10, size=(100000,5)),
                   columns=['a', 'b', 'c', 'd', 'e'])

# Make 'e' a column of strings
df['e'] = df['e'].astype(str)

# Save to csv
df.to_csv('df.csv')

# Convert to an xarray's Dataset
ds = xr.Dataset.from_dataframe(df)

# Save NetCDF file
ds.to_netcdf('ds.nc')

# Compute stats
stats1 = os.stat('df.csv')
stats2 = os.stat('ds.nc')
print('csv=',str(stats1.st_size))
print('nc =',str(stats2.st_size))
print('nc/csv=',str(stats2.st_size/stats1.st_size))
</code></pre>

<p>The result:</p>

<pre><code>&gt;&gt;&gt; csv = 1688902 bytes
&gt;&gt;&gt;  nc = 6432441 bytes
&gt;&gt;&gt; nc/csv = 3.8086526038811015
</code></pre>

<p>As you can see, the .nc file is about 4 times larger than the .csv file. </p>

<p>I found <a href=""https://www.unidata.ucar.edu/support/help/MailArchives/netcdf/msg13324.html"" rel=""nofollow noreferrer"">this post</a> suggesting that changing from type 'string' to type 'char' drastically reduces file size, but how to I do this in xarray?</p>

<p>Also, note that even when having all data as Integers (i.e. comment-out <code>df['e'] = df['e'].astype(str)</code>) the resulting .nc file is still 50% larger than .csv</p>

<p>Am I missing a compression setting? ...or something else?</p>
","2654962","","","csv to netCDF produces .nc files 4X larger than the original .csv","<python><csv><netcdf><python-xarray><netcdf4>","2","0","1860"
"49056869","2018-03-01 18:59:31","1","","<p>Try to use below XPath:</p>

<pre><code>//td[contains(., ""Fiscal Yr"")]/following-sibling::td/a[img[@title=""Edit Filter""]]
</code></pre>

<p>You might need to use ExplicitWait for dynamic nodes:</p>

<pre><code>from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait as wait
from selenium.webdriver.support import expected_conditions as EC

wait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//td[contains(., ""Fiscal Yr"")]/following-sibling::td/a[img[@title=""Edit Filter""]]'))).click()
</code></pre>
","4549554","4549554","2018-03-01 20:37:53","12","557","Andersson","2015-02-10 08:27:34","40727","5512","1461","1828","49056755","","2018-03-01 18:52:26","0","69","<p>Hi I would like to click on the Edit Filter button, which appears to be in the same tr for the Fiscal Yr item but in a different td.</p>

<p><a href=""https://i.stack.imgur.com/0VOyw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0VOyw.png"" alt=""enter image description here""></a></p>

<p>This is what I tried:</p>

<pre><code>driver.find_elements_by_xpath(""//body//tr[@class='FilterEditCell']/td[2]/a[1]"").click()
</code></pre>

<p>Could someone please guide me?</p>

<p>Thanks.</p>
","6762734","4549554","2018-03-01 19:01:35","Python Selenium click on a link in the same tr different td","<python><selenium><xpath>","1","2","506"
"49056908","2018-03-01 19:02:22","1","","<p>I do not much idea on how this can be achieved in <code>luigi</code>. What I may suggest is to simple approach to write the output for <code>luigi</code> script in normal delimited format (say comma delimited format). </p>

<p>Create an external hive table on top of that:</p>

<pre><code>CREATE EXTERNAL TABLE temp_table(
&lt;col_name&gt; &lt;col_type&gt;, 
&lt;col_name2&gt; &lt;col_type&gt;
.......
....... 
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ‘,’
LOCATION ‘ /hive/data/weatherext’;
</code></pre>

<p>Insert the data into original table (having ORC format data) using simple hive <code>insert-into-select</code> query.</p>

<pre><code>INSERT INTO TABLE target_table
PARTITION( xxx )
SELECT 
COL_NAME1,
COL_NAME2
FROM temp_table;
</code></pre>

<p>Your target table would have data in ORC format and hive would handle the conversion for you.</p>

<p>For detail syntax, refer 
<a href=""https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-InsertingdataintoHiveTablesfromqueries"" rel=""nofollow noreferrer"">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-InsertingdataintoHiveTablesfromqueries</a></p>
","2748004","2748004","2018-03-05 16:00:14","2","1181","Gyanendra Dwivedi","2013-09-04 17:56:06","4232","548","105","43","49029913","49056908","2018-02-28 12:44:44","0","1042","<p>suppose we have such job:</p>

<pre><code>class MRjob(JobTask):
  def output(self):
    return ...

  def requires(self):
    return ...

  def mapper(self, line):
    # some line process
    yield key, (...information, stored in hashable type...)

  def reducer(self,key,values):
    # some reduce logic... for example this
    unique = set(values)
    for elem in unique:
      yield key, elem[0], elem[1] 
</code></pre>

<p>What should I do inside the output method to insert data to existing table partition (also table is stored in orc format)? I'd like to skip process of converting data to orc, hence I tried to </p>

<pre><code>return HivePartitionTarget(self.insert_table, database=self.database_name, partition=partition)
</code></pre>

<p>but this didn't work. I also found that luigi tries to pass output to some file. With HivePartitionTarget luigi returns error like 'object has no attribute write', so my assumption is that HivePartitionTarget just doesn't contain write method. Thus I think I'm doing something wrong and should use another method but didn't managed to find a single example</p>
","3826180","","","How to write output to partitioned table with orc format with luigi?","<python><hadoop><mapreduce><etl><luigi>","1","1","1114"
"49056952","2018-03-01 19:04:30","2","","<p>You need to use an input tag.</p>

<pre><code>&lt;input name=""name"" value=""{{ item }}""&gt;
</code></pre>
","104349","","","0","108","Daniel Roseman","2009-05-10 12:36:13","489411","52610","12851","10717","49049617","","2018-03-01 12:20:18","0","119","<p>I have a html page which uses jinja to display a list.
I want to be able to get the user to click a button and the list will be added to a database. I have put the button in side a form and got it to link to my url which then calls a function.</p>

<p>HTML:</p>

<pre><code>&lt;form method='post' action='../../accounts/myaccount/' name= '{{item}}'&gt;
                                {% csrf_token %}
                                &lt;a name = '{{ item }}'&gt;&lt;button type='submit' class='btn'&gt;&lt;img src={% static 'results/images/basket_02.png' %} alt='Image cannot be displayed right now'&gt;&lt;/button&gt;&lt;/a&gt;
                            &lt;/form&gt;
</code></pre>

<p>Views:</p>

<pre><code>def myaccount(request):
    if request.user.is_authenticated():
        if request.method == 'POST':
            product = request.GET.get('name')
            print('product: ' , product)
            return render(request, 'signup/myaccount.html')
</code></pre>

<p>The function is called and it prints: product: NONE , whereas i want product to be set to the list.
I know how to add to database within my views but is there a way to actually access my list?</p>
","7834246","7834246","2018-03-03 09:35:29","How to access an attribute of a html tag in views with django","<python><html><django><jinja2>","1","0","1179"
"49056975","2018-03-01 19:05:22","6","","<p>Simply because the <strong><code>socketC</code></strong>, being the instance of a <strong><code>REQ</code></strong> archetype, cannot ever send another message ( as was coded inside the implementation of the <strong><code>.send()</code></strong> class-method above ), without a prior call to <strong><code>socketC.recv()</code></strong> instance-method.</p>

<p>Both <strong><code>REQ</code></strong> and <strong><code>REP</code></strong> archetypes are well documented to have to obey a two-step dance of <code>.send()-.recv()-.send()-.recv()-...</code> resp. <code>.recv()-.send()-.recv()-...</code> using their native instance-methods.</p>

<p>This is how the ZeroMQ <code>REQ / REP</code>  sockets were designed and documented.</p>
","3666197","","","2","739","user3666197","2014-05-22 17:36:09","21974","5766","1564","81","49056602","49056975","2018-03-01 18:43:37","2","822","<p>I am trying to make a class that will be able to send data and then receive them.</p>

<p>Right now, it is working only for the first send/receive and with another attempt to <code>.send()</code> it will throw an error below.</p>

<pre><code>&gt;Traceback (most recent call last):
  File ""main.py"", line 31, in &lt;module&gt;
    zq.send(arr)
  File ""D:\ITIM\video2\MQCompare\cZMQ.py"", line 17, in send
    self.socketC.send(data)
  File ""zmq/backend/cython/socket.pyx"", line 636, in zmq.backend.cython.socket.S
ocket.send (zmq\backend\cython\socket.c:7305)
  File ""zmq/backend/cython/socket.pyx"", line 683, in zmq.backend.cython.socket.S
ocket.send (zmq\backend\cython\socket.c:7048)
  File ""zmq/backend/cython/socket.pyx"", line 206, in zmq.backend.cython.socket._
send_copy (zmq\backend\cython\socket.c:3032)
  File ""zmq/backend/cython/socket.pyx"", line 201, in zmq.backend.cython.socket._
send_copy (zmq\backend\cython\socket.c:2920)
  File ""zmq/backend/cython/checkrc.pxd"", line 25, in zmq.backend.cython.checkrc.
_check_rc (zmq\backend\cython\socket.c:10014)
    raise ZMQError(errno)
zmq.error.ZMQError: Operation cannot be accomplished in current state`
</code></pre>

<p>The code I'm using looks like this:</p>

<pre><code>import zmq

class ZeroMQ:

def __init__(self):
    self.context = zmq.Context()
    self.socketS = self.context.socket(zmq.REP)
    self.socketS.bind(""tcp://*:5555"")
    self.socketC = self.context.socket(zmq.REQ)
    self.socketC.connect(""tcp://localhost:5555"")

def __exit__(self, exc_type, exc_value, traceback):
    self.socketC.close()
    self.socketS.close()

def send(self, data):
    self.socketC.send(data)

def recv(self):    
    self.socketS.recv()
</code></pre>

<p>Am I making the connection right?</p>

<p>Why is the function send throwing an error?  </p>

<p>I will appreciate any help. Thank you.</p>
","6746237","3666197","2018-03-01 19:24:43","ZeroMQ operation throws EXC: [ Operation cannot be accomplished in current state ]","<python><sockets><message-queue><zeromq>","1","0","1853"
"49056990","2018-03-01 19:06:32","1","","<p>While I can't get your code to actually draw a paddle, I do notice that you create a new Paddle instance in every iteration of the loop, so the position resets to 300 each time.</p>

<p>Try this instead:</p>

<pre><code>def run(self):
    paddle = Paddle()
    while 1:
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                sys.exit()
        # fps lock, screen fill and method call for input
        clock.tick(60)
        screen.fill(BLACK)
        paddle.draw_paddle()
        paddle.move_paddle_left()
        pygame.display.flip()
</code></pre>

<p>That way you create a paddle object and then re-use its values in each iteration and it'll keep moving left until it hits 0.</p>
","5297811","","","4","731","alkanen","2015-09-03 16:57:53","598","31","252","9","49056617","49056990","2018-03-01 18:44:30","0","111","<p>When I run the code below, the pygame rect wont move. It is set to move -7 in the x direction at each left arrow press, but nothing happens. I tried to print the position of the rect, and it seems like it's position is updated once, from the initial position 300, to 293, although there is no movement on screen. Any help is much appreciated!</p>

<pre><code>import sys
import pygame

PINK = (255, 102, 255)
BLACK = (0, 0, 0)

pygame.init()
clock = pygame.time.Clock()
pygame.display.init()

font = pygame.font.SysFont(""impact"", 20)


screen = pygame.display.set_mode(750, 550)

class Paddle:
    def __init__(self):
        self.paddle = pygame.Rect(300, 730,
                                  10,
                                  52)

    def draw_paddle(self):
        # Draw paddle
        pygame.draw.rect(screen, PINK,
                         self.paddle)

    def move_paddle_left(self):
        key = pygame.key.get_pressed()
        if key[pygame.K_LEFT]:
            self.paddle.left -= 7
            if self.paddle.left &lt; 0:
                self.paddle.left = 0
            print(self.paddle)


class Game:
    def __init__(self):
        self.run()
        Paddle()
        # Levels().draw_level_one()
    def run(self):
        while 1:
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    sys.exit()
            # fps lock, screen fill and method call for input
            clock.tick(60)
            screen.fill(BLACK)
            Paddle().draw_paddle()
            Paddle().move_paddle_left()
            pygame.display.flip()
# Creates instance of the game class, and runs it
if __name__ == ""__main__"":
    Game()
    Game().run()
</code></pre>
","9351296","5297811","2018-03-01 19:02:16","How to move a pygame rect?","<python><python-3.x><pygame>","1","0","1728"
"49057014","2018-03-01 19:08:07","1","","<p>I see a reasonable performance improvement by using <code>.loc</code> rather than chained indexing:</p>

<pre><code>import random, pandas as pd, numpy as np

df = pd.DataFrame([[4,5,19],[1,2,0],[2,5,9],[8,2,5]], columns=['a','b','c'])

df = pd.concat([df]*1000000)

x = df.sample(n=2)

def get_new(row):
    a, b, c = row
    return random.choice(df[(df['a'] != a) &amp; (df['b'] == b) &amp; (df['c'] != c)]['c'].values)

def get_new2(row):
    a, b, c = row
    return random.choice(df.loc[(df['a'] != a) &amp; (df['b'] == b) &amp; (df['c'] != c), 'c'].values)


%timeit x.apply(lambda row: get_new(row), axis=1)   # 159ms
%timeit x.apply(lambda row: get_new2(row), axis=1)  # 119ms
</code></pre>
","9209546","","","5","701","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49053252","","2018-03-01 15:36:31","4","1178","<p>I have a Pandas dataframe and I would like to add a new column based on the values of the other columns. A minimal example illustrating my usecase is below.</p>

<pre class=""lang-py prettyprint-override""><code>df = pd.DataFrame([[4,5,19],[1,2,0],[2,5,9],[8,2,5]], columns=['a','b','c'])
df

    a   b   c
---------------
0   4   5   19
1   1   2   0
2   2   5   9
3   8   2   5

x = df.sample(n=2)
x

    a   b   c
---------------
3   8   2   5
1   1   2   0

def get_new(row):
    a, b, c = row
    return random.choice(df[(df['a'] != a) &amp; (df['b'] == b) &amp; (df['c'] != c)]['c'].values)

y = x.apply(lambda row: get_new(row), axis=1)
x['new'] = y
x

    a   b   c   new
--------------------
3   8   2   5   0
1   1   2   0   5
</code></pre>

<p>Note: The original dataframe has ~4 million rows and ~6 columns. The number of rows in the sample might vary between 50 and 500. I am running on a 64-bit machine with 8 GB RAM.</p>

<p>The above works, except that it is quite slow (takes about 15 seconds for me). I also tried using <code>x.itertuples()</code> instead of <code>apply</code> and there is not much of an improvement in this case.</p>

<ol>
<li><p>It seems that apply(with axis=1) is slow since it does not make use of the vectorized operations. Is there some way I could achieve this in a faster way?</p></li>
<li><p>Can the filtering(in the <code>get_new</code> function) be modified or made more efficient compared to using conditional boolean variables, as I currently have?</p></li>
<li><p>Can I in some way use numpy here for some speedup?</p></li>
</ol>

<p>Edit: <code>df.sample()</code> is also quite slow and I cannot use <code>.iloc</code> or <code>.loc</code> since I am further modifying the sample and do not wish for this to affect the original dataframe.</p>
","2546600","2546600","2018-03-01 22:47:02","Pandas alternative to apply - to create new column based on multiple columns","<python><pandas><numpy><dataframe><apply>","1","4","1795"
"49057020","2018-03-01 19:08:20","1","","<p>You want something like this:</p>

<pre><code>&gt;&gt;&gt; df[(df.c_h == 'ham') &amp; (df.qual == 'bad')].index.min()
2
</code></pre>

<p>But if you don't just want the index, you can use the indexers:</p>

<pre><code>&gt;&gt;&gt; df.loc[(df.c_h == 'ham') &amp; (df.qual == 'bad'), 'price'].iloc[0]
11.0
&gt;&gt;&gt; df.loc[(df.c_h == 'ham') &amp; (df.qual == 'bad'), 'price'].iloc[[0]]
2    11.0
Name: price, dtype: float64
</code></pre>

<p>Note, the above takes the <em>first</em> index, not the <em>lowest</em> index. If you index is a normal, int-range index, then these will be equivalent.</p>

<p>However, if it isn't:</p>

<pre><code>&gt;&gt;&gt; df.index = [3,1,2,4,0]
&gt;&gt;&gt; df
      c_h  price  qty  qual
3  cheese    1.1   14  good
1     ham   66.3    2  good
2     ham   11.0    1   bad
4  cheese   15.2   10  good
0     ham    1.1    1   bad
&gt;&gt;&gt; df.loc[(df.c_h == 'ham') &amp; (df.qual == 'bad'), 'price']
2    11.0
0     1.1
Name: price, dtype: float64
</code></pre>

<p>Then get the <em>first</em> the same way:</p>

<pre><code>&gt;&gt;&gt; df.loc[(df.c_h == 'ham') &amp; (df.qual == 'bad'), 'price'].iloc[[0]]
2    11.0
Name: price, dtype: float64
</code></pre>

<p>But the <em>lowest</em> would require something to the effect of:</p>

<pre><code>&gt;&gt;&gt; df.loc[(df.c_h == 'ham') &amp; (df.qual == 'bad'), 'price'].sort_index().iloc[[0]]
0    1.1
Name: price, dtype: float64
</code></pre>
","5014455","5014455","2018-03-01 19:11:12","3","1430","juanpa.arrivillaga","2015-06-16 08:18:23","42745","9720","6722","648","49056949","49057020","2018-03-01 19:04:20","0","200","<p>I've got a df: </p>

<pre><code>import pandas as pd
import numpy as np

df = pd.DataFrame({""price"":[1.1,66.3,11,15.2,1.1], 
                   ""qty"":[14,2,1,10,1],
                   ""c_h"":['cheese','ham','ham','cheese','ham'],
                   ""qual"":['good','good','bad','good','bad']})
</code></pre>

<p>The df looks like this when printed:  </p>

<pre><code>      c_h   price  qty  qual
0  cheese     1.1   14  good
1     ham    66.3    2  good
2     ham    11.0    1   bad
3  cheese    15.2   10  good
4     ham     1.1    1   bad
</code></pre>

<p>I'm trying to return a <code>price</code> of <code>'c_h'=='ham' and 'qual=='bad'</code> on the minimum index value from a the df.  The minimum index is the lowest numerical value for index currently <code>[0,1,2,...]</code>in which that criteria is met </p>

<p>In this example, the minimum index sought would be 2 and the returned price would be 11.0.  </p>

<p>Note: I'm working mostly with <code>pandas</code> but I could also use <code>numpy</code>.  </p>

<p>I thought it'd be something like </p>

<pre><code>df[df['c_h']=='ham' and 'qual'=='bad'].min()[index]
</code></pre>

<p>but that's not working.  </p>
","5965312","5965312","2018-03-01 19:08:42","Python Pandas extract value from dataframe based on minimum index","<python><pandas><dataframe><indexing>","2","2","1173"
"49057021","2018-03-01 19:08:26","3","","<p>You can use <code>all</code> and <code>any</code>:</p>

<pre><code>s1 = set(['red', 'gold', 'black', 'gold'])
s2 = ['golden', 'blackstone', 'golden', 'goldlike', 'blackstone', 'golden', 'redline', 'red']
print(all(any(i.startswith(b) for b in s1) for i in s2))
</code></pre>

<p>Output:</p>

<pre><code>True
</code></pre>

<p>Edit:</p>

<p>Checking if every element in <code>s1</code> appears in <code>s2</code>:</p>

<pre><code>print(all(any(b.startswith(i) for b in s2) for i in s1))
</code></pre>
","7326738","7326738","2018-03-01 19:33:31","9","503","Ajax1234","2016-12-21 16:39:57","49079","3709","2930","360","49056976","49057144","2018-03-01 19:05:25","-2","57","<p>This works, but it seems overly complicated:</p>

<pre><code>s1 = list(set(['red', 'gold', 'black', 'gold']))

s2 = ['golden', 'blackstone', 'golden', 'goldlike', 'blackstone', 'golden', 'redline', 'red']

lst = []
for i in s1:
    for j in s2:
        if j.startswith(i):
            lst.append(i)
lst2 = set(lst)
if len(s1) == len(lst2):
    print(s2)

# output: ['golden', 'blackstone', 'golden', 'goldlike', 'blackstone', 'golden', 'redline', 'red']
</code></pre>

<p>Is there a more efficient and compact way to do it?</p>
","6274604","","","Check if all words in a list appear as the start of at least one word in the words in another list","<python>","2","0","531"
"49057067","2018-03-01 19:11:15","2","","<p>An <a href=""https://github.com/uber/horovod/blob/master/examples/tensorflow_mnist_estimator.py"" rel=""nofollow noreferrer"">TensorFlow Estimator example</a> has been added to the Horovod repo.</p>
","3391864","","","0","198","bytesinflight","2014-03-07 09:01:16","787","57","180","0","47770624","49057067","2017-12-12 10:43:16","2","428","<p>How can I extend the <a href=""https://github.com/uber/horovod"" rel=""nofollow noreferrer"">Horovod</a> example that uses <code>tf.train.MonitoredTrainingSession</code> to instead use <code>tf.estimator.Estimator</code>? I am using Tensorflow 1.4.0.</p>

<p><a href=""https://gist.github.com/peterroelants/9956ec93a07ca4e9ba5bc415b014bcca"" rel=""nofollow noreferrer"">Here is an example</a> that closely resembles my current code.</p>

<p>I want to use this together with <code>hyperopt</code>, and I like how I can easily do something like</p>

<pre><code>tf.contrib.learn.learn_runner.run(
      experiment_fn=_create_my_experiment,
      run_config=run_config,
      schedule=""train_and_evaluate"",
      hparams=hparams)
</code></pre>

<p>to train with different hyperparameters, <code>hparams</code>. This also gives me separate Tensorboard log directories for training and validation sets - and I'd like this to be true with a Horovod solution as well. I played around with a  <code>tf.train.SingularMonitoredSession(hooks=hooks, config=config)</code> where <code>hooks</code> contains a <code>tf.train.SummarySaverHook</code>, but I only could make it work nicely with the training set.</p>
","3391864","3391864","2017-12-12 10:50:28","Horovod and Tensorflow estimators","<python><tensorflow><tensorflow-gpu>","1","0","1194"
"49057070","2018-03-01 19:11:41","1","","<pre><code>a = set([1,2])
b = set([3,4])
c = set([6,7,8])

print [set([x, y, z]) for x in a for y in b for z in c]
#[set([8, 1, 3]), set([1, 3, 6]), set([1, 3, 7]), set([8, 1, 4]), set([1, 4, 6]), set([1, 4, 7]), set([8, 2, 3]), set([2, 3, 6]), set([2, 3, 7]), set([8, 2, 4]), set([2, 4, 6]), set([2, 4, 7])]
</code></pre>
","314922","","","0","323","Personman","2010-04-12 20:57:16","1448","160","148","10","49057027","49057073","2018-03-01 19:08:50","-2","62","<p>I came across the following problem.</p>

<p>Is there a fast python built-in method to do the following:</p>

<pre><code>Input: sets {1,2}, {3,4}, {6,7,8}

Output: sets {1,3,6}, {1,3,7}, {1,3,8}, {1,4,6}, {1,4,7}, {1,4,8}, {2,3,6}, {2,3,7}, {2,3,8}, {2,4,6}, {2,4,7}, {2,4,8}
</code></pre>

<p>Thanks!</p>
","617845","","","multiset combinatorics generation","<python><algorithm>","3","0","309"
"49057073","2018-03-01 19:11:53","2","","<p>Here is one way to do it:</p>

<pre><code>&gt;&gt;&gt; map(set, itertools.product({1,2}, {3,4}, {6,7,8}))
[set([8, 1, 3]), set([1, 3, 6]), set([1, 3, 7]), set([8, 1, 4]), set([1, 4, 6]), set([1, 4, 7]), set([8, 2, 3]), set([2, 3, 6]), set([2, 3, 7]), set([8, 2, 4]), set([2, 4, 6]), set([2, 4, 7])]
</code></pre>

<p>Note that sets are unordered. If you need to preserve ordering, work with lists or tuples:</p>

<pre><code>&gt;&gt;&gt; map(tuple, itertools.product((1,2), (3,4), (6,7,8)))
[(1, 3, 6), (1, 3, 7), (1, 3, 8), (1, 4, 6), (1, 4, 7), (1, 4, 8), (2, 3, 6), (2, 3, 7), (2, 3, 8), (2, 4, 6), (2, 4, 7), (2, 4, 8)]
</code></pre>

<p>This readily generalized to a variable number of sets or other collections:</p>

<pre><code>&gt;&gt;&gt; coll = ((1,2), (3,4), (6,7,8))
&gt;&gt;&gt; map(tuple, itertools.product(*coll))
[(1, 3, 6), (1, 3, 7), (1, 3, 8), (1, 4, 6), (1, 4, 7), (1, 4, 8), (2, 3, 6), (2, 3, 7), (2, 3, 8), (2, 4, 6), (2, 4, 7), (2, 4, 8)]
</code></pre>
","367273","","","2","977","NPE","2010-06-15 12:55:43","380640","23045","4140","677","49057027","49057073","2018-03-01 19:08:50","-2","62","<p>I came across the following problem.</p>

<p>Is there a fast python built-in method to do the following:</p>

<pre><code>Input: sets {1,2}, {3,4}, {6,7,8}

Output: sets {1,3,6}, {1,3,7}, {1,3,8}, {1,4,6}, {1,4,7}, {1,4,8}, {2,3,6}, {2,3,7}, {2,3,8}, {2,4,6}, {2,4,7}, {2,4,8}
</code></pre>

<p>Thanks!</p>
","617845","","","multiset combinatorics generation","<python><algorithm>","3","0","309"
"49057079","2018-03-01 19:12:20","2","","<p>Building an array of same-shaped arrays is not well supported by numpy which prefers to create a maximum depth array of minimum depth elements instead.</p>

<p>It turns out that <code>numpy.frompyfunc</code> is quite useful in circumventing this tendency where it is unwanted.</p>

<p>In your specific case one could do:</p>

<pre><code>result = np.frompyfunc(zeroMatrix.copy, 0, 1)(np.empty((7, 7, 7), object))
</code></pre>

<p>Indeed:</p>

<pre><code>&gt;&gt;&gt; result.shape
(7, 7, 7)
&gt;&gt;&gt; result.dtype
dtype('O')
&gt;&gt;&gt; result[0, 0, 0].shape
(40, 30, 80)
</code></pre>
","7207392","","","0","592","Paul Panzer","2016-11-24 23:39:00","37645","7185","734","1","49050642","49057079","2018-03-01 13:22:55","0","273","<p>Hello I have the following question. I create zero arrays of dimension (40,30,80). Now I need 7*7*7 of these zero arrays in an array. How can I do this?
One of my matrices is created like this:</p>

<pre><code>import numpy as np
zeroMatrix = np.zeros((40,30,80))
</code></pre>

<p>My first method was to put the zero matrices in a 7*7*7 list. But i want to have it all in a numpy array. I know that there is a way with structured arrays I think, but i dont know how. If i copy my 7*7*7 list with np.copy() it creates a numpy array with the given shape, but there must be a way to do this instantly, isnt there?</p>

<p><strong>EDIT</strong></p>

<p>Maybe I have to make my question clearer. I have a 7*7 list of my zero matrices. In a for loop all of that arrays will be modified. In another step, this tempory list is appended to an empty list which will have a length of 7 in the end ( So i append the 7*7 list 7 times to the empty list. In the end I have a 7*7*7 List of those matrices. But I think this will be better If I have a numpy array of these zero matrices from the beginning.</p>
","9319043","9319043","2018-03-01 14:09:44","Python: Creating multi dimensional array of multidimensional zero array","<python><numpy><scipy>","1","4","1096"
"49057098","2018-03-01 19:13:48","1","","<pre><code>&gt;&gt;&gt; from itertools import product
&gt;&gt;&gt; list(product([1,2],[3,4,5],[6,7,8]))
[(1, 3, 6), (1, 3, 7), (1, 3, 8), (1, 4, 6), (1, 4, 7), (1, 4, 8), (1, 5, 6), (1, 5, 7), (1, 5, 8), (2, 3, 6), (2, 3, 7), (2, 3, 8), (2, 4, 6), (2, 4, 7), (2, 4, 8), (2, 5, 6), (2, 5, 7), (2, 5, 8)]
</code></pre>
","5095849","","","0","317","Amaro Vita","2015-07-08 21:03:14","432","27","8","24","49057027","49057073","2018-03-01 19:08:50","-2","62","<p>I came across the following problem.</p>

<p>Is there a fast python built-in method to do the following:</p>

<pre><code>Input: sets {1,2}, {3,4}, {6,7,8}

Output: sets {1,3,6}, {1,3,7}, {1,3,8}, {1,4,6}, {1,4,7}, {1,4,8}, {2,3,6}, {2,3,7}, {2,3,8}, {2,4,6}, {2,4,7}, {2,4,8}
</code></pre>

<p>Thanks!</p>
","617845","","","multiset combinatorics generation","<python><algorithm>","3","0","309"
"49057114","2018-03-01 19:15:23","3","","<pre><code>list(&lt;string&gt;) 
</code></pre>

<p>will split a string into a list of characters </p>

<pre><code>food = ['eel', 'egg', 'yam', 'nut', 'oats']

print(list(food[0]))
print(list(food[1]))
</code></pre>
","5033630","","","0","215","Sunimal S.K Malkakulage","2015-06-21 15:48:37","435","82","17","1","49056972","49057114","2018-03-01 19:05:15","1","105","<p>For a list of words, how can I access each alphabet of the word. For example</p>

<pre><code>food = ['eel', 'egg', 'yam', 'nut', 'oats']
</code></pre>

<p>I need to retrieve each food by its individual letters and make it into a list, i.e. </p>

<pre><code>each_food[1] = ['e', 'e', 'l']
each_food[2] = ['e', 'g', 'g']
</code></pre>

<p>Any help is appreciated. </p>
","9293468","","","Accessing sub-element of a list","<python>","2","1","370"
"49057144","2018-03-01 19:17:39","1","","<p>The question is: Check if all words in a list appear as the start of at least one word in the words in another list.</p>

<p>Assuming that op wants all words in S1 to appear at least once as the beginning of an word in S2.</p>

<p>You can sort both input</p>

<pre><code>def contain(s1, s2):
    count = 0
    for i in s1:
        while ( count &lt; len(s2) and s2[count].startswith(i) == False ):
            count += 1
        if (count &gt;= len(s2)): return False
    return True
s1 = sorted(set(['red', 'gold', 'black', 'gold', 'red', 're']))
s2 = sorted(['golden', 'blackstone', 'golden', 'goldlike', 'blackstone', 'golden', 'redline', 'red'])
print( contain(s1, s2) )
</code></pre>

<p>Output:</p>

<p><code>True</code></p>

<p><strong><em>Edit to include complexity:</em></strong></p>

<p>Let’s assume S1 has <code>n</code> elements and S2 has <code>m</code> elements.</p>

<p>A naive solution that have nested loops to iterate through both list will have the complexity of <code>O(n*m)</code>.</p>

<p>By sorting both S1 and S2 we can reduce the complexity of the solution.</p>

<p>Sort S1: <code>O(n*log n)</code>, Sort S2: <code>O(m*log m)</code> and Contain: <code>O(m)</code> (<code>m if m &gt; n else n</code>)</p>

<p>As pointed out in the comments by Stefan, by sorting it will have better complexity than the naive approach.</p>
","2540607","2540607","2018-03-01 20:13:51","3","1349","wendelbsilva","2013-07-01 22:13:31","694","172","526","70","49056976","49057144","2018-03-01 19:05:25","-2","57","<p>This works, but it seems overly complicated:</p>

<pre><code>s1 = list(set(['red', 'gold', 'black', 'gold']))

s2 = ['golden', 'blackstone', 'golden', 'goldlike', 'blackstone', 'golden', 'redline', 'red']

lst = []
for i in s1:
    for j in s2:
        if j.startswith(i):
            lst.append(i)
lst2 = set(lst)
if len(s1) == len(lst2):
    print(s2)

# output: ['golden', 'blackstone', 'golden', 'goldlike', 'blackstone', 'golden', 'redline', 'red']
</code></pre>

<p>Is there a more efficient and compact way to do it?</p>
","6274604","","","Check if all words in a list appear as the start of at least one word in the words in another list","<python>","2","0","531"
"49057167","2018-03-01 19:18:52","0","","<p>I think there is no way to do this. Try matrix.dtype. This should give you something like dtype('int32'). Your headers would be strings. </p>

<p>As far as I know you can only store one datatype in a numpy array/matrix.</p>
","8403890","","","2","227","G.Brown","2017-08-02 07:18:39","82","17","23","0","49057107","","2018-03-01 19:14:42","0","1073","<p>I have a numpy.ndarray having dimensions of 23411 x 3.
I would like to add headers to the top of the matrix called: ""summary"", ""age"", and ""label"". In that order. </p>

<p>In:</p>

<pre><code>matrix.shape
</code></pre>

<p>Out:</p>

<pre><code>(23411L, 3L)
</code></pre>

<p>In:</p>

<pre><code>type(matrix)
</code></pre>

<p>Out:</p>

<pre><code>numpy.ndarray
</code></pre>

<p>I tried using the numpy.recarray but it did not work. any suggestions??</p>
","8778033","8778033","2018-03-01 19:19:23","how to add headers to a numpy.ndarray","<python><numpy>","4","1","457"
"49057183","2018-03-01 19:20:07","1","","<p>Use:</p>

<pre><code>canvas = tkinter.Canvas(...)
canvas['highlightthickness'] = 0
</code></pre>

<p>or specifically:</p>

<pre><code>grid[-1][-1]['highlighthickness'] = 0
</code></pre>
","7032856","","","0","189","Nae","2016-10-17 19:19:28","6877","1192","1235","658","49054827","49057183","2018-03-01 16:52:55","0","56","<p>I have the following code that generates a grid of canvases but there are spaces between each</p>

<pre><code>from tkinter import *

grid = []

master = Tk()

for n in range(0,10):
    grid.append([])
    for i in range(0,10):
        grid[n].append(Canvas(master, bg=""#222"", height=""20"", width=""20""))
        grid[n][i].grid(row=n, column=i)
</code></pre>

<p>How would I remove these so that it looks like one big canvas?</p>

<p>Here's what it looks like:</p>

<p><a href=""https://i.stack.imgur.com/Ka9M2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Ka9M2.png"" alt=""""></a></p>
","9352391","9352391","2018-03-01 21:10:18","Creating a grid of Canvases without gaps in tkinter python","<python><python-3.x><tkinter>","1","2","605"
"49057186","2018-03-01 19:20:12","2","","<h2>Easy:</h2>

<p>your initial setup associated a symbol <strong><code>led</code></strong>, not <strong><code>led21</code></strong></p>

<pre><code>...
# Define LED
# Put LED Numbers
led = 21
</code></pre>

<p>while the later parts of the code used a not defined symbol <strong><code>led21</code></strong></p>

<pre><code>GPIO.output( led21, GPIO.HIGH )
</code></pre>

<p>replace the names so as to become ""coherent"" and voilá ... :o)</p>
","3666197","","","2","440","user3666197","2014-05-22 17:36:09","21974","5766","1564","81","49057024","","2018-03-01 19:08:40","1","62","<p>I'm trying to light up an led on raspberrypi via AWSIoT but I keep getting this error</p>

<blockquote>
  <p>File ""mypub.py"", line 71, in <br>
  GPIO.output(led21,GPIO.HIGH)<br>
  Connection returned result: 0<br>
  NameError: name 'led21' is not defined  </p>
</blockquote>

<p>Can anyone help resolve this?</p>

<p>I am playing around with MQTT, trying to light up LED-s and interact with other sensors eventually.</p>

<p>I am using code I got from <a href=""https://github.com/anujdutt9/AWS_IoT_Python"" rel=""nofollow noreferrer""><strong>here</strong></a> </p>

<pre><code># Publishes the Data to AWS IoT

import os
import socket
import ssl
import paho.mqtt.client as mqtt   # Import the Paho-MQTT Client
from time import sleep            # Import sleep from time for delays
import RPi.GPIO as GPIO           # Import GPIO Library for Raspberry Pi

connection_flag = False           # Initialize the Connection Flag as False    

GPIO.setmode(GPIO.BCM)            # Set Mode of RPi Pins i.e Broadcom or Chipset

# Define LED
led = 21                          # Put LED Numbers

# Set Pin as Output
GPIO.setup( led, GPIO.OUT )       # Pin 21
GPIO.output(led, GPIO.LOW )       # Initialize LED's

def on_connect(client, userdata, flags, rc): # on_connect()-Event handler
    global connection_flag        # global to check if the Connection to AWS Cloud has been Made.
    connection_flag = True
    print( ""Connection returned result: "" + str( rc ) )

def on_message(client, userdata, msg):       # on_message()-Event handler
    print( msg.topic + "" "" + str( msg.payload ) )

mqttc = mqtt.Client()             # Initiate Paho-MQTT Client
mqttc.on_connect = on_connect     # .set on_connect Event handler
mqttc.on_message = on_message     # .set on_message

# Define the AWS Host Key  ; Thing Name defined in AWS IoT; Root Certificate Path; Certificate Path; Private Key Certificate Path  
awshost   = ""xxxxxxxxxxxxxxxxxxxxxxxxxxx""
awsport   =  8883                 # AWS Port( Default: 8883 )
clientId  = ""raspberrypi""         # Client ID
thingName = ""raspberrypi""         # Thing Name defined in AWS IoT
caPath    = ""root-CA.crt""         # Root Certificate Path
certPath  = ""raspberrypi.cert.pem""     # Certificate Path
keyPath   = ""raspberrypi.private.key""  # Private Key Certificate Path

# Configure network encryption and authentication options
# Enable SSL/TLS support
mqttc.tls_set(caPath, certfile=certPath, keyfile=keyPath, cert_reqs=ssl.CERT_REQUIRED, tls_version=ssl.PROTOCOL_TLSv1_2, ciphers=None)

mqttc.connect(awshost, awsport, keepalive=60) # Connect to AWS Host
mqttc.loop_start()

while True:
    if connection_flag == True:
        GPIO.output( led21, GPIO.HIGH )

        # Update LED Data on AWS IoT in Real Time
        # State tells the current and previous state of LED
        # Reported gives the timestamp
        jsonMessage = ""{  \""state\"": { \""reported\"": { \""Led\"": "" + str(state) + ""} } }""
        mqttc.publish( ""$aws/things/raspberrypi/shadow/update"",
                        jsonMessage,
                        qos = 1
                        )
        mqttc.publish( ""LED: "",         # Publish the Data to AWS IOT and get it on Subscription
                        state,
                        qos = 1
                        )
        print( ""LED: "" + ""%d"" % state )
        sleep( 1.0 )

        GPIO.output( led21, GPIO.HIGH ) # Update LED Data on AWS IoT in Real Time
        jsonMessage = ""{ \""state\"": { \""reported\"": { \""Led\"": "" + str(state) + ""} } }""
        mqttc.publish( ""$aws/things/raspberrypi/shadow/update"",
                        jsonMessage,
                        qos = 1
                        )
        sleep( 1.0 )
        mqttc.publish( ""LED: "",        # Publish the Data to AWS IOT and get it on Subscription
                        state,
                        qos = 1
                        )
        print( ""LED: "" + ""%d"" % state )
   else:
        print( ""Waiting for Connection..."" )

ser.close()
GPIO.cleanup()
</code></pre>
","3308338","9368836","2018-09-23 08:54:00","raspberry pi led not defined error awsiot mqtt","<python><mqtt><led>","1","0","4005"
"49057201","2018-03-01 19:21:09","1","","<p>The error is caused by <a href=""https://github.com/pbucher/django-bootstrap-datepicker/issues/12"" rel=""nofollow noreferrer"">this issue</a> submitted to the widget's Github page, and has not yet been solved. So I switched to <a href=""https://github.com/monim67/django-bootstrap-datepicker-plus"" rel=""nofollow noreferrer"">django-bootstrap-datepicker-plus</a>, and it is working in my DJango version 2.0.2 just fine. But the question remains that needs to be answered.</p>

<blockquote>
  <p>What is a reversible object? Why we get this Error?</p>
</blockquote>

<p>The error is raised by the python built-in function <code>reversed</code>, that takes a sequence as only parameter and reverses the sequence.</p>

<blockquote>
  <p><a href=""https://www.programiz.com/python-programming/methods/built-in/reversed"" rel=""nofollow noreferrer""><strong>reversed() Parameters</strong></a><br>
  <strong>seq</strong> - sequence that should be reversed.  </p>
  
  <ul>
  <li>Could be an object that supports sequence protocol (<code>__len__()</code> and <code>__getitem__()</code> methods) as tuple, string, list or range  </li>
  <li>Could be an object that has implemented <code>__reversed__()</code></li>
  </ul>
</blockquote>

<p>So all sequences (eg. lists, tuples) are reversible. But to make an object reversible we need to implement a method named <code>__reversed__</code>, or both <code>__len__()</code> and <code>__getitem__()</code> methods. If we pass an object to <code>reversed()</code> function which does not fulfill any of the above criteria, it will raise an Exception <code>TypeError - object is not reversible</code>.</p>

<p>DJango 2.0 use this <code>reversed()</code> function to the assets added by any widget. As the <strong>JSFiles</strong> object used in the above widget does not implement reversible criteria, the error is raised.</p>
","9276329","","","0","1855","Munim Munna","2018-01-27 12:33:52","13359","1604","202","628","48997083","49057201","2018-02-26 21:05:41","-3","383","<p>I am trying to include <a href=""https://github.com/pbucher/django-bootstrap-datepicker/"" rel=""nofollow noreferrer"">this datepicket widget</a> in my DJango version 2.0.2, but it raises error</p>

<blockquote>
  <p><strong>Request Method:</strong>   GET<br>
  <strong>Request URL:</strong>  <a href=""http://127.0.0.1:8000/xuser/1/edit"" rel=""nofollow noreferrer"">http://127.0.0.1:8000/xuser/1/edit</a><br>
  <strong>Django Version:</strong>   2.0.2<br>
  <strong>Exception Type:</strong>   TypeError<br>
  <strong>Exception Value:</strong> 'JSFiles' object is not reversible<br>
  <strong>Exception Location:</strong>   D:\DevTools\Python\lib\site-packages\django\forms\widgets.py in merge, line 114<br>
  <strong>Python Executable:</strong>    D:\DevTools\Python\python.exe<br>
  <strong>Python Version:</strong>   3.6.3  </p>
</blockquote>

<p>I have already looked around for similar errors in following threads</p>

<ul>
<li><a href=""https://stackoverflow.com/q/43184081/9276329"">What does it mean by object not reversible Django
</a></li>
<li><a href=""https://stackoverflow.com/q/42952940/9276329"">TypeError at /admin/ 'set' object is not reversible
</a></li>
</ul>

<p>But these are just <strong>typo errors</strong> about <code>urlpatterns</code> and does not even disclose what reversible actually mean in python. The <a href=""https://www.google.com/search?q=python%20reversible%20object"" rel=""nofollow noreferrer"">google search</a> about reversible object does not yield anything more than the above threads. So, my question is,</p>

<ul>
<li>What does reversible object mean?</li>
<li>How can I solve this issue?</li>
</ul>

<blockquote>
  <p><strong>Traceback:</strong></p>
</blockquote>

<pre><code>Environment:


Request Method: GET
Request URL: http://127.0.0.1:8000/xuser/1/edit

Django Version: 2.0.2
Python Version: 3.6.3
Installed Applications:
['bootstrap3',
 'bootstrap_datepicker',
 'core.apps.CoreConfig',
 'django.contrib.admin',
 'django.contrib.auth',
 'django.contrib.contenttypes',
 'django.contrib.sessions',
 'django.contrib.messages',
 'django.contrib.staticfiles']
Installed Middleware:
['django.middleware.security.SecurityMiddleware',
 'django.contrib.sessions.middleware.SessionMiddleware',
 'django.middleware.common.CommonMiddleware',
 'django.middleware.csrf.CsrfViewMiddleware',
 'django.contrib.auth.middleware.AuthenticationMiddleware',
 'django.contrib.messages.middleware.MessageMiddleware',
 'django.middleware.clickjacking.XFrameOptionsMiddleware']


Template error:
In template D:\Python\dj_abstractbaseuser2\core\templates\core\edit.html, error at line 8
   'JSFiles' object is not reversible
   1 : {# Load the tag library #}
   2 : {% load bootstrap3 %}
   3 : 
   4 : {# Load CSS and JavaScript #}
   5 : {% bootstrap_css %}
   6 : {% bootstrap_javascript %}
   7 : {% block extrahead %}
   8 :  {{ form.media }} 
   9 : {% endblock %}
   10 : 
   11 : {# Display django.contrib.messages as Bootstrap alerts #}
   12 : {% bootstrap_messages %}
   13 : &lt;form method=""post""&gt;
   14 :     {% csrf_token %}
   15 :     {% bootstrap_field form.first_name %}
   16 :     {% bootstrap_field form.last_name %}
   17 :     {% bootstrap_field form.date_of_birth %}
   18 :     {% buttons %}


Traceback:

File ""D:\DevTools\Python\lib\site-packages\django\forms\forms.py"" in __getitem__
  157.             field = self.fields[name]

During handling of the above exception ('media'), another exception occurred:

File ""D:\DevTools\Python\lib\site-packages\django\template\base.py"" in _resolve_lookup
  835.                     current = current[bit]

File ""D:\DevTools\Python\lib\site-packages\django\forms\forms.py"" in __getitem__
  163.                     ', '.join(sorted(f for f in self.fields)),

During handling of the above exception (""Key 'media' not found in 'UserEditForm'. Choices are: date_of_birth, first_name, last_name.""), another exception occurred:

File ""D:\DevTools\Python\lib\site-packages\django\core\handlers\exception.py"" in inner
  35.             response = get_response(request)

File ""D:\DevTools\Python\lib\site-packages\django\core\handlers\base.py"" in _get_response
  158.                 response = self.process_exception_by_middleware(e, request)

File ""D:\DevTools\Python\lib\site-packages\django\core\handlers\base.py"" in _get_response
  156.                 response = response.render()

File ""D:\DevTools\Python\lib\site-packages\django\template\response.py"" in render
  106.             self.content = self.rendered_content

File ""D:\DevTools\Python\lib\site-packages\django\template\response.py"" in rendered_content
  83.         content = template.render(context, self._request)

File ""D:\DevTools\Python\lib\site-packages\django\template\backends\django.py"" in render
  61.             return self.template.render(context)

File ""D:\DevTools\Python\lib\site-packages\django\template\base.py"" in render
  175.                     return self._render(context)

File ""D:\DevTools\Python\lib\site-packages\django\template\base.py"" in _render
  167.         return self.nodelist.render(context)

File ""D:\DevTools\Python\lib\site-packages\django\template\base.py"" in render
  943.                 bit = node.render_annotated(context)

File ""D:\DevTools\Python\lib\site-packages\django\template\base.py"" in render_annotated
  910.             return self.render(context)

File ""D:\DevTools\Python\lib\site-packages\django\template\loader_tags.py"" in render
  58.                 result = self.nodelist.render(context)

File ""D:\DevTools\Python\lib\site-packages\django\template\base.py"" in render
  943.                 bit = node.render_annotated(context)

File ""D:\DevTools\Python\lib\site-packages\django\template\base.py"" in render_annotated
  910.             return self.render(context)

File ""D:\DevTools\Python\lib\site-packages\django\template\base.py"" in render
  993.             output = self.filter_expression.resolve(context)

File ""D:\DevTools\Python\lib\site-packages\django\template\base.py"" in resolve
  676.                 obj = self.var.resolve(context)

File ""D:\DevTools\Python\lib\site-packages\django\template\base.py"" in resolve
  802.             value = self._resolve_lookup(context)

File ""D:\DevTools\Python\lib\site-packages\django\template\base.py"" in _resolve_lookup
  843.                         current = getattr(current, bit)

File ""D:\DevTools\Python\lib\site-packages\django\forms\widgets.py"" in _media
  148.             base = sup_cls.media

File ""D:\DevTools\Python\lib\site-packages\django\forms\widgets.py"" in _media
  148.             base = sup_cls.media

File ""D:\DevTools\Python\lib\site-packages\django\forms\forms.py"" in media
  460.             media = media + field.widget.media

File ""D:\DevTools\Python\lib\site-packages\django\forms\widgets.py"" in _media
  148.             base = sup_cls.media

File ""D:\DevTools\Python\lib\site-packages\django\forms\widgets.py"" in _media
  163.                 return m + Media(definition)

File ""D:\DevTools\Python\lib\site-packages\django\forms\widgets.py"" in __add__
  135.         combined._js = self.merge(self._js, other._js)

File ""D:\DevTools\Python\lib\site-packages\django\forms\widgets.py"" in merge
  114.         for path in reversed(list_2):

Exception Type: TypeError at /xuser/1/edit
Exception Value: 'JSFiles' object is not reversible
</code></pre>
","9276329","9276329","2018-02-26 21:38:40","DJango TypeError - JSFiles object is not reversible","<python><django><object><typeerror><django-widget>","1","0","7333"
"49057203","2018-03-01 19:21:14","0","","<p>I'm afraid that this question might be ill-framed. I copied the HTML into a file then ran the following code:</p>

<pre><code>&gt;&gt;&gt; import bs4
&gt;&gt;&gt; soup = bs4.BeautifulSoup(open('matthew.htm').read(), 'lxml')
&gt;&gt;&gt; soup.find('p').text
'             \n                    Alts called now through 53. No more will be called til the 12:50 group. EMCs are still on the table to be seen.\n\nITR info:\n\nRachel Hoffman, CD\nChris Kory, acc.\n\nMonitor is Iftiaz Haroon.                '
</code></pre>

<p>Obviously it's a simple matter to recover the required text. </p>
","131187","","","0","591","Bill Bell","2009-06-30 16:25:06","16680","2009","764","2","49056625","","2018-03-01 18:45:14","0","56","<p>I'm writing a script using <code>BeautifulSoup</code> to extract text from <code>&lt;p&gt;</code> elements; it works well until I encounter a <code>&lt;p&gt;</code> element that contains <code>&lt;br&gt;</code> tags, in which case it only captures the text BEFORE the first <code>&lt;br&gt;</code> tag. How can I edit my code to capture all of the text?</p>

<p>My code:</p>

<pre><code>coms = soup.select('li &gt; div[class=comments]')[0].select('p')
inp = [i.find(text=True).lstrip().rstrip() for i in coms]
</code></pre>

<p>The problem HTML (note the <code>&lt;br&gt;</code> tags):</p>

<pre><code>&lt;p&gt;             
                    Alts called now through 53. No more will be called til the 12:50 group. EMCs are still on the table to be seen.&lt;br&gt;
&lt;br&gt;
ITR info:&lt;br&gt;
&lt;br&gt;
Rachel Hoffman, CD&lt;br&gt;
Chris Kory, acc.&lt;br&gt;
&lt;br&gt;
Monitor is Iftiaz Haroon.                &lt;/p&gt;
</code></pre>

<p>What my code currently outputs:</p>

<pre><code>&gt;&gt; 'Alts called now through 53. No more will be called til the 12:50 group. EMCs are still on the table to be seen.'
</code></pre>

<p>What my code SHOULD output (note the extra text):</p>

<pre><code>&gt;&gt; 'Alts called now through 53. No more will be called til the 12:50 group. EMCs are still on the table to be seen. ITR info: Rachel Hoffman, CD Chris Kory, acc. Monitor is Iftiaz Haroon.'
</code></pre>

<p>(<strong>Note</strong>: Forgive my sometimes-questionable terminology; I'm largely self-taught.)</p>
","5745722","7832176","2018-03-02 09:39:16","Extract Text from <p> element over <br> elements","<python><html><web-scraping><beautifulsoup>","2","2","1518"
"49057207","2018-03-01 19:21:27","3","","<p>You can achieve this with <a href=""https://pandas.pydata.org/"" rel=""nofollow noreferrer"">pandas</a>.</p>

<pre><code>import pandas as pd
matrix = [...] # your ndarray

matrix = pd.DataFrame(data=matrix, columns=[""summary"", ""age"", ""label""])
</code></pre>
","5406448","","","0","257","sarthak","2015-10-04 10:23:26","373","50","392","93","49057107","","2018-03-01 19:14:42","0","1073","<p>I have a numpy.ndarray having dimensions of 23411 x 3.
I would like to add headers to the top of the matrix called: ""summary"", ""age"", and ""label"". In that order. </p>

<p>In:</p>

<pre><code>matrix.shape
</code></pre>

<p>Out:</p>

<pre><code>(23411L, 3L)
</code></pre>

<p>In:</p>

<pre><code>type(matrix)
</code></pre>

<p>Out:</p>

<pre><code>numpy.ndarray
</code></pre>

<p>I tried using the numpy.recarray but it did not work. any suggestions??</p>
","8778033","8778033","2018-03-01 19:19:23","how to add headers to a numpy.ndarray","<python><numpy>","4","1","457"
"49057211","2018-03-01 19:22:02","1","","<p>See the <a href=""http://web2py.com/books/default/chapter/29/09/access-control#Authorization"" rel=""nofollow noreferrer"">Authorization</a> section of the Access Control chapter -- as noted there, you can use the <strong>appadmin</strong> interface (described <a href=""http://web2py.com/books/default/chapter/29/03/overview#An-image-blog"" rel=""nofollow noreferrer"">here</a>) or add groups and members programmatically.</p>

<p>To access appadmin, just go to <code>/yourapp/appadmin</code> (if you are not logged into the <code>/admin</code> app, you will be prompted to do so).</p>

<p>To add a new Auth group/role, add a new record to the <code>db.auth_group</code> table in appadmin. To add a new member to that group, add a new record to <code>db.auth_membership</code>, which links records from <code>db.auth_user</code> and <code>db.auth_group</code>.</p>

<p>You can also add groups and members programmatically, either via app code or a web2py shell (which can be started via <code>python web2py.py -S yourapp -M</code>, as described <a href=""http://web2py.com/books/default/chapter/29/04/the-core#Command-line-options"" rel=""nofollow noreferrer"">here</a>). Add groups with <code>auth.add_group</code> and members with <code>auth.add_membership</code> (as documented at the link above).</p>
","440323","","","1","1297","Anthony","2010-09-06 03:15:01","24538","1214","133","9","49055834","49057211","2018-03-01 17:53:26","0","128","<p>I'm going through <a href=""http://www.web2py.com/books/default/chapter/29/03/overview#Simple-examples"" rel=""nofollow noreferrer"">Web2py book documentation</a> because i'm new to it and i can't find any better tutorial anywhere (recommendations are welcomed). While going through the overview section, i got to an instruction that says </p>

<blockquote>
  <p>Using appadmin create a group ""manager"" and make some users members of the group.</p>
</blockquote>

<p>I've been trying to figure out how to do this for the past few hours and still no success. I can't find any interface in the app admin for creating groups. I tried <a href=""https://github.com/zvolsky/plugin_manage_groups"" rel=""nofollow noreferrer"">this plugin manager</a> for managing groups and i was still getting errors. All suggestions are welcomed</p>
","6214350","","","Web2py - how to create a group ""manager"" using appadmin","<python><python-3.x><python-2.7><web2py><web2py-modules>","1","0","823"
"49057220","2018-03-01 19:22:41","0","","<p>The A in the url must be capitalized:</p>

<pre><code>self.trading_api = 'https://poloniex.com/tradingApi'
</code></pre>

<p>While Poloniex's documentation does not make note of this (in fact the url used was copied directly from their page), remember to capitalize it! </p>
","1052828","","","0","278","Jason Woodcock","2011-11-17 22:39:04","5","34","0","0","48994519","49057220","2018-02-26 18:06:08","0","49","<p>I am writing a custom Python class to encapsulate the Poloniex trading API. However, I am running in to a problem with the request returning a ""404 Error"". I have been over and over the documentation and am quite sure that I am utilizing the right endpoint... What else could I be doing wrong here:</p>

<pre><code>...

self.trading_api = 'https://poloniex.com/tradingapi'
self.api_key = 'My API key'
self.secret_key = bytes('My Secret Key', 'latin-1')

...

req['nonce'] = int(time.time()*1000)
    data = urllib.parse.urlencode(req).encode()
    sign = hmac.new(self.secret_key, data, sha512)
    signature=sign.hexdigest()
    headers = dict(Key=self.api_key, Sign=signature)
    conn = urllib.request.Request(self.trading_api, headers=headers)
    self.rate_limit()
    try:
        requested = urllib.request.urlopen(conn, data=data)

return requested
</code></pre>
","1052828","","","Poloniex API Request Gives 404 Error","<python><python-3.x><poloniex>","1","4","874"
"49057259","2018-03-01 19:25:44","1","","<p>I need to create <code>wagtail_hooks.py</code> file, and ,as said in the <a href=""http://docs.wagtail.io/en/v2.0/reference/hooks.html#id18"" rel=""nofollow noreferrer"">docs</a>, define hooks there: </p>

<p><strong>models.py</strong>:</p>

<pre><code>from wagtail.images.models import Image
...

class ExtenedWagtailImage(Image):
    filepath = models.FilePathField()


class PhotoEventPageGalleryImage(Orderable):
    page = ParentalKey(PhotoEventPage, related_name='gallery_images')
    image = models.ForeignKey(
        ExtenedWagtailImage, on_delete=models.CASCADE, related_name='+'
    )
    caption = models.CharField(blank=True, max_length=250)

    panels = [
        ImageChooserPanel('image'),
        FieldPanel('caption')
    ]
</code></pre>

<p><strong>wagtail_hooks.py</strong>:</p>

<pre><code>import os
import zipfile

from django.core.files.images import ImageFile
from django.db import IntegrityError

from wagtail.core import hooks

from .models import PhotoEventPageGalleryImage, ExtenedWagtailImage as EWI


@hooks.register('after_edit_page')
@hooks.register('after_create_page')
def create_gallery(request, page):
    if page.__class__.__name__ == 'PhotoEventPage':
        with zipfile.ZipFile(page.photos.path, ""r"") as zip_ref:
            for file_name in zip_ref.namelist():

                image_file_path = os.path.join(
                    os.path.dirname(page.photos.path), file_name)

                if not os.path.isfile(image_file_path):
                    zip_ref.extract(
                        file_name,
                        path=os.path.dirname(page.photos.path))

                with open(image_file_path, ""rb"") as image_file:
                    try:
                        image_obj, created = EWI.objects.get_or_create(
                            filepath=image_file_path,
                            defaults={
                                'file': ImageFile(image_file, name=file_name),
                                'title': file_name}
                        )
                    # if it's not an image
                    except IntegrityError:
                        continue

                photo_event_amount = len(
                    PhotoEventPageGalleryImage.objects.filter(
                        page_id=page.id, image_id=image_obj.id))

                if created or photo_event_amount == 0:
                    PhotoEventPageGalleryImage(
                        image_id=image_obj.id, page_id=page.id).save()
</code></pre>
","3572950","3572950","2018-03-02 21:08:01","0","2502","Alexey","2014-04-25 12:40:10","648","96","344","11","48976797","49057259","2018-02-25 18:13:19","1","276","<p>I have a project and i have idea to make <code>wagtail</code> <code>Page</code> where user can upload an <code>zip</code> archive of images in the admin section. And then I want to unzip this archive and put each unzipped image to Image Gallery connected to this page:</p>

<pre><code>import urllib.parse
import os
import zipfile

from django.db import models
from django.conf import settings

from wagtail.wagtailcore.models import Page, Orderable
from wagtail.wagtailcore.fields import RichTextField
from wagtail.wagtailadmin.edit_handlers import FieldPanel, InlinePanel
from wagtail.wagtailsearch import index
from wagtail.wagtailimages.edit_handlers import ImageChooserPanel
from wagtail.wagtailimages.models import Image
from taggit.models import TaggedItemBase

from modelcluster.fields import ParentalKey
from modelcluster.contrib.taggit import ClusterTaggableManager

from .forms import PhotoEventPageForm
from utils import get_paginated_pages, get_all_tags

...

class PhotoEventPage(Page):
    photos = models.FileField(upload_to=directory_path)
    photos_unpacked = models.BooleanField(default=False)    
    ...

    base_form_class = PhotoEventPageForm

    def main_image(self):
        gallery_item = self.gallery_images.first()
        if gallery_item:
            return gallery_item.image
        else:
            return None

    def save(self, *args, **kwargs):
        if os.path.isfile(self.photos.path) and not self.photos_unpacked:
            with zipfile.ZipFile(self.photos.path, ""r"") as zip_ref:
                for file_name in zip_ref.namelist():
                    zip_ref.extract(
                        file_name,
                        path=os.path.dirname(self.photos.path))
                    # now i have image file, this line prints True:
                    # print(os.path.isfile(os.path.join(os.path.dirname(self.photos.path), file_name)))
                    # so now I have saved image and i want to create Image gallery,
                    # I've tried this code:

                    # img = Image()
                    # img.save()
                    # gallery_img = PhotoEventPageGalleryImage(
                    #     image_id=img.id, page_id=self.id)
                    # gallery_img.save()

                    # but it's not working
            self.photos_unpacked = True
        return super().save(*args, **kwargs)

class PhotoEventPageGalleryImage(Orderable):
    page = ParentalKey(PhotoEventPage, related_name='gallery_images')
    image = models.ForeignKey(
        'wagtailimages.Image', on_delete=models.CASCADE, related_name='+'
    )
    caption = models.CharField(blank=True, max_length=250)

    panels = [
        ImageChooserPanel('image'),
        FieldPanel('caption'),
    ]
</code></pre>

<p>But It's not working, I dont know how to create <code>wagtail.wagtailimages.models.Image</code> instance from my unzipped image, when  i uncoment this piece of code:</p>

<pre><code>img = Image()
img.save()
gallery_img = PhotoEventPageGalleryImage(
                image_id=img.id, page_id=self.id)
gallery_img.save()
</code></pre>

<p>i'm getting <code>NOT NULL constraint failed: wagtailimages_image.width</code>. So maybe there is a way to do it?</p>

<p>After some googling, thanks to Paulo Scardine, also checked:
<a href=""https://groups.google.com/forum/#!topic/wagtail/Get0wrrJ-3c"" rel=""nofollow noreferrer"">this</a>
I came up with following code:</p>

<pre><code>from django.core.files.images import ImageFile

from wagtail.wagtailcore.models import Page, Orderable
from wagtail.wagtailcore.fields import RichTextField
from wagtail.wagtailadmin.edit_handlers import FieldPanel, InlinePanel
from wagtail.wagtailsearch import index
from wagtail.wagtailimages.edit_handlers import ImageChooserPanel
from wagtail.wagtailimages.models import Image
from taggit.models import TaggedItemBase

...

class PhotoEventPage(Page):
    ...

    def save(self, *args, **kwargs):
        if os.path.isfile(self.photos.path) and not self.photos_unpacked:
            with zipfile.ZipFile(self.photos.path, ""r"") as zip_ref:
                for file_name in zip_ref.namelist():
                    zip_ref.extract(
                        file_name,
                        path=os.path.dirname(self.photos.path))
                    # print(os.path.isfile(os.path.join(os.path.dirname(self.photos.path), file_name)))

                    image_file = open(
                        os.path.join(
                            os.path.dirname(
                                self.photos.path), file_name), ""rb"")

                    image = Image(
                        title=""Image title"",
                        file=ImageFile(image_file, name=file_name),
                    )

                    image.save()
                    image_file.close()

                    gallery_img = PhotoEventPageGalleryImage(
                        image_id=image.id, page_id=self.id)
                    gallery_img.save()

            self.photos_unpacked = True
        return super().save(*args, **kwargs)
</code></pre>

<p>And it's strange, i mean it's indeed working without errors and I can save <code>PhotoEventPage</code> without errors and images are extracted, but there is no any items inside <code>self.gallery_images</code> after saving, don`t know why.</p>
","3572950","3572950","2018-03-01 08:07:11","How to make image gallery from zip archive in wagtail?","<python><python-3.x><wagtail>","1","1","5328"
"49057299","2018-03-01 19:28:25","0","","<p>So if I've understood this correctly, your function does the following: </p>

<ol>
<li>Take two values at random from <code>nextList</code></li>
<li>Check whether they match a pair from <code>roundTwo</code></li>
<li>Result of check:

<ul>
<li>If they <em>don't</em> match, remove them from <code>nextList</code></li>
<li>If they <em>do</em> match, choose another two</li>
</ul></li>
</ol>

<p>But do you really mean just choose another two? Or do you mean go back to step 1. and repeat until you get two that don't match? Or do you not choose another two at all? </p>

<hr>

<p>Your error comes from looping over <code>nextList</code> to get your <code>i</code> values (eg 'JO90', 'MA78') and then trying to look these up as indexes in your <code>roundTwo</code> list. If you want to loop over all the little sets of 4 in <code>roundTwo</code> to check against , that bit of your script should look like: </p>

<pre><code>for item in roundTwo:  # eg item = ['JO90', '1', 'MA78', '8']
    if one == item[0] and two == item[2]:
        # choose new one and two
</code></pre>

<p>If they do match a pair from <code>roundTwo</code>, your function currently seems to try to choose alternatives somehow from the <code>roundTwo</code> list, but I think this is a typo and should be <code>nextList</code>, but without knowing more details of what your function is doing I can't say.</p>

<hr>

<p>If I can guess that you'r algorithm is supposed to do the following:</p>

<ol>
<li>Take two values at random from <code>nextList</code></li>
<li>Check whether they match a pair from <code>roundTwo</code></li>
<li>Result of check:

<ul>
<li>If they <em>don't</em> match, remove them from <code>nextList</code></li>
<li>If they <em>do</em> match, start again to step 1.</li>
</ul></li>
</ol>

<p>Then this code should work:</p>

<pre><code>import random

nextList = ['JO90', 'MA78', 'FE29', 'HT27', 'EQ37', 'BF50', 'LJ93', 'UT21', 'KJ40', 'WE82', 'WQ28', 'BV98', 'FE32', 'EF10', 'SA14', 'SP16']
roundTwo = [['JO90', '1', 'MA78', '8'], ['B208', '2', 'DF18', '3'], ['PD06', '5', 'BS07', '7'], ['SA14', '4', 'SP16', '7']]

while True:
    # choose one and two at random
    one = nextList[random.randint(0, len(nextList) - 1)]
    two = nextList[random.randint(0, len(nextList) - 1)]
    # loop over every set in roundTwo
    for i in roundTwo:
        # check whether one and two match
        if one == i[0] and two == i[2]:
            print ""Bad pair: {0}, {1}"".format(one, two)
            # break out of for loop
            # will hit end of while loop and start again
            break
    # got to end of for loop without breaking, so *didn't* match pair in roundTwo
    else:
        print ""Good pair: {0}, {1}"".format(one, two)
        nextList.remove(one)
        nextList.remove(two)
        # we found a good pair, so can break out of the while loop
        break
</code></pre>

<p>This will currently produce an error if <code>one</code> and <code>two</code> come out as the same. If you want them to be different, you could add a check immediately after you choose them:</p>

<pre><code>if one == two:
    print ""They're the same""
    continue
</code></pre>

<p>The <code>continue</code> will jump back to the start of the <code>while</code> loop.</p>

<p>Or if you are allowed to have the same, you need to add a check whether they're in <code>nextList</code> before you remove them (like you had in your original script) but you should only need to check for <code>two</code> - at least <code>one</code> should always be in the list: </p>

<pre><code>nextList.remove(one)
if two in nextList:
    nextList.remove(two)
</code></pre>

<hr>

<p>This uses the <code>for</code>-<code>else</code> construction: if you finish the <code>for</code> loop and haven't broken out of it sooner, then Python executes the <code>else</code> branch. This <code>else</code> branch contains a <code>break</code> statement to get out of the <code>while True</code> loop, which would otherwise go round forever. I suggest you read the Python tutorial on this if you haven't come across <code>while True</code> loops before, or <code>else</code> branches on <code>for</code> loops, or <code>break</code> statements: <a href=""https://docs.python.org/2/tutorial/controlflow.html"" rel=""nofollow noreferrer"">https://docs.python.org/2/tutorial/controlflow.html</a></p>
","9219425","","","0","4347","Tim","2018-01-15 12:37:25","734","61","102","0","49051468","","2018-03-01 14:08:46","0","55","<p>I was trying to make a function so that random values from the 'next' list are assigned to 'One' and 'Two'.  If the value that is assigned to 'One' and 'Two' coincide with the position of the values [i][0] and [i][2] in 'roundTwo' then 'One' and 'Two' are assigned new values.</p>

<p>After this the values 'one' and 'two' are then removed from the 'next' list.</p>

<p>As an example, if 'one' was to be assigned 'J090' and 'two' was to be assigned 'MA78', then they would both be assigned new values, as in 'roundTwo' there is: </p>

<blockquote>
  <p>['JO90', '1', 'MA78', '8']</p>
</blockquote>

<p>However, if 'one' was assigned 'J090' and 'two' was assigned 'B208' it would be correct and the program would then continue to remove 'J090' and 'B208' from the 'next' list.</p>

<p>Below is an example of my code, apologies if what I have written doesn't make 
too much sense here, so just ask if you think it needs editing!</p>

<pre><code>nextList = ['JO90', 'MA78', 'FE29', 'HT27', 'EQ37', 'BF50', 'LJ93', 'UT21', 'KJ40', 'WE82', 'WQ28', 'BV98', 'FE32', 'EF10', 'SA14', 'SP16']
roundTwo = [['JO90', '1', 'MA78', '8'], ['B208', '2', 'DF18', '3'], ['PD06', '5', 'BS07', '7'], ['SA14', '4', 'SP16', '7']]
one = nextList[random.randint(0, len(nextList) - 1)]
two = nextList[random.randint(0, len(nextList) - 1)]
for i in nextList:
    if one in roundTwo[i][0] and two in roundTwo[i][2]:  
        one = roundTwo[random.randint(0, len(roundTwo) - 1)]
        two = roundTwo[random.randint(0, len(roundTwo) - 1)]
if one in nextList:
    nextList.remove(one)
if two in nextList:
    nextList.remove(two)
</code></pre>

<p>I am getting this error when running through and I am not quite sure how to make it work correctly:</p>

<blockquote>
  <p>if one in roundTwo[i][0] and two in roundTwo[i][2]:</p>
  
  <p>TypeError: list indices must be integers or slices, not str</p>
</blockquote>

<p>Thanks!</p>
","8907524","8907524","2018-03-01 14:15:07","Finding matching String in two Lists of Lists","<python><string><list><random>","1","2","1904"
"49057303","2018-03-01 19:28:42","0","","<p>You coule use the ‘pandas.DataFrame.query()‘ method :  </p>

<pre><code>df.query(""col1 == value1 and col2==value2"").sort_index()[""target_column""].iloc[0]
</code></pre>
","7786148","","","0","171","gcharbon","2017-03-29 13:33:05","580","36","37","5","49056949","49057020","2018-03-01 19:04:20","0","200","<p>I've got a df: </p>

<pre><code>import pandas as pd
import numpy as np

df = pd.DataFrame({""price"":[1.1,66.3,11,15.2,1.1], 
                   ""qty"":[14,2,1,10,1],
                   ""c_h"":['cheese','ham','ham','cheese','ham'],
                   ""qual"":['good','good','bad','good','bad']})
</code></pre>

<p>The df looks like this when printed:  </p>

<pre><code>      c_h   price  qty  qual
0  cheese     1.1   14  good
1     ham    66.3    2  good
2     ham    11.0    1   bad
3  cheese    15.2   10  good
4     ham     1.1    1   bad
</code></pre>

<p>I'm trying to return a <code>price</code> of <code>'c_h'=='ham' and 'qual=='bad'</code> on the minimum index value from a the df.  The minimum index is the lowest numerical value for index currently <code>[0,1,2,...]</code>in which that criteria is met </p>

<p>In this example, the minimum index sought would be 2 and the returned price would be 11.0.  </p>

<p>Note: I'm working mostly with <code>pandas</code> but I could also use <code>numpy</code>.  </p>

<p>I thought it'd be something like </p>

<pre><code>df[df['c_h']=='ham' and 'qual'=='bad'].min()[index]
</code></pre>

<p>but that's not working.  </p>
","5965312","5965312","2018-03-01 19:08:42","Python Pandas extract value from dataframe based on minimum index","<python><pandas><dataframe><indexing>","2","2","1173"
"49057306","2018-03-01 19:28:55","0","","<p>Creating a new series explicitly is a bit shorter:</p>

<pre><code>df['new column'] = pd.Series(df.index, index=df.index).map(d)
</code></pre>
","837534","","","0","146","Mike Müller","2011-07-10 10:47:45","59443","2890","1608","51","49057154","49057306","2018-03-01 19:18:15","0","1252","<p>I want to create a new column on a pandas dataframe using values on the index and a dictionary that translates these values into something more meaningful. My initial idea was to use map. I arrived to a solution but it is very convoluted and there must be a more elegant way to do it. Suggestions?</p>

<pre><code>#dataframe and dict definition
df=pd.DataFrame({'foo':[1,2,3],'boo':[3,4,5]},index=['a','b','c'])
d={'a':'aa','b':'bb','c':'cc'}

df['new column']=df.reset_index().set_index('index',drop=False)['index'].map(d)
</code></pre>
","4513726","","","how to use map in index of pandas dataframe","<python><pandas><dataframe>","2","2","541"
"49057333","2018-03-01 19:30:34","0","","<p>After <code>to_series</code>, you can using <code>map</code> or <code>replace</code></p>

<pre><code>df.index=df.index.to_series().map(d)
df
Out[806]: 
    boo  foo
aa    3    1
bb    4    2
cc    5    3
</code></pre>

<p>Or we think about another way </p>

<pre><code>df['New']=pd.Series(d).get(df.index)
df
Out[818]: 
   boo  foo New
a    3    1  aa
b    4    2  bb
c    5    3  cc
</code></pre>
","7964527","7964527","2018-03-01 19:39:48","0","401","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49057154","49057306","2018-03-01 19:18:15","0","1252","<p>I want to create a new column on a pandas dataframe using values on the index and a dictionary that translates these values into something more meaningful. My initial idea was to use map. I arrived to a solution but it is very convoluted and there must be a more elegant way to do it. Suggestions?</p>

<pre><code>#dataframe and dict definition
df=pd.DataFrame({'foo':[1,2,3],'boo':[3,4,5]},index=['a','b','c'])
d={'a':'aa','b':'bb','c':'cc'}

df['new column']=df.reset_index().set_index('index',drop=False)['index'].map(d)
</code></pre>
","4513726","","","how to use map in index of pandas dataframe","<python><pandas><dataframe>","2","2","541"
"49057355","2018-03-01 19:32:15","0","","<p>If you need to store the lists in an array named <code>each_food</code>, you can use a for loop to split the string into a list of individual characters and then append each list of characters to <code>each_food</code>:</p>

<pre><code>food = ['eel', 'egg', 'yam', 'nut', 'oats']    
each_food = []

for item in food:
    each_food.append(list(item))
</code></pre>

<p>This way you can access each list of characters with the corresponding string index (starting from 0). For example:</p>

<pre><code>each_food[0]
</code></pre>

<p>Would produce the first list as output:</p>

<pre><code>['e', 'e', 'l']
</code></pre>
","9289749","","","0","621","Estefania Cass. N.","2018-01-30 15:04:43","1","1","0","0","49056972","49057114","2018-03-01 19:05:15","1","105","<p>For a list of words, how can I access each alphabet of the word. For example</p>

<pre><code>food = ['eel', 'egg', 'yam', 'nut', 'oats']
</code></pre>

<p>I need to retrieve each food by its individual letters and make it into a list, i.e. </p>

<pre><code>each_food[1] = ['e', 'e', 'l']
each_food[2] = ['e', 'g', 'g']
</code></pre>

<p>Any help is appreciated. </p>
","9293468","","","Accessing sub-element of a list","<python>","2","1","370"
"49057413","2018-03-01 19:36:14","1","","<p>The solution was a simple <code>for</code> loop. I looped over the forms keys using the <code>.key()</code> method that form has and was able to extract the value with the <code>.getvalue()</code> method. That method takes a single argument of <code>key</code>. Worked like a charm!</p>

<pre><code>if self.path=='/getOne':
        form = cgi.FieldStorage(
            fp=self.rfile, 
            headers=self.headers,
            environ={'REQUEST_METHOD':'POST',
            'CONTENT_TYPE':self.headers['Content-Type'],
        })

        for key in form.keys():
            value = str(form.getvalue(key))
            t = ('%' + value + '%')

        c.execute('select * from appointments where description like ?' , (t,))
        res = c.fetchall()
        _json = json.dumps(res)
        self.send_response(200)
        self.send_header(""Content-type"", ""application/json"")
        self.end_headers()
        self.wfile.write(_json)
        print ""I'm ya huckleberry"", res
    return
</code></pre>
","7693351","","","0","1006","str8up7od","2017-03-11 03:48:16","102","42","77","0","48842144","49057413","2018-02-17 14:03:54","0","405","<p>My code looks like <a href=""https://i.stack.imgur.com/FzmlC.png"" rel=""nofollow noreferrer"">this</a>. I just need to be able to access that object. I come from a javascript background and am used to being able to capture the response object and access the response body and all is well. I am not quite understanding how I am to access that though.  I have tried <code>form[""key_name""].value</code> etc but still get back nothing. Can someone please help me access my data from <code>FieldStorage(None, None, '{""phrase"":""work mudasucka!""}')</code>? I would greatly appreciate it!</p>

<pre><code> def do_POST(self):
        if self.path==""/send"":
            form = cgi.FieldStorage(
                fp=self.rfile, 
                headers=self.headers,
                environ={'REQUEST_METHOD':'POST',
                'CONTENT_TYPE':self.headers['Content-Type'],
                })

            print (form)
            self.send_response(200)
            self.end_headers()
        return

 #This is what prints in my console.
 #FieldStorage(None, None, '{""phrase"":""work mudasucka!""}')
</code></pre>
","7693351","","","python access FieldStorage data","<python><rest><cgi>","1","0","1104"
"49057415","2018-03-01 19:36:20","1","","<p>Create your own class with members including the numpy array and the headings as strings.</p>
","5924453","","","0","97","ColonelFazackerley","2016-02-14 06:50:46","620","45","43","5","49057107","","2018-03-01 19:14:42","0","1073","<p>I have a numpy.ndarray having dimensions of 23411 x 3.
I would like to add headers to the top of the matrix called: ""summary"", ""age"", and ""label"". In that order. </p>

<p>In:</p>

<pre><code>matrix.shape
</code></pre>

<p>Out:</p>

<pre><code>(23411L, 3L)
</code></pre>

<p>In:</p>

<pre><code>type(matrix)
</code></pre>

<p>Out:</p>

<pre><code>numpy.ndarray
</code></pre>

<p>I tried using the numpy.recarray but it did not work. any suggestions??</p>
","8778033","8778033","2018-03-01 19:19:23","how to add headers to a numpy.ndarray","<python><numpy>","4","1","457"
"49057432","2018-03-01 19:37:19","4","","<p>You are calling <code>is_valid</code> on the <code>User</code> object, but that's not a method you've defined on the User (or that exists already on AbstractUser).  If you take a closer look at your tutorial, they're actually calling it on the <code>UserForm</code>.  Forms have a built-in <code>is_valid</code> method used to make sure all the form data submitted is valid (what valid means can differ based on your use case... maybe you're making sure everything's filled in, or that something's a real email address, or that a date is more than six months in the future). </p>

<p>Your code says:</p>

<p><code>form1=User(request.POST or None)
    if form1.is_valid():
        form1.save()</code></p>

<p>It looks like you <em>meant</em> to define <code>form1</code> as a form object (otherwise that's maybe the worst variable name ever).  You probably have something called <code>UserForm</code> (or similar) in your <code>forms.py</code>.  You'll want to import that, and instantiate it like:</p>

<p><code>form1 = UserForm(request.POST, instance=request.user)</code></p>

<p><a href=""https://docs.djangoproject.com/en/2.0/ref/forms/validation/"" rel=""nofollow noreferrer"">https://docs.djangoproject.com/en/2.0/ref/forms/validation/</a> </p>

<p>(side note:  When you come back to your code in a year, will you remember what <code>form1</code> was supposed to mean?  Try to name your variable something that explains itself--<code>user_form</code> or something similar)</p>
","1695507","1695507","2018-03-01 19:43:43","0","1481","thumbtackthief","2012-09-24 20:13:54","2902","859","1097","80","49057171","49057432","2018-03-01 19:19:25","2","1108","<p>I am making a registration form for users to signup using Django 1.8 and python 3.5</p>

<p>I have created a User(Extending User Model Using a Custom Model Extending AbstractUser)(ie I wanted to add custom fields to the default django's Users table like bio, date of birth etc)</p>

<p>This  is my <code>mainpage/models.py</code></p>

<pre><code>from django.db import models
from django.contrib.auth.models import AbstractUser

class User(AbstractUser):
    bio = models.TextField(max_length=500, blank=True)
    location = models.CharField(max_length=30, blank=True)
    birth_date = models.DateField(null=True, blank=True)
</code></pre>

<p>this is <code>signup/view.py</code></p>

<pre><code>from django.shortcuts import render
from mainpage.models import User
def signup(request):
    form1=User(request.POST or None)
    if form1.is_valid():
        form1.save()
    context = {
    ""form1"": form1,
 }
return render(request, ""signup.html"",context)
</code></pre>

<p><strong>Traceback</strong></p>

<pre><code>Environment:


Request Method: GET
Request URL: http://localhost:8000/signup/

Django Version: 1.8
Python Version: 3.5.4
Installed Applications:
('django.contrib.admin',
 'django.contrib.auth',
 'django.contrib.contenttypes',
 'django.contrib.sessions',
 'django.contrib.messages',
 'django.contrib.staticfiles',
 'mainpage',
 'signup',
 'login',
 'currency',
 'rest_framework',
 'corsheaders')
Installed Middleware:
('django.contrib.sessions.middleware.SessionMiddleware',
 'corsheaders.middleware.CorsMiddleware',
 'django.middleware.common.CommonMiddleware',
 'django.middleware.csrf.CsrfViewMiddleware',
 'django.contrib.auth.middleware.AuthenticationMiddleware',
 'django.contrib.auth.middleware.SessionAuthenticationMiddleware',
 'django.contrib.messages.middleware.MessageMiddleware',
 'django.middleware.clickjacking.XFrameOptionsMiddleware',
 'django.middleware.security.SecurityMiddleware')


Traceback:
File ""C:\Users\vaibhav2\AppData\Local\Programs\Python\Python35\lib\site-packages\django\core\handlers\base.py"" in get_response
  132.                     response = wrapped_callback(request, *callback_args, **callback_kwargs)
File ""C:\Users\vaibhav2\PycharmProjects\MajorProject\src\signup\views.py"" in signup
  12.     if form1.is_valid():

Exception Type: AttributeError at /signup/
Exception Value: 'User' object has no attribute 'is_valid'
</code></pre>

<p><strong>SOME ADDITIONAL INFO</strong>
I am refering to this blog for creating AbstractUser  <a href=""https://simpleisbetterthancomplex.com/tutorial/2016/07/22/how-to-extend-django-user-model.html#abstractuser"" rel=""nofollow noreferrer"">https://simpleisbetterthancomplex.com/tutorial/2016/07/22/how-to-extend-django-user-model.html#abstractuser</a></p>
","9364941","1695507","2018-03-01 19:53:06","'User' object has no attribute 'is_valid' Django","<python><django>","1","7","2745"
"49057462","2018-03-01 19:39:32","0","","<p><code>for index, row in df.iterrows():
    small_df = df[index - 5:index]
    df['uniques'][index] = len(small_df.unique())</code></p>

<p>Here's my quick shot at it.  </p>
","8766025","","","0","176","ChootsMagoots","2017-10-12 14:46:59","523","126","84","33","49057325","","2018-03-01 19:29:55","1","571","<p>I want to calculate the number of distinct port numbers that exist between the current row and the 5 previous rows (sliding window) <strong>and this when the same address appears.</strong> 
For instance,</p>

<p>If the input is (csv file):
 </p>

<pre><code>ID      PORT     ADDRESS
1        21       ad3 
2        22       ad1  
3        23       ad2
4        25       ad2 
5        25       ad1
6        22       ad1 
7        22       ad1
8        21       ad4
</code></pre>

<p>The output should be:</p>



<pre><code>ID      PORT     ADDRESS      COUNT_DISC_PORT
1        21       ad3        -
2        22       ad1        -
3        23       ad2        - 
4        25       ad2        - 
5        25       ad1        - 
6        22       ad1        2 
7        23       ad1        3
8        21       ad4        1 
</code></pre>

<p>I have read the documentation about the rolling function in pandas and I have tried combining group by and rolling with no success.</p>

<p>I am using Python 3.7 and the pandas package 0.22.
Any feedback would be appreciated.</p>
","6939295","6939295","2018-03-01 21:18:29","Count distinct strings in rolling window using pandas + python (with a condition)","<python><pandas>","2","6","1072"
"49057486","2018-03-01 19:41:11","1","","<p><strong>Time Delay in Above Solution</strong></p>

<p>@MaxU's solution adding <code>isolation_level=None</code> to the database connection is short and sweet. For whichever reason, however, it slowed writing/committing each chunk to the database dramatically. For example, when I tested the solution on a table of 12 million rows, the code took over 6 hours to complete. Conversely, building the original table from several text files took a few minutes.</p>

<blockquote>
  <p>This insight led to a faster but less elegant solution, which <em>took less than 7 minutes</em> to complete on a table of 12 million rows versus over 6 hours. The output rows matched the input rows, solving the problem in my original question. </p>
</blockquote>

<p><strong>Faster but less Elegant Solution</strong></p>

<p>Since constructing the original table from text files/csv files and using SQL scripts to load the data, I combined that approach with Panda's chunk capabilities. The essential basic steps are as follows:</p>

<ol>
<li>Connect to the db</li>
<li>Use a SQL script to create a new table (columns and order should match whatever you do to the pandas df)</li>
<li>Read the massive table in chunks</li>
<li>For each chunk, modify the df as desired, write to csv, load csv using sql, and commit the change. </li>
</ol>

<p><strong>Main code of solution:</strong></p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
import sqlite3

#Note I Used Functions I Wrote in build_db.py
#(shown below after example solution)
from build_db import *


#Helper Functions Used in Example
def lower_var(var, df):
    s = df[var].str.lower()
    df = df.drop(var, axis=1)
    df = pd.concat([df, s], axis=1)
    return(df)


#Connect to Data
db = sqlite3.connect(""test.db"")
c = db.cursor()

#create statement
create_table(c, ""create_test.sql"", path='sql_clean/')

#Load Data in Chunks
df_generator = pd.read_sql_query(""select * from example_table;"", con=db, chunksize = 100000)

for df in df_generator:
    #functions to modify data, example
    df = lower_var(""name"", df) #changes column order

    #restore df to column order in sql table
    db_order = [""cmte_id"", ""amndt_ind"", ""rpt_tp"", ""transaction_pgi"", ""image_num"", ""transaction_tp"", \
        ""entity_tp"", ""name"", ""city"", ""state"", ""zip_code"", ""employer"", ""occupation"", ""transaction_dt"", \
        ""transaction_amt"", ""other_id"", ""tran_id"", ""file_num"", ""memo_cd"", ""memo_text"", ""sub_id""]
    df = df[db_order]

    #write chunk to csv
    file = ""df_chunk.csv""
    df.to_csv(file, sep='|', header=None, index=False)

    #insert chunk csv to db
    insert_file_into_table(c, ""insert_test.sql"", file, '|', path='sql_clean/')
    db.commit()


#Count results
count_result(c, ""test_indiv"")
</code></pre>

<p><strong>Imported User Functions for Above Code</strong></p>

<pre class=""lang-py prettyprint-override""><code>#Relavant Functions in build_db.py

def count_result(c, table):
    ([print(""[*] total: {:,} rows in {} table""
        .format(r[0], table)) 
        for r in c.execute(""SELECT COUNT(*) FROM {};"".format(table))])

def create_table(cursor, sql_script, path='sql/'):
    print(""[*] create table with {}{}"".format(path, sql_script))
    qry = open(""{}{}"".format(path, sql_script), 'rU').read()
    cursor.executescript(qry)


def insert_file_into_table(cursor, sql_script, file, sep=',', path='sql/'):
    print(""[*] inserting {} into table with {}{}"".format(file, path, sql_script))
    qry = open(""{}{}"".format(path, sql_script), 'rU').read()
    fileObj = open(file, 'rU', encoding='latin-1')
    csvReader = csv.reader(fileObj, delimiter=sep, quotechar='""')

    try:
        for row in csvReader:
            try:
                cursor.execute(qry, row)
            except sqlite3.IntegrityError as e:
                pass

    except Exception as e:
        print(""[*] error while processing file: {}, error code: {}"".format(file, e))
        print(""[*] sed replacing null bytes in file: {}"".format(file))
        sed_replace_null(file, ""clean_null.sh"")
        subprocess.call(""bash clean_null.sh"", shell=True)

        try:
            print(""[*] inserting {} into table with {}{}"".format(file, path, sql_script))
            fileObj = open(file, 'rU', encoding='latin-1')
            csvReader = csv.reader(fileObj, delimiter=sep, quotechar='""')
            for row in csvReader:
                try:
                    cursor.execute(qry, row)
                except sqlite3.IntegrityError as e:
                    pass
                    print(e)    

        except Exception as e:
            print(""[*] error while processing file: {}, error code: {}"".format(file, e))
</code></pre>

<p><strong>SQL User Scripts</strong></p>

<pre class=""lang-sql prettyprint-override""><code>--create_test.sql

DROP TABLE if exists test_indiv;

CREATE TABLE test_indiv (
    cmte_id TEXT NOT NULL,
    amndt_ind TEXT,
    rpt_tp TEXT,
    transaction_pgi TEXT,
    image_num TEXT,
    transaction_tp TEXT,
    entity_tp TEXT,
    name TEXT,
    city TEXT,
    state TEXT,
    zip_code TEXT,
    employer TEXT,
    occupation TEXT,
    transaction_dt TEXT,
    transaction_amt TEXT,
    other_id TEXT,
    tran_id TEXT,
    file_num NUMERIC,
    memo_cd TEXT,
    memo_text TEXT,
    sub_id NUMERIC NOT NULL
);

CREATE UNIQUE INDEX idx_test_indiv ON test_indiv (sub_id);
</code></pre>

<pre class=""lang-sql prettyprint-override""><code>--insert_test.sql

INSERT INTO test_indiv (
    cmte_id,
    amndt_ind,
    rpt_tp,
    transaction_pgi,
    image_num,
    transaction_tp,
    entity_tp,
    name,
    city,
    state,
    zip_code,
    employer,
    occupation,
    transaction_dt,
    transaction_amt,
    other_id,
    tran_id,
    file_num,
    memo_cd,
    memo_text,
    sub_id
    ) 
VALUES (
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?,
    ?
);
</code></pre>
","4611713","","","1","5935","data-cruncher524","2015-02-26 18:52:08","56","6","3","0","49039734","49040292","2018-02-28 22:32:36","1","1011","<p><strong>Existing Database and Desired Outcome:</strong></p>

<p>I have a larger SQLite database (12gb, tables with 44 million+ rows) that I would like to modify using Pandas in Python3.</p>

<blockquote>
  <p><em>Example Objective</em>: I hope to read one of these large tables (44 million rows) into a DF in chunks, manipulate the DF chunk, and write the result to a new table. If possible, I would like to replace the new table if it exists, and append each chunk to it. </p>
  
  <p>Because my manipulations only add or modify columns, <strong>the new table should have the same number of rows as the original table.</strong></p>
</blockquote>

<p><strong>Issues:</strong></p>

<p>The primary issue seems to stem from the following line in the below code:</p>

<p><code>df.to_sql(new_table, con=db, if_exists = ""append"", index=False)</code></p>

<ol>
<li>When this line is run in the below code, I seem to consistently get an additional chunk of size=N, plus one observation than I expected.</li>
<li>The first time this code runs with a new table name, I get an error:</li>
</ol>



<pre class=""lang-py prettyprint-override""><code> Traceback (most recent call last):
  File ""example.py"", line 23, in &lt;module&gt;
    for df in df_generator:
  File ""/usr/local/lib/python3.5/site-packages/pandas/io/sql.py"", line 1420, in _query_iterator
    data = cursor.fetchmany(chunksize)
sqlite3.OperationalError: SQL logic error or missing database
</code></pre>

<ol start=""3"">
<li><p>If I then rerun the script, with the same new table name, it runs for each chunk, and an extra chunk, +1 row.</p></li>
<li><p>When the <code>df.to_sql()</code> line is commented out, the loop runs for the expected number of chunks.</p></li>
</ol>

<p><strong>Test Example of Issue with Complete Code:</strong></p>

<p><strong>Complete Code: <em>example.py</em></strong>
</p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
import sqlite3

#Helper Functions Used in Example
def ren(invar, outvar, df):
    df.rename(columns={invar:outvar}, inplace=True)
    return(df)

def count_result(c, table):
    ([print(""[*] total: {:,} rows in {} table""
        .format(r[0], table)) 
        for r in c.execute(""SELECT COUNT(*) FROM {};"".format(table))])


#Connect to Data
db = sqlite3.connect(""test.db"")
c = db.cursor()
new_table = ""new_table""

#Load Data in Chunks
df_generator = pd.read_sql_query(""select * from test_table limit 10000;"", con=db, chunksize = 5000)

for df in df_generator:
    #Functions to modify data, example
    df = ren(""name"", ""renamed_name"", df)
    print(df.shape)
    df.to_sql(new_table, con=db, if_exists = ""append"", index=False)


#Count if new table is created
try:
    count_result(c, new_table)
except:
    pass
</code></pre>

<blockquote>
  <p><strong>1. Result when</strong>
   <code>#df.to_sql(new_table, con=db, if_exists = ""append"", index=False)</code> </p>
  
  <p>(the problem line is commented out):</p>
</blockquote>

<pre class=""lang-py prettyprint-override""><code>$ python3 example.py 
(5000, 22)
(5000, 22)
</code></pre>

<p>Which I expect since the example code limits my large table to 10k rows. </p>

<blockquote>
  <p><strong>2. Result when</strong>
   <code>df.to_sql(new_table, con=db, if_exists = ""append"", index=False)</code> </p>
  
  <p>a. the problem line is not commented out</p>
  
  <p>b. this is the <strong>first time</strong> the code is run with a new_table:</p>
</blockquote>

<pre class=""lang-py prettyprint-override""><code>$ python3 example.py 
(5000, 22)
Traceback (most recent call last):
  File ""example.py"", line 23, in &lt;module&gt;
    for df in df_generator:
  File ""/usr/local/lib/python3.5/site-packages/pandas/io/sql.py"", line 1420, in _query_iterator
    data = cursor.fetchmany(chunksize)
sqlite3.OperationalError: SQL logic error or missing database
</code></pre>

<blockquote>
  <p><strong>3. Result when</strong>
   <code>df.to_sql(new_table, con=db, if_exists = ""append"", index=False)</code> </p>
  
  <p>a. the problem line is not commented out</p>
  
  <p>b. the above code is run a <strong>second time</strong> with the new_table:</p>
</blockquote>

<pre class=""lang-py prettyprint-override""><code>$ python3 example.py 
(5000, 22)
(5000, 22)
(5000, 22)
(1, 22)
[*] total: 20,001 rows in new_table table
</code></pre>

<p>Thus, I have the issue of first the code breaking when run the first time (Result 2) and second, the total number of rows when run the second time (Result 3) is more than double what I expected.</p>

<p><em>Any suggestions on how I can solve this issue would be greatly appreciated.</em></p>
","4611713","","","Pandas errors in writing chunks to database with df.to_sql()","<python><pandas><sqlite><pandas-to-sql>","3","4","4597"
"49057500","2018-03-01 19:42:35","0","","<pre><code>from requests_negotiate_sspi import HttpNegotiateAuth

r=requests.get(""https://example"", auth=HttpNegotiateAuth(), verify=False)
</code></pre>

<p>That should do it.</p>
","9430857","5007059","2018-03-01 20:06:30","0","181","Someguy","2018-03-01 19:42:35","1","0","0","0","44520193","","2017-06-13 11:25:58","1","503","<p>I am trying to fetch details from sharepoint rest api using get request.
Using Java I am able to get the details with using any credentials.
However when trying from python I get 401 error
Is it possible to access it without sending credential</p>

<pre><code>Python Code:
import requests
from requests_ntlm import HttpNtlmAuth


headers = {
""Accept"":""application/json; odata=verbose"",
""Content-Type"":""application/json; odata=verbose"",
""odata"":""verbose"",
""X-RequestForceAuthentication"": ""true"",
""Connection"":""Keep-alive"",
""Upgrade-Insecure-Requests"":'1',
""User-Agent"":""Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36""
}


auth = HttpNtlmAuth('username','password')
response =requests.get(""url"", auth=auth)
print(""--------"",response.request.headers)
for r in response.history:
    print (""--------"",r.headers)
print(response)

Response:
------- {'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'Ke
ep-Alive', 'User-Agent': 'python-requests/2.17.3', 'Authorization': 'NTLM TlRMTV
NTUAADAAAAGAAYAGYAAAAYABgAfgAAAAIAAgBIAAAADAAMAEoAAAAQABAAVgAAAAAAAACWAAAABYKIog
UBKAoAAAAPLgBhAGMAbgByAGYAcwBMADAAMQA0ADIAMQAxADMAItYC2wYJ7G4AAAAAAAAAAAAAAAAAAA
AA8n1+n9UWFFRUMQzjMj8muwmYNCYfa91n'}
-------- {'X-FRAME-OPTIONS': 'SAMEORIGIN', 'X-Content-Type-Options': 'nosniff',
'Content-Type': 'text/plain; charset=utf-8', 'SPRequestDuration': '3', 'SPIisLat
ency': '0', 'X-Powered-By': 'ASP.NET', 'WWW-Authenticate': 'Negotiate, NTLM', 'X
-MS-InvokeApp': '1; RequireReadOnly', 'Content-Length': '16', 'X-SPWFE': 'W00025
0', 'Date': 'Tue, 13 Jun 2017 10:03:18 GMT', 'SPRequestGuid': '5231fb9d-1eac-002
a-e59e-04fcc12587ee', 'request-id': '5231fb9d-1eac-002a-e59e-04fcc12587ee', 'Mic
rosoftSharePointTeamServices': '15.0.0.4763', 'Server': 'Microsoft-IIS/8.5'}
-------- {'X-FRAME-OPTIONS': 'SAMEORIGIN', 'SPRequestDuration': '1', 'X-Content-
Type-Options': 'nosniff', 'WWW-Authenticate': 'NTLM TlRMTVNTUAACAAAADAAMADgAAAAF
gomiXpOD7CdoaSEAAAAAAAAAALIAsgBEAAAABgOAJQAAAA9DAEcAVQBTAEUAUgACAAwAQwBHAFUAUwBF
AFIAAQAOAFcAMAAwADAAMgA1ADAABAAmAGMAZwB1AHMAZQByAC4AYwBhAHAAZwByAG8AdQBwAC4AYwBv
AG0AAwA2AHcAMAAwADAAMgA1ADAALgBjAGcAdQBzAGUAcgAuAGMAYQBwAGcAcgBvAHUAcAAuAGMAbwBt
AAUAGABjAGEAcABnAHIAbwB1AHAALgBjAG8AbQAHAAgAqlFmSCzk0gEAAAAA, Negotiate', 'SPIis
Latency': '0', 'X-Powered-By': 'ASP.NET', 'MicrosoftSharePointTeamServices': '15
.0.0.4763', 'Content-Length': '0', 'X-SPWFE': 'W000250', 'Date': 'Tue, 13 Jun 20
17 10:03:18 GMT', 'SPRequestGuid': '5231fb9d-0eaf-002a-e59e-0ff3040d6d28', 'requ
est-id': '5231fb9d-0eaf-002a-e59e-0ff3040d6d28', 'X-MS-InvokeApp': '1; RequireRe
adOnly', 'Server': 'Microsoft-IIS/8.5'}
</code></pre>
","7572574","","","Sharepoint rest api get request using python returns 401","<python><rest><sharepoint-2013>","1","0","2692"
"49057587","2018-03-01 19:48:33","1","","<pre><code>button3 = tk.Button(self, text=""Quit"",
                        command=lambda: controller.quit_program)
</code></pre>

<p>Doesn't make <code>button3</code> to call anything as it lacks the call <code>()</code> syntax inside  <code>lambda</code>. Replace it with:</p>

<pre><code>button3 = tk.Button(self, text=""Quit"",
                        command=lambda: controller.quit_program())
</code></pre>

<p>or better yet with:</p>

<pre><code>button3 = tk.Button(self, text=""Quit"",
                        command=controller.quit_program)
</code></pre>

<p>Additionally, If you want to make quit functionality, you can use <code>quit</code> method instead, as it will destroy all GUI as opposed to the object it's attached to like <code>destroy</code> does:</p>

<pre><code>button3 = tk.Button(self, text=""Quit"",
                        command=controller.quit)
</code></pre>
","7032856","","","0","883","Nae","2016-10-17 19:19:28","6877","1192","1235","658","49041160","49041347","2018-03-01 01:10:02","0","84","<p>I'm planning on making a fairly complex GUI in Python using Tkinter for a senior project. I came across <a href=""https://stackoverflow.com/questions/7546050/switch-between-two-frames-in-tkinter"">this</a> link that provides a great structured way to go about handling switching between frames by stacking them.</p>

<p>I want to make a simple quit button that exits the program when pressed because the GUI I plan to make will not have the window frame around it to minimize, maximize or exit. If I add a function such as this:</p>

<pre><code>def quit_program(self):

    self.destroy()
</code></pre>

<p>And I put that function below the show_frame function and then in another class call upon it like so:</p>

<pre><code>button3 = tk.Button(self, text=""Quit"",
                        command=lambda: controller.quit_program)
</code></pre>

<p>It doesn't work. Why is that? And how would I go about making a quit button with this frame structure? </p>
","9426359","","","Python/Tkinter quit button for stacked frames","<python><python-3.x><tkinter>","2","0","956"
"49057634","2018-03-01 19:51:57","0","","<p><code>CENTER</code> is a variable(actually they usually are referred to as constants) of <a href=""/questions/tagged/tkinter"" class=""post-tag"" title=""show questions tagged &#39;tkinter&#39;"" rel=""tag"">tkinter</a> module which equals to <code>'center'</code>. So simply replace the line with:</p>

<pre><code>label.place(..., anchor='center')
</code></pre>
","7032856","","","0","358","Nae","2016-10-17 19:19:28","6877","1192","1235","658","49040437","","2018-02-28 23:39:33","0","832","<p>I am new to tkinter and have been using:</p>

<pre><code>from tkinter import * 
</code></pre>

<p>but have read this is bad practice. 
I rewrote a very small bit of code to start using the following:</p>

<pre><code>import tkinter as tk
</code></pre>

<p>However when I run the rest of the code. I get the error:
<code>label.place(relx=0.4, rely=0.35, anchor=CENTER)
NameError: name 'CENTER' is not defined</code></p>

<pre><code>root = tk.Tk()
label = tk.Label(root, text=""I am a label widget"")
label.place(relx=0.4, rely=0.35, anchor=CENTER)    
button = tk.Button(root, text=""I am a button"")
label.pack()
button.pack()
root.mainloop()
</code></pre>

<p>Is this a namespace issue? How can I solve the problem?</p>
","9394122","8372104","2018-02-28 23:49:16","Using Tkinter in Python Label does not recognize anchor=CENTER","<python><tkinter><label><justify>","2","2","719"
"49057649","2018-03-01 19:53:01","1","","<p>The following straightforward string example runs a fair amount faster than Serge's second example above (at least if the data held in the stream is relatively small) and works for simple read and writes to the same stream:</p>

<pre><code>class BytesLoop:
    def __init__(self, s=b''):
        self.buffer = s

    def read(self, n=-1):
        chunk = self.buffer[:n]
        self.buffer = self.buffer[n:]
        return chunk

    def write(self, s):
        self.buffer += s
</code></pre>
","2132312","","","0","497","Matthew D. Scholefield","2013-03-04 15:19:19","1096","153","292","23","33395004","33396272","2015-10-28 15:22:20","5","1960","<p>I'm looking for a pythonic means of both reading and writing to a stream (in the IOBase hierarchy) without having to manage the stream position via seek() and tell().  This would be similar to how a socket stream would be expected to work where the receiving end would be able to continuously read while bytes where being received.</p>

<p>I've tried using a BufferedReader and BufferedWriter both attached to the same raw stream, but operations on one affect the stream position on the other.  seek()/tell() appear to pass directly through to the underlying raw stream.  Are there other IOBase types that can be used to act effectively as an IO stream where concurrent input and output are supported without the need to manage the stream position (similar to C++ stringstream >> and &lt;&lt; ).</p>

<p>Thanks!</p>

<pre><code>&gt;&gt;&gt; import io
&gt;&gt;&gt; buf = io.BytesIO()
&gt;&gt;&gt; r = io.BufferedReader(buf)
&gt;&gt;&gt; w = io.BufferedWriter(buf)
&gt;&gt;&gt; w.write('foo bar')
7L
&gt;&gt;&gt; r.read(1)
''
&gt;&gt;&gt; r.tell()
0L
&gt;&gt;&gt; w.flush()
&gt;&gt;&gt; r.tell()
7L
&gt;&gt;&gt; r.flush()
&gt;&gt;&gt; r.tell()
7L
&gt;&gt;&gt; w.tell()
7L
&gt;&gt;&gt; buf.tell()
7L
</code></pre>
","3482566","","","Python StreamIO reading and writing from the same stream","<python><inputstream>","2","0","1214"
"49057668","2018-03-01 19:54:27","0","","<p>You data is not actually a 6-level dictionary like a dictionary in a 3-level example you referenced to. The difference is: your dictionary has a data on multiple different levels, e.g. 'Lambo' value is on second level of hierarchy with key ('Things','Car') but 'Eclipse' value is on sixth level of hierarchy with key ('Things','Gadgets','Laptop','Programs','Coding','Java')</p>

<p>If you want to 'flatten' your structure you will need to decide what to do with 'missed' key values for deeper levels for values like 'Lambo'.</p>

<p>Btw, maybe it is not actually a solution for your problem, maybe you need to use more appropriate UI widgets like TreeView to work with such kind of hierarchical data, but I will try to directly <strong>address your exact question</strong>. </p>

<p>Unfortunately it seems to be no easy way to reference all different level values uniformly in one simple dict or list comprehension statement.
Just look at your 'value extractor' (<code>Dict[i][j][k][l][m][n]</code>) there are no such values for i,j,k,l,m,n exists which allows you to get a 'Lambo'. Because to get a Lambo you will need to just use <code>Dict['Things']['Car']</code> (ironically, in a real life it is also could be difficult to get a Lambo :-) )</p>

<p>One straightforward way to solve your task is:
extract a second level data, extract a third level data, and so on, and combine them together. 
E.g. to extract second level values you can write something like this:</p>

<pre><code>val_level2 = {(k1,k2):Dict[k1][k2] 
   for k1 in Dict 
   for k2 in Dict[k1] 
   if isinstance(Dict[k1],dict) and 
      not isinstance(Dict[k1][k2],dict)}
</code></pre>

<p>but if you want to combine it later with six level values, it will need to add some padding to your key tuples:</p>

<pre><code>val_level2 = {(k1,k2,'','','',''):Dict[k1][k2] 
   for k1 in Dict 
   for k2 in Dict[k1] 
   if isinstance(Dict[k1],dict) and 
      not isinstance(Dict[k1][k2],dict)}
</code></pre>

<p>later you can combine all together by something like:</p>

<pre><code>d = {}
d.update(val_level2)
d.update(val_level3)
</code></pre>

<p>But usually the most organic way to work with hierarchical data is to use some recursion, like this:</p>

<pre><code>def flatten_dict(d,key_prefix,max_deep):
    return [(tuple(key_prefix+[k]+['']*(max_deep-len(key_prefix))),v) 
        for k,v in d.items() if not isinstance(v,dict)] +\
        sum([flatten_dict(v,key_prefix+[k],max_deep) 
              for k,v in d.items() if isinstance(v,dict)],[])
</code></pre>

<p>And later with code like this:</p>

<pre><code>d={k:v for k,v in flatten_dict(Dict,[],5)}
mux = pd.MultiIndex.from_tuples(d.keys())
df = pd.DataFrame(list(d.values()), index=mux)
df.reset_index()
</code></pre>

<p>I actually get this result with your data:</p>

<p><a href=""https://i.stack.imgur.com/PmcXc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PmcXc.png"" alt=""resulting data_frame""></a></p>

<p>P.S. According to <a href=""https://www.python.org/dev/peps/pep-0008/#prescriptive-naming-conventions"" rel=""nofollow noreferrer"">https://www.python.org/dev/peps/pep-0008/#prescriptive-naming-conventions</a> we prefer a lowercase_with_underscores for variable names, CapWords is for classes. So src_dict would be much better, than Dict in your case.</p>
","2037068","","","2","3310","Recontemplator","2013-02-03 12:14:12","56","6","34","0","49052687","49057668","2018-03-01 15:10:18","0","427","<pre><code>Dict = {'Things' : {'Car':'Lambo', 'Home':'NatureVilla', 'Gadgets':{'Laptop':{'Programs':{'Data':'Excel', 'Officework': 'Word', 'Coding':{'Python':'PyCharm', 'Java':'Eclipse', 'Others': 'SublimeText'}, 'Wearables': 'SamsungGear', 'Smartphone': 'Nexus'}, 'clothes': 'ArmaaniSuit', 'Bags':'TravelBags'}}}}



d = {(i,j,k,l,m,n): Dict[i][j][k][l][m][n]
     for i in Dict.keys()
     for j in Dict[i].keys()
     for k in Dict[j].keys()
     for l in Dict[k].keys()
     for m in Dict[l].keys()
     for n in Dict[n].keys()
     }

mux = pd.MultiIndex.from_tuples(d.keys())
df = pd.DataFrame(list(d.values()), index=mux)
print (df)
</code></pre>

<p><strong>What I have already done:</strong>
I tried to Multiindex this Irregular Data using pandas but I am getting KeyError at 'Car'. Then I tried to handle exceptions and tried to PASS it but then it results in a Syntax Error. So May be I lost the direction. If there is any other module or way I can index this irregular data and put it in a table somehow. I have a chunk of raw data like this.</p>

<p><strong>What I am trying to do:</strong>
I wanted to use this data for printing in QTableView which is from PyQt5 (Making a program with GUI). </p>

<p><strong>Conditions:</strong>
This Data keeps on updating every hour from an API.</p>

<p><strong>What I have thought till now:</strong>
May be I can append all this data to MySQL. But then when this data updates from API, only Values will change, rest of the KEYS will be the same. But then It will require more space.</p>

<p><strong>References:</strong>
<a href=""https://stackoverflow.com/questions/41278428/how-to-convert-a-3-level-dictionary-to-a-desired-format?noredirect=1&amp;lq=1"">How to convert a 3-level dictionary to a desired format?</a></p>

<p><a href=""https://stackoverflow.com/questions/47416113/how-to-build-a-multiindex-pandas-dataframe-from-a-nested-dictionary-with-lists?noredirect=1&amp;lq=1"">How to build a MultiIndex Pandas DataFrame from a nested dictionary with lists</a></p>

<p>Any Help will be appreciated. Thanks for reading the question. </p>
","9429073","","","How to convert Multilevel Dictionary with Irregular Data to Desired Format","<python><pandas><dictionary><dataframe><qtableview>","2","0","2088"
"49057674","2018-03-01 19:54:46","0","","<p>Ok , seems like you data inout is mismatch with the df your show to us </p>

<pre><code>df.groupby('ADDRESS').PORT.apply(lambda x : pd.Series(x).rolling(5,min_periods=1).apply(lambda y: len(set(y))))
Out[844]: 
0    1.0
1    1.0
2    1.0
3    2.0
4    2.0
5    2.0
Name: PORT, dtype: float64
</code></pre>
","7964527","","","3","309","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49057325","","2018-03-01 19:29:55","1","571","<p>I want to calculate the number of distinct port numbers that exist between the current row and the 5 previous rows (sliding window) <strong>and this when the same address appears.</strong> 
For instance,</p>

<p>If the input is (csv file):
 </p>

<pre><code>ID      PORT     ADDRESS
1        21       ad3 
2        22       ad1  
3        23       ad2
4        25       ad2 
5        25       ad1
6        22       ad1 
7        22       ad1
8        21       ad4
</code></pre>

<p>The output should be:</p>



<pre><code>ID      PORT     ADDRESS      COUNT_DISC_PORT
1        21       ad3        -
2        22       ad1        -
3        23       ad2        - 
4        25       ad2        - 
5        25       ad1        - 
6        22       ad1        2 
7        23       ad1        3
8        21       ad4        1 
</code></pre>

<p>I have read the documentation about the rolling function in pandas and I have tried combining group by and rolling with no success.</p>

<p>I am using Python 3.7 and the pandas package 0.22.
Any feedback would be appreciated.</p>
","6939295","6939295","2018-03-01 21:18:29","Count distinct strings in rolling window using pandas + python (with a condition)","<python><pandas>","2","6","1072"
"49057685","2018-03-01 19:55:22","0","","<p>beta are components!</p>

<p>beta1 = -0.32703417</p>

<p>beta2 = 0.29320425</p>

<p>beta3 = 0.45731291</p>

<p>beta4 = 0.55565347</p>

<p>beta5 = 0.53776765</p>
","7965204","","","0","164","Thaise","2017-05-04 19:21:09","374","57","23","0","49049771","49057685","2018-03-01 12:30:36","0","72","<p>I'm using sklearn PCA technique. I need to solve:</p>

<pre><code>pca1 =  beta1. c1 + beta2. c2 + beta3. c3 + beta4. c4 + beta5. c5
</code></pre>

<p>I read in the documentation that The components are sorted by explained_variance_. How do I know who the beta values are?</p>

<pre><code>d = {'c1': [3, 7 ,1 ,4], 'c2': [8, 2 ,9 ,5], 'c3': [0, 7 ,9 ,2], 'c4': [3, 5 ,9 ,1], 'c5': [4, 6 ,8 ,3]}
data= pd.DataFrame(data=d)
print(""data:\n"",data,""\n"")
x = StandardScaler().fit_transform(data)
pca = PCA(n_components=1)
principalComponents = pca.fit_transform(x)
principalDf = pd.DataFrame(data = principalComponents, columns = ['principal 
component 1'])
print(""\ncomponents: \n"",pca.components_,""\n"")
print(""\nexplained_variance_\n"",pca.explained_variance_,""\n"")
</code></pre>

<blockquote>
  <p>Result: </p>
</blockquote>

<p>data:</p>

<pre><code>+--+----+----+----+-----+----+
|  | c1 | c2 | c3 |  c4 | c5 |
|0 |  3 |  8 |  0 |  3  | 4  |
|1 |  7 |  2 |  7 |  5  | 6  |
|2 |  1 |  9 |  9 |  9  | 8  |
|3 |  4 |  5 |  2 |  1  | 3  |
+--+----+----+----+-----+----+
</code></pre>

<p>components: </p>

<pre><code>[[-0.32703417  0.29320425  0.45731291  0.55565347  0.53776765]] 
</code></pre>

<p>explained_variance_:</p>

<pre><code>[ 3.10207373] 
</code></pre>
","7965204","7965204","2018-03-01 19:55:46","In which order PCA components is printed? I need the parameters to solve pca formula. How do I know who the beta values are?","<python><pandas><scikit-learn><sklearn-pandas>","1","2","1261"
"49057691","2018-03-01 19:55:47","1","","<p>At <a href=""https://pypi.python.org/pypi/allen-bradley-toolkit/2.0.0"" rel=""nofollow noreferrer"">https://pypi.python.org/pypi/allen-bradley-toolkit/2.0.0</a> I see that the wheel is only available for Python 3. You're trying to install it with Python 2.7.</p>

<p>To publish a universal wheel (suitable for both Py2 and Py3) you need to set</p>

<pre><code>[bdist_wheel]
universal = 1
</code></pre>

<p>in <code>setup.cfg</code> or run</p>

<pre><code>python setup.py bdist_wheel --universal
</code></pre>
","7976758","7976758","2018-03-01 21:32:41","2","508","phd","2017-05-07 15:40:03","32575","3331","2903","3411","49056702","49057691","2018-03-01 18:49:01","0","41","<p>I have a package that I am trying to install via <code>pip install allen-bradley-toolkit</code>. The package is failing with the following reason.</p>

<p><a href=""https://i.stack.imgur.com/VTpKY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VTpKY.png"" alt=""enter image description here""></a></p>

<p>The problem seems to related to the fact that pip is trying to install <code>1.0a1.post0</code> instead of the latest release version <code>2.0.0</code>.  Does anyone have any ideas on what to do about this.  Perhaps there is something wrong in my deployment script.  You can view the <a href=""https://github.com/cmseaton42/Allen-Bradley-Toolkit"" rel=""nofollow noreferrer"">Github</a> Library here to see how I am deploying to PyPi. </p>

<p>There is an issue opened on the GitHub Tracker <a href=""https://github.com/cmseaton42/Allen-Bradley-Toolkit/issues/2"" rel=""nofollow noreferrer"">#2</a> that you can also reference for more info.</p>

<p>NOTE: The package seems to install fine on my win10 machine.  But I am unable to get it to install on a win7 VM.</p>

<p>Ive also tried installing with the following commands:</p>

<ul>
<li><code>pip install --no-cache-dir allen-bradley-toolkit</code></li>
<li><code>pip install allen-bradley-toolkit==2.0.0</code> -> this ones throws a 'doesnt exist error`</li>
</ul>
","7496355","7496355","2018-03-01 19:08:15","Pip installing wrong version on win7,","<python><python-2.7><pip><package>","2","0","1337"
"49057696","2018-03-01 19:56:19","1","","<p>You can simply append two tables together:</p>

<pre><code>df_train_scaled = df_train.iloc[:,1:].replace(['Ex','Gd','TA','Fa','Po'], [5, 4, 3, 2, 1])
df_train_scaled.columns = [x + ""_new"" for x in df_train_scaled.columns]
pd.concat([df_train, df_train_scaled], axis=1)
</code></pre>
","3216980","","","0","286","Yilun Zhang","2014-01-20 22:22:55","3929","358","173","44","49057589","49057696","2018-03-01 19:48:52","0","357","<p>I'm a newbie to python so please bear with me. I have a data frame where I want to replace values for specific strings. Below is my starting df (df_train):</p>

<pre><code>       A    B     C     D
0     .5   Ex    Ex    Po
1     35   Gd    TA    Gd
2     52   TA    Fa    Ex
3     47   Bd    Po    Gd
</code></pre>

<p>I can easily replace the values I'd like and create a new df(df_train_scaled), per below:</p>

<pre><code>df_train_scaled = df_train.replace(['Ex','Gd','TA','Fa','Po'], [5, 4, 3, 2, 1])
</code></pre>

<p>I'm curious if I should do this and go to a new df(df_train_scaled) to continue data pre-processing before modeling, or if I should create a new column in the same df (df_train). Regardless of the answer, I do want to figure out how to add a new column to the same df with the replaced values. Output below:</p>

<pre><code>       A    B   B_new  C   C_new   D   D_new
0     .5   Ex     5    Ex     5    Po    1
1     35   Gd     4    TA     3    Gd    4
2     52   TA     3    Fa     2    Ex    5
3     47   Gd     4    Po     1    Gd    4
</code></pre>

<p>If I do this, I can experiment to see if my ordinal, or scaled, variables will perform better in my modeling efforts. Thanks in advance for any help!</p>
","7096399","","","Pandas - create new column with replaced values while keeping original column","<python><pandas><replace><data-processing>","2","0","1240"
"49057719","2018-03-01 19:58:10","1","","<p>First, note that a <em>set</em> does not have an implicit ordering: not in Python, not in set algebra.</p>

<p>I suggest that you're attacking the problem from a difficult angle.  Rather than finding exactly the permutations you want from the C(8,3) possibilities, why not <em>generate</em> the ones you want, and no more?</p>

<p>Start with empty sub-lists.  Iterate through the 3^3 possibilities, placing each letter in the indicated sub-list.  Sort the sub-lists and print.</p>

<pre><code>for ai in range(3):
    for bi in range(3):
        for ci in range(3):
            permute = [ [], [], [] ]
            permute[ai].append('a')    
            permute[bi].append('b')    
            permute[ci].append('c')
            print(permute)
</code></pre>

<p>Output:</p>

<pre><code>[['a', 'b', 'c'], [], []]
[['a', 'b'], ['c'], []]
[['a', 'b'], [], ['c']]
[['a', 'c'], ['b'], []]
[['a'], ['b', 'c'], []]
[['a'], ['b'], ['c']]
[['a', 'c'], [], ['b']]
[['a'], ['c'], ['b']]
[['a'], [], ['b', 'c']]
[['b', 'c'], ['a'], []]
[['b'], ['a', 'c'], []]
[['b'], ['a'], ['c']]
[['c'], ['a', 'b'], []]
[[], ['a', 'b', 'c'], []]
[[], ['a', 'b'], ['c']]
[['c'], ['a'], ['b']]
[[], ['a', 'c'], ['b']]
[[], ['a'], ['b', 'c']]
[['b', 'c'], [], ['a']]
[['b'], ['c'], ['a']]
[['b'], [], ['a', 'c']]
[['c'], ['b'], ['a']]
[[], ['b', 'c'], ['a']]
[[], ['b'], ['a', 'c']]
[['c'], [], ['a', 'b']]
[[], ['c'], ['a', 'b']]
[[], [], ['a', 'b', 'c']]
</code></pre>

<p>Yes, this is brute-force.  Simplifications (e.g. see <code>itertools.product</code>) are left as an exercise for the reader.  :-)</p>
","4785185","4785185","2018-03-01 20:16:42","0","1584","Prune","2015-04-14 00:37:53","54183","8845","3232","13592","49057495","49057719","2018-03-01 19:42:10","0","80","<p>Let's say I have a set with n=3 elements: [a,b,c]</p>

<p>Using combinatorics we know that this set has 8 subsets with j elements: </p>

<p><code>[∅], [a], [b], [c], [a,b], [a,c], [b,c], [a,b,c]</code></p>

<p>Now what I want to do using Python is print all of the permutations of these 8 subsets with the constraints being that there must be exactly 3 subsets for each permutation (empty subsets are fine), all elements must be used, and alphabetical order must be maintained within each subset (alphabetical order does not need to be maintained outside of the subset--e.g. <code>[c],[a],[b]</code> is fine). </p>

<p>I have attempted something like this: </p>

<pre><code>x=1
y=3

for i in set(permutations(chain.from_iterable(set_n))):
    while x&lt;=3:
        permuted = sorted([i[:y], i[x:]])
        x = x+1
        y = y-1

    print permuted
</code></pre>

<p>Where <code>set_n</code> is my set of n elements, but this of course only gives permutations of two subsets and only a single permutation of those two subsets. It's also not maintaining alphabetical order within the subsets.</p>
","4839906","355230","2018-03-01 19:58:01","Print all combinations of a set with n elements split between subsets with j elements while retaining alphabetical order","<python><arrays><sorting><permutation><combinatorics>","1","1","1102"
"49057790","2018-03-01 20:01:47","0","","<p>Did you download python or build it yourself? If you download python binaries, it's already compiled and doesn't use your gcc. </p>

<p>If you want to compile python with gcc 6, download the cpython source from <a href=""https://github.com/python/cpython"" rel=""nofollow noreferrer"">here</a>
and go wild.  </p>
","6227316","","","0","312","T. McManus","2016-04-19 22:12:39","1","0","0","0","49057646","49057795","2018-03-01 19:52:55","-2","1085","<p>I updated gcc to v6 few weeks ago. Today i noticed that python2 and python3 both the interpreters were using gcc v5. Why does python interpreter show gcc v5 but I have gcc v6 installed? I am using xubuntu 16.</p>

<p>Here is my terminal:
<a href=""https://i.stack.imgur.com/scoas.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/scoas.png"" alt=""wrong interpreters!""></a></p>
","8972012","8972012","2018-03-01 19:55:02","Python shows wrong gcc version","<python><gcc><interpreter>","2","4","395"
"49057794","2018-03-01 20:02:02","2","","<p>Here is an O(1) solution using lookup table compared to OP's (first) solution and <code>numpy.searchsorted</code>. It's not 100% fair because OP's solution is not vectorized. Anyway, timings:</p>

<pre><code>True                  # results equal
True                  # results equal
0.08163515606429428   # lookup
2.1996873939642683    # OP
0.016975965932942927  # numpy.searchsorted
</code></pre>

<p>For this small list size <code>seachsorted</code> wins even though it is O(log n).</p>

<p>Code:</p>

<pre><code>import numpy as np

class find_next:
    def __init__(self, a, max_bins=100000):
        self.a = np.sort(a)
        self.low = self.a[0]
        self.high = self.a[-1]
        self.span = self.a[-1] - self.a[0]
        self.damin = np.diff(self.a).min()
        if self.span // self.damin &gt; max_bins:
            raise ValueError('a too unevenly spaced for max_bins')
        self.lut = np.searchsorted(self.a, np.linspace(self.low, self.high,
                                                       max_bins + 1))
        self.no_bins = max_bins
    def f_pp(self, x):
        i = np.array((x-self.low)/self.span * self.no_bins, int)
        return self.a[self.lut[i + (x &gt; self.a[self.lut[i]])]]
    def lowest(self, x):
        return self.a[self.a &gt;= x][0]
    def f_ss(self, x):
        return self.a[self.a.searchsorted(x)]

a = np.array([2, 1, 3, 4, 5, 6, 7, 8, 9])

x = np.random.uniform(1, 9, (10000,))

fn = find_next(a)
sol_pp = fn.f_pp(x)
sol_OP = [fn.lowest(xi) for xi in x]
sol_ss = fn.f_ss(x)

print(np.all(sol_OP == sol_pp))
print(np.all(sol_OP == sol_ss))

from timeit import timeit
kwds = dict(globals=globals(), number=10000)

print(timeit('fn.f_pp(x)', **kwds))
print(timeit('[fn.lowest(xi) for xi in x]', **kwds))
print(timeit('fn.f_ss(x)', **kwds))
</code></pre>
","7207392","","","0","1813","Paul Panzer","2016-11-24 23:39:00","37645","7185","734","1","49056911","49057794","2018-03-01 19:02:31","0","57","<p>EDIT: My question is different than the suggested duplicate because I already have a method of implementing <code>lowest</code>.  My question is not how to implement <code>lowest</code>, but rather how to optimize <code>lowest</code> to run faster.  </p>

<p>Assume that I have an array <code>a</code>.  For example:</p>

<pre><code>import numpy as np
a = np.array([2, 1, 3, 4, 5, 6, 7, 8, 9])
</code></pre>

<p>Assume that I have a float <code>x</code>.  For example:</p>

<pre><code>x = 6.5
</code></pre>

<p>I want to return the lowest value in <code>a</code> that is also greater than or equal to <code>x</code>.  So in this case...</p>

<pre><code>print lowest(a, x)
&gt;&gt;&gt; 7
</code></pre>

<p>I have tried a number of function in place of <code>lowest</code>.  For example:</p>

<pre><code>def lowest(a, x):
"""""" `a` should be a sorted numpy array""""""
    return lowest[lowest &gt;= x][0]

def lowest(a, x):
"""""" `a` should be a sorted `list`, not a numpy array""""""
    k = sorted(a + [x])
    return k[k.index(x) + 1]
</code></pre>

<p>However, the function <code>lowest</code> remains the bottleneck of my code at ~90%.  </p>

<p><strong>Is there a faster way to implement the function <code>lowest</code>?</strong></p>

<p>Some rules about my code:</p>

<ul>
<li><code>a</code> can be assumed to have a length of 10</li>
<li>the function <code>lowest</code> is run at least 100k times. This may be a design problem, but I am interested if there is a faster implementation of my problem first.  </li>
<li><code>a</code> can be preprocessed before being run through these loops.  <code>x</code> will vary, but <code>a</code> will not.</li>
<li>It can be assumed that <code>a[0] &lt;= x &lt;= a[-1]</code> is always <code>True</code></li>
</ul>
","1324967","4829258","2018-03-01 20:51:39","Optimization: Return lowest value from array that is greater than (or equal to) `x`","<python><python-2.7><numpy><optimization>","1","6","1756"
"49057795","2018-03-01 20:02:06","0","","<p>On your platform, <code>gcc-6</code> command is referring to <em>GCC V6</em>. <code>gcc</code> command is still referring to <em>GCC V5</em>,</p>

<p><strong>Note:</strong> You can check it via typing <code>gcc --version</code> on terminal.</p>
","8013471","","","0","248","cse","2017-05-15 09:43:16","3106","419","35","354","49057646","49057795","2018-03-01 19:52:55","-2","1085","<p>I updated gcc to v6 few weeks ago. Today i noticed that python2 and python3 both the interpreters were using gcc v5. Why does python interpreter show gcc v5 but I have gcc v6 installed? I am using xubuntu 16.</p>

<p>Here is my terminal:
<a href=""https://i.stack.imgur.com/scoas.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/scoas.png"" alt=""wrong interpreters!""></a></p>
","8972012","8972012","2018-03-01 19:55:02","Python shows wrong gcc version","<python><gcc><interpreter>","2","4","395"
"49057810","2018-03-01 20:03:07","1","","<p>Jupyter under the <a href=""https://winpython.github.io/"" rel=""nofollow noreferrer"">WinPython</a> environment has a batch file in the <code>scripts</code> folder called:</p>

<pre><code>make_working_directory_be_not_winpython.bat
</code></pre>

<p>You need to edit the following line in it:</p>

<pre><code>echo WINPYWORKDIR = %%HOMEDRIVE%%%%HOMEPATH%%\Documents\WinPython%%WINPYVER%%\Notebooks&gt;&gt;""%winpython_ini%""
</code></pre>

<p>replacing the <code>Documents\WinPython%%WINPYVER%%\Notebooks</code> part with your folder address. </p>

<p>Notice that the <code>%%HOMEDRIVE%%%%HOMEPATH%%\</code> part will identify the root and user folders (i.e. <code>C:\Users\your_name\</code>) which will allow you to point different WinPython installations on separate computers to the same cloud storage folder (e.g. OneDrive), accessing and working with the same files from different machines. I find that very useful.</p>
","5133074","","","0","922","Muhamed Al Khalil","2015-07-19 20:43:06","157","53","127","0","35664972","35665295","2016-02-27 02:28:02","25","64301","<p>I couldn't find a place for me to change the working directory in Jupyter Notebook, so I couldn't use the pd.read_csv method to read in a specific csv document.</p>

<p>Is there any way to make it? FYI, I'm using Python3.5.1 currently.</p>

<p>Thanks!</p>
","5860262","","","How to change working directory in Jupyter Notebook?","<python><jupyter-notebook>","6","1","259"
"49057833","2018-03-01 20:04:27","0","","<p>Updated doc link: <a href=""https://tools.ietf.org/doc/python-webob/docs/modules/webob.html#misc-functions-and-internals"" rel=""nofollow noreferrer"">Webob MultiDict</a></p>

<p>You probably want <code>mixed()</code> or <code>dict_of_lists()</code>.</p>
","737689","","","0","254","Mandeep Sandhu","2011-05-04 09:21:07","189","47","56","0","15957433","15957503","2013-04-11 19:40:03","4","4207","<p>I am receiving a POST request with data formatted as a MultiDict Object. Where can I find documentation about this data structure? and what is the best method (library) to decode these data into a dictionary object (with lists and dictionaries inside)</p>

<p>I did find <a href=""http://code.google.com/p/urllib3/source/browse/urllib3/multidict.py?name=multidict"" rel=""nofollow"">this, in urllib3</a>, but not sure if that's the. preferred way.</p>

<p>I already have written most of the code to match this style of data, so not really looking forward to changing the way the data is sent from the HTML form itself.</p>

<p>Thank you</p>
","1888726","","","decoding pyramid POST data (MultiDict Object)","<python><json><pyramid>","2","0","640"
"49057846","2018-03-01 20:05:00","1","","<p>Problem solved! My final command:</p>

<pre><code>m.pcolormesh(lon_var, lat_var, tg[0,:,:], latlon = True)
</code></pre>

<p>the <code>latlon = True</code> keyword argument was required to properly display my data. Separately, I realized that <code>lat_var</code> and <code>lon_var</code> were read over as lists, and needed to convert these into arrays with <code>np.array()</code>.</p>
","9404057","","","0","391","k.mcgee","2018-02-24 00:34:27","56","17","6","0","48958439","","2018-02-24 01:26:18","0","301","<p>I'm new to python and still learning, so forgive me if I missed something obvious!</p>

<p>I'm trying to plot a pcolormesh map of temperature data ('tg') using Basemap in matplotlib. tg is a 3D array of time, latitudes and longitudes. For some reason, my output only shows the continent and states, but the temperature data is not overlain and is not visible. What am I missing?</p>

<p>Here is a sample of my code:</p>

<pre><code>import matplotlib.pyplot as plt
from mpl_toolkits.basemap import Basemap, cm

lon_0 = (lon_var[:].mean())
lat_0 = (lat_var[:].mean())
latcorners = lat_var[:]
loncorners = lon_var[:]

m = Basemap(projection = 'lcc',\
        lon_0 = -100, lat_0 = 39, lat_ts = lat_0,\
        llcrnrlat=latcorners[0,0],urcrnrlat=latcorners[169,56],\
        llcrnrlon=loncorners[0,0],urcrnrlon= loncorners[169,56],\
        resolution='l')

m.drawcoastlines()
m.drawstates()
m.drawcountries()

parallels = np.arange(lat_var[0,0], lat_var[169,56])
m.drawparallels(parallels)

meridians = np.arange(lon_var[0,0], lon_var[169,56])
m.drawmeridians(meridians)


clevs = np.linspace(30,50, 2)

cs = m.pcolormesh(lon_var, lat_var, tg[0,:,:])
plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/fQpSI.png"" rel=""nofollow noreferrer"">Here is the output map that is created</a></p>

<p>Thanks!</p>
","9404057","","","Unable to view data on basemap pcolormesh map","<python><netcdf><matplotlib-basemap>","1","4","1316"
"49057870","2018-03-01 20:06:26","1","","<p>You need to change your regex to use lookarounds, as follows:</p>

<pre><code>my_text = '""posted_data"":""2e54eba66f8f2881c8e78be8342428xd"",""isropa"":false,""rx"":""NO"",""readal"":""false""'
extract_posted_data = re.search(r'(?&lt;=""posted_data"":"")\w*(?="")', my_text)
print (extract_posted_data[0])
</code></pre>

<p>Prints  <code>2e54eba66f8f2881c8e78be8342428xd</code></p>

<p>Also <code>re.search()</code> returns a Match object, so to get the first match (the only match) you get index 0 of the match:</p>
","797744","","","0","503","DBedrenko","2011-06-14 13:34:09","2738","491","2167","785","49057818","49057900","2018-03-01 20:03:40","2","79","<p>My text is </p>

<pre><code>my_text = '""posted_data"":""2e54eba66f8f2881c8e78be8342428xd"",""isropa"":false,""rx"":""NO"",""readal"":""false""'
</code></pre>

<p>I am trying to extract value of <code>posted_data</code> which is <code>2e54eba66f8f2881c8e78be8342428xd</code> </p>

<p>My code :</p>

<pre><code>extract_posted_data = re.search(r'(\""posted_data\"": \"")(\w*)', my_text)
print (extract_posted_data)
</code></pre>

<p>and it prints None </p>

<p>Thank you</p>
","9409695","","","how do i extract value inside quotes using regex python?","<python><regex><python-3.x>","4","1","459"
"49057880","2018-03-01 20:07:04","1","","<p>Jupyter under the <a href=""https://winpython.github.io/"" rel=""nofollow noreferrer"">WinPython</a> environment has a batch file in the <code>scripts</code> folder called:</p>

<pre><code>make_working_directory_be_not_winpython.bat
</code></pre>

<p>You need to edit the following line in it:</p>

<pre><code>echo WINPYWORKDIR = %%HOMEDRIVE%%%%HOMEPATH%%\Documents\WinPython%%WINPYVER%%\Notebooks&gt;&gt;""%winpython_ini%""
</code></pre>

<p>replacing the <code>Documents\WinPython%%WINPYVER%%\Notebooks</code> part with your folder address. </p>

<p>Notice that the <code>%%HOMEDRIVE%%%%HOMEPATH%%\</code> part will identify the root and user folders (i.e. <code>C:\Users\your_name\</code>) which will allow you to point different WinPython installations on separate computers to the same cloud storage folder (e.g. OneDrive) where you could store, access, and work with the same files from different machines. I find that very useful.</p>
","5133074","","","0","939","Muhamed Al Khalil","2015-07-19 20:43:06","157","53","127","0","18901185","18901898","2013-09-19 17:22:18","56","87658","<p>I just started IPython Notebook, and I tried to use ""Save"" to save my progress. However, instead of saving the *.ipynb in my current working directory, it is saved in my python/Scripts folder. Would there be a way to set this?</p>

<p>Thanks!</p>
","2203311","","","IPython Notebook save location","<python><ipython><ipython-notebook>","8","0","250"
"49057884","2018-03-01 20:07:17","3","","<p>This particular example doesn't seem like it needs regular expressions at all.</p>

<pre><code>&gt;&gt;&gt; my_text
'""posted_data"":""2e54eba66f8f2881c8e78be8342428xd"",""isropa"":false,""rx"":""NO"",""readal"":""false""'
&gt;&gt;&gt; import json
&gt;&gt;&gt; result = json.loads('{%s}' % my_text)
&gt;&gt;&gt; result
{'posted_data': '2e54eba66f8f2881c8e78be8342428xd', 'isropa': False, 'rx': 'NO', 'readal': 'false'}
&gt;&gt;&gt; result['posted_data']
'2e54eba66f8f2881c8e78be8342428xd'
</code></pre>

<p>With <code>BeautifulSoup</code>:</p>

<pre><code>&gt;&gt;&gt; import json
... 
... from bs4 import BeautifulSoup
... 
... soup = BeautifulSoup('&lt;script type=""text/javascript""&gt; ""posted_data"":""2738273283723hjasda"" &lt;/script&gt;')
... 
... result = json.loads('{%s}' % soup.script.text)
&gt;&gt;&gt; result
{'posted_data': '2738273283723hjasda'}
&gt;&gt;&gt; result['posted_data']
'2738273283723hjasda'
</code></pre>
","8079103","8079103","2018-03-01 20:47:23","3","918","G_M","2017-05-29 00:31:33","3102","440","139","287","49057818","49057900","2018-03-01 20:03:40","2","79","<p>My text is </p>

<pre><code>my_text = '""posted_data"":""2e54eba66f8f2881c8e78be8342428xd"",""isropa"":false,""rx"":""NO"",""readal"":""false""'
</code></pre>

<p>I am trying to extract value of <code>posted_data</code> which is <code>2e54eba66f8f2881c8e78be8342428xd</code> </p>

<p>My code :</p>

<pre><code>extract_posted_data = re.search(r'(\""posted_data\"": \"")(\w*)', my_text)
print (extract_posted_data)
</code></pre>

<p>and it prints None </p>

<p>Thank you</p>
","9409695","","","how do i extract value inside quotes using regex python?","<python><regex><python-3.x>","4","1","459"
"49057900","2018-03-01 20:08:09","1","","<p>This is because your original code has an additional space. It should be:</p>

<pre><code>extract_posted_data = re.search(r'(\""posted_data\"":\"")(\w*)', my_text)
</code></pre>

<p>And in fact, <code>'\'</code> is unnecessary here. Just:</p>

<pre><code>extract_posted_data = re.search(r'(""posted_data"":"")(\w*)', my_text)
</code></pre>

<p>Then:</p>

<pre><code>extract_posted_data.group(2)
</code></pre>

<p>is what you want.</p>

<pre><code>&gt;&gt;&gt; my_text = '""posted_data"":""2e54eba66f8f2881c8e78be8342428xd"",""isropa"":false,""rx"":""NO"",""readal"":""false""'
&gt;&gt;&gt; extract_posted_data = re.search(r'(""posted_data"":"")(\w*)', my_text)   
&gt;&gt;&gt; extract_posted_data.group(2)
'2e54eba66f8f2881c8e78be8342428xd'
</code></pre>
","8605791","9409695","2018-03-01 21:12:47","4","735","llllllllll","2017-09-13 21:41:23","14078","1653","562","12957","49057818","49057900","2018-03-01 20:03:40","2","79","<p>My text is </p>

<pre><code>my_text = '""posted_data"":""2e54eba66f8f2881c8e78be8342428xd"",""isropa"":false,""rx"":""NO"",""readal"":""false""'
</code></pre>

<p>I am trying to extract value of <code>posted_data</code> which is <code>2e54eba66f8f2881c8e78be8342428xd</code> </p>

<p>My code :</p>

<pre><code>extract_posted_data = re.search(r'(\""posted_data\"": \"")(\w*)', my_text)
print (extract_posted_data)
</code></pre>

<p>and it prints None </p>

<p>Thank you</p>
","9409695","","","how do i extract value inside quotes using regex python?","<python><regex><python-3.x>","4","1","459"
"49057904","2018-03-01 20:08:40","0","","<p>Recently playing with sockets myself an I ran into the same problem. What you should do is encode any data you are sending to the receiver and decode any data that you are receiving at the client.</p>

<p>so you should use something to the affect of <code>chunk = self.socket.recv(n - len(data)).decode()</code></p>

<p>on the sending side you should encode as such: <code>socket.send(data.encode())</code></p>
","7496663","","","2","414","Adam  M.","2017-01-31 18:19:31","389","35","196","12","49057834","49057904","2018-03-01 20:04:29","0","69","<p>I need to write a tcp client that runs in the background. I found an interesting class that does exactly what I need at this link: <a href=""https://eli.thegreenplace.net/2011/05/18/code-sample-socket-client-thread-in-python"" rel=""nofollow noreferrer"">Code sample - socket client thread</a>. I'd like to implement it in my project because I find it to be better than the examples in the standard library or the modules in <a href=""https://pymotw.com/3/socket/tcp.html#choosing-an-address-for-listening"" rel=""nofollow noreferrer"">PyMOTW-3</a>. Problem is, it is written in Python2 and I keep getting an error with this method:</p>

<pre><code>def _recv_n_bytes(self, n):
    data = ''
    while len(data) &lt; n:
        chunk = self.socket.recv(n - len(data))
        print(chunk)
        if chunk == '':
            break
        data += chunk
    return data
</code></pre>

<p>During my research I've come to realize that Py2 and Py3 have a different behavior as to string interpretation. So I've tried basically any combination of decoding/encoding('UTF-8') the 'data' or the 'chunk', but somehow I end always end up at this line <code>chunk = self.socket.recv(n - len(data))</code>, where I get a generic 'MemoryError' (no further description)!</p>

<p>Does anyone know what's going on? Or alternatively, can anyone suggest me a ready-made class to set up a separate thread for a tcp client connection?</p>

<p>Thanks.</p>
","9206839","","","converting a tcp client socket class from python2 to python3","<python><sockets>","1","0","1429"
"49057921","2018-03-01 20:09:53","0","","<p>In Python everything is an object. But you don't need to specify classes to everything. Some objects have their types (classes) hard-defined in the language core - that is the case for functions, integers, float, lists, dictionaries, strings and the like</p>

<p>So, whether you define a function inside a module or use a native function from some 3rd party package or from the builtins module, the function's type is ""FunctionType"" - which never needs to be declared explicitly.</p>

<p>And more related with your doubt: functions do not need to be related to any class - they are objects on their own, and the syntax of adding an optional list of arguments enclosed in mandatory parenthesis after their name calls them.</p>

<p>So just like C, Javascript, etc... you can create very complexes programs in Python with never defining a class.</p>

<p>Functions defined inside class bodies, on the other hand, are used as methods when retrieved through an instance of that class (or through the class if they are classmethods). That is Python 3 - Python 2 would be more complicated: functions defined inside a class body retrieved though the class itself are ""unbound methods"" - another object type.</p>

<p>And finally, the is a special module in Python called  <code>__builtins__</code>, which is populated by the Python runtime itself. Any name you try to use in a section of code is checked to be in one of these contexts: local context, nonlocal (outer closure for nested functions), global (variables, functions and classes defined at module level), or builtin (it is present in the <code>__builtins__</code> module).</p>

<p>There are a few functions and several classes defined in <code>__builtins__</code> which allow one to write fairly complete Python code without the need for any imports:</p>

<pre><code>&gt;&gt;&gt; dir(__builtins__)
['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BufferError', 'BytesWarning', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EnvironmentError', 'Exception', 'False', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'NameError', 'None', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'ReferenceError', 'RuntimeError', 'RuntimeWarning', 'StandardError', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', '_', '__debug__', '__doc__', '__import__', '__name__', '__package__', 'abs', 'all', 'any', 'apply', 'basestring', 'bin', 'bool', 'buffer', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'cmp', 'coerce', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'execfile', 'exit', 'file', 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'intern', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'long', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'quit', 'range', 'raw_input', 'reduce', 'reload', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'unichr', 'unicode', 'vars', 'xrange', 'zip']
</code></pre>

<p>So, what you type in a Python module is either a statement, one of the names above, or have to be declared prior to be used in some form (with an <code>=</code> statement, or though the use of <code>import</code>, or even a function with the <code>def</code> statement).</p>

<p>As a final advice, since you are learning Python you probably don't have a legacy codebase in Python 2 around there: you should be learning Python 3. It makes a lot of things simpler, and contains  more than 9 years of innovations  over Python 2, which will cease to be maintained 2 years from now. </p>
","108205","","","0","4198","jsbueno","2009-05-16 17:35:21","62274","3753","2414","235","49023982","","2018-02-28 07:20:05","0","59","<p>I noticed that some functions, for example <code>sorted</code>, can be called without specifying the instance they belong to - just like some function <code>f</code> I would define in my own class and won't need to specify that I'm calling them from my class.</p>

<p>Where do these functions belong and how does this hierarchy work?</p>
","9391576","3001761","2018-03-03 09:02:52","Calling a function in Python - no class specified?","<python><python-2.7><python-internals>","1","6","341"
"49057937","2018-03-01 20:11:35","1","","<p>I suggest that you keep a list of strings, rather than a multi-dimensional list.  Just a couple of simple changes:</p>

<pre><code># Initialize empty rails
dataRails = [""""] * rails
...
        if activeRail == count:
            dataRails[activeRail] += m
        else:
            dataRails[activeRail] += '.'
</code></pre>

<p>I tested with ""We Are Dis"":</p>

<pre><code>W...A... ...s...
.e...r...D..
.. ...e...i.
</code></pre>

<p>Now you can deal with removing non-letters and properly reversing direction.
Is that good for now?</p>
","4785185","","","1","540","Prune","2015-04-14 00:37:53","54183","8845","3232","13592","49056200","49057937","2018-03-01 18:17:26","0","55","<p>I have this method:</p>

<pre><code>def encode(message, rails):
    result = """"
    dataRails = []
    activeRail = 0
    # allocate multi-dimensional array...seems inefficient
    for r in range(rails):
        dataRails.append([])

    # copy characters from message into one of the arrays, or .
    for m in message:
        count = 0
        # for each rail either give it the character or a .
        while count &lt;= rails:
            print(""Count: "", str(count), "" Active Rail:"", str(activeRail))
            if activeRail == count:
                dataRails[activeRail][count] = m
            else:
                dataRails[activeRail][count] = "".""
            count += 1

        activeRail += 1
        if activeRail &gt;= rails:
            activeRail = 0

    for r in dataRails:
        print(r)
    # ill calculate result once I get the above right    
    return result
</code></pre>

<p>Message is a string of text.  Rails is a number.  The <code>encode</code> method would be called like this:</p>

<pre><code>encode('XOXOXOXOXOXOXOXOXO', 2)
</code></pre>

<p>In this case, I want to allocate my dataRails as 2 elements, each the same length as input message.  I would replace elements in the arrays with either a letter from message or a ""."".</p>

<p>But, it seems rather inefficient to use a loop to allocate dataRails.</p>

<p>When I run this, I get the following error:</p>

<pre><code>dataRails[activeRail][count] = m
IndexError: list assignment index out of range
</code></pre>

<p>The print statement looks like valid index values:</p>

<pre><code>Count:  0  Active Rail: 0
</code></pre>

<p>It feels like there are two problems with my multi-dimensional array.  1) allocation and 2) access.</p>

<p>If there is a duplicate question, please post a link. I searched through stackoverflow.  Answers that seemed relevant relied on a library, which I did not want to use. I have just started learning python and want to learn the basics of python, not using libraries.</p>

<p>Are arrays really that difficult in python or did I make it more difficult than it needs to me?</p>

<p>Thanks
Matt</p>

<p><strong>Edit</strong>:
Ultimately, if the message input was this ""WE ARE DIS"", the return of this method would be ""WEERDSAI"". I am working through a tutorial on <a href=""http://exercism.io/exercises/python/rail-fence-cipher/readme"" rel=""nofollow noreferrer"">exercism.io</a>.  I haven't completed the method yet. I am stuck on the array I defined.</p>
","535867","10012683","2019-01-08 16:20:42","How do I manipulate a multi dimension array in a python not using a library?","<python>","1","5","2478"
"49057960","2018-03-01 20:12:59","0","","<p>This will do it for your samples, did not try it with big lists.The intermediate powersets get gigantic, so might not be the right choice:</p>

<pre><code>from itertools import chain,product,islice

l1 = [10318, 6032,1518, 4061, 4380, 73160, 83607, 9202, 28812, 40359, 28457, 
 3292, 2678, 8492, 7149, 19417, 7372, 8534, 3889, 11123, 8415, 5989]

l2 = [5760, 1541, 2085, 637,1518, 4061, 4380, 73160, 83607, 9202, 28812, 40359, 
 28457, 3292, 2678, 8492, 7149, 19417, 7372, 8534, 3889, 11123]

# not really a receipt - but inspired by partition and powerset
# from https://docs.python.org/3/library/itertools.html#itertools-recipes
def powerskiptakeset(iterab): 
    """"""Creates non-empty partitions of a given iterable in existing order 
       from len(1) to len(iterab). 

    Example: 
        [1,2,3,4] --&gt; {(1,), (2,), (3,), (4,), (1, 2), (2, 3), (3, 4),
                       (1, 2, 3), (2, 3, 4),  (1, 2, 3, 4)}""""""
    s = list(iterab)
    return set(chain.from_iterable([tuple(islice(s, start, stop))] for 
                               start,stop in product(range(len(s)+1),range(len(s)+1)) 
                               if start &lt; stop))


l1_set = powerskiptakeset(l1)   
l2_set = powerskiptakeset(l2)

core = max( l1_set&amp; l2_set, key=lambda coll: len(coll))

print(list(core))
</code></pre>

<p>Output:</p>

<pre><code>[1518, 4061, 4380, 73160, 83607, 9202, 28812, 40359, 28457, 3292, 
 2678, 8492, 7149, 19417, 7372, 8534, 3889, 11123]
</code></pre>

<hr>

<p>For a <code>rage(300)</code> the resulting set has 45150 elements. You can tune that by f.e. restrincting the powerskiptakeset's to a min lenght 25% of the input iterables length:</p>

<pre><code>from itertools import chain,product,islice

def powerskiptakeset_25perc(iterab): 
    """"""Creates non-empty partitions of a given iterable in order of len(iterab)//4 to len(iterab)

    [1,2,3,4] --&gt; set([(1, 2), (1, 2, 3, 4), (1,), (2,), (3,), (1, 2, 3), (2, 3), (2, 3, 4), (4,), (3, 4)])""""""

    s = list(iterab)
    return set(chain.from_iterable([tuple(islice(s, start, stop))] for 
                               start,stop in product(range(len(s)+1),range(len(s)+1)) 
                               if start &lt; stop and stop-start &gt;= len(iterab)//4))

print(len(powerskiptakeset_25perc(range(300))))
</code></pre>

<p>which drops the amount of tuples in the set down to about 25k.</p>
","7505395","7505395","2018-03-01 20:44:29","2","2383","Patrick Artner","2017-02-02 10:46:51","30736","5120","3506","4713","49057494","","2018-03-01 19:42:05","-3","50","<p>I am searching for an efficient way to find core patterns in two different lists, I'll explain:</p>

<p>List 1:</p>

<pre><code>[10318, 6032,1518, 4061, 4380, 73160, 83607, 9202, 28812, 40359, 28457, 
 3292, 2678, 8492, 7149, 19417, 7372, 8534, 3889, 11123, 8415, 5989]
</code></pre>

<p>List 2:</p>

<pre><code>[5760, 1541, 2085, 637,1518, 4061, 4380, 73160, 83607, 9202, 28812, 40359, 
 28457, 3292, 2678, 8492, 7149, 19417, 7372, 8534, 3889, 11123]
</code></pre>

<p>The two lists could have more than 300 elements, the similar elements in each list is statisticaly very large each time (probably more than 60%)</p>

<p>My goal, find the point where the ""core"" start in each list.
A new list come every 5 minutes and will be compared to the previous one. 
What I am interested in is the part that is not the core. In other word I need to retrieve the start of the list up until the core (that was identified) of the previous list. </p>

<p>Efficiency is the key, new list each 5 minutes, but hundreds parallels processing.</p>

<p>Any algo or math way or solution will help :)</p>

<p>I hope I was precise in my request</p>
","2462626","7505395","2018-03-01 19:43:22","Python 3.6 - find core pattern in two list","<python><list>","1","6","1130"
"49057964","2018-03-01 20:13:30","1","","<p><code>replace</code> + <code>concat</code></p>

<pre><code>d=dict(zip(['Ex','Gd','TA','Fa','Po'], [5, 4, 3, 2, 1]))
df.replace(d)
Out[848]: 
      A   B  C  D
0   0.5   5  5  1
1  35.0   4  3  4
2  52.0   3  2  5
3  47.0  Bd  1  4
pd.concat([df,df.iloc[:,1:].replace(d).add_suffix('_New')],1).sort_index(1)
Out[849]: 
      A     B B_New   C  C_New   D  D_New
0   0.5     Ex     5  Ex      5  Po      1
1  35.0     Gd     4  TA      3  Gd      4
2  52.0     TA     3  Fa      2  Ex      5
3  47.0     Bd    Bd  Po      1  Gd      4
</code></pre>
","7964527","","","0","549","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49057589","49057696","2018-03-01 19:48:52","0","357","<p>I'm a newbie to python so please bear with me. I have a data frame where I want to replace values for specific strings. Below is my starting df (df_train):</p>

<pre><code>       A    B     C     D
0     .5   Ex    Ex    Po
1     35   Gd    TA    Gd
2     52   TA    Fa    Ex
3     47   Bd    Po    Gd
</code></pre>

<p>I can easily replace the values I'd like and create a new df(df_train_scaled), per below:</p>

<pre><code>df_train_scaled = df_train.replace(['Ex','Gd','TA','Fa','Po'], [5, 4, 3, 2, 1])
</code></pre>

<p>I'm curious if I should do this and go to a new df(df_train_scaled) to continue data pre-processing before modeling, or if I should create a new column in the same df (df_train). Regardless of the answer, I do want to figure out how to add a new column to the same df with the replaced values. Output below:</p>

<pre><code>       A    B   B_new  C   C_new   D   D_new
0     .5   Ex     5    Ex     5    Po    1
1     35   Gd     4    TA     3    Gd    4
2     52   TA     3    Fa     2    Ex    5
3     47   Gd     4    Po     1    Gd    4
</code></pre>

<p>If I do this, I can experiment to see if my ordinal, or scaled, variables will perform better in my modeling efforts. Thanks in advance for any help!</p>
","7096399","","","Pandas - create new column with replaced values while keeping original column","<python><pandas><replace><data-processing>","2","0","1240"
"49057992","2018-03-01 20:15:19","1","","<p>You have two versions of Python added to path.  To differentiate between 2.7 and 3.6 you have to tell it which version you want otherwise each pip conflicts with the other (it does not know what to install and where) in other words you type <code>pip</code> you could either mean for Python 2 or for Python 3. </p>

<p>Do not rename <code>pip</code> it will break your system (you should not need to rename).  Instead use those <a href=""https://stackoverflow.com/questions/2812520/pip-dealing-with-multiple-python-versions"">already provided.</a>.  </p>

<p>Your system should have these already:</p>

<p><code>pip</code> is universal.  Best for one installation.</p>

<p><code>pip3</code> for Python 3.  Best to distinguish between Python 2 and 3</p>

<p><code>pip3.6</code> to distinguish between different Python 3 installations.</p>

<p>The same goes for Python 2 installation.</p>

<p><code>pip</code>, <code>pip2</code> and <code>pip2.7</code>.  </p>

<p>You need to use either <code>pip3</code> (or <code>pip2</code>) or <code>pip3.6</code> (or <code>pip2.7</code>) to install in future.  This will allow the different versions to be recognised:</p>

<p>For Python 2:</p>

<pre><code>pip2 install seaborn
</code></pre>

<p>For Python 3:</p>

<pre><code>pip3 install seaborn
</code></pre>

<hr>

<p>You should also now use shebang lines as well now (if you are not already) to distinguish between versions.</p>
","8372104","8372104","2018-03-01 21:12:23","4","1419","Simon","2017-07-26 19:03:27","6383","1766","5398","222","49057888","","2018-03-01 20:07:39","1","7972","<p>I've seen many threads about this, and have tried all options except for completely wiping Python off of my machine and re-downloading everything...</p>

<p>I'm using a Windows 10, 64-bit machine, and had already downloaded Python2.7. Commands like 'C:\>pip install seaborn' were not an issue.</p>

<p>I recently downloaded Python3.6, and now my pip will not work - it returns the error in the title.</p>

<p>I have added <code>C:\Python27, C:\Python36, C:\Python27\Scripts, C:\Python36\Scripts</code> to my Path, and still it won't work.</p>

<p>If I type in the command <code>C:\&gt;python27 -m pip install seaborn</code>, however, the pip works. I am really confused why I can no longer just type in pip install  and have it work.</p>

<p>Thanks in advance!</p>
","9430920","8372104","2018-03-01 20:24:05","Pip error: Fatal error in launcher: Unable to create process using '""'","<python><python-3.x><python-2.7><pip><python-3.6>","4","0","768"
"49058011","2018-03-01 20:17:04","1","","<p>It turns out the exception handling put it into object mode.</p>

<p>Fixed as follows:</p>

<pre><code>@jit
def unique_in_sorted(arr):
    result = np.empty_like(arr)
    count_out =_unique_in_sorted(arr, result)
    result.resize(count_out)
    return result

@jit(nopython=True)
def _unique_in_sorted(arr, result):
    result[0] = arr[0]
    last_out = arr[0]
    count_out = 1
    for i in range(len(arr)):
        a = arr[i]
        # if a&lt;last_out:
        #     raise Exception(""Input not sorted: {} .. {}"".format(last_out, a))
        if last_out!=a:
            result[count_out] = a
            last_out = a
    return count_out
</code></pre>
","48956","","","1","658","user48956","2008-12-24 19:29:33","5458","718","590","42","49057801","","2018-03-01 20:02:38","1","51","<p>I'm experimenting with numba as a replacement some of our cython code.</p>

<p>Here:</p>

<pre><code>@jit
def unique_in_sorted(arr):
    result = np.empty_like(arr)
    result[0] = arr[0]
    last_out = arr[0]
    count_out = 1
    for i in range(len(arr)):
        a = arr[i]
        if a&lt;last_out:
            raise Exception(""Input not sorted: {} .. {}"".format(last_out, a))
        if last_out!=a:
            result[count_out] = a
            last_out = a

    return result.resize(count_out)
</code></pre>

<p>... I find that the above runs about the same speed as vanilla  python.</p>

<pre><code>def test_unique_in_sorted(self):
    unsorted = np.random.random_integers(0, 200, 1000000)
    a = np.sort(unsorted)
    for x in range(10):
        with timed(""unique_in_sorted""):
            r = unique_in_sorted(a)
    unique_in_sorted.inspect_types()
</code></pre>

<p>Looking about the output of inspect_types it seems that all of the local variables are python objects, not typed C values. For example in the inspect_types output we have:</p>

<pre><code>#   $0.12 = getitem(index=$const0.11, value=arr)  :: pyobject
#   last_out = $0.12  :: pyobject

last_out = arr[0]
</code></pre>

<p>which makes me think last_out is treated as a pyobject, not the int64 in arr.</p>

<p>Is there are way to optimize the above so it runs at a similar speed to an equivalent cython implementation?</p>

<p>Here's the full output of inspect_types.</p>

<pre><code>unique_in_sorted (array(int64, 1d, C),)
--------------------------------------------------------------------------------
# File: /home/user1/py/fast_ops.py
# --- LINE 142 --- 
# label 0
#   del $0.1
#   del $0.2
#   del $0.4
#   del $const0.6
#   del $const0.9
#   del $0.7
#   del $const0.11
#   del $0.12
#   del $const0.13

@jit

# --- LINE 143 --- 

def unique_in_sorted(arr):

    # --- LINE 144 --- 
    #   arr = arg(0, name=arr)  :: pyobject
    #   $0.1 = global(np: &lt;module 'numpy' from '/usr/local/lib/python2.7/dist-packages/numpy/__init__.pyc'&gt;)  :: pyobject
    #   $0.2 = getattr(attr=empty_like, value=$0.1)  :: pyobject
    #   $0.4 = call $0.2(arr, kws=[], args=[Var(arr, /home/user1/py/fast_ops.py (144))], func=$0.2, vararg=None)  :: pyobject
    #   result = $0.4  :: pyobject

    result = np.empty_like(arr)

    # --- LINE 145 --- 
    #   $const0.6 = const(int, 0)  :: pyobject
    #   $0.7 = getitem(index=$const0.6, value=arr)  :: pyobject
    #   $const0.9 = const(int, 0)  :: pyobject
    #   result[$const0.9] = $0.7  :: pyobject

    result[0] = arr[0]

    # --- LINE 146 --- 
    #   $const0.11 = const(int, 0)  :: pyobject
    #   $0.12 = getitem(index=$const0.11, value=arr)  :: pyobject
    #   last_out = $0.12  :: pyobject

    last_out = arr[0]

    # --- LINE 147 --- 
    #   $const0.13 = const(int, 1)  :: pyobject
    #   count_out = $const0.13  :: pyobject
    #   jump 45
    # label 45

    count_out = 1

    # --- LINE 148 --- 
    #   jump 48
    # label 48
    #   $48.1 = global(range: &lt;built-in function range&gt;)  :: pyobject
    #   $48.2 = global(len: &lt;built-in function len&gt;)  :: pyobject
    #   $48.4 = call $48.2(arr, kws=[], args=[Var(arr, /home/user1/py/fast_ops.py (144))], func=$48.2, vararg=None)  :: pyobject
    #   del $48.2
    #   $48.5 = call $48.1($48.4, kws=[], args=[Var($48.4, /home/user1/py/fast_ops.py (148))], func=$48.1, vararg=None)  :: pyobject
    #   del $48.4
    #   del $48.1
    #   $48.6 = getiter(value=$48.5)  :: pyobject
    #   del $48.5
    #   $phi64.1 = $48.6  :: pyobject
    #   del $48.6
    #   jump 64
    # label 64
    #   $64.2 = iternext(value=$phi64.1)  :: pyobject
    #   $64.3 = pair_first(value=$64.2)  :: pyobject
    #   $64.4 = pair_second(value=$64.2)  :: pyobject
    #   del $64.2
    #   $phi153.2 = $phi64.1  :: pyobject
    #   del $phi153.2
    #   $phi153.1 = $64.3  :: pyobject
    #   del $phi153.1
    #   $phi67.1 = $64.3  :: pyobject
    #   del $64.3
    #   branch $64.4, 67, 153
    # label 67
    #   del $64.4
    #   i = $phi67.1  :: pyobject
    #   del $phi67.1
    #   del i
    #   del $67.4
    # label 155
    #   del a
    #   del $119.3
    #   jump 64

    for i in range(len(arr)):

        # --- LINE 149 --- 
        #   $67.4 = getitem(index=i, value=arr)  :: pyobject
        #   a = $67.4  :: pyobject

        a = arr[i]

        # --- LINE 150 --- 
        #   $67.7 = a &lt; last_out  :: pyobject
        #   branch $67.7, 92, 119
        # label 92
        #   del result
        #   del count_out
        #   del arr
        #   del $phi64.1
        #   del $67.7
        #   del $const92.2
        #   del last_out
        #   del a
        #   del $92.3
        #   del $92.6
        #   del $92.1

        if a&lt;last_out:

            # --- LINE 151 --- 
            #   $92.1 = global(Exception: &lt;type 'exceptions.Exception'&gt;)  :: pyobject
            #   $const92.2 = const(str, Input not sorted: {} .. {})  :: pyobject
            #   $92.3 = getattr(attr=format, value=$const92.2)  :: pyobject
            #   $92.6 = call $92.3(last_out, a, kws=[], args=[Var(last_out, /home/user1/py/fast_ops.py (146)), Var(a, /home/user1/py/fast_ops.py (149))], func=$92.3, vararg=None)  :: pyobject
            #   $92.7 = call $92.1($92.6, kws=[], args=[Var($92.6, /home/user1/py/fast_ops.py (151))], func=$92.1, vararg=None)  :: pyobject
            #   raise $92.7
            # label 119
            #   del $67.7

            raise Exception(""Input not sorted: {} .. {}"".format(last_out, a))

        # --- LINE 152 --- 
        #   $119.3 = last_out != a  :: pyobject
        #   branch $119.3, 131, 155
        # label 131
        #   del $119.3
        #   del a

        if last_out!=a:

            # --- LINE 153 --- 
            #   result[count_out] = a  :: pyobject

            result[count_out] = a

            # --- LINE 154 --- 
            #   last_out = a  :: pyobject
            #   jump 155
            # label 153
            #   del last_out
            #   del arr
            #   del $phi67.1
            #   del $phi64.1
            #   del $64.4
            #   jump 154
            # label 154
            #   del result
            #   del count_out
            #   del $154.2
            #   del $154.4

            last_out = a

        # --- LINE 155 --- 



    # --- LINE 156 --- 
    #   $154.2 = getattr(attr=resize, value=result)  :: pyobject
    #   $154.4 = call $154.2(count_out, kws=[], args=[Var(count_out, /home/user1/py/fast_ops.py (147))], func=$154.2, vararg=None)  :: pyobject
    #   $154.5 = cast(value=$154.4)  :: pyobject
    #   return $154.5

    return result.resize(count_out)
</code></pre>
","48956","48956","2018-03-01 20:09:26","Can infer or hint types of locals in numba?","<python><numba>","1","0","6680"
"49058046","2018-03-01 20:19:49","2","","<p>the issue is the ambiguity between the two <code>pip</code> that you've mentioned in the <code>Environments</code>. As you mentioned the issue only started occurring when you installed <code>python3</code> on the same system where <code>python2</code> was installed and both have <code>pip</code> and hence when you fire up <code>pip</code> in your <code>cmd</code>, Windows System isn't able to pick one out of the two. </p>

<p><strong>Why does your <code>C:&gt;python27 -m pip install seaborn</code> work?</strong>
Well it's quite simple, since you've mentioned the <code>python27</code> there, windows knows exactly which pip you're talking about.</p>

<hr>

<hr>

<h2>How to fix it?</h2>

<blockquote>
  <p>see the edits for this section. (I tried this, it didn't work) Removed it from the final answer to avoid confusion.</p>
</blockquote>

<hr>

<p>Alternatively, what you can do is, </p>

<p>rename your python.exe for python 3 to python3. Don't forget to put it inside your PATH environment. Just use python for python 2, python3 for python 3.
Their pip are separated, pip for python 2. pip3 for python 3. </p>

<p>Now, run and see the below commands behave:</p>

<pre><code># will return the default version of pip
pip --version
# will use the Python 2 version of pip
pip2 --version
# will use the Python 3 version of pip
pip3 --version
</code></pre>
","3766231","3766231","2018-03-01 20:36:26","9","1364","iam.Carrot","2014-06-23 05:45:47","2549","547","208","77","49057888","","2018-03-01 20:07:39","1","7972","<p>I've seen many threads about this, and have tried all options except for completely wiping Python off of my machine and re-downloading everything...</p>

<p>I'm using a Windows 10, 64-bit machine, and had already downloaded Python2.7. Commands like 'C:\>pip install seaborn' were not an issue.</p>

<p>I recently downloaded Python3.6, and now my pip will not work - it returns the error in the title.</p>

<p>I have added <code>C:\Python27, C:\Python36, C:\Python27\Scripts, C:\Python36\Scripts</code> to my Path, and still it won't work.</p>

<p>If I type in the command <code>C:\&gt;python27 -m pip install seaborn</code>, however, the pip works. I am really confused why I can no longer just type in pip install  and have it work.</p>

<p>Thanks in advance!</p>
","9430920","8372104","2018-03-01 20:24:05","Pip error: Fatal error in launcher: Unable to create process using '""'","<python><python-3.x><python-2.7><pip><python-3.6>","4","0","768"
"49058112","2018-03-01 20:23:59","3","","<p>You can fiddle the dtype:</p>

<pre><code>&gt;&gt;&gt; a = np.arange(12).reshape(4, 3)
&gt;&gt;&gt; 
&gt;&gt;&gt; dt = a.dtype
&gt;&gt;&gt; 
&gt;&gt;&gt; ahead = a.view(np.dtype([('summary', dt), ('age', dt), ('label', dt)]))
&gt;&gt;&gt; 
&gt;&gt;&gt; ahead
array([[(0,  1,  2)],
       [(3,  4,  5)],
       [(6,  7,  8)],
       [(9, 10, 11)]],
      dtype=[('summary', '&lt;i8'), ('age', '&lt;i8'), ('label', '&lt;i8')])
&gt;&gt;&gt; ahead['summary']
array([[0],
       [3],
       [6],
       [9]])
</code></pre>

<p>But be warned that those composite dtype arrays are not very useful as far as I can tell:</p>

<pre><code>&gt;&gt;&gt; ahead @ ahead.T
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
TypeError: invalid data type for einsum
</code></pre>

<p>to give just one example.</p>
","7207392","","","0","833","Paul Panzer","2016-11-24 23:39:00","37645","7185","734","1","49057107","","2018-03-01 19:14:42","0","1073","<p>I have a numpy.ndarray having dimensions of 23411 x 3.
I would like to add headers to the top of the matrix called: ""summary"", ""age"", and ""label"". In that order. </p>

<p>In:</p>

<pre><code>matrix.shape
</code></pre>

<p>Out:</p>

<pre><code>(23411L, 3L)
</code></pre>

<p>In:</p>

<pre><code>type(matrix)
</code></pre>

<p>Out:</p>

<pre><code>numpy.ndarray
</code></pre>

<p>I tried using the numpy.recarray but it did not work. any suggestions??</p>
","8778033","8778033","2018-03-01 19:19:23","how to add headers to a numpy.ndarray","<python><numpy>","4","1","457"
"49058152","2018-03-01 20:26:28","1","","<p>You got 2 parameter <code>O_m</code> and <code>M</code> which you set a range for them. but you got <code>[:,2]</code> here. 2 is for 3 parameters! we start from 0 not 1. this is Numpy.
then you want to define 3 out put for your code! <code>m_mcmc, b_mcmc, f_mcmc</code>
this must be 2 outputs not three. I am not sure what are m and b and f. but I know one one them must be removed.
Then you got the answer.</p>
","8339406","","","1","416","Ethan","2017-07-20 15:35:45","141","46","37","3","49052387","","2018-03-01 14:55:45","0","158","<p>I have the following code which is about constraining the parameters.
I get this error when I run the code:</p>

<p><code>samples[:, 2] = np.exp(samples[:, 2])
IndexError: index 2 is out of bounds for axis 1 with size 2</code></p>

<p>Any Help Please, How should I do to fix this error? I appreciate your help and your attention
 import numpy as np
    import emcee
    import matplotlib.pyplot as plt
    from math import *
    import numpy as np
    from scipy.integrate import quad
    from scipy.integrate import odeint</p>

<pre><code>xx=np.array([0.01,0.012,0.014,0.016])    #or xx=[0.01.......]
yy=np.array([32.95388698,33.87900347,33.84214074,34.11856704])
Cov=[[137,168],[28155,-2217]]     
#Initial points
rc=0.09, c=0.7, H01 = 70, O_m1 = 0.31, z0=0, M=1, O_m = 0.31, H0=70
np.random.seed(123)

def ant(z,O_m,O_D):          # first function   
    return 1/sqrt(((1+z)**2)*(1+O_m*z)-z*(2+z)*O_D)

def new_calculation(n):        
    O_D=1-O_m
    q=quad(ant,0,xx[n],args=(O_m,O_D))[0]     #using the first function in integration
    h=log10((1+xx[n])*q)   
   fn=(yy[n]-M-h)
   return fn

def log_likelihood(theta):    
    M, O_m= theta
    f_list = []
    for i in range(2):  # the value '2' reflects matrix size
                f_list.append(new_calculation(i))
    rdag=[f_list]
    rmat=[[f] for f in f_list]
    mm=np.dot(rdag,Cov)
    zz=np.dot(mm,rmat)
    hh=np.linalg.det(zz)*0.000001
    return hh          #calculation of matrix


   from scipy.optimize import minimize
np.random.seed(42)
nll = lambda *args: -log_likelihood(*args)
initial = np.array([M, O_m1]) + 0.1*np.random.randn(2)
soln = minimize(nll, initial)
M_ml, O_m0_ml = soln.x

def log_prior(theta):
    M, O_m= theta
    if  0.22 &lt; O_m &lt; 0.32 and 0 &lt; M &lt; 12:
        return 0.0
    return -np.inf

def log_probability(theta):
    lp = log_prior(theta)
    if not np.isfinite(lp):
        return -np.inf
    return lp + log_likelihood(theta)

pos = soln.x + 1e-4*np.random.randn(80, 2)
nwalkers, ndim = pos.shape
sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability)
sampler.run_mcmc(pos, 250);
samples = sampler.chain[:, 50:, :].reshape((-1, ndim))
from IPython.display import display, Math
samples[:, 2] = np.exp(samples[:, 2])         #the error may be resulted from here
m_mcmc, b_mcmc, f_mcmc = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),
                         zip(*np.percentile(samples, [16, 50, 84],
                                            axis=0)))
print(m_mcmc, b_mcmc)
</code></pre>
","8926947","","","index 2 is out of bounds","<python><index-error><emcee>","1","5","2513"
"49058156","2018-03-01 20:26:36","2","","<p>You can use <code>session.expire_on_commit = False</code> so session will be available for next usage.</p>

<p>You can also set this parameter on <code>scoped_session</code> init.</p>

<p>For more information: <a href=""http://docs.sqlalchemy.org/en/latest/orm/session_api.html?highlight=expire_on_commit#sqlalchemy.orm.session.Session.params.expire_on_commit"" rel=""nofollow noreferrer"">Session API</a></p>
","2474573","","","1","409","Deniz Kaplan","2013-06-11 12:48:07","516","68","13","2","49018283","49058156","2018-02-27 21:33:04","0","2467","<p>I haven't too much experience with Python and sqlalchemy.
I checked that similar questions asked before but still i couldn't solve my problem. 
I have a standalone pooling pgbouncer.  And i'm trying to use sqlalchemy front of pgbouncer. for the don't leave connections open i tried to use contextmanager and with statement.  I think my mistake in get_db_session() method. But still couldn't find.</p>

<p>this is my repository.py</p>

<pre><code>import logging
import threading
from contextlib import contextmanager

import sqlalchemy
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, scoped_session
from sqlalchemy.orm.exc import NoResultFound
from sqlalchemy.pool import StaticPool
from sqlalchemy.pool import NullPool


@contextmanager
def get_db_session():
    try:
        engine = create_engine(
            'postgresql://superuser:@localhost:6432/testdbname', poolclass=NullPool)
        session_factory = sessionmaker(bind=engine)
        Session = scoped_session(session_factory)
        some_session = Session()
        print ""got new session""
        yield some_session
        print ""after yield goingt to commit""
        some_session.commit()
    except Exception as ex:
        print(ex)
        some_session.roleback()
    finally:
        some_session.expunge_all()
        some_session.close()
        print ""closing""


def save(entity, _clazz=None):
    if _clazz:
        if hasattr(entity, 'id'):  # usually id is None so this method acs as normal save
            _id = entity.id
        else:
            _id = entity.name
        try:
            if _id:
                found = find(_clazz, _id)
                if found is not None:
                    if isinstance(found, list):
                        for e in found:
                            delete(e)
                    else:
                        delete(found)
        except NoResultFound:
            pass

    with get_db_session() as se:
        se.add(entity)
        se.commit()

def delete(entity):
    with get_db_session() as se:
        se.delete(entity)
        se.commit()

def find_by_element_value(_clazz, element, value):
    with get_db_session() as se:
        res = se.query(_clazz).filter(element == value).all()
        se.commit()
    return res

def get_all(_class):
    print ""get_all starte""
    with get_db_session()  as se:
        print ""entered with""
        res = se.query(_class).all()
        print ""going to commit""
        se.commit()
    return res
</code></pre>

<p>and here Im using it test.py</p>

<pre><code>import repositories as repository 
import model 

if __name__ == '__main__':
    a = repository.get_all(model.HomeCategory)
    a[0].slug
</code></pre>

<p>then i get this error . Where is my mistake i could not understand.</p>

<pre><code>Traceback (most recent call last):
  File ""/home/sahin/workspace/myspider/myspider/spiders/test.py"", line 6, in &lt;module&gt;
    a[0].slug
  File ""/usr/local/lib/python2.7/dist-packages/sqlalchemy/orm/attributes.py"", line 237, in __get__
    return self.impl.get(instance_state(instance), dict_)
  File ""/usr/local/lib/python2.7/dist-packages/sqlalchemy/orm/attributes.py"", line 579, in get
    value = state._load_expired(state, passive)
  File ""/usr/local/lib/python2.7/dist-packages/sqlalchemy/orm/state.py"", line 592, in _load_expired
    self.manager.deferred_scalar_loader(self, toload)
  File ""/usr/local/lib/python2.7/dist-packages/sqlalchemy/orm/loading.py"", line 644, in load_scalar_attributes
    (state_str(state)))
DetachedInstanceError: Instance &lt;HomeCategory at 0x7f157008dd90&gt; is not bound to a Session; attribute refresh operation cannot proceed
</code></pre>

<p>Maybe someone give a help about this. 
Thanks.</p>
","971796","","","DetachedInstanceError: Instance <HomeCategory > is not bound to a Session; attribute refresh operation cannot proceed","<python><sqlalchemy>","1","1","3744"
"49058223","2018-03-01 20:30:57","1","","<p>In signup/forms.py</p>

<p>Change:</p>

<p><code>user=super(User,self).save(commit=False)</code></p>

<p>To</p>

<p><code>user = super(allusers1, self).save(commit=False)</code></p>

<p>And read some articles on coding style. Like <a href=""https://www.python.org/dev/peps/pep-0008/"" rel=""nofollow noreferrer"">PEP-8</a> and <a href=""https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/"" rel=""nofollow noreferrer"">Django style</a>. It helps others (and your future self) to read and understand your code.</p>
","991572","991572","2018-03-02 08:59:44","3","545","allcaps","2011-10-12 13:46:41","8158","383","230","34","49058127","49058223","2018-03-01 20:24:38","0","1509","<p>I am making a registration form for users to signup using Django 1.8 and python 3.5</p>

<p>I have created a User(Extending User Model Using a Custom Model Extending AbstractUser)(ie I wanted to add custom fields to the default django's Users table like bio, date of birth etc)</p>

<p>When I try to enter username and password I get an error TypeError at /signup/</p>

<p>This  is my <code>mainpage/models.py</code></p>

<pre><code>from django.db import models
from django.contrib.auth.models import AbstractUser

class User(AbstractUser):
    bio = models.TextField(max_length=500, blank=True)
    location = models.CharField(max_length=30, blank=True)
    birth_date = models.DateField(null=True, blank=True)
</code></pre>

<p>This is my <code>signup/forms.py</code></p>

<pre><code>from django import forms
from mainpage.models import User
from django import forms
from django.contrib.auth.forms import UserCreationForm
class allusers1(forms.Form):
    username1=forms.CharField(label = ""Username"")
    password1=forms.CharField(label=""passwordwa"",max_length=40)
    class Meta:
        model=User
        fields=(
            'username',

            'password',

        )
    def save(self,commit=True):
        user=super(allusers1,self).save(commit=False)
        user.username=self.cleaned_data['username1']
        user.password=self.cleaned_data['password1']
        if commit:
            user.save()

        return user
</code></pre>

<p>this is <code>signup/views.py</code></p>

<pre><code>from django.shortcuts import render
from .forms import allusers1
def signup(request):       
    form1=allusers1(request.POST or None)
    if form1.is_valid():
        form1.save()
    context = {
   ""form1"": form1,
         }
    return render(request, ""signup.html"",context)
</code></pre>

<p><strong>SOME ADDITIONAL INFO</strong>
I am refering to this blog for creating AbstractUser  <a href=""https://simpleisbetterthancomplex.com/tutorial/2016/07/22/how-to-extend-django-user-model.html#abstractuser"" rel=""nofollow noreferrer"">https://simpleisbetterthancomplex.com/tutorial/2016/07/22/how-to-extend-django-user-model.html#abstractuser</a></p>

<p><strong>Traceback</strong>
    Environment:</p>

<pre><code>Request Method: POST
Request URL: http://localhost:8000/signup/

Django Version: 1.8
Python Version: 3.5.4
Installed Applications:
('django.contrib.admin',
 'django.contrib.auth',
 'django.contrib.contenttypes',
 'django.contrib.sessions',
 'django.contrib.messages',
 'django.contrib.staticfiles',
 'mainpage',
 'signup',
 'login',
 'currency',
 'rest_framework',
 'corsheaders')
Installed Middleware:
('django.contrib.sessions.middleware.SessionMiddleware',
 'corsheaders.middleware.CorsMiddleware',
 'django.middleware.common.CommonMiddleware',
 'django.middleware.csrf.CsrfViewMiddleware',
 'django.contrib.auth.middleware.AuthenticationMiddleware',
 'django.contrib.auth.middleware.SessionAuthenticationMiddleware',
 'django.contrib.messages.middleware.MessageMiddleware',
 'django.middleware.clickjacking.XFrameOptionsMiddleware',
 'django.middleware.security.SecurityMiddleware')


Traceback:
File ""C:\Users\vaibhav2\AppData\Local\Programs\Python\Python35\lib\site-packages\django\core\handlers\base.py"" in get_response
  132.                     response = wrapped_callback(request, *callback_args, **callback_kwargs)
File ""C:\Users\vaibhav2\PycharmProjects\MajorProject\src\signup\views.py"" in signup
  13.         form1.save()
File ""C:\Users\vaibhav2\PycharmProjects\MajorProject\src\signup\forms.py"" in save
  26.         user=super(allusers1,self).save(commit=False)

Exception Type: AttributeError at /signup/
Exception Value: 'super' object has no attribute 'save'
</code></pre>
","9364941","9364941","2018-03-01 20:49:33","'super' object has no attribute 'save' Django","<python><django>","1","0","3713"
"49058228","2018-03-01 20:31:15","1","","<p>I am assuming you are using the Keras <a href=""https://keras.io/utils/#to_categorical"" rel=""nofollow noreferrer""><code>to_categorical</code></a> method which computes a one-hot encoding matrix such that each row is the one-hot encoded label of a training sample.  In that case, your comparison is not correct.  You need to first find where the elements are not equal, then impose that if any of them are not correct, you write out the image to file.</p>

<p>Therefore, first find all positions where the one-hot encoding vector do not correspond to each other: <code>y_pred[i] != y_test[i]</code> and only then do you impose the <code>any</code> method on it that checks for any elements that aren't equal <code>(y_pred[i] != y_test[i]).any()</code>.  This means your <code>if</code> statement needs to change:</p>

<pre><code>for i in range(0, len(y_test)):
    if (y_pred[i] != y_test[i]).any(): # Change
        image = x_test_copy[i]
        path = 'path'
        cv2.imwrite(os.path.join(path , str(i)+'.jpg'), image)
</code></pre>
","3250829","3250829","2018-03-01 20:37:20","2","1040","rayryeng - Reinstate Monica","2014-01-29 21:44:22","88164","17081","7428","3044","49058179","49058228","2018-03-01 20:28:05","1","334","<p>I'm training a CNN on a large dataset of images with two classes, and I've done one hot encoding to my validation classes (y_test):</p>

<pre><code>y_test = to_categorical(y_test, num_classes=2)
</code></pre>

<p>I want to compare these with the predictions my classifier makes, which I've also one hot encoded like:</p>

<pre><code>y_pred = model.predict_classes(x_test)
y_pred = to_categorical(y_pred, num_classes=2)
</code></pre>

<p>What I want to accomplish with this comparison is to find where my classifier has made a mistake, and to save the image that's been classified incorrectly in a new folder. But I don't think I'm doing the comparison right at all:</p>

<pre><code>for i in range(0, len(y_test)):
if y_pred[i].any() != y_test[i].any():
    image = x_test_copy[i]
    path = 'path'
    cv2.imwrite(os.path.join(path , str(i)+'.jpg'), image)
</code></pre>

<p>Does somebody know what I am doing wrong?</p>
","7812497","3250829","2018-03-01 20:40:14","How to compare two one hot encoded lists?","<python><opencv><machine-learning><keras><one-hot-encoding>","1","6","924"
"49058296","2018-03-01 20:35:57","0","","<p>It sounds like you enabled the telnet client application in Windows 10, the command <code>telnet localhost 135</code> attempts to connect to an already running telnet server running on localhost port 135.  There was no output as I am guessing it did not successfully connect to anything.</p>

<p>You most likely need a telnet server, which appears to have been deprecated from recent versions of Windows due to being terribly insecure.  Microsoft recommends replacing telnet with Remote Desktop</p>
","7111761","","","2","502","GracefulRestart","2016-11-03 19:08:09","621","42","6","2","49058169","","2018-03-01 20:27:22","0","261","<p>I am trying to send ""Hello Word!"" to localhost using telnetlib in python3.5. My code:</p>

<pre><code>import telnetlib

HOST = ""127.0.0.1""

tn = telnetlib.Telnet(HOST, 135) # host, port, timeout

tn.write(""Hello World!"".encode('ascii'))
</code></pre>

<p>I have enabled telnet in my windows 10. I went to cmd and ran:</p>

<pre><code>telnet localhost 135
</code></pre>

<p>I then got a blank screen:
<a href=""https://i.stack.imgur.com/f2jDW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/f2jDW.png"" alt=""enter image description here""></a></p>

<p>After that I ran my code and it just simply finishes in 0.3s. There is no output in the terminal. It just stay blank. Why didn't ""Hello World!"" come up on the telnet cmd? What is happening? I'm new with this.</p>

<p>EDIT:</p>

<p>Just tried netcat client. Still doesn't work.</p>

<p><a href=""https://i.stack.imgur.com/kNQv9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kNQv9.png"" alt=""enter image description here""></a></p>
","6288172","6288172","2018-03-01 20:55:33","Telnet client not receiving. Python telnetlib as server","<python><python-3.x><localhost><telnet><telnetlib>","1","0","1018"
"49058317","2018-03-01 20:37:18","1","","<p>I suspect the problem is to do with contour labels, which are known not to work well in Cartopy (see <a href=""https://github.com/SciTools/cartopy/issues/13"" rel=""nofollow noreferrer"">https://github.com/SciTools/cartopy/issues/13</a> and <a href=""https://github.com/SciTools/cartopy/issues/327"" rel=""nofollow noreferrer"">https://github.com/SciTools/cartopy/issues/327</a>). If you remove the labels the contours should render correctly.</p>
","1867427","","","2","443","ajdawson","2012-11-30 20:15:21","1759","90","16","3","49048411","","2018-03-01 11:10:53","1","365","<p>I am trying to plot contours over the north pole, using cartopy. I have used add_cyclic_point and this has successfully filled in the gap at the prime meridian in pcolormesh, but the contours do not cross successfully, and instead wrap all the way around the globe to connect (but it seems not always?) My longitudes go from 0-360 and I have tried to switch to -180-180 but still get the same issue.</p>

<p>Here is my code:</p>

<pre><code>import numpy as np
from netCDF4 import Dataset
import cartopy.crs as ccrs
import cartopy
from cartopy.util import add_cyclic_point as cycpt
import matplotlib.pyplot as plt


date = '2018_02_10'
pdatafile = Dataset(date+'_mslp.nc')
plat = np.array(pdatafile.variables['lat'])
plon = np.array(pdatafile.variables['lon'])
p = np.array(pdatafile.variables['slp'][0,:,:])

p_cyclic,lon_cyclic = cycpt(p,coord=plon)
lon_cyclic = np.ma.getdata(lon_cyclic)

plon2d,plat2d= np.meshgrid(lon_cyclic,plat)
p_cyclic = np.ma.getdata(p_cyclic)

g1000datafile = Dataset(date+'_1000mb_gph.nc')
g1lat = np.array(g1000datafile.variables['lat'])
g1lon = np.array(g1000datafile.variables['lon'])
g1000 = np.array(g1000datafile.variables['hgt'][0,0,:,:])
g1_cyclic,g1lon_cyclic = cycpt(g1000,coord=g1lon)
g1lon2d,g1lat2d= np.meshgrid(g1lon_cyclic,g1lat)
g1lon2d = np.ma.getdata(g1lon2d)
g1_cyclic = np.ma.getdata(g1_cyclic)

g500datafile = Dataset(date+'_500mb_gph.nc')
g5lat = np.array(g500datafile.variables['lat'])
g5lon = np.array(g500datafile.variables['lon'])
g500 = np.array(g500datafile.variables['hgt'][0,0,:,:])
g5_cyclic,g5lon_cyclic = cycpt(g500,coord=g5lon)
g5lon2d,g5lat2d= np.meshgrid(g5lon_cyclic,g5lat)
g5lon2d = np.ma.getdata(g5lon2d)
g5_cyclic = np.ma.getdata(g5_cyclic)

thickness = g5_cyclic - g1_cyclic

mslplevels=[960,970,980,990,1000,1010,1020,1030,1040,1050]
levels500hPa = [470,480,490,500,510,520,530,540,550,560]

ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=0))
ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())
plt.pcolormesh(plon2d,plat2d,thickness/10, transform=ccrs.PlateCarre(),cmap='inferno')
cbar=plt.colorbar()
cbar.set_label('ReTop (gpdam)')
cs=plt.contour(plon2d,plat2d,g5_cyclic/10,colors='w',transform=ccrs.PlateCarree(),\
           levels=levels500hPa)
plt.clabel(cs,inline=1,fontsize=6,fmt='%3.0f')
ax.coastlines()
plt.show()
plt.close()
</code></pre>

<p><a href=""https://i.stack.imgur.com/RImUf.png"" rel=""nofollow noreferrer"">an example plot</a></p>

<pre><code>import numpy as np
from netCDF4 import Dataset
import cartopy.crs as ccrs
from cartopy.util import add_cyclic_point as cycpt
import matplotlib.pyplot as plt

pdatafile = Dataset('X158.39.88.89.59.7.59.32.nc')
plat = np.array(pdatafile.variables['lat'])
plon = np.array(pdatafile.variables['lon'])
p = np.array(pdatafile.variables['slp'][0,:,:])

p_cyclic,lon_cyclic = cycpt(p,coord=plon)
lon_cyclic = np.ma.getdata(lon_cyclic)
p_cyclic = np.ma.getdata(p_cyclic)

plon2d,plat2d= np.meshgrid(lon_cyclic,plat)

ax = plt.axes(projection=ccrs.NorthPolarStereo(central_longitude=0))
ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())
plt.contour(plon2d,plat2d,g5_cyclic/10,colors='w',transform=ccrs.PlateCarree())
plt.clabel(cs,inline=1,fontsize=6,fmt='%3.0f')
ax.coastlines()
plt.show()
</code></pre>

<p><a href=""ftp://ftp.cdc.noaa.gov/Public/www/X158.39.88.89.59.7.59.32.nc"" rel=""nofollow noreferrer"">ftp://ftp.cdc.noaa.gov/Public/www/X158.39.88.89.59.7.59.32.nc</a></p>
","8436147","3938208","2018-04-30 18:49:56","cartopy North Pole Stereographic contour plot does not plot correctly even with cyclic point","<python><map-projections><cartopy>","2","1","3436"
"49058328","2018-03-01 20:38:03","1","","<p>Convert each tuple to a <em>Row</em> object and then call <code>toDF</code> method; <code>Row(ID=t[0], **t[1])</code> pass the dictionary in the tuple as keyword arguments to each row, and use <code>ID = t[0]</code> to create a new key value pair with <code>ID</code> as the key:</p>

<pre><code>from pyspark.sql import Row
rdd.map(lambda t: Row(ID=t[0], **t[1])).toDF().show()
+---+------+---+---------+
|Age|Colour| ID| location|
+---+------+---+---------+
| 27|  Pink|991|Australia|
| 55| Black|993|Singapore|
| 12|  Blue|993|   Mexico|
| 24|   Red|994|      USA|
+---+------+---+---------+
</code></pre>
","4983450","5880706","2018-03-02 06:32:19","2","611","Psidom","2015-06-07 13:40:28","137976","6288","3736","111","49058182","49058328","2018-03-01 20:28:15","0","714","<p>I have processed some data in pyspark and it is an RDD that has this structure</p>

<pre><code>[(u'991', {'location': 'Australia', 'Age': '27', 'Colour': Pink}), (u'993', {'location': 'Singapore', 'Age': '55', 'Colour': Black}), (u'993', {'location': 'Mexico', 'Age': '12', 'Colour': Blue}), (u'994', {'location': 'USA', 'Age': '24', 'Colour': Red})]
</code></pre>

<p>How do I convert this structure into a Dataframe? My end goal is that I can store a hive table, with 4 columns (ID (i.e. 991,), Location, Age, Colour)</p>

<p>The Row solution does not seem to work given that the dictionary is within a tuple</p>
","3703912","3703912","2018-03-02 01:41:10","PySpark RDD to dataframe with list of tuple and dictionary","<python><dictionary><apache-spark><dataframe><rdd>","1","0","618"
"49058375","2018-03-01 20:41:57","2","","<p>This is basically the same answer as helloV in the case you use <code>Session</code> as I'm doing.</p>

<pre><code>from boto3.session import Session
import settings

session = Session(aws_access_key_id=settings.AWS_ACCESS_KEY_ID,
                          aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY)
s3 = session.resource(""s3"")

get_last_modified = lambda obj: int(obj.last_modified.strftime('%s'))


bckt = s3.Bucket(""my_bucket"")
objs = [obj for obj in bckt.objects.all()]

objs = [obj for obj in sorted(objs, key=get_last_modified)]
last_added = objs[-1].key
</code></pre>

<p>Having <code>objs</code> sorted allows you to quickly delete all files but the latest with</p>

<pre><code>for obj in objs[:-1]:
    s3.Object(""my_bucket"", obj.key).delete()
</code></pre>
","4819376","","","0","780","rpanai","2015-04-22 12:16:39","3144","437","1374","8","45375999","","2017-07-28 14:27:28","5","12455","<p>The other questions I could find were refering to an older version of Boto. I would like to download the latest file of an S3 bucket. In the <a href=""http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.list_object_versions"" rel=""noreferrer"">documentation</a> I found that there is a method list_object_versions() that gets you a boolean IsLatest. Unfortunately I only managed to set up a connection and to download a file. Could you please show me how I can extend my code to get the latest file of the bucket? Thank you</p>

<pre><code>import boto3
conn = boto3.client('s3',
                    region_name=""eu-west-1"",
                    endpoint_url=""customendpoint"",
                    config=Config(signature_version=""s3"", s3={'addressing_style': 'path'}))
</code></pre>

<p>From here I dont know how to get the latest added file from a bucket called <code>mytestbucket</code>. There are various csv files in the bucket but all of course with a different name.</p>

<p>Update:</p>

<pre><code>import boto3
from botocore.client import Config

s3 = boto3.resource('s3', region_name=""eu-west-1"", endpoint_url=""custom endpoint"", aws_access_key_id = '1234', aws_secret_access_key = '1234', config=Config(signature_version=""s3"", s3={'addressing_style': 'path'}))
my_bucket = s3.Bucket('mytestbucket22')
unsorted = []
for file in my_bucket.objects.filter():
   unsorted.append(file)

files = [obj.key for obj in sorted(unsorted, key=get_last_modified, reverse=True)][0:9]
</code></pre>

<p>This gives me the following error:</p>

<pre><code>NameError: name 'get_last_modified' is not defined
</code></pre>
","3080315","3080315","2017-07-28 15:31:41","How to download the latest file of an S3 bucket using Boto3?","<python><amazon-web-services><amazon-s3><boto><boto3>","5","0","1632"
"49058378","2018-03-01 20:42:20","3","","<p>Yes, you should add the <code>transform</code> keyword to the <code>plot</code> call. You should also specify the coordinate system you want to set the extents in:</p>

<pre><code>def plotpt(ax, extent=(-15,15,46,62)):
    ax.plot(mypt[0], mypt[1], 'r*', ms=20, transform=ccrs.PlateCarree())
    ax.set_extent(extent, crs=ccrs.PlateCarree())
    ax.coastlines(resolution='50m')
    ax.gridlines(draw_labels=True)
</code></pre>

<p>A basic guide on transforms and projections is now available in the cartopy documentation <a href=""http://scitools.org.uk/cartopy/docs/latest/tutorials/understanding_transform.html"" rel=""nofollow noreferrer"">http://scitools.org.uk/cartopy/docs/latest/tutorials/understanding_transform.html</a>. To avoid surprises, you should <em>always</em> specify a transform when plotting data on a map.</p>
","1867427","","","1","829","ajdawson","2012-11-30 20:15:21","1759","90","16","3","49053816","49058378","2018-03-01 16:03:25","1","564","<p>In the  following example, I am losing my point (i.e., I don't understand the change in coordinates) if I am using the <code>ccrs.Mercator()</code> projection instead of the <code>ccrs.PlateCarree()</code>:</p>

<pre><code>import matplotlib.pyplot as plt
import cartopy.crs as ccrs

mypt = (6, 56)

ax0 = plt.subplot(221, projection=ccrs.PlateCarree()) # OK
ax1 = plt.subplot(222, projection=ccrs.Mercator())    # NOT OK
ax2 = plt.subplot(224, projection=ccrs.Mercator())    # NOT OK

def plotpt(ax, extent=(-15,15,46,62)):
    ax.plot(mypt[0], mypt[1], 'r*', ms=20)
    ax.set_extent(extent)
    ax.coastlines(resolution='50m')
    ax.gridlines(draw_labels=True)

plotpt(ax0)
plotpt(ax1)
plotpt(ax2, extent=(-89,89,-89,89))

plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/BpR1a.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BpR1a.png"" alt=""enter image description here""></a></p>

<p>It looks like the coordinates of my point go from (6,56) to (0,0)
What am I missing? 
Why is the behaviour correct with <code>ccrs.PlateCarree()</code> and not with <code>ccrs.Mercator()</code>? Should I add any transform somewhere?</p>

<hr>

<p>[<em>EDIT with the solution</em>]</p>

<p>My initial confusion came from the fact that <code>projection</code> applies to the plot, while <code>transform</code> applies to the data, meaning they should be set different when they do not share the same system - my first attempts with <code>transform</code> where wrong as in <code>ax1</code> below, <code>ax1bis</code> is the solution.</p>

<pre><code>import matplotlib.pyplot as plt
import cartopy.crs as ccrs

mypt = (6, 56)

ax0 = plt.subplot(221, projection=ccrs.PlateCarree())
ax1 = plt.subplot(222, projection=ccrs.Mercator())
ax1bis = plt.subplot(223, projection=ccrs.Mercator())
ax2 = plt.subplot(224, projection=ccrs.Mercator())

def plotpt(ax, extent=(-15,15,46,62), **kwargs):
    ax.plot(mypt[0], mypt[1], 'r*', ms=20, **kwargs)
    ax.set_extent(extent)
    ax.coastlines(resolution='50m')
    ax.gridlines(draw_labels=True)
    ax.xaxis.set_ticks_position('bottom')
    ax.yaxis.set_ticks_position('left')

plotpt(ax0) # correct because projection and data share the same system
plotpt(ax1, transform=ccrs.Mercator()) # WRONG
plotpt(ax1bis, transform=ccrs.PlateCarree()) # Correct, projection and transform are different!
plotpt(ax2, extent=(-89,89,-89,89), transform=ccrs.Mercator()) # WRONG

plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/bNBnl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bNBnl.png"" alt=""enter image description here""></a></p>
","2050686","2050686","2018-03-06 13:56:03","Adapting coordinates in cartopy depending on the projection of a plot","<python><python-2.7><cartopy>","1","0","2621"
"49058407","2018-03-01 20:44:38","4","","<p>What that for loop does is loop over <code>s1</code>. For every iteration it assigns an element of iterable container <code>s1</code> to variable <code>char1</code>.</p>

<p>Therefore, on the first iteration of the loop <code>for char1 in s1</code>, <code>char1</code> will have the string value <code>'m'</code>, on the second iteration string value <code>'i'</code>.</p>

<p>Note that even after the loop has finished executing, <code>char1</code> will still have a value assigned (the last iteration means it will have value <code>'k'</code>).</p>

<p>What your iterating over doesn't have to be a string, it can be any object that defines <code>__iter__</code> and <code>__next__</code> methods. So some examples are a list <code>[1,2,3]</code> or a generator like what is returned by function invokation <code>range(5)</code>.</p>
","797744","797744","2018-03-01 20:50:45","1","839","DBedrenko","2011-06-14 13:34:09","2738","491","2167","785","49058382","49058407","2018-03-01 20:42:34","1","66","<p>I came across code like this:</p>

<pre><code>s1 = ""mit u rock""
s2 = ""i rule mit""
if len(s1) == len(s2):
    for char1 in s1:
        for char2 in s2:
            if char1 == char2:
                print(""common letter"")
                break
</code></pre>

<p>I notice there are no previous defines for the variable like <code>char1</code> or <code>char2</code>, so how does this work? I think it might be some ""keyword for a variable"" that Python understands. If so, could you tell me what's it called, and what are other common variables like this?</p>
","9185955","797744","2018-03-01 20:54:30","How do the variables in a `for` statement get defined?","<python><for-loop>","1","3","559"
"49058439","2018-03-01 20:47:35","1","","<p>You might try the following:</p>

<pre><code>from collections import Counter

def common_words(words, number_of_words, reverse=False):
    counter = Counter(words)
    return sorted(counter, key = counter.get, reverse=reverse)[:number_of_words]
</code></pre>

<p>Here we make sure that the Counter dictionary is sorted by its value. After the sort, we return the least most words. Here is a test example:</p>

<pre><code>words = []
for i,num in enumerate('one two three four five six seven eight nine ten'.split()):
    words.extend([num]*(i+1))

print(common_words(words,5))
</code></pre>

<p>This example got the 5 least common words from your list of words.</p>

<p>Results:</p>

<pre><code>['one', 'two', 'three', 'four', 'five']
</code></pre>

<p>We can also get the most common words:</p>

<pre><code>print(common_words(words,5, reverse=True))
</code></pre>

<p>Results:</p>

<pre><code>['ten', 'nine', 'eight', 'seven', 'six']
</code></pre>
","6233386","6233386","2018-03-01 20:52:43","0","951","Mike Peder","2016-04-21 03:40:45","604","60","66","8","49058353","","2018-03-01 20:39:26","1","308","<p>I have done the counter of most common words to keep only the 128 most common words in my list in order:</p>

<pre><code>words = my_list
mcommon_words = [word for word, word_count in Counter(words).most_common(128)]
my_list = [x for x in my_list if x in mcommon_words]
my_list = OrderedDict.fromkeys(my_list)
my_list = list(my_list.keys())
</code></pre>

<p>But now I want to count the 128 less common words in the same way. A faster solution would help me a lot too</p>
","4104459","","","less common words in a python list","<python><list><counter>","2","1","474"
"49058457","2018-03-01 20:49:00","2","","<p><code>most_common</code> returns the words and their counts as a list of tuples. Furthermore, <a href=""https://docs.python.org/3/library/collections.html#collections.Counter.most_common"" rel=""nofollow noreferrer"">if no argument is given, it returns all the words</a>.</p>

<p>The fact that the method returns a list means that you can use slicing to get the first and last <code>n</code> elements.</p>

<p>Demo:</p>

<pre><code>l = list(""asadfabsdfasodfjoasdffsafdsa"")
sorted_items = [w for w, _ in Counter(l).most_common()]

print(sorted_items[:2])  ## Print top 2 items
print(sorted_items[-2:]) ## Print last 2 items
</code></pre>
","9310553","9310553","2018-03-01 21:02:03","0","636","nisemonoxide","2018-02-03 21:08:39","441","36","10","10","49058353","","2018-03-01 20:39:26","1","308","<p>I have done the counter of most common words to keep only the 128 most common words in my list in order:</p>

<pre><code>words = my_list
mcommon_words = [word for word, word_count in Counter(words).most_common(128)]
my_list = [x for x in my_list if x in mcommon_words]
my_list = OrderedDict.fromkeys(my_list)
my_list = list(my_list.keys())
</code></pre>

<p>But now I want to count the 128 less common words in the same way. A faster solution would help me a lot too</p>
","4104459","","","less common words in a python list","<python><list><counter>","2","1","474"
"49058499","2018-03-01 20:52:09","1","","<p>as others have mentioned json would be a better tool for this data but you can also use this regex (I added a \s* in case in the future there are spaces in between): </p>

<p>regex: <code>""posted_data"":\s*""(?P&lt;posted_data&gt;[^""]+)""</code></p>

<pre><code>import re

my_text = '""posted_data"":""2e54eba66f8f2881c8e78be8342428xd"",""isropa"":false,""rx"":""NO"",""readal"":""false""'
m = re.search(r'""posted_data"":\s*""(?P&lt;posted_data&gt;[^""]+)""', my_text)
if m:
    print(m.group('posted_data'))
</code></pre>
","1132603","","","0","505","Totoro","2012-01-05 16:22:26","641","55","9","0","49057818","49057900","2018-03-01 20:03:40","2","79","<p>My text is </p>

<pre><code>my_text = '""posted_data"":""2e54eba66f8f2881c8e78be8342428xd"",""isropa"":false,""rx"":""NO"",""readal"":""false""'
</code></pre>

<p>I am trying to extract value of <code>posted_data</code> which is <code>2e54eba66f8f2881c8e78be8342428xd</code> </p>

<p>My code :</p>

<pre><code>extract_posted_data = re.search(r'(\""posted_data\"": \"")(\w*)', my_text)
print (extract_posted_data)
</code></pre>

<p>and it prints None </p>

<p>Thank you</p>
","9409695","","","how do i extract value inside quotes using regex python?","<python><regex><python-3.x>","4","1","459"
"49058502","2018-03-01 20:52:18","0","","<p>To execute a command, you can use the os library. Executing the command you've shown above is as simple as:</p>

<pre><code>import os
os.system('ipconfig /displaydns')
</code></pre>

<p>If you want to store the output of a command in a variable, you can use:</p>

<pre><code>x = os.popen('ipconfig /displaydns')
</code></pre>
","2714050","","","0","329","Daniel O'Brien","2013-08-24 17:26:46","73","13","28","0","49058273","","2018-03-01 20:34:15","-1","109","<p>Using Python, is there a way using psutil or something else to return the output of ""ipconfig /displaydns"" or something similar?</p>

<p>Spawning a cmd process and running the command is not an option.</p>
","1314011","","","Using python how to display dns","<python><python-2.7><psutil>","2","0","209"
"49058504","2018-03-01 20:52:27","0","","<p>I think it would work if you made your list variable a list:</p>

<pre><code>list=[one, two, three]
for arr in list:
    arr=arr[2,1]+1
</code></pre>
","7111761","","","1","153","GracefulRestart","2016-11-03 19:08:09","621","42","6","2","49058472","49058581","2018-03-01 20:49:40","1","66","<p>Suppose i have 3 Numpy arrays containing floats with the following names: one two three.</p>

<p>Is it possible to refer to them in a for-loop in the following manner:</p>

<pre><code>list=one two three

for arr in list:
    arr=arr[2,1]+1
</code></pre>

<p>The above example obviously does not work but i was wondering if there is a way to do this?</p>
","8682794","","","Referring to arrays in a for-loop","<python><python-3.x><numpy><for-loop>","2","4","357"
"49058535","2018-03-01 20:54:37","0","","<p>After some trial and error, I found a working recipe:</p>

<pre><code>def fade(self, widget):
    self.effect = QGraphicsOpacityEffect()
    widget.setGraphicsEffect(self.effect)

    self.animation = QtCore.QPropertyAnimation(self.effect, b""opacity"")
    self.animation.setDuration(1000)
    self.animation.setStartValue(1)
    self.animation.setEndValue(0)
    self.animation.start()

def unfade(self, widget):
    self.effect = QGraphicsOpacityEffect()
    widget.setGraphicsEffect(self.effect)

    self.animation = QtCore.QPropertyAnimation(self.effect, b""opacity"")
    self.animation.setDuration(1000)
    self.animation.setStartValue(0)
    self.animation.setEndValue(1)
    self.animation.start()
</code></pre>

<p>I guess you can call it on any widget. I call it on QLabel. For example:</p>

<pre><code>self.fade(self._your_widget_here_)
# or
self.unfade(self._your_widget_here_)
</code></pre>

<p>It will fadein or fadeout your widget.</p>
","529663","","","0","953","lenooh","2010-12-03 17:16:00","6813","210","2489","5","48191399","48192704","2018-01-10 16:00:31","2","1309","<p>I'm currently trying to fade a specific QLabel in and out. My first try was to use the setAlphaChannel, however this just didn't work.
My current approach is to use a for-loop and set the stylesheet of the QLabel. Sadly this makes a unverifiable bug, sometimes the fading works properly, sometimes the QLabel doesn't fade out but is fading in and more random stuff. For me the problem is untraceable.</p>

<p>Here is my current code:</p>

<pre><code>def fade_greeting(self, foo, bar):
    for i in range(255, -1, -5):
        print(i)
        string = ""font : 45px; font : bold; color : rgba(220, 220, 220, "" + str (i) + ""); font-family : HelveticaNeue-UltraLight""
        time.sleep(0.2)
        self.greeting_text.setStyleSheet(string)


    time.sleep(2)
    self.greeting_text.setText(greeting())
    time.sleep(2)

    for i in range(0, 256, 5):
        print(i)
        string = ""font : 45px; font : bold; color : rgba(220, 220, 220, "" + str (i) + ""); font-family : HelveticaNeue-UltraLight""
        time.sleep(0.2)
        self.greeting_text.setStyleSheet(string)
</code></pre>

<p>Is there something I missed? Or is there maybe a different approach to this problem?</p>

<p>Already thanks for your help!</p>
","9199439","6622587","2019-03-15 19:43:02","PyQt Fading a QLabel","<python><pyqt><qlabel>","2","1","1219"
"49058542","2018-03-01 20:55:12","2","","<p>Just use the <code>in</code> operator:</p>

<pre><code>print('some_key' in my_dict)
</code></pre>
","2422776","","","0","101","Mureinik","2013-05-26 17:34:48","199924","14860","8797","37764","49058503","","2018-03-01 20:52:23","2","53","<p>I was wondering the best way to find if a key exist in python dictionary, not visiting the whole list of keys again and again. I am thinking of try except. Is there any better way? </p>
","9431101","2422776","2018-03-01 21:02:49","Using try except to find if a key exist in dictionary","<python><dictionary><try-catch>","4","4","189"
"49058548","2018-03-01 20:56:13","1","","<p>General procedure: Move everything to the left side of the <code>=</code> so you get <code>stuff = 0</code>.  Replace all other variables with given values.  Make any simplifications possible, like replace <code>2.37 * 3.3</code> with <code>7.821</code>.  You now have an expression with one unknown variable.  Example: <code>exp(x) + 2.7*sin(x) -33</code>.  Make this into a function, with any necessary imports.</p>

<pre><code>from math import exp, sin
def f(x):
    return exp(x) + 2.7*sin(x) -33
</code></pre>

<p>Now look for a value of x that makes f(x) = 0.  Start by finding 2 values that make f both less and greater than 0.</p>

<pre><code>&gt;&gt;&gt; f(3)
-12.533439055050689
&gt;&gt;&gt; f(4)
19.554783295812832
</code></pre>

<p>At this point, you can use a bracketing root finder (scipy must have one) with 3 and 4 as the initial guesses, or continue by hand.  I would try 3.5 next, and then 3.25 or 3.75 depending on the sign of f(3.5).  As an exercise, you could write a function yourself that automates the binary search.</p>
","722804","","","0","1048","Terry Jan Reedy","2011-04-24 17:44:02","13264","2153","202","90","49058266","","2018-03-01 20:33:25","0","69","<p>Have an equation where I cannot get the variable I want to solve for onto only one side. I want to solve for that variable for given values of all the other variables in the equation.</p>

<p>For a simple example as clarification, suppose you couldn't get x onto only one side of the following equation even though you can:</p>

<p>sqrt(x)=(a/13)*log(b/x^2)</p>

<p>Since you can't get it onto one side, you can't define x as an expression - how would you solve for x (with given values of a and b) when x is an undefined variable?</p>
","8327674","8327674","2018-03-01 20:44:38","How to solve an inseparable equation when you cannot get the variable you're solving for onto one side? (Python)","<python>","2","4","539"
"49058581","2018-03-01 20:58:43","1","","<p>You need to specify where you'd like to save the value:</p>

<pre><code>arr[2,1] = arr[2,1] + 1
</code></pre>

<p>or just:</p>

<pre><code>arr[2,1] += 1
</code></pre>

<p>So the whole code becomes:</p>

<pre><code>import numpy as np
one = np.arange(6).reshape(3, 2)
two = np.arange(10).reshape(5, 2)
arrays = [one, two]
for arr in arrays:
    arr[2, 1] += 1
</code></pre>
","6419007","","","0","375","Eric Duminil","2016-06-03 10:18:21","43942","3113","4335","246","49058472","49058581","2018-03-01 20:49:40","1","66","<p>Suppose i have 3 Numpy arrays containing floats with the following names: one two three.</p>

<p>Is it possible to refer to them in a for-loop in the following manner:</p>

<pre><code>list=one two three

for arr in list:
    arr=arr[2,1]+1
</code></pre>

<p>The above example obviously does not work but i was wondering if there is a way to do this?</p>
","8682794","","","Referring to arrays in a for-loop","<python><python-3.x><numpy><for-loop>","2","4","357"
"49058583","2018-03-01 20:58:51","1","","<p>webapp2 has a built-in <code>redirect</code> method:</p>

<p><code>return redirect('/some-path')</code></p>

<p>However, I think you would probably rather send the gathered data to the <code>greetings.html</code> template?  Under the <code>POST</code> method, you could do:</p>

<pre><code>template_values = {
    'guestbook_name': guestbook_name,
    # etc.,
}

template = JINJA_ENVIRONMENT.get_template('greetings.html')
self.response.write(template.render(template_values))
</code></pre>
","3524613","3524613","2018-03-01 21:16:03","3","494","GAEfan","2014-04-11 16:43:08","6984","718","48","36","49053953","49058583","2018-03-01 16:10:24","0","72","<p>I'm working my way through Google's App Engine Guestbook example (to be found here: <a href=""https://cloud.google.com/appengine/docs/standard/python/getting-started/creating-guestbook"" rel=""nofollow noreferrer"">https://cloud.google.com/appengine/docs/standard/python/getting-started/creating-guestbook</a>)</p>

<p>I'm trying to redirect the output (the Greetings) to another page as opposed to the index.html where they're currently displayed after a user presses the ""Sign the Guestbook"" button. I created a separate page called greetings.html where I copied the display code from the index.html page. However, I don't know how to modify guestbook.py to make the output go to the new page.</p>
","9429926","5079316","2018-03-07 17:57:41","How can I redirect to a new page after submitting a form using Jinja template?","<python><google-app-engine><jinja2>","1","0","699"
"49058590","2018-03-01 20:59:38","1","","<p>The Pythonic way would be be to follow the <a href=""https://docs.python.org/3/glossary.html#term-eafp"" rel=""nofollow noreferrer"">EAFP</a> (Easier to Ask for Forgivenes than Permission) principle.</p>

<p>That means assuming the key is in the dict, and catching the exception if it's not, like so:</p>

<pre><code>my_dict = {""key"": ""value""}
try:
    print my_dict[""badkey""]
except KeyError:
    print ""No such key found""
</code></pre>
","797744","","","0","437","DBedrenko","2011-06-14 13:34:09","2738","491","2167","785","49058503","","2018-03-01 20:52:23","2","53","<p>I was wondering the best way to find if a key exist in python dictionary, not visiting the whole list of keys again and again. I am thinking of try except. Is there any better way? </p>
","9431101","2422776","2018-03-01 21:02:49","Using try except to find if a key exist in dictionary","<python><dictionary><try-catch>","4","4","189"
"49058591","2018-03-01 20:59:38","0","","<p>You can use gradient descent tools to solve it. Look here where they use tensorflow (maybe too much for the example but it is not bad to learn anyway): <a href=""https://medium.com/@liccowee/tensorflow-to-solve-simple-math-equation-27f42a44f0f1"" rel=""nofollow noreferrer"">https://medium.com/@liccowee/tensorflow-to-solve-simple-math-equation-27f42a44f0f1</a></p>
","1132603","","","0","365","Totoro","2012-01-05 16:22:26","641","55","9","0","49058266","","2018-03-01 20:33:25","0","69","<p>Have an equation where I cannot get the variable I want to solve for onto only one side. I want to solve for that variable for given values of all the other variables in the equation.</p>

<p>For a simple example as clarification, suppose you couldn't get x onto only one side of the following equation even though you can:</p>

<p>sqrt(x)=(a/13)*log(b/x^2)</p>

<p>Since you can't get it onto one side, you can't define x as an expression - how would you solve for x (with given values of a and b) when x is an undefined variable?</p>
","8327674","8327674","2018-03-01 20:44:38","How to solve an inseparable equation when you cannot get the variable you're solving for onto one side? (Python)","<python>","2","4","539"
"49058593","2018-03-01 20:59:45","4","","<p>If you don't like the repetition of <code>\t</code> in your code, you can use the fact:</p>

<pre><code>&gt;&gt;&gt; '\t' * 4 == '\t\t\t\t'
True
</code></pre>

<p>For consistent alignment of integers or floats you can use the following syntax:</p>

<pre><code>&gt;&gt;&gt; print('{:5d}'.format(100))
  100
</code></pre>

<p>Here you indicate how many characters you want an integer/float that you are inserting into a string to take. Since <code>100</code> is only 3 characters, it will be displayed with 2 leading whitespaces.</p>

<p>You can read more on formatting print statements <a href=""https://docs.python.org/3/tutorial/inputoutput.html"" rel=""nofollow noreferrer"">here</a>.</p>
","6929294","6929294","2018-03-01 21:40:13","2","690","Maxim Mikhaylov","2016-10-06 00:57:27","377","86","363","5","49058491","","2018-03-01 20:51:27","-2","37","<p>Here I have a dictionary of dictionaries I omitted them but I am trying to have each city print out the follow with with proper alignment when the user types into the console the correct name. So far I've just been using a lot of <code>\t</code>'s which is fine, but seems rather messy, maybe there is a better way to use the <code>\t</code>'s or something else. Here is my code:</p>

<pre><code>mydict = { 'Shenzhen' : {
    'Population': 14383936,
    'Category': 'want to visit',
    'Interesting Fact': 'was one of the fastest-growing cities in the world during the 1990s and the 2000s',
    'Geographic Coordinates': (22.542883, 114.062996)
            } }


if userInput == 'Shenzhen':
    print( '{0}:\t\t\t\t\t{1}'.format(""City Name"",""Shenzhen"") )
    print( ""{0}:\t\t\t\t\t{1}"".format( mydict['Shenzhen'].keys()[0], mydict['Shenzhen'].values()[0] ) )
    print( ""{0}:\t\t\t{1}"".format( mydict['Shenzhen'].keys()[1], mydict['Shenzhen'].values()[1] ) )
    print(""{0}:\t\t\t\t\t{1}"".format(""Longitude"", mydict['Shenzhen']['Geographic Coordinates'][0]))
    print(""{0}:\t\t\t\t\t{1}"".format(""Latitude"", mydict['Shenzhen']['Geographic Coordinates'][1]))
    print( ""{0}:\t\t\t\t\t{1}"".format( mydict['Shenzhen'].keys()[3], mydict['Shenzhen'].values()[3] ) )
</code></pre>

<p>I want it to print out evenly like:</p>

<pre class=""lang-none prettyprint-override""><code>City Name:     Shenzhen
Longitude:     2138530259
Latitude:      2302968049
Category:      Want to visit
</code></pre>

<p>and so on.</p>
","5451118","355230","2018-03-01 20:58:27","Is there a cleaner more organized or ""pythonic"" way for these print statements about a city?","<python>","1","1","1513"
"49058611","2018-03-01 21:00:49","0","","<p>So, the problem seems to have been that the file was being garbage collected, since the handle <code>lock_file</code> was not being used after the function. If the <code>return</code> statement is modified to <code>return lock_file</code> then the desired behaviour is achieved.</p>
","6437485","","","0","286","Gavin Kirby","2016-06-07 22:00:47","26","9","1","0","49048620","49058611","2018-03-01 11:22:00","0","458","<p>I am trying to define functions to ease the locking of files with the fcntl module. When I manually run </p>

<pre><code>fcntl.lockf(lock_file, fcntl.LOCK_EX | fcntl.LOCK_NB)
</code></pre>

<p>in two separate instances of Python, I get the expected exception</p>

<pre><code>BlockingIOError: [Errno 11] Resource temporarily unavailable
</code></pre>

<p>but when I define functions to automate this in <code>mylock.py</code>:</p>

<pre><code>import fcntl

def lock(filepath):
    lock_file = open(filepath, ""a"")
    try:
        fcntl.lockf(lock_file, fcntl.LOCK_EX | fcntl.LOCK_NB)
    except OSError or BlockingIOError:
        return False
    return True

def unlock(filepath):
    lock_file = open(filepath, ""a"")
    try:
        fcntl.lockf(lock_file, fcntl.LOCK_UN)
    except OSError or BlockingIOError:
        return False
    return True
</code></pre>

<p>and then import this into two separate python instances and do </p>

<pre><code>mylock.lock(""test.txt"")
</code></pre>

<p>which unexpectedly returns <code>True</code> in both instances. Is my error handling inappropriate? I have also tried <code>except IOError:</code>, <code>except Exception:</code> and <code>except:</code> -- I don't understand why the BlockingIOError raised when I run the fcntl commands in isolation doesn't cause the <code>except</code> logic to be executed.</p>
","6437485","3789550","2018-03-01 11:43:01","File locking in Python with fcntl","<python><exception-handling><locking><fcntl>","1","0","1356"
"49058628","2018-03-01 21:02:15","0","","<p>You just need to simply use the '+' operator to concatenate strings together, like so:</p>

<p>INPUT:</p>

<pre><code>x = 'How '
y = 'are'
z = ' you?'

print('Hello ' + 'there!\n' + x + y + z + '\nGreat!') 
</code></pre>

<p>OUTPUT:</p>

<pre><code>Hello there!
How are you?
Great!
</code></pre>
","8146556","","","0","299","rahlf23","2017-06-12 02:38:50","6078","662","435","19","49058564","","2018-03-01 20:57:10","-3","54","<p>I am very new to coding and I wanted to try and create a MadLib using Python. I've already created the inputs, but I can't figure out how to add multiple variables into one print syntax. </p>

<p><code>print(""Suddenly he grabs me. tipping me across his"", bodyPart1, adj1 ""movement, he angles his"", noun1 ""so my"", bodyPart2 ""is resting on the"", noun2 ""beside him"")</code></p>
","9431100","","","How to add multiple variables in text using python","<python>","3","2","378"
"49058643","2018-03-01 21:03:18","0","","<p><code>string1 = ""is""
string2 = ""some""
print(""This {} a {} with {} formatting."".format(string1, ""string"", string2)</code></p>

<p>returns </p>

<p>""This is a string with some formatting.""</p>

<p>Alternately: </p>

<p><code>print(""This "" + string1 + "" a string with "" + string2 + "" formatting."")</code></p>

<p>I like the first one better because it lets you keep track of spaces etc more easily.  </p>
","8766025","","","0","405","ChootsMagoots","2017-10-12 14:46:59","523","126","84","33","49058564","","2018-03-01 20:57:10","-3","54","<p>I am very new to coding and I wanted to try and create a MadLib using Python. I've already created the inputs, but I can't figure out how to add multiple variables into one print syntax. </p>

<p><code>print(""Suddenly he grabs me. tipping me across his"", bodyPart1, adj1 ""movement, he angles his"", noun1 ""so my"", bodyPart2 ""is resting on the"", noun2 ""beside him"")</code></p>
","9431100","","","How to add multiple variables in text using python","<python>","3","2","378"
"49058646","2018-03-01 21:03:23","0","","<p>As @Mureinik mentioned, you can just use:</p>

<pre><code>key_name in dict
</code></pre>

<p>to return either true or false. However, if you desperately wanted to use try and except, you could use:</p>

<pre><code>try:
    x = dict[key_name]
except KeyError:
    # Handle error here
</code></pre>
","2714050","","","0","300","Daniel O'Brien","2013-08-24 17:26:46","73","13","28","0","49058503","","2018-03-01 20:52:23","2","53","<p>I was wondering the best way to find if a key exist in python dictionary, not visiting the whole list of keys again and again. I am thinking of try except. Is there any better way? </p>
","9431101","2422776","2018-03-01 21:02:49","Using try except to find if a key exist in dictionary","<python><dictionary><try-catch>","4","4","189"
"49058652","2018-03-01 21:03:41","1","","<p>When creating multiple distinct models, you need to make sure they all receive unique variable names. The most straightforward way I can see here would be something like this:</p>

<pre><code>def neural_network_model(data, layer_sizes, name):
    num_layers = len(layer_sizes) - 1 # hidden and output layers
    layers = [] # hidden and output layers

    # initialise the weights
    for i in range(num_layers):
        with tf.variable_scope(name):
            layers.append({
                'weights': tf.get_variable(""W"" + str(i+1),
                           [layer_sizes[i], layer_sizes[i+1]], 
                           initializer = tf.contrib.layers.xavier_initializer()),
                'biases': tf.get_variable(""b"" + str(i+1), [layer_sizes[i+1]], 
                      initializer = tf.zeros_initializer())
            })
    ...
</code></pre>

<p>Note how there is an additional <code>name</code> argument to name your models. Then you could create multiple ones like </p>

<pre><code>model1 = neural_network_model(data, some_layers, ""model1"")
model2 = neural_network_model(data, other_layers, ""model2"")
</code></pre>

<p>etc. The models will have variable names such as ""model1/W0"". Note that you can also use <code>variable_scope</code> to name the parameters for the different layers. I.e. instead of using names such as <code>""W"" + str(i)</code> you could wrap a <code>tf.variable_scope(""layer"" + str(i))</code> around <code>get_variable</code>. This would give you names such as ""model1/layer0/W"". Scopes can be nested arbitrarily.</p>

<p>You might want to read <a href=""https://www.tensorflow.org/programmers_guide/variables"" rel=""nofollow noreferrer"">the TF Programmer's Guide on variables</a>.</p>
","9393102","9393102","2018-03-01 21:37:47","3","1727","xdurch0","2018-02-21 20:26:51","4479","386","399","1167","49058510","","2018-03-01 20:53:22","2","197","<p>I am trying to implement a deep neural network, where I want to experiment with the number of hidden layers. In order to avoid error-prone code repetition, I have placed the creation of the layers in a for-loop, as follows:</p>

<pre><code>def neural_network_model(data, layer_sizes):
    num_layers = len(layer_sizes) - 1 # hidden and output layers
    layers = [] # hidden and output layers

    # initialise the weights
    for i in range(num_layers):
        layers.append({
            'weights': tf.get_variable(""W"" + str(i+1),
                       [layer_sizes[i], layer_sizes[i+1]], 
                       initializer = tf.contrib.layers.xavier_initializer()),
             'biases': tf.get_variable(""b"" + str(i+1), [layer_sizes[i+1]], 
                       initializer = tf.zeros_initializer())
        })
        ...
</code></pre>

<p>The list <code>layer_sizes</code> given as input looks something like this:</p>

<pre><code>layer_sizes = [num_inputs, num_hl_1, num_hl_2, ..., num_hl_n, num_outputs]
</code></pre>

<p>When I ran this code for the first time I had no problems. However, when I changed <code>layer_sizes</code> to have a different number of layers, I got an error:</p>

<pre><code>ValueError: Variable W1 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope
</code></pre>

<p>I understand that this is because of the naming of the layers (which I don't even care about). How can I work around this and allow renaming when rerunning? I've done some googling and the solution seems to lie in the use of <code>with tf.variable_scope()</code>, but I can't figure out exactly how.</p>

<p>EDIT - Just to be clear: I do not want to reuse any names or variables. I just want to (re-)initialise the weights and biases every time <code>neural_network_model</code> is called.</p>
","7064415","7064415","2018-03-01 23:17:41","Unable to share/rename variable in TensorFlow","<python><variables><tensorflow><scope>","3","3","1846"
"49058659","2018-03-01 21:04:36","0","","<p>You could try:</p>

<pre><code>print(""Suddenly he grabs me. tipping me across his"", bodyPart1, adj1, ""movement, he angles his"", noun1, ""so my"", bodyPart2, ""is resting on the"", noun2, ""beside him"")
</code></pre>

<p>or</p>

<pre><code>print(""Suddenly he grabs me. tipping me across his"" + str(bodyPart1) + str(adj1) + ""movement, he angles his"" + str(noun1) + ""so my"" + str(bodyPart2) + ""is resting on the"" + str(noun2) + ""beside him"")
</code></pre>

<p>For case 1, you need to add comma after each ""word"" and variable.
2nd case is called string concatenation. I am enclosing the variables in <code>str()</code> to make sure that the variable type changes to string, thus allowing for concatenation.</p>

<p>Hope this helps.</p>
","1869715","","","0","730","Arun Das","2012-12-02 02:55:35","311","36","131","0","49058564","","2018-03-01 20:57:10","-3","54","<p>I am very new to coding and I wanted to try and create a MadLib using Python. I've already created the inputs, but I can't figure out how to add multiple variables into one print syntax. </p>

<p><code>print(""Suddenly he grabs me. tipping me across his"", bodyPart1, adj1 ""movement, he angles his"", noun1 ""so my"", bodyPart2 ""is resting on the"", noun2 ""beside him"")</code></p>
","9431100","","","How to add multiple variables in text using python","<python>","3","2","378"
"49058664","2018-03-01 21:04:59","4","","<p>You need to instantiate the class <code>MATRIX</code> like so, before you can use its instance methods:</p>

<pre><code>m = MATRIX()
z = m.add(X, Y)
</code></pre>

<p>But if there is no instance data, then there is not much point in having instance methods. In this case you can make the methods static, and not have to instantiate the class to make use of its methods:</p>

<pre><code>class MATRIX:

    # Note that `self` parameter is removed, as it's no longer an
    # instance method.
    @staticmethod
    def add(M1,M2):
         return M1 + M2

z = MATRIX.add(X, Y)
</code></pre>
","797744","797744","2018-03-01 21:10:15","2","591","DBedrenko","2011-06-14 13:34:09","2738","491","2167","785","49058586","49058664","2018-03-01 20:59:05","1","56","<p>I have a class:</p>

<pre><code> class MATRIX:

     # convenience function
     def getDimensions(self,M):
         r = len(M)
         c = len(M[0])
         return r,c

     def add(self,M1,M2):
         res = []
         r1,c1 = self.getDimensions(M1)
         r2,c2 = self.getDimensions(M2)
         if (r1 != r2) or (c1 != c2):
             print(""dimensions not the same"")
             return res

         for i in range(len(M1)):
             row=[]
             for j in range(len(M1[i])):
                 element=M1[i][j] + M2[i][j]
                 row.append(element)
             res.append(row)

    return res
</code></pre>

<p>Simple class, saves no state, just has a function which adds two matrices. I am a beginner at OOP in Python, so, unless I am wrong, all class functions must begin with a self parameter.</p>

<p>The function is meant to be called like:</p>

<pre><code> Z = MATRIX.add(X,Y)
</code></pre>

<p>Where X and Y are matrices</p>

<p>When I try to do this, I get the following error:</p>

<pre><code> Traceback (most recent call last):
   File ""temp.py"", line 82, in &lt;module&gt;
Z = MATRIX(X,Y)
 TypeError: object() takes no parameters
</code></pre>

<p>In this instance:</p>

<pre><code> X = [[1,1,1], [2,2,2], [3,3,3]]
 Y = [[4,4,4], [5,5,5], [6,6,6]]
</code></pre>

<p>Why is this error showing up? How can I fix it?</p>
","483281","","","Can't call class function in python (TypeError: object() takes no parameters)","<python><python-3.x><oop><matrix>","1","4","1366"
"49058743","2018-03-01 21:10:05","0","","<p>Try adding the pathex list to the spec file with a path to the root project directory.</p>

<pre><code>a = Analysis(['main.py']),
             pathex=['C:/Users/&lt;user&gt;/Path to the root directory'],
             # rest of spec file
</code></pre>

<p>Sometimes you need to add module locations to the pathex list.  This is a list of paths that pyinstaller will search first.</p>
","6594646","","","3","386","MalloyDelacroix","2016-07-15 14:22:43","1533","83","278","41","49057966","","2018-03-01 20:13:42","2","646","<p>Assume that this is my file structure: </p>

<pre><code>main.py
modules
  |--&gt; feature1.py
  |--&gt; feature2.py
  |--&gt; feature3.py
</code></pre>

<p>My <code>main.py</code> code is as following:</p>

<pre><code>from modules.feature1 import Awesomefeature
...
</code></pre>

<p>I used the following spec-file for <a href=""http://www.pyinstaller.org/"" rel=""nofollow noreferrer"">PyInstaller</a>:</p>

<pre><code># -*- mode: python -*-

block_cipher = None


a = Analysis(['main.py'],
             runtime_hooks=[],
             excludes=[],
             win_no_prefer_redirects=False,
             win_private_assemblies=False,
             cipher=block_cipher)
pyz = PYZ(a.pure, a.zipped_data,
             cipher=block_cipher)
exe = EXE(pyz,
          a.scripts,
          a.binaries,
          a.zipfiles,
          a.datas,
          name='main',
          debug=False,
          strip=False,
          upx=False,
          runtime_tmpdir=None,
          console=True , icon='icon.ico')
</code></pre>

<p>Unfortunately I get the following message after I compile my code to a windows executable and execute this (main.exe file):</p>

<pre><code>ModuleNotFoundError: no module named 'modules'
</code></pre>

<p>Is it completely impossible to have subfolders with pythoncode in it while using pyinstaller? </p>
","5989986","4099593","2019-05-26 19:36:33","Subfolders with python code pyinstaller","<python><python-3.x><pyinstaller><python-module>","1","2","1320"
"49058745","2018-03-01 21:10:11","2","","<p>What you can do is use the cluster centroids as well as the labels to index into the cluster centroids to get what each example is represented as.  You can then compute the distortion of each example separately.  Recall that the distortion or inertia of a K-Means clustering result is simply the sum of squared differences between an example and it's corresponding representative centroid.  To compute the individual distortion values, you simply find the representative centroid of each example, then find the sum of squared differences of the components.  The total distortion is the sum of all of these values.</p>

<p>Therefore:</p>

<pre><code>cluster_centers = km.cluster_centers_
centroids = cluster_centers[y_km]
distortion = ((df_tr_std - centroids)**2.0).sum(axis=1)
</code></pre>

<p>The first line of code accesses the cluster centres of your fitted K-means model.  The second line of code obtains the representative centroids per example using the labels output from the fit result.  With the last line, you can then compute the distortion by subtracting each row or example of your input and its representative centroid component wise, square each element, then sum along each row. </p>

<p>It may be convenient to do this in one line without the need for temporary variables:</p>

<pre><code>distortion = ((df_tr_std - km.cluster_centers_[y_km])**2.0).sum(axis=1)
</code></pre>

<p>This now gives you the computed distortion per example.  Concretely, <code>distortion</code> is a <code>N,</code> NumPy array with <code>N</code> being the number of examples in your dataset.  Each element corresponds to the distortion contributed by the corresponding example to the overall distortion.</p>

<p>To verify, you can check the <code>km.inertia_</code> which is the total distortion matches the sum of the distortion array computed in the last line, so check <code>distortion.sum()</code> and <code>km.inertia_</code>.</p>

<p>As a reproducible example:</p>

<pre><code>In [27]: import numpy as np

In [28]: from sklearn.cluster import KMeans

In [29]: df_tr_std = np.random.rand(1000,3)

In [30]: km = KMeans(n_clusters=3, init='k-means++',n_init=10,max_iter=300,tol=
    ...: 1e-04,random_state=0)

In [31]: y_km = km.fit_predict(df_tr_std)

In [32]: distortion = ((df_tr_std - km.cluster_centers_[y_km])**2.0).sum(axis=1)

In [33]: km.inertia_
Out[33]: 147.01626670004867

In [34]: distortion.sum()
Out[34]: 147.01626670004865
</code></pre>

<p>Take note that there are some slight differences towards the trailing end of the value and this is due to numerical precision, but you can assure yourself that we have computed the distortion of each example separately.</p>

<p>Once you have the array of distortions, you can add an additional column that represents these in your data frame and you can locate which row gave you the largest or smallest distortion as you wish.</p>
","3250829","3250829","2018-03-01 21:27:30","0","2893","rayryeng - Reinstate Monica","2014-01-29 21:44:22","88164","17081","7428","3044","49058507","49058745","2018-03-01 20:52:43","4","228","<p>Here's a little bit of the code:</p>

<pre><code>df_tr_std = stats.zscore(df_tr[clmns])

km = KMeans(n_clusters=3, init='k-means++',n_init=10,max_iter=300,tol=1e-04,random_state=0)
y_km = km.fit_predict(df_tr_std)
</code></pre>

<p>I tried referencing inertial_ but that's the total distortion. This following code works to calculate the individual distances:</p>

<pre><code>distance = euclidean_distances(km.cluster_centers_, df_tr_std)
</code></pre>

<p>but it separates the distances into 3 arrays (or however many number of clusters I create). Is there a way to do this without separating by labels/cluster?</p>

<p>I would like to extend my original dataset with a column of the distances so that I can identify the largest distances. I also wanted the closest distances but I was able to find that using this code:</p>

<pre><code>closest, _ = pairwise_distances_argmin_min(km.cluster_centers_, df_tr_std)
</code></pre>
","9431086","3250829","2018-03-01 21:17:22","Is there a way to output the distortions for each row when creating clusters with kmeans?","<python><machine-learning><scikit-learn><k-means>","1","0","930"
"49058750","2018-03-01 21:10:49","1","","<p><code>release_pan</code> or <code>release_zoom</code> are callbacks. Those are the functions which are called once the conditions of the user releasing the mouse in pan or zoom mode are satisfied. You cannot connect them, but you may connect <em>to</em> them and of course you may call them if needed. </p>

<p>The possible events to connect are listed in <a href=""https://matplotlib.org/2.1.2/api/backend_bases_api.html?highlight=release_zoom#matplotlib.backend_bases.FigureCanvasBase.events"" rel=""nofollow noreferrer"">the documentation</a>. They are </p>

<blockquote>
<pre><code>events = ['resize_event', 
          'draw_event', 
          'key_press_event', 
          'key_release_event', 
          'button_press_event', 
          'button_release_event', 
          'scroll_event', 
          'motion_notify_event', 
          'pick_event', 
          'idle_event', 
          'figure_enter_event', 
          'figure_leave_event', 
          'axes_enter_event', 
          'axes_leave_event', 
          'close_event']
</code></pre>
</blockquote>

<p>Since there is no such thing as a <code>""release_zoom_event""</code>, this can also not be connected.</p>

<p><strong>But..</strong> you may create this <code>""release_zoom_event""</code> yourself, if needed. This is essentially described in <a href=""https://stackoverflow.com/questions/14896580/matplotlib-hooking-in-to-home-back-forward-button-events"">matplotlib hooking in to home/back/forward button events</a> for the ""home"" button. Adapting that example to the <code>""release_zoom_event""</code> would look like this:</p>

<pre><code>import matplotlib.pyplot as plt
from matplotlib.backend_bases import NavigationToolbar2

release_zoom = NavigationToolbar2.release_zoom

def new_release_zoom(self, *args, **kwargs):
    s = 'release_zoom_event'
    self.canvas.callbacks.process(s, args[0])
    release_zoom(self, *args, **kwargs)

NavigationToolbar2.release_zoom = new_release_zoom

def handle_release_zoom(evt):
    print('release_zoom_event')
    print(evt.xdata,evt.ydata)

fig = plt.figure()
fig.canvas.mpl_connect('release_zoom_event', handle_release_zoom)
plt.plot([1,3,1])
plt.show()
</code></pre>
","4124317","4124317","2018-03-01 22:31:22","5","2172","ImportanceOfBeingErnest","2014-10-09 07:50:43","173272","28712","2299","3162","49057890","49058750","2018-03-01 20:07:44","1","451","<p>I am not able to find a working code example for the various NavigationToolbar2 callbacks.
I have read through <a href=""https://matplotlib.org/2.1.2/api/backend_bases_api.html?highlight=release_zoom#matplotlib.backend_bases.NavigationToolbar2.release_zoom"" rel=""nofollow noreferrer"">the docs</a>, but am still working my way up the learning curve and am not having <em>any</em> luck locating code examples showing how to properly connect to the events I'm interested in. </p>

<p>For specificity, let's focus only on ""How do I attach code to release_zoom()?""</p>

<p>The above link provides this documentation:</p>

<p><strong>release_pan(event) - Callback for mouse button release in pan/zoom mode.</strong></p>

<p>Lines of interest in the (incorrectly) working example below are:</p>

<pre><code>self.nt.release_zoom('button_release_event')
self.canvas.mpl_connect('button_release_event', self.on_rel_zoom1)
self.canvas.mpl_connect('release_zoom', self.on_rel_zoom2)
</code></pre>

<p>I only manage to connect to the button_release_event. How do I correctly connect to release_zoom()?</p>

<pre><code>from PyQt5 import QtWidgets
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.backends.backend_qt5agg import NavigationToolbar2QT as NavigationToolbar
from matplotlib.figure import Figure
import numpy as np


class PlotWin(QtWidgets.QMainWindow):
    def __init__(self, parent=None):
        super(PlotWin, self).__init__(parent)
        QtWidgets.QMainWindow.__init__(self, parent)

        self.win = QtWidgets.QWidget(self)
        self.setCentralWidget(self.win)
        layout = QtWidgets.QVBoxLayout(self.win)

        self.canvas = FigureCanvas(Figure())
        layout.addWidget(self.canvas)
        self.nt = NavigationToolbar(self.canvas, self)
        layout.addWidget(self.nt)
        self.ax1 = self.canvas.figure.add_subplot(111)
        self.ax1.plot(np.linspace(1, 100, 100), np.random.rand(100, 1))

        self.nt.release_zoom('button_release_event')
        self.canvas.mpl_connect('button_release_event', self.on_rel_zoom1)
        self.canvas.mpl_connect('release_zoom', self.on_rel_zoom2)

    def on_rel_zoom1(self, event):
        print('One')

    def on_rel_zoom2(self, event):
        print('Two')


if __name__ == '__main__':
    import sys

    if not QtWidgets.QApplication.instance():
        app = QtWidgets.QApplication(sys.argv)
    else:
        app = QtWidgets.QApplication.instance()
    window = PlotWin()
    window.show()
    app.exec_()
</code></pre>
","9120461","","","matplotlib NavigationToolbar2 callbacks (e.g. release_zoom()) syntax example?","<python><matplotlib>","1","0","2547"
"49058763","2018-03-01 21:12:09","1","","<p>I think that what you need is just a simple merge of two dataframe:</p>

<pre><code>lookup.merge(data, left_on='C', right_on='A', how='left')
</code></pre>

<p>That's all</p>
","3211950","","","3","178","enneppi","2014-01-19 11:07:09","494","86","218","3","49058596","","2018-03-01 20:59:59","0","225","<p>In the following table I have a list of dates. I am trying to index the second dataframe and extract the corresponding value in the first dataframe. I want to create column D. </p>

<p>I have referenced 
<a href=""https://stackoverflow.com/questions/46754398/pandas-merge-returns-nan"">Pandas Merge returns NaN</a> 
as well, and both columns are indeed the same type(str)</p>

<pre><code>print(data)

A          B
1/1/17     15
1/2/17     16
1/3/17     14
1/4/17     15
1/5/17     16
1/6/17     14
1/7/17     15
1/8/17     16
1/9/17     14

print(lookup)

C         D
1/4/17    15
1/7/17    15
1/8/17    16
</code></pre>

<p>So basically I have the 'data' pandas dataframe, but I dont know how to create a column D in the 'lookup' dataframe to populate the two 15 and the 16 values. This is a smaller example of a bigger problem, Im trying to utilize a similar reference table to create a column in a much larger dataframe that pulls off the reference table. The dates in column C clearly already exist in the lookup dataframe as they are what im trying to use as a reference. </p>

<p>Thanks for your help !</p>
","7253998","7253998","2018-03-07 19:54:42","Pandas Index Match Alternative as in Excel","<python><pandas><indexing><lookup><matching>","3","5","1114"
"49058812","2018-03-01 21:16:07","0","","<p>This has to do with return values. If you're chaining statements, then your return value is going to be whatever the last method in the chain returns. <code>Label()</code> returns a label object. <code>pack()</code> returns <code>None</code>. You can imagine now what the error ""<strong>None</strong>Type object has no attribute 'X'"" actually means.</p>

<p>So, the solution is, use <code>Label()</code> and save the object to a variable. Then, call the method <code>pack()</code> on the object. <code>pack()</code> still returns <code>None</code>, but the <code>label</code> variable is not overwritten with <code>None</code>. It still contains the label object.</p>

<p>Edit: I figured I'd elaborate a bit.</p>

<p>All functions in python return a value, even if this is not done explicitly. When you write a function like</p>

<pre><code>def return_something():
    return ""some value""

return_value = return_something()
</code></pre>

<p>then the <code>return_value</code> variable will refer to a string with text ""some value"". </p>

<p>Consider a function that does not return anything like so</p>

<pre><code>def return_nothing():
    print ""No values returned in this function""

returned_value = return_nothing()
</code></pre>

<p>The <code>return_nothing()</code> will have return value of <code>None</code> and that's the value that will be assigned to <code>returned_value</code>. If you had anything in there before, it will be gone.</p>

<p>When doing method chaining like you do in your <code>Label().pack()</code> example, what you're actually doing is calling the method <code>pack()</code> on the object that is returned by <code>Label()</code>. The final return value of the chain will be whatever the last method returns. <code>pack()</code> returns nothing, so the return value is <code>None</code> and that's what is assigned to the variable <code>label</code>. However, if you end the chain with <code>Label()</code> then the return value is a label object and that's what goes in <code>label</code>. When you call <code>pack()</code> on a separate line, the return value <code>None</code> is discarded (it does not overwrite the label object inside <code>label</code>).</p>

<p>Hopefully that's a little more clear :)</p>
","7835165","7835165","2018-03-01 21:28:32","1","2248","Kamil Jarosz","2017-04-07 23:03:08","337","38","36","22","49058775","","2018-03-01 21:12:38","-1","46","<p>I have a quick question regarding why I should use <code>.pack()</code> in another line.</p>

<p>Example:
If I call the <code>Label</code> function as follows:</p>

<pre><code>import tkinter as tk

root = tk.Tk()
label = tk.Label(root, text=""Sample Text"").pack()
</code></pre>

<p>it has the same effect in <a href=""/questions/tagged/tkinter"" class=""post-tag"" title=""show questions tagged &#39;tkinter&#39;"" rel=""tag"">tkinter</a> as:</p>

<pre><code>label = tk.Label(root, text=""Sample Text"")
label.pack()
</code></pre>

<p>But as soon I want to configure the label later on, the first example dosen´t work:</p>

<pre><code>label = tk.Label(root, text=""Sample Text"").pack()
label.config(bg=""YELLOW"")
</code></pre>

<p>raises an:</p>

<pre><code>AttributeError: 'NoneType' object has no attribute 'config'
</code></pre>

<p>This is fixed as soon I write the <code>pack()</code> function in a separate line:</p>

<pre><code>label = tk.Label(root, text=""Sample Text"")
label.pack()
label.config(bg=""YELLOW"")
</code></pre>

<p>Why is <a href=""/questions/tagged/python"" class=""post-tag"" title=""show questions tagged &#39;python&#39;"" rel=""tag"">python</a> behaving like that?</p>
","9431124","7032856","2018-03-02 05:30:47","Why use the pack() method in another line?","<python><python-3.x><function><methods><tkinter>","2","0","1176"
"49058853","2018-03-01 21:19:22","3","","<p>To run a cron job only on weekdays you can define a <a href=""https://cloud.google.com/appengine/docs/standard/python/config/cronref#schedule_format"" rel=""nofollow noreferrer"">""custom interval""</a>:</p>

<pre><code>schedule: every mon,tue,wed,thu,fri 00:10
</code></pre>

<p>Would need to see your code for the <code>publish/daily-tick</code> handler to see why you're not getting an email</p>
","3524613","8831875","2018-03-07 14:41:05","4","396","GAEfan","2014-04-11 16:43:08","6984","718","48","36","49053112","49058853","2018-03-01 15:30:43","3","548","<p>Just tested a scheduling service over GAE + Cron + PubSub. The Endpoint is .NET Web API. It works fine except some setting requirement in <code>cron.yaml</code>.</p>

<p>Reference is <a href=""https://firebase.googleblog.com/2017/03/how-to-schedule-cron-jobs-with-cloud.html?m=1"" rel=""nofollow noreferrer"">How to Schedule (Cron) Jobs with Cloud Functions for Firebase</a></p>

<p>My cron.yaml</p>

<pre><code>cron:
- description: Push a ""tick"" onto pubsub every day. Every tues,wed,thurs,fri,sat 00:10.
  url: /publish/daily-tick
  schedule: every day 00:10
</code></pre>

<p>As you can see the script runs successfully every day at 00:10. 
<a href=""https://i.stack.imgur.com/BhF0K.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BhF0K.jpg"" alt=""gae_task_queue.jpg""></a></p>

<p>2 questions are:</p>

<ol>
<li>How I can script a daily job triggered only on the weekday ? (As
description says)</li>
<li><p>I manually click ""Run Now"" on GCP > GAE > Task queues got also
successful message but actually no Web API response came out for
this kind of scenario. (Expect got an email). The cron log is like
this:</p>

<p><code>protoPayload.taskName=""f389b******************""
protoPayload.taskQueueName=""__cron""</code></p></li>
</ol>

<p>Any hint I can go to check? Thanks a lot.</p>
","1979166","6202039","2018-10-04 06:54:34","Script weekday daily job in cron.yaml on GAE (GCP)","<python><google-app-engine><cron>","1","2","1297"
"49058869","2018-03-01 21:20:35","1","","<p>Because:</p>

<ol>
<li><p><em>All</em> methods return something, be it <code>None</code> or some other
particular object.</p></li>
<li><p><code>call1().call2().call3()....calln()</code> returns whatever <code>calln()</code>
supposed to return.</p></li>
<li>left-hand side of an assignment (<code>lh = rh</code>) is assigned whatever
expression(if any) in the <code>rh</code> returns.</li>
</ol>

<p><code>grid</code>, <code>pack</code>, <code>place</code> are all <em>methods</em> on <a href=""/questions/tagged/tkinter"" class=""post-tag"" title=""show questions tagged &#39;tkinter&#39;"" rel=""tag"">tkinter</a> widgets that return <code>None</code> (the default return value when the absence of an actual <code>return</code> statement).</p>

<p>Here's a very similar behavior:</p>

<pre><code>def return_a_list():
    return [0, 1]
rh = return_a_list().append(3)
lh = rh
input(lh)
</code></pre>
","7032856","7032856","2018-03-01 21:29:28","0","894","Nae","2016-10-17 19:19:28","6877","1192","1235","658","49058775","","2018-03-01 21:12:38","-1","46","<p>I have a quick question regarding why I should use <code>.pack()</code> in another line.</p>

<p>Example:
If I call the <code>Label</code> function as follows:</p>

<pre><code>import tkinter as tk

root = tk.Tk()
label = tk.Label(root, text=""Sample Text"").pack()
</code></pre>

<p>it has the same effect in <a href=""/questions/tagged/tkinter"" class=""post-tag"" title=""show questions tagged &#39;tkinter&#39;"" rel=""tag"">tkinter</a> as:</p>

<pre><code>label = tk.Label(root, text=""Sample Text"")
label.pack()
</code></pre>

<p>But as soon I want to configure the label later on, the first example dosen´t work:</p>

<pre><code>label = tk.Label(root, text=""Sample Text"").pack()
label.config(bg=""YELLOW"")
</code></pre>

<p>raises an:</p>

<pre><code>AttributeError: 'NoneType' object has no attribute 'config'
</code></pre>

<p>This is fixed as soon I write the <code>pack()</code> function in a separate line:</p>

<pre><code>label = tk.Label(root, text=""Sample Text"")
label.pack()
label.config(bg=""YELLOW"")
</code></pre>

<p>Why is <a href=""/questions/tagged/python"" class=""post-tag"" title=""show questions tagged &#39;python&#39;"" rel=""tag"">python</a> behaving like that?</p>
","9431124","7032856","2018-03-02 05:30:47","Why use the pack() method in another line?","<python><python-3.x><function><methods><tkinter>","2","0","1176"
"49058903","2018-03-01 21:23:10","1","","<p>Invoke your code with <code>bash</code>, not <code>/bin/sh</code> (as is default for <code>system()</code>):</p>

<pre><code>subprocess.Popen(['bash', '-c', '{ time ./test.out &lt; inp;} &gt; out 2&gt; exe_time'])
</code></pre>

<p>Note however that the above code is not safe to parameterize to work with arbitrary filenames. A better-practices implementation might instead look like:</p>

<pre><code>o, e = subprocess.Popen(['bash', '-c', 'time ""$@"" 2&gt;&amp;1', '_', './test.out'],
                        stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()

print(""Output from command is:"")
sys.stdout.write(o + ""\n"")
print(""Output from time is:"")
sys.stdout.write(e + ""\n"")
</code></pre>

<p>Note:</p>

<ul>
<li>We're explicitly invoking <code>bash</code>, and thus ensuring that its built-implementation of <code>time</code> is used.</li>
<li>Passing arguments out-of-band from the shell script makes it safe to pass arbitrary arguments to the script being run without worrying about whether those arguments contain attempted shell injection attacks.</li>
<li>Redirecting <code>2&gt;&amp;1</code> within the shell script ensures that any stderr written by <code>test.out</code> is joined with other output, not mixed in with the output from the <code>time</code> command.</li>
<li>If we <em>did</em> want to redirect output to files, the better-practice approach would be to do that from Python, as with <code>stdout=open('out', 'w'), stderr=open('exe_time', 'w')</code>.</li>
</ul>
","14122","14122","2018-03-01 21:28:35","5","1503","Charles Duffy","2008-09-16 22:05:28","195843","17220","4431","2834","49058794","49058903","2018-03-01 21:14:07","1","108","<p>I want to calculate the time taken to execute a c program inside a python script. I used os.system() function for this.</p>

<pre><code>os.system(""{ time ./test.out &lt; inp;} &gt; out 2&gt; exe_time"")
</code></pre>

<ul>
<li>test.out is my c executable </li>
<li>inp contains input for c </li>
<li>out stores the output of c program</li>
<li>exe_time stores the execution time of the program.</li>
</ul>

<p>The result I get in exe_time is something like this</p>

<blockquote>
  <p>0.00user 0.00system 0:00.00elapsed ?%CPU (0avgtext+0avgdata 1416maxresident)k 0inputs+8outputs (0major+65minor)pagefaults 0swaps</p>
</blockquote>

<p>But when I execute { time ./test.out &lt; inp;} > out 2> exe_time in terminal I get in the exe_time file </p>

<blockquote>
  <p>real    0m0.001s<br>
  user    0m0.000s<br>
  sys     0m0.000s</p>
</blockquote>

<p>How do I get the second version of output by using python? </p>
","4397381","","","Executing linux time command inside python","<python><linux><shell><time><subprocess>","2","3","916"
"49058908","2018-03-01 21:23:40","1","","<p><code>os.system()</code> uses <code>/bin/sh</code>. Bash has its own <code>time</code> builtin that it uses instead of the <code>time</code> binary:</p>

<pre><code>$ /usr/bin/time ls /asd
ls: /asd: No such file or directory
        0.00 real         0.00 user         0.00 sys
$ time ls /asd
ls: /asd: No such file or directory

real    0m0.018s
user    0m0.008s
sys     0m0.013s
</code></pre>

<p>If you want to see how long it takes for a command to be executed, just use <code>subprocess</code>:</p>

<pre><code>import time
import subprocess

with open('inp', 'rb') as input_file:
    with open('out', 'wb') as output_file:
        start = time.time()
        subprocess.call(['./test.out'], stdin=input_file, stdout=output_file)
        runtime = time.time() - start
</code></pre>
","464744","","","1","789","Blender","2010-10-02 17:47:48","223387","26068","2924","740","49058794","49058903","2018-03-01 21:14:07","1","108","<p>I want to calculate the time taken to execute a c program inside a python script. I used os.system() function for this.</p>

<pre><code>os.system(""{ time ./test.out &lt; inp;} &gt; out 2&gt; exe_time"")
</code></pre>

<ul>
<li>test.out is my c executable </li>
<li>inp contains input for c </li>
<li>out stores the output of c program</li>
<li>exe_time stores the execution time of the program.</li>
</ul>

<p>The result I get in exe_time is something like this</p>

<blockquote>
  <p>0.00user 0.00system 0:00.00elapsed ?%CPU (0avgtext+0avgdata 1416maxresident)k 0inputs+8outputs (0major+65minor)pagefaults 0swaps</p>
</blockquote>

<p>But when I execute { time ./test.out &lt; inp;} > out 2> exe_time in terminal I get in the exe_time file </p>

<blockquote>
  <p>real    0m0.001s<br>
  user    0m0.000s<br>
  sys     0m0.000s</p>
</blockquote>

<p>How do I get the second version of output by using python? </p>
","4397381","","","Executing linux time command inside python","<python><linux><shell><time><subprocess>","2","3","916"
"49059005","2018-03-01 21:30:41","0","","<p>As @kazemakase has commented, the answer is simply using: </p>

<pre><code>np.random.rand(k, 2) * [300, 100]
</code></pre>
","9023305","","","0","126","Sharan Duggirala","2017-11-29 02:18:50","23","10","5","0","47552767","49059005","2017-11-29 12:21:05","0","58","<pre><code>[[ 208.47   26.  ]
 [ 202.84   17.  ]
 [ 143.37   10.  ]
 ..., 
 [  45.99    3.  ]
 [ 159.31   10.  ]
 [  34.12    4.  ]]
[[ 58.64   1.  ]
 [ 44.31  19.  ]
 [ 37.89  14.  ]
 ..., 
 [ 46.86   4.  ]
 [ 60.73   5.  ]
 [ 41.91   6.  ]]
[[  36.6     4.  ]
 [ 219.29   17.  ]
 [  64.77    5.  ]
 ..., 
 [  51.85   37.  ]
 [ 161.26   10.  ]
 [  53.63   20.  ]]
[[  52.97   32.  ]
 [  51.32    3.  ]
 [ 196.23    4.  ]
 ..., 
 [  41.39    8.  ]
 [  47.49    5.  ]
 [  34.34    3.  ]]
</code></pre>

<p>I have this <code>numpy</code> array entering my function:</p>

<pre><code>def initialize_centroids(points, k):
    """"""returns k centroids from the initial points""""""
    centroids = points.copy()
    np.random.shuffle(centroids)
    print centroids
    return centroids[:k]
</code></pre>

<p>Now what the function is currently doing is, shuffling the values and sending the first k of them. I want to basically randomize the values of the first column between 0 and 300 and the second between 0 and 100. How would I do this? </p>

<p>This is part of my work on building a K-Means algorithm using Python. </p>
","9023305","","","How can I randomize the values within my numpy array?","<python><numpy>","1","4","1114"
"49059006","2018-03-01 21:30:43","3","","<p>Python is pass by value. That means that the value of the variables passed to a function will be copied. If you modify a parameter variable of a function, it won't be changed outside it.</p>

<p>You just have to return the new length at the end of the function and call like:</p>

<blockquote>
  <p>length = numcheck(length,' length of the block ')</p>
</blockquote>

<p>That way, you'll store the result in the <code>length</code> variable.</p>

<p>It's also not a very good practice to do your input both inside and outside the function. Duplicating the call to input is not really a problem, but both calls should be inside the function, the current way is ugly. But that's not the problem here.</p>
","168465","168465","2018-03-01 21:36:08","0","706","kriss","2009-09-04 11:37:44","17425","1264","2101","28","49058919","49059006","2018-03-01 21:24:36","1","66","<p>Just recently started learning python and ran into a bit of an odd problem. I've created this function to ensure that the number entered by a user is larger than zero:</p>

<pre><code>def numcheck(value,variable):

    while value &lt;= 0:
        print('The' +str(variable) + 'must be greater than zero! ')
        value = float(input('Please enter a positive number for' +str(variable)+ \
                            'and press enter. '))
    return value
</code></pre>

<p>The function is used within a main function as follows:</p>

<pre><code>def main():
    length = float(input('What is the length of the block of cheese? '))
    numcheck(length,' length of the block ' )
</code></pre>

<p>My problem is that the function successfully recognizes non-positive values, but when a new value is entered, the original number is still passed to the rest of the function. For example, if -10 is entered into length, I will be prompted to enter another value. If 15 is entered, the while loop will close but -10 will still pass from the function completely ruining the arithmetic that follows. I have spent several hours trying to remedy this with no success. I would appreciate any advice y'all have to offer. Thanks so much!</p>
","9431174","4785185","2018-03-01 21:34:00","Python While Loop Not Returning Desired Value","<python><python-3.x><while-loop><return><conditional>","1","6","1233"
"49059016","2018-03-01 21:31:55","1","","<p>Unfortunately, due to the way scrapy's <code>Item</code> is implemented, the information about the order of field definitions is not preserved.</p>

<p>If the order matters, the best you can do is define the order you want as a separate class variable, and use that in your pipeline. Passing the <a href=""https://doc.scrapy.org/en/latest/topics/exporters.html#scrapy.exporters.BaseItemExporter.fields_to_export"" rel=""nofollow noreferrer""><code>fields_to_export</code></a> argument to <code>CsvItemExporter</code> would probably be simplest.</p>

<p>Here's a basic idea you can play around with:</p>

<pre><code># items.py
class Item1(scrapy.Item):
    fields_to_export = ['fi', 'f2']
    f1 = scrapy.Field()
    f2 = scrapy.Field()
</code></pre>



<pre><code># pipelines.py
from project.items import Item1


class SomeSitePipeline(object):
    save_types = {'item1': Item1}

    def spider_opened(self, spider):
        # (...)
        self.exporters = dict(
            (name, CsvItemExporter(self.files[name], fields_to_export=item_type.fields_to_export))
            for name, item_type in self.save_types.items()
        )
        # (...)
</code></pre>

<p>Also, I just noticed you're using list comprehensions for side-effects, which is a bad idea, you should just use a normal loop instead.</p>
","975755","975755","2018-03-02 09:38:15","1","1305","stranac","2011-10-02 19:53:05","17050","525","103","13","49058067","49678536","2018-03-01 20:21:22","0","419","<p>I have a spider which exports data to different CSV files (per the names of the class definitions as defined in the spider class). However, I also wanted to keep the order of the fields in a specific order as they were being processed and exported into their different CSV files.</p>

<p>For example, this is my items.py:</p>

<pre><code>import scrapy

class first_class_def_Item(scrapy.Item):
    f1 = scrapy.Field() # f1 an arbitrary id used for both class definition items
    f2 = scrapy.Field()
    f3 = scrapy.Field()

class second_class_def_Item(scrapy.Item):
    f1 = scrapy.Field()
    f4 = scrapy.Field()
    f5 = scrapy.Field()
    f6 = scrapy.Field()
</code></pre>

<p>This is my pipelines.py:</p>

<pre><code>from scrapy.exporters import CsvItemExporter
from scrapy import signals
from pydispatch import dispatcher


def item_type(item):
    # The CSV file names are used (imported) from the scrapy spider.
    # For this example, I just want to keep ""first_class_def.csv"" without,
    # the ""_item"", as in ""first_class_def_Item.csv"" as defined in the main scrapy spider
    return type(item).__name__.replace('_Item','')

class SomeSitePipeline(object):
    # For simplicity, I'm using the same class def names as found in the,
    # main scrapy spider and as defined in the items.py
    SaveTypes = ['first_class_def','second_class_def']

    def __init__(self):
        dispatcher.connect(self.spider_opened, signal=signals.spider_opened)
        dispatcher.connect(self.spider_closed, signal=signals.spider_closed)

    def spider_opened(self, spider):
        self.files = dict([ (name, open(""/somefolder/""+name+'.csv','wb')) for name in self.SaveTypes ])
        self.exporters = dict([ (name,CsvItemExporter(self.files[name])) for name in self.SaveTypes ])
        [e.start_exporting() for e in self.exporters.values()]

    def spider_closed(self, spider):
        [e.finish_exporting() for e in self.exporters.values()]
        [f.close() for f in self.files.values()]

    def process_item(self, item, spider):
        typesItem = item_type(item)
        if typesItem in set(self.SaveTypes):
            self.exporters[typesItem].export_item(item)
        return item
</code></pre>

<p>And this is my spider.py:</p>

<pre><code>import os
import scrapy
from itertools import zip_longest
from somesite.items import first_class_def_Item, second_class_def_Item
from csv import DictReader

path = os.path.join(os.path.expanduser('~'), 'user', 'somefolder', 'IDs.csv')

class SomeSiteSpider(scrapy.Spider):
    name = 'somesite'
    allowed_domains = ['somesite.com']
    start_urls = ['https://somesite.com/login.aspx']

    def parse(self, response):

        return scrapy.FormRequest.from_response(response,
                            formdata={'txtLogin$txtInput': 'User',
                                      'txtPassword$txtInput': 'pass',
                                      'btnLogin.x': '53',
                                      'btnLogin.y': '33'},
                            callback=self.Tables)

    def Tables(self, response):

        with open(path) as rows:

            for row in DictReader(rows):

                id=row[""id""]

            yield scrapy.Request(""https://somesite.com/page1.aspx"",
                meta={'mid': mid,
                      'form_control': some_form_control},
                dont_filter = True,
                callback=self.first_class_def)

            yield scrapy.Request(""https://somesite.com/page2.aspx"",
                meta={'mid': mid,
                      'form_control': some_form_control},
                dont_filter = True,
                callback=self.second_class_def)

    def first_class_def(self, response):

        return scrapy.FormRequest.from_response(response,
                    formdata={'id': response.meta['id'],
                              'form_control': response.meta['some_form_control'],
                              'SearchControl$btnCreateReport': 'Create Report'},
                    meta={'id': response.meta['id']},
                    callback=self.scrap_page_1)

    def scrap_page_1(self, response):
        items = first_class_def_Item()

        field_1 = response.xpath('//*[@class=""formatText""][1]/text()').extract()
        field_2 = response.xpath('//*[@class=""formatCurrency""][1]/text()').extract()

        for a,b in zip(field_1,field_2):
            items['f1'] = response.meta['id']
            items['f2'] = a
            items['f3'] = b

            yield items

    def second_class_def(self, response):

        return scrapy.FormRequest.from_response(response,
                    formdata={'id': response.meta['id'],
                              'form_control': response.meta['some_form_control'],
                              'form_control_two': 'some_form_control_two',
                              'SearchControl$btnCreateReport': 'Create Report'},
                    meta={'id': response.meta['id']},
                    callback=self.scrap_page_2)

    def scrap_page_2(self, response):
        items = second_class_def_Item()

        field_1 = response.xpath('//*[@class=""formatText""][1]/text()').extract()
        field_2 = response.xpath('//*[@class=""formatCurrency""][1]/text()').extract()
        field_3 = response.xpath('//*[@class=""formatText""][3]/text()').extract()

        for a,b,c in zip(field_1,field_2,field_3):
            items['f1'] = response.meta['id']
            items['f4'] = a
            items['f5'] = b
            items['f6'] = c

            yield items
</code></pre>

<p>As the spider was processing and exporting data, I was looking for a way to keep the fields in the CSV generated files ""first_class_def.csv"" and ""second_class_def.csv"", exported in the same order as in the items.py:</p>

<p>f1,f2,f3</p>

<p>and</p>

<p>f1,f4,f5,f6</p>

<p>However, whenever I would crawl the spider, the fields within the CSV files were being exported in random order:</p>

<p>f2,f1,f3 and f5,f1,f4,f6</p>

<p>The solution is posted below!</p>
","9414342","9414342","2018-04-10 04:18:41","How To Keep/Export Field Items in Specific Order Per Spider Class Definition, Utilizing The Items Pipeline in Scrapy","<python><python-3.x><scrapy><scrapy-spider><scrapy-pipeline>","2","1","6013"
"49059029","2018-03-01 21:33:05","6","","<p>Unfortunately the <a href=""https://github.com/isagalaev/ijson"" rel=""nofollow noreferrer"">ijson</a> library (v2.3 as of March 2018) does not handle parsing multiple JSON objects. It can only handle 1 overall object, and if you attempt to parse a second object, you will get an error: <code>""ijson.common.JSONError: Additional data""</code>. See bug reports here:</p>

<ul>
<li><a href=""https://github.com/isagalaev/ijson/issues/40"" rel=""nofollow noreferrer"">https://github.com/isagalaev/ijson/issues/40</a></li>
<li><a href=""https://github.com/isagalaev/ijson/issues/42"" rel=""nofollow noreferrer"">https://github.com/isagalaev/ijson/issues/42</a></li>
<li><a href=""https://github.com/isagalaev/ijson/issues/67"" rel=""nofollow noreferrer"">https://github.com/isagalaev/ijson/issues/67</a></li>
<li><a href=""https://stackoverflow.com/questions/34217042/python-how-do-i-parse-a-stream-of-json-arrays-with-ijson-library"">python: how do I parse a stream of json arrays with ijson library</a></li>
</ul>

<p>It's a big limitation. However, as long as you have line breaks (new line character) after each JSON object, you can parse each one line-by-line <em>independently</em>, like this:</p>

<pre><code>import io
import ijson

with open(filename, encoding=""UTF-8"") as json_file:
    cursor = 0
    for line_number, line in enumerate(json_file):
        print (""Processing line"", line_number + 1,""at cursor index:"", cursor)
        line_as_file = io.StringIO(line)
        # Use a new parser for each line
        json_parser = ijson.parse(line_as_file)
        for prefix, type, value in json_parser:
            print (""prefix="",prefix, ""type="",type, ""value="",value)
        cursor += len(line)
</code></pre>

<p>You are still streaming the file, and not loading it entirely in memory, so it can work on large JSON files. It also uses the line streaming technique from: <a href=""https://stackoverflow.com/questions/620367/how-to-jump-to-a-particular-line-in-a-huge-text-file"">How to jump to a particular line in a huge text file?</a> and uses <code>enumerate()</code> from: <a href=""https://stackoverflow.com/questions/522563/accessing-the-index-in-python-for-loops"">Accessing the index in &#39;for&#39; loops?</a></p>
","6512057","6512057","2019-03-21 12:32:09","0","2213","Mr-IDE","2011-11-29 18:27:03","2784","354","668","3","37200302","37200606","2016-05-13 02:26:49","9","8287","<p>I'm trying to parse a large (~100MB) json file using ijson package which allows me to interact with the file in an efficient way. However, after writing some code like this,</p>

<pre><code>with open(filename, 'r') as f:
    parser = ijson.parse(f)
    for prefix, event, value in parser:
        if prefix == ""name"":
            print(value)
</code></pre>

<p>I found that the code parses only the first line and not the rest of the lines from the file!!</p>

<p>Here is how a portion of my json file  looks like:</p>

<pre><code>{""name"":""accelerator_pedal_position"",""value"":0,""timestamp"":1364323939.012000}
{""name"":""engine_speed"",""value"":772,""timestamp"":1364323939.027000}
{""name"":""vehicle_speed"",""value"":0,""timestamp"":1364323939.029000}
{""name"":""accelerator_pedal_position"",""value"":0,""timestamp"":1364323939.035000}
</code></pre>

<p>In my opinion, I think <code>ijson</code> parses only one json object.</p>

<p>Can someone please suggest how to work around this?</p>
","3010158","261542","2016-05-13 03:32:01","Using python ijson to read a large json file with multiple json objects","<python><json>","2","3","974"
"49059047","2018-03-01 21:35:01","-1","","<p>So it turns out looping through my columns and using numpy is faster</p>

<pre><code>    for col in mylist:
        df[col] = np.nan_to_num(df[col].values)
</code></pre>
","2080581","","","0","173","strv7","2013-02-17 14:25:54","55","20","18","0","49056768","","2018-03-01 18:53:17","-1","124","<p>I have a set of columns in my dataframe that I want to impute the NaN values with 0. For example</p>

<pre><code>mylist = ['col1', 'col2','col3','col4', 'col5']
df[mylist] = df[mylist].fillna(0)
</code></pre>

<p>This is actually taking an important amount of time in my application and I was wondering if there is a faster way to accomplish this.</p>
","2080581","4686625","2018-03-01 19:02:06","Is there a faster way to impute my null values in pandas data frame than fillna()?","<python><pandas><fillna>","2","3","355"
"49059061","2018-03-01 21:36:03","1","","<p>In principle I see three problems:</p>

<ul>
<li><p><code>on_text_validate</code> <strong>isn't fired in multiline inputs</strong>. You should set <code>multiline</code> property to <code>False</code>.</p></li>
<li><p>Use <a href=""https://kivy.org/docs/api-kivy.uix.textinput.html#kivy.uix.textinput.TextInput.hint_text"" rel=""nofollow noreferrer"">hint_text</a> property to set the suggestion text.</p></li>
<li><p>The weird behavior of your accordion is probably caused because you are loading your kv file twice (Your <code>""Multiple screens named ...""</code> warnings are indicative of that.). I recommend renaming your kv to <code>vocabularyjournal.kv</code> and not using <code>Builder.load_file ()</code>. You can look at <a href=""https://stackoverflow.com/a/48695485/7131499"">this related answer</a>.</p></li>
</ul>

<p><strong>main.py:</strong></p>

<pre><code>import kivy
kivy.require('1.10.0')

from kivy.app import App
from kivy.uix.screenmanager import ScreenManager, Screen
from kivy.properties import ObjectProperty
from kivy.properties import StringProperty


import json


class MenuPage(Screen):
    pass

class DisplayPage(Screen):                  
    search_box= ObjectProperty()
    label_maening=StringProperty()
    label_synonym=StringProperty()
    label_ant=StringProperty()
    label_sentence=StringProperty()


    def search_function(self):
        with open('vocab_words.json') as rfile:
            data=json.load(rfile)

        word=self.search_box.text

        for value in data:
            if value['word']==word:
                self.label_maening=value['meaning']
                self.label_synonym=value['synonym']
                self.label_ant=value['antonyms']
                self.label_sentence=value['sentence']


class WordInsertPage(Screen):
    pass


class NewWordPage(Screen):
    word_box = ObjectProperty()
    meaning_box = ObjectProperty()
    synonym_box = ObjectProperty()
    ant_box = ObjectProperty()
    sentence_box = ObjectProperty()


    def saving_data(self):

        with open('vocab_words.json') as rfile:
            data=json.load(rfile)


        entry={'word': self.word_box.text, 'meaning': self.meaning_box.text, 'synonym': self.synonym_box.text, 'antonyms': self.ant_box.text, 'sentence': self.sentence_box.text}
        data.append(entry)


        with open('vocab_words.json','w') as wfile:
            json.dump(data,wfile,indent=4)


class FlashCard(Screen):
    pass

class WordGroups(Screen):
    pass

class Manager(ScreenManager):
    pass

class VocabularyJournalApp(App):
    def build(self):
        return Manager()

obj = VocabularyJournalApp()
obj.run()
</code></pre>

<p><strong>vocabularyjournal.kv:</strong></p>

<pre><code>&lt;Manager&gt;:
    MenuPage:
        name: 'menu'
    WordInsertPage:
        name: 'insertword'
    NewWordPage:
        name: 'newword'
    FlashCard:
        name: 'flashcard'
    WordGroups:
        name: 'wordgroup'
    DisplayPage:
        name: 'display'

&lt;MenuPage&gt;:
    Label:
        text: ""Vocabulary Journal""
        size_hint: .90,.10

    StackLayout:
        orientation: 'tb-rl'
        spacing: 10
        padding: 10

        Button:
            text: 'Search'
            size_hint: None,.20
            width: 130
            background_down:'darkgrey.png'
            on_press: root.manager.current='insertword'
        Button:
            text: 'New Word'
            size_hint: None,.20
            width: 130
            background_down:'darkgrey.png'
            on_press: root.manager.current='insertword'
        Button:
            text: 'Flash Cards'
            size_hint: None,.20
            width: 130
            background_down:'darkgrey.png'
            on_press: root.manager.current='flashcard'

        Button:
            text: 'Word Groups'
            size_hint: None,.20
            width: 130
            background_down:'darkgrey.png'
            on_press: root.manager.current='wordgroup'

&lt;WordInsertPage&gt;:

    FloatLayout:

        Button:
            text: ""New Word""
            on_press: root.manager.current='newword'
            font_size: 30
            color: 0,0,0,1
            size_hint: .2, .1
            pos_hint: {""center_x"": .5, ""center_y"": 0.3}
            background_down: 'darkgrey.png'
        Button:
            text: ""search word""
            on_press: root.manager.current='display'
            font_size: 30
            color: 0,0,0,1
            size_hint: .2, .1
            pos_hint: {""center_x"": .5, ""center_y"": 0.5}
            background_down: 'darkgrey.png'
        Button:
            text: 'Flash Cards'
            on_press: root.manager.current=""flashcard""
            font_size: 30
            color: 0,0,0,1
            size_hint: .2, .1
            pos_hint: {""center_x"": .5, ""center_y"": 0.7}
            background_down: 'darkgrey.png'



    &lt;NewWordPage&gt;:
        id: refer_to_it
        word_box: word_input
        meaning_box: meaning_input
        synonym_box: Synonym_input
        ant_box: ant_input
        sentence_box: sentence_input
        StackLayout:
            orientation: 'tb-rl'
            spacing: 10
            padding: 90
            TextInput:
                hint_text: ""write your word here""
                color: 1,1,1,1
                id: word_input
                width: 300
                size_hint: None, .10

            TextInput:
                hint_text: ""write meaning of your word here""
                color: 1,1,1,1
                id: meaning_input
                width: 600
                size_hint: None, .20

            TextInput:
                hint_text: ""write Synonyms of your word here""
                color: 1,1,1,1
                id: Synonym_input
                width: 600
                size_hint: None, .20

            TextInput:
                hint_text: ""write antonyms of your text here""
                color: 1,1,1,1
                id: ant_input
                width: 600
                size_hint: None, .20

            TextInput:
                hint_text: ""write a sentence based on your word here""
                color: 1,1,1,1
                id: sentence_input
                width: 600
                size_hint: None, .20

            Button:
                hint_text: 'Save'
                size_hint: None,.10
                width: 130
                background_down:'darkgrey.png'
                on_press: refer_to_it.saving_data()

    &lt;DisplayPage&gt;:                          # here is the display page
        search_box: search_text
        BoxLayout:
            size_hint_y: None
            height: '48dp'

            TextInput:
                hint_text:'enter the word you wanna search here'
                id: search_text
                multiline: False
                on_text_validate: root.search_function()

        Accordion:
            orientation: 'vertical'

            AccordionItem:
                title:'meaning'

                Label:
                    text: root.label_maening
                    text_size: self.width, None

            AccordionItem:
                title:'Synonym'

                Label:
                    text: root.label_synonym
                    text_size: self.width, None

            AccordionItem:
                title:'Antonym'

                Label:
                    text: root.label_ant
                    text_size: self.width, None

            AccordionItem:
                title:'Sentence'

                Label:
                    text: root.label_sentence
                    text_size: self.width, None
</code></pre>

<blockquote>
  <p><strong>Note:</strong> You shouldn't use <code>object</code> as variable name. It is a built-in function.</p>
</blockquote>
","7131499","","","1","7772","FJSevilla","2016-11-08 11:59:44","2628","190","117","0","49058162","49059061","2018-03-01 20:27:09","1","53","<p>On display screen of my code i have used accordions, I have done every thing as instructed and the code for <code>TextInput</code> in that page is right but accordions are not working as intended and the textInput is not taking any inputs. I am new to kivy and as far as I know every thing seems right to me.</p>

<p>Heres my code:</p>

<pre><code>    import kivy
    kivy.require('1.10.0')

    from kivy.uix.stacklayout import StackLayout
    from kivy.uix.floatlayout import FloatLayout
    from kivy.uix.boxlayout import BoxLayout
    from kivy.uix.label import Label 
    from kivy.app import App
    from kivy.uix.popup import Popup  
    from kivy.uix.screenmanager import ScreenManager, Screen 
    from kivy.lang import Builder 
    from kivy.properties import ObjectProperty
    from kivy.uix.textinput import TextInput
    from kivy.properties import StringProperty


    import json

    Builder.load_file('VocabularyJournal.kv')

    class MenuPage(Screen):
        pass

    class DisplayPage(Screen):                   # here is the display page[![enter image description here][1]][1]
        search_box= ObjectProperty()
        label_maening=StringProperty()
        label_synonym=StringProperty()
        label_ant=StringProperty()
        label_sentence=StringProperty()


        def search_function(self):
            with open('vocab_words.json') as rfile:
                data=json.load(rfile)

            word=self.search_box.text 

            for value in data:
                if value['word']==word:
                    self.label_maening=value['meaning']
                    self.label_synonym=value['synonym']
                    self.label_ant=value['antonyms']
                    self.label_sentence=value['sentence']


    class WordInsertPage(Screen):
        pass


    class NewWordPage(Screen):
        word_box = ObjectProperty()
        meaning_box = ObjectProperty()
        synonym_box = ObjectProperty()
        ant_box = ObjectProperty()
        sentence_box = ObjectProperty()


        def saving_data(self):

            with open('vocab_words.json') as rfile:
                data=json.load(rfile)


            entry={'word': self.word_box.text, 'meaning': self.meaning_box.text, 'synonym': self.synonym_box.text, 'antonyms': self.ant_box.text, 'sentence': self.sentence_box.text}
            data.append(entry)


            with open('vocab_words.json','w') as wfile:
                json.dump(data,wfile,indent=4)


    class FlashCard(Screen):
        pass

    class WordGroups(Screen):
        pass

    class Manager(ScreenManager):
        pass

    class VocabularyJournalApp(App):
        def build(self):
            return Manager()

    object = VocabularyJournalApp()
    object.run()
</code></pre>

<p>heres the kivy code-</p>

<pre><code>    &lt;Manager&gt;:
        MenuPage:
            name: 'menu'
        WordInsertPage:
            name: 'insertword'
        NewWordPage:
            name: 'newword'
        FlashCard:
            name: 'flashcard'
        WordGroups:
            name: 'wordgroup'
        DisplayPage:
            name: 'display'

    &lt;MenuPage&gt;:
        Label: 
            text: ""Vocabulary Journal""
            size_hint: .90,.10

        StackLayout:
            orientation: 'tb-rl'
            spacing: 10
            padding: 10

            Button:
                text: 'Search'
                size_hint: None,.20
                width: 130
                background_down:'darkgrey.png'
                on_press: root.manager.current='insertword'
            Button:
                text: 'New Word'
                size_hint: None,.20
                width: 130
                background_down:'darkgrey.png'
                on_press: root.manager.current='insertword'
            Button:
                text: 'Flash Cards'
                size_hint: None,.20
                width: 130
                background_down:'darkgrey.png'
                on_press: root.manager.current='flashcard'

            Button:
                text: 'Word Groups'
                size_hint: None,.20
                width: 130
                background_down:'darkgrey.png'
                on_press: root.manager.current='wordgroup'

    &lt;WordInsertPage&gt;:

        FloatLayout:

            Button: 
                text: ""New Word""
                on_press: root.manager.current='newword'
                font_size: 30
                color: 0,0,0,1
                size_hint: .2, .1
                pos_hint: {""center_x"": .5, ""center_y"": 0.3}
                background_down: 'darkgrey.png'
            Button:
                text: ""search word""
                on_press: root.manager.current='display'
                font_size: 30
                color: 0,0,0,1
                size_hint: .2, .1
                pos_hint: {""center_x"": .5, ""center_y"": 0.5}
                background_down: 'darkgrey.png'
            Button:
                text: 'Flash Cards'
                on_press: root.manager.current=""flashcard""
                font_size: 30
                color: 0,0,0,1
                size_hint: .2, .1
                pos_hint: {""center_x"": .5, ""center_y"": 0.7}
                background_down: 'darkgrey.png'



    &lt;NewWordPage&gt;:
        id: refer_to_it
        word_box: word_input
        meaning_box: meaning_input
        synonym_box: Synonym_input
        ant_box: ant_input
        sentence_box: sentence_input
        StackLayout:
            orientation: 'tb-rl'
            spacing: 10
            padding: 90
            TextInput:
                text: ""write your word here""
                color: 1,1,1,1
                id: word_input
                width: 300
                size_hint: None, .10

            TextInput:
                text: ""write meaning of your word here""
                color: 1,1,1,1
                id: meaning_input
                width: 600
                size_hint: None, .20

            TextInput:
                text: ""write Synonyms of your word here""
                color: 1,1,1,1
                id: Synonym_input
                width: 600
                size_hint: None, .20

            TextInput:
                text: ""write antonyms of your text here""
                color: 1,1,1,1
                id: ant_input
                width: 600
                size_hint: None, .20

            TextInput:
                text: ""write a sentence based on your word here""
                color: 1,1,1,1
                id: sentence_input
                width: 600
                size_hint: None, .20

            Button:
                text: 'Save'
                size_hint: None,.10
                width: 130
                background_down:'darkgrey.png'
                on_press: refer_to_it.saving_data()     

    &lt;DisplayPage&gt;:                          # here is the display page
        search_box: search_text
        BoxLayout:
            size_hint_y: None
            height: '48dp'

            TextInput:
                text:'enter the word you wanna search here'
                id: search_text
                on_text_validate: root.search_function()

        Accordion:
            orientation: 'vertical'

            AccordionItem:
                title:'meaning'

                Label:
                    text: root.label_maening
                    text_size: self.width, None

            AccordionItem:
                title:'Synonym'

                Label:
                    text: root.label_synonym
                    text_size: self.width, None

            AccordionItem:
                title:'Antonym'

                Label:
                    text: root.label_ant
                    text_size: self.width, None

            AccordionItem:
                title:'Sentence'

                Label:
                    text: root.label_sentence
                    text_size: self.width, None
</code></pre>

<p><a href=""https://i.stack.imgur.com/r6lOW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/r6lOW.png"" alt=""enter image description here""></a></p>
","9355642","7131499","2018-03-01 20:58:58","I am using accordions is behaving weird and my textinput on that screen is not working either","<python><kivy>","1","0","8105"
"49059068","2018-03-01 21:36:34","1","","<p>Your view <code>second_function</code> returns a response. As long as the view doesn't raise an exception, your <code>first_function</code> will continue, whatever the status code of that response.</p>

<p>If you want to return the redirect, then you'll have to assign the result to a status code, then you'll have to assign the result of <code>second_function</code> to a variable, then check the status code.</p>

<pre><code>def first_function(request):
    """""" Here is some stuff """"""
    response = second_function(request)
    if response.status_code == '302':
        return response
    return render(request, 'first.html', context)
</code></pre>

<p>This isn't a good way to structure your code, but I can't suggest an alternative because your code show what you're really trying to do.</p>
","113962","","","0","801","Alasdair","2009-05-28 20:26:55","203443","9896","5891","530","49058831","","2018-03-01 21:17:48","0","12","<p>Got a real problem here. I have got 2 views in backend and really need to redirect FROM second view</p>

<p>Views like this:</p>

<pre><code>def first_function(request):
    """""" Here is some stuff """"""
    second_function(request)
    return render(request, 'first.html', context)

def second_function(request)
    """""" Check here something """"""
    if ok:
        return
    else: 
        return redirect('/') # this redirect does not work
</code></pre>
","5970072","","","Redirect from second view","<python><django><http><http-headers>","1","0","456"
"49059088","2018-03-01 21:37:40","0","","<p>I was able to figure something out. I pieced together this:</p>

<pre><code>y = ""user input id variable""
x = y

for i in data['result']: 
if i['id'] == x:
    NL_id = i['id']
    NL_Rc = i['recordtype']
    NL_Itid = i['columns']['itemid']
    break`
</code></pre>

<p>This returns the data from the json dict's I need in the way that I need it. Maybe this will help someone else like myself. (fifth day in python = total noob). </p>
","9420470","","","0","437","Jbigger","2018-02-27 18:55:35","6","5","0","0","49051373","","2018-03-01 14:03:21","0","117","<p>Python 2.7</p>

<p>I am new to python and this is my first post for help. </p>

<p>I am sending a post request to the web and having a json file returned. It looks like this:</p>

<p><a href=""https://i.stack.imgur.com/NzIQs.jpg"" rel=""nofollow noreferrer"">json Example</a></p>

<p>if i do:</p>

<blockquote>
  <p>print data['result']</p>
</blockquote>

<p>I get all the items listed</p>

<p>if i do:</p>

<blockquote>
  <p>print data['result']['recordtype'] </p>
</blockquote>

<p>I get ""list indices must be integers, not str"" (because I need ['result'][0]['recordtype']? but that would limit it to only the first item)</p>

<p>I can get ""some"" info with:</p>

<blockquote>
  <p>print(data['result'](type is a list)</p>
  
  <p>print(data['result'][0])(type is a dict)</p>
  
  <p>print(data['result'][0]['columns'](type is a dict)</p>
</blockquote>

<p>But this only returns the first item. ([0]). Any other attempts gets me a ""must be integer not str"". </p>

<p>Ultimately, I would like to enter item ""id"" and have all the attributes ""itemid"", ""displayname"", ""columns"", etc returned for that item as variables. (""columns"" will vary from json file to json but the rest should remain uniform) </p>

<p>Questions:</p>

<p>How can I loop through all these items based on the ""id"" value and return all the values associated with that item as variables?</p>
","9420470","9420470","2018-03-01 18:28:32","Python parsing json file into something usable","<python><json>","3","1","1357"
"49059100","2018-03-01 21:38:12","0","","<p>This should do what you want:</p>

<pre><code>lookup['D'] = [data.B[data.A[data.A==i].index[0]] for i in lookup.C.tolist()]
</code></pre>

<p>Explanation:</p>

<p>Creates a new column in <code>lookup</code> called 'D' that is the value of column 'B' in <code>data</code> that corresponds to when the value in column 'A' in <code>data</code> is equal to the current element being iterated on in the list of values from column 'C' in <code>lookup</code></p>
","8146556","","","1","459","rahlf23","2017-06-12 02:38:50","6078","662","435","19","49058596","","2018-03-01 20:59:59","0","225","<p>In the following table I have a list of dates. I am trying to index the second dataframe and extract the corresponding value in the first dataframe. I want to create column D. </p>

<p>I have referenced 
<a href=""https://stackoverflow.com/questions/46754398/pandas-merge-returns-nan"">Pandas Merge returns NaN</a> 
as well, and both columns are indeed the same type(str)</p>

<pre><code>print(data)

A          B
1/1/17     15
1/2/17     16
1/3/17     14
1/4/17     15
1/5/17     16
1/6/17     14
1/7/17     15
1/8/17     16
1/9/17     14

print(lookup)

C         D
1/4/17    15
1/7/17    15
1/8/17    16
</code></pre>

<p>So basically I have the 'data' pandas dataframe, but I dont know how to create a column D in the 'lookup' dataframe to populate the two 15 and the 16 values. This is a smaller example of a bigger problem, Im trying to utilize a similar reference table to create a column in a much larger dataframe that pulls off the reference table. The dates in column C clearly already exist in the lookup dataframe as they are what im trying to use as a reference. </p>

<p>Thanks for your help !</p>
","7253998","7253998","2018-03-07 19:54:42","Pandas Index Match Alternative as in Excel","<python><pandas><indexing><lookup><matching>","3","5","1114"
"49059106","2018-03-01 21:38:58","2","","<p>For a high level description - see docs <a href=""http://numba.pydata.org/numba-doc/latest/proposals/type-inference.html#numba-type-semantic"" rel=""nofollow noreferrer"">here</a>.  Here's a retelling based on my (limited!) understanding of that.</p>

<p>In numba's compilation process there is a type unification process/solver to convert everything to efficient low level ops.  This can produce multiple verions of the function depending on the inputs.</p>

<p>In your function, a constraint is that this line - <code>result</code> and <code>arr[i]</code> <em>must</em> be the same type.</p>

<pre><code>result += arr[i]
</code></pre>

<p>Absent an input, <code>result</code> would be an integer.  but in the context of <code>arr</code> being a double, the only lossless way to unify types is casting <code>result</code> to a double.  If you went the other way, converting <code>arr</code> to an int, you'd destroy information.</p>
","3657742","","","0","933","chrisb","2014-05-20 17:36:56","28789","672","433","13","49058729","49059106","2018-03-01 21:09:02","2","57","<p>Numba does something cool and surprising:</p>

<pre><code>@jit(nopython=True, nogil=True)
def sum(arr):
    result = 0
    for i in range(len(arr)):
        result += arr[i]
    return result
</code></pre>

<p>When called with an int64 array, it returns an int. When called with a float64, it returns a float.</p>

<p>This is suprising since, result is initialized with a literal integer 0 -- which I assumed it would determine the type of result. Why isn't the result always an int?</p>

<p>Here's when <code>sum.inspecttypes()</code> says for the float64 array case:</p>

<pre><code>================================================================================
sum (readonly array(float64, 1d, C),)
--------------------------------------------------------------------------------
# File: /home/.../fast_ops.py
# --- LINE 164 --- 
# label 0
#   del $const0.1

@jit(nopython=True, nogil=True)

# --- LINE 165 --- 

def sum(arr):

    # --- LINE 166 --- 
    #   arr = arg(0, name=arr)  :: readonly array(float64, 1d, C)
    #   $const0.1 = const(int, 0)  :: int64
    #   result = $const0.1  :: float64
    #   jump 6
    # label 6

    result = 0
</code></pre>
","48956","48956","2018-03-01 22:09:15","How does numba infer the types of literally initialized locals?","<python><numba>","1","7","1168"
"49059113","2018-03-01 21:39:35","0","","<p>This is one straightforward method:</p>

<pre><code>lookup['D'] = lookup['C'].map(data.set_index('A')['B'])
</code></pre>

<p>You can also reach this result via <code>pd.merge</code>, but the above is likely more efficient.</p>

<p><strong>Explanation</strong></p>

<ul>
<li><code>data.set_index('A')['B']</code> creates a <code>pd.Series</code> mapping 'A' to 'B'. This works because the indices are unique.</li>
<li><a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html"" rel=""nofollow noreferrer""><code>pd.Series.map</code></a> can take a series as an input.</li>
</ul>
","9209546","","","1","608","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49058596","","2018-03-01 20:59:59","0","225","<p>In the following table I have a list of dates. I am trying to index the second dataframe and extract the corresponding value in the first dataframe. I want to create column D. </p>

<p>I have referenced 
<a href=""https://stackoverflow.com/questions/46754398/pandas-merge-returns-nan"">Pandas Merge returns NaN</a> 
as well, and both columns are indeed the same type(str)</p>

<pre><code>print(data)

A          B
1/1/17     15
1/2/17     16
1/3/17     14
1/4/17     15
1/5/17     16
1/6/17     14
1/7/17     15
1/8/17     16
1/9/17     14

print(lookup)

C         D
1/4/17    15
1/7/17    15
1/8/17    16
</code></pre>

<p>So basically I have the 'data' pandas dataframe, but I dont know how to create a column D in the 'lookup' dataframe to populate the two 15 and the 16 values. This is a smaller example of a bigger problem, Im trying to utilize a similar reference table to create a column in a much larger dataframe that pulls off the reference table. The dates in column C clearly already exist in the lookup dataframe as they are what im trying to use as a reference. </p>

<p>Thanks for your help !</p>
","7253998","7253998","2018-03-07 19:54:42","Pandas Index Match Alternative as in Excel","<python><pandas><indexing><lookup><matching>","3","5","1114"
"49059114","2018-03-01 21:39:36","1","","<p>In your code you have the line:</p>

<pre><code>import IHR_TestSuiteConfig.py
</code></pre>

<p>That won't work because you don't specify modules to import by file name but by module name, e.g.:</p>

<pre><code>import IHR_TestSuiteConfig
</code></pre>

<p>But looking at your screenshot you have a bigger issue of the code being kept in a <code>Settings</code> directory at the same level as your <code>Lib</code> directory containing the code you are importing into.</p>

<p>You need to either anchor all of your code up a level so you can do:</p>

<pre><code>from ..Settings import IHR_TestSuiteConfig
</code></pre>

<p>Or you need to manipulate your <code>PYTHONPATH</code> environment variable to put <code>Settings</code> directly on to <code>sys.path</code> (in VS Code you can create a <code>.env</code> file to do this, but it won't' affect running Python from the terminal, only when VS Code runs e.g. Pylint).</p>
","236574","","","1","927","Brett Cannon","2009-12-22 04:31:02","3809","593","113","5","49010636","49059114","2018-02-27 14:07:48","0","340","<p>This code worked on Friday without problems and still running on a colleagues laptop, but I cannot run it anymore.
As you can see in the screenshot, my editor doesnt find some moduls anymore and the pylint Error ""E0401: Unable to import"" occurs. 
The missing file exists in the folder Settings, as you can see in the Explorer on the left side.</p>

<p>Today I deactivated/activated pylint, reinstalled vs code and python, added the <strong>init</strong>.py to Settings folder, tried the same code in eclipse, modified the Path enviroment variable and created the PYTHONPATH enviroment variable. All this with no success:/</p>

<p>I am greatful for each hint, which provide me to solve this problem.</p>

<p><a href=""https://i.stack.imgur.com/wfz1O.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wfz1O.jpg"" alt=""enter image description here""></a></p>

<p>The error output as text:</p>

<pre><code>    Windows PowerShell
Copyright (C) Microsoft Corporation. Alle Rechte vorbehalten.

PS C:\Users\Evgenij\Desktop\Desktop\Eth_Test_Dev&gt; &amp; C:/Python27/python.exe c:\Users\Evgenij\Desktop\Desktop\Eth_Test_Dev\Code\__TC__Template.py
Traceback (most recent call last):
  File ""c:\Users\Evgenij\Desktop\Desktop\Eth_Test_Dev\Code\__TC__Template.py"", line 36, in &lt;module&gt;
    from Lib.IHR_EthApi import EthApi as ETH
  File ""c:\Users\Evgenij\Desktop\Desktop\Eth_Test_Dev\Code\Lib\IHR_EthApi.py"", line 6, in &lt;module&gt;
    from IHR_GeneralApi import GeneralApi as SYS
  File ""c:\Users\Evgenij\Desktop\Desktop\Eth_Test_Dev\Code\Lib\IHR_GeneralApi.py"", line 4, in &lt;module&gt;
    import IHR_TestSuiteConfig.py
ImportError: No module named IHR_TestSuiteConfig.py
PS C:\Users\Evgenij\Desktop\Desktop\Eth_Test_Dev&gt;
</code></pre>
","9390828","9390828","2018-02-28 14:50:21","Import errors between some python moduls/functions/variables","<python><visual-studio-code><importerror><pylint>","1","2","1758"
"49059118","2018-03-01 21:40:04","0","","<p>The following does what you describe -- but I'm still not sure it does what you want.  It basically calculates recursions/branches two different ways: once by counting; once by recursive formula:</p>

<pre><code>from math import cos, sin, radians, pi
from turtle import Turtle, Screen

branchRatio = .65
bendAngle = radians(15)
branchAngle = radians(37)

def tree(t, n, x, y, a, branchRadius):
    global count
    count += 1

    cx = x + cos(a) * branchRadius
    cy = y + sin(a) * branchRadius

    t.width(1 * n ** 1.2)
    t.color('pink' if t.width() &lt; 0.3 else 'black')

    t.goto(x, y)
    t.pendown()
    t.goto(cx, cy)
    t.penup()

    if n &gt; 0:
        tree(t, n-1, cx, cy, a + bendAngle - branchAngle, branchRadius * branchRatio)
        tree(t, n-1, cx, cy, a + bendAngle + branchAngle, branchRadius * branchRatio)
        tree(t, n-1, cx, cy, a + bendAngle, branchRadius * (1 - branchRatio))

def count_num_branches(n):
    branches = 1

    if n &gt; 0:
        branches += 3 * count_num_branches(n - 1)

    return branches

N = 3  # Run with N = 1, 2, 3, 4, 5 and 6

screen = Screen()
screen.setworldcoordinates(0, 0, 1, 1)
screen.bgcolor('cyan')
screen.title(""My Tree:  N = {0}"".format(N))
screen.tracer(15)

turtle = Turtle(visible=False)
#turtle.speed('fastest')
turtle.penup()

count = 0
tree(turtle, N, .5, 0, pi/2, .3)

screen.title(""My Tree:  N = {0}, Recursive calls = {1:,}, # Branches = {2:,}"".format(N, count, count_num_branches(N)))
screen.exitonclick()
</code></pre>
","5771269","","","0","1508","cdlane","2016-01-10 23:40:41","23572","1435","378","265","49051781","","2018-03-01 14:25:04","-1","112","<p>In a tutorial that I am working through, there's sample code of a tree being drawn with different levels of branches. I am trying to write a function that displays the number of branches when the ""level"" of the tree changes ""denoted by N"".</p>

<p>In the code below, the two commented # lines below show what I am trying to accomplish. I completely understand that when N is incremented by 1, the number of branches added to the tree is a multiple of 3, but I do not understand how to utilize a function <code>count_num_branches()</code> to display the number of branches on the tree at each recursive call.</p>

<pre><code>__author__ = 'Python Tutotial'
from math import cos, sin, radians, pi
import turtle

"""""" Run with br = 1, 2, 3, 4, and 5 and put together a recursive formula
that can be used to determine the count)num_branches.
""""""

def tree(t, n, x, y, a, branchRadius):
    global count
    count += 1
    bendAngle   = radians(15)
    branchAngle = radians(37)
    branchRatio = .65

    cx = x + cos(a) * branchRadius
    cy = y + sin(a) * branchRadius

    t.width(1 * n ** 1.2)
    if t.pensize() &lt; .3:
        t.color('pink')
    else:
        t.color('black')

    t.goto(x, y)
    t.down()
    t.goto(cx, cy)
    t.up()
    if not n:
        return None

    tree(t, n-1, cx, cy, a + bendAngle - branchAngle, branchRadius * branchRatio)
    tree(t, n-1, cx, cy, a + bendAngle + branchAngle, branchRadius * branchRatio)
    tree(t, n-1, cx, cy, a + bendAngle,               branchRadius * (1 - branchRatio))

# def count_num_branches(br):

def main():
    global count
    count = 0
    N = 1  #Run with N = 1, 2, 3, 4, and 5
    t = turtle.Turtle()
    wn = turtle.Screen()
    wn.setworldcoordinates(0, 0, 1, 1)
    wn.bgcolor('cyan')
    wn.title(""My Tree  N = ""+str(N))
    #t.speed(0)
    turtle.tracer(15)
    t.ht()
    t.up()
    tree(t, N, .5, 0, pi/2, .3)
    # wn.title(""My Tree  N = {0}, Recursive calls: {1:,} count_num_branches = {2:,}"".format(N, count, count_num_branches(br)))
    wn.exitonclick()
</code></pre>
","9397646","5771269","2018-03-02 00:04:38","Python - Recursive Formula","<python><recursion><turtle-graphics>","1","2","2050"
"49059141","2018-03-01 21:41:28","0","","<p>You can read the file line by line into a list, and then use regex:</p>

<pre><code>import re
data = filter(None, [i.strip('\n') for i in open('filename.txt')])
new_data = [i for i in data if re.findall('^[A-Z\s]+$', i)]
</code></pre>

<p>Output:</p>

<pre><code>['THIS IS A TITLE', 'THIS IS A TITLE', 'THIS IS A TITLE']
</code></pre>
","7326738","","","0","338","Ajax1234","2016-12-21 16:39:57","49079","3709","2930","360","49059091","49059785","2018-03-01 21:37:48","-2","54","<p>Here is my input file:</p>

<pre><code>THIS IS A TITLE

1. THIS IS A SUBTITLE

This is body text.
This is body text.

This is body text.
This is body text.

THIS IS A TITLE

This is body text.

THIS IS A TITLE

1. THIS IS A SUBTITLE

2. THIS IS A SUBTITLE

This is body text.
This is body text.
</code></pre>

<p>I want to create a list of just titles, but not subtitles or body text. How do I do that? So far, I thought of looping through the file, grabbing the line if it <code>isupper()</code>, but that grabs the subtitles too. <code>isalpha()</code> rejects any titles with spaces in the line, so that doesn't work. What can I do? I prefer to loop rather than regex.</p>
","8729810","8729810","2018-03-01 21:54:49","How to parse a file to return a list of uppercase lines without numbers?","<python><regex><loops>","3","0","679"
"49059145","2018-03-01 21:41:47","0","","<p>I was able to figure out a solution:</p>

<pre><code>import numpy
filename = '../HTRU2/test.csv'
file = open(filename, 'rU')
data = numpy.loadtxt(file, delimiter=',')
training_data = list()
for test in data:
    training_data.append((test[:-1].reshape(8, 1), test[-1].reshape(1, 1)))
</code></pre>

<p>Where the number of input neurons is 8 and the number of output neurons is 1.</p>
","6105802","","","0","387","Daniel Marques","2016-03-23 17:46:15","195","63","50","5","49036453","49059145","2018-02-28 18:42:50","-1","80","<p>I'm new to python and I'm trying to perform a simple task which is to read a .csv file and save it in a specific data structure. I'm using numpy to load the data and I get a <code>ndarray</code> of <code>ndarray</code>'s, which is not exactly what I want.</p>

<p>My code:</p>

<pre><code>import numpy
filename = '../HTRU2/HTRU_2.csv'
raw_data = open(filename, 'rU')
data = numpy.loadtxt(raw_data, delimiter=',')
</code></pre>

<p>The data structure I'm looking for is a <code>list</code> of <code>tuples</code>. The <code>tuples</code> are a pair (x,y) of <code>ndarray</code>s: <em>x</em> is a <code>ndarray</code> of shape (<em>nx</em> - 1, 1) filled with <code>float</code>s, where <em>nx</em> is the number of elements of each line in the file minus 1; y is a <code>ndarray</code> of shape (1, 1) that holds the last element of the line (also a <code>float</code>).</p>

<p>You might think this is some crazy data structure I've made up, but it's actually quite useful since my end goal is to put this in a Neural Network (if you know about NN's you probably guessed the tuple is actually a pair of inputs/output, where both are a column matrix). I must not change the data structure.</p>

<p>File sample:</p>

<pre><code>140.5625,55.68378214,-0.234571412,-0.699648398,3.199832776,19.11042633,7.975531794,74.24222492,0
102.5078125,58.88243001,0.465318154,-0.515087909,1.677257525,14.86014572,10.57648674,127.3935796,0
</code></pre>

<p>Each tuple would look like this:</p>

<pre><code>#     x                      y
[[140.5625]               
[55.68378214]
[-0.234571412]
[-0.699648398]
[3.199832776]
[19.11042633]
[7.975531794]
[74.24222492]]     ,      [[0]]
</code></pre>
","6105802","6105802","2018-02-28 23:22:01","Read artificial intelligence training data (.csv) to specific data structure in Python","<python><csv><numpy><data-structures><artificial-intelligence>","3","6","1683"
"49059163","2018-03-01 21:43:19","1","","<p>Without regular expressions you can do it like this:</p>

<pre><code># Read the file in as a single string, with all the newlines intact.
with open('file.txt', 'r') as f:
    file_str = f.read()

# Split into paragraphs
paragraphs = file_str.split('\n\n')

titles = []
for p in paragraphs:
    # Split a paragraph into lines, and get the first line of the paragraph
    # (which is the title).
    titles.append(p.split('\n')[0])
</code></pre>

<p>If you put the sample input you provided in the question into <code>file.txt</code>, variable <code>titles</code> will end up with:</p>

<pre><code>['THIS IS A TITLE', 'THIS IS A TITLE', 'THIS IS A TITLE']
</code></pre>
","797744","","","2","671","DBedrenko","2011-06-14 13:34:09","2738","491","2167","785","49059091","49059785","2018-03-01 21:37:48","-2","54","<p>Here is my input file:</p>

<pre><code>THIS IS A TITLE

1. THIS IS A SUBTITLE

This is body text.
This is body text.

This is body text.
This is body text.

THIS IS A TITLE

This is body text.

THIS IS A TITLE

1. THIS IS A SUBTITLE

2. THIS IS A SUBTITLE

This is body text.
This is body text.
</code></pre>

<p>I want to create a list of just titles, but not subtitles or body text. How do I do that? So far, I thought of looping through the file, grabbing the line if it <code>isupper()</code>, but that grabs the subtitles too. <code>isalpha()</code> rejects any titles with spaces in the line, so that doesn't work. What can I do? I prefer to loop rather than regex.</p>
","8729810","8729810","2018-03-01 21:54:49","How to parse a file to return a list of uppercase lines without numbers?","<python><regex><loops>","3","0","679"
"49059172","2018-03-01 21:44:01","1","","<p>seems like you are missing a <code>\</code> - use <code>os.path.join</code>:</p>

<pre><code>from os.path import dirname, join, abspath
filename = join(dirname(abspath(__file__)), 'starttext')
file = open(filename, 'r')
</code></pre>

<ul>
<li><code>__file__</code> - the path to the module's source file (you can also do import <code>requests;requests.__file__</code>)</li>
<li><code>os.path.abspath</code> - returns the absolute filename (e.g. <code>abspath('..')</code> returns <code>/home</code>)</li>
<li><code>os.path.dirname</code> - returns the dirname of a file</li>
<li><code>os.path.join</code> - joins a file parts compatible on both linux and windows</li>
</ul>
","7438048","7438048","2018-03-01 21:49:40","6","678","ShmulikA","2017-01-18 21:53:44","1711","165","721","9","49058713","49059172","2018-03-01 21:08:07","0","132","<p>I am writing something in Python where I want to use predefined texts from files within the package. Somehow I can't manage to get it to work in Eclipse PyDev Console.</p>

<p><a href=""https://i.stack.imgur.com/edq1j.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/edq1j.jpg"" alt=""filepath""></a></p>

<p>This is my path structure. From ""story.py"" I want to use the content of ""starttext"".</p>

<p>I tried open() with multiple variations of os.getcwd() and os.path.dirname(sys.argv[0]) which resulted in</p>

<blockquote>
  <p>FileNotFoundError: [Errno 2] No such file or directory: '..\starttext'</p>
</blockquote>

<p>My last attempt was trying something like</p>

<pre><code>import pkg_resources
resource_package = __name__
resource_path = '/'.join(('.', 'starttext'))
template = pkg_resources.resource_stream(resource_package, resource_path)
</code></pre>

<p>resulting in:</p>

<pre><code> Traceback (most recent call last):
  File ""&lt;input&gt;"", line 1, in &lt;module&gt;
  File ""C:\Program Files\Python\Python36-64\lib\site-packages\pkg_resources\__init__.py"", line 1232, in resource_stream
    self, resource_name
  File ""C:\Program Files\Python\Python36-64\lib\site-packages\pkg_resources\__init__.py"", line 1479, in get_resource_stream
    return io.BytesIO(self.get_resource_string(manager, resource_name))
  File ""C:\Program Files\Python\Python36-64\lib\site-packages\pkg_resources\__init__.py"", line 1482, in get_resource_string
    return self._get(self._fn(self.module_path, resource_name))
  File ""C:\Program Files\Python\Python36-64\lib\site-packages\pkg_resources\__init__.py"", line 1560, in _get
    ""Can't perform this operation for loaders without 'get_data()'""
NotImplementedError: Can't perform this operation for loaders without 'get_data()'
</code></pre>

<p>which appears to have something to do with python 3.x?</p>

<p>This seems to be such an easy task and I don't understand whats wrong.
Any help is appreciated.</p>

<p>Thank you.</p>

<p><strong>update</strong></p>

<p>Thanks to ShmulikA I changed it to:</p>

<pre><code>    from os.path import dirname, join, abspath
    filename = join(dirname(abspath(communitybot.anthology.teststory.story.__file__)), 'starttext')
    file = open(filename, 'r')

    content = file.read()
</code></pre>

<p>This works although I think it is a little bit long, but I'm certain I am still doing something wrong there.</p>
","3731191","3731191","2018-03-01 23:05:09","How to get content of file inside package","<python><eclipse><python-3.6>","1","0","2413"
"49059179","2018-03-01 21:44:27","0","","<p>Based on my understanding of your requirement. I would suggest this approach:</p>

<ol>
<li><p>Create Login Class with a method to return driver. (Here, you initialize a driver and return it. So, you can use the same browser while using other classes also)</p></li>
<li><p>For all your six Classes, define methods which take driver as a parameter and return the same after statements. (So, every time you call these methods, you can give your driver to them) 
Note: you don't need to write Login statements again.</p></li>
<li><p>Finally, write a new script which imports all the classes you have created. Here initialize a Login Class and get driver handler by calling log method (based on your Login Class). Then call other methods from any class that you want by providing the driver you received as an argument.</p></li>
</ol>

<p>i. Since you are initializing firefox driver in both Login and ClassName1, two sessions are created. You should avoid initializing driving in ClassName because you have already specific code for it in Login Class.</p>

<p>ii. Yes, you can test all the classes with one browser session using above guidelines.</p>

<p>Hope this helps to organize your code.</p>
","9157925","","","0","1198","Madan","2017-12-31 07:31:02","26","3","0","0","49057075","","2018-03-01 19:12:00","0","366","<p>I have an application with six functions. Each of them begins with logging in to the website. I create another class named login (below the code).
The structure of the project is 6 classes and main class.
How do you use this function in these six classes?
This my code for login in every single class and login class</p>

<pre><code>class ClassName1(unittest.TestCase):
    WebDriver driver=new FirefoxDriver();
    driver.get(""URL"");
    login=driver.find_element_by_name('Login')
    password=driver.find_element_by_name('Password')
    username.send_keys(""login"")
    password.send_keys(""password"")
    driver.find_element_by_name(""submit"").click()
</code></pre>

<p>I created Login class:</p>

<pre><code>class Login(unittest.TestCase)
    def log(self):
        WebDriver driver=new FirefoxDriver();
            driver.get(""URL"");
        login=driver.find_element_by_name('Login')
        password=driver.find_element_by_name('Password')
        username.send_keys(""login"")
        password.send_keys(""password"")
        selenium.find_element_by_name(""submit"").click()
</code></pre>

<p>My proposition is:</p>

<p><strong>from file import Login</strong> -> to ClassName1 and in class:
        <strong>Login.log()</strong> but I don't know how use this
I have two session browser and error i don't know how to combine it into one session</p>

<p>And second question in my app in every single class I make - webdriver, can I test my six class in on browser session? Every single class open browser. I would like this in one. It's possible ? 
<strong>And second question</strong> in my app in every single class I make - webdriver, can I test my six class in one browser session? It's possible ? How I should change my code? Thank you!</p>
","9429143","9429143","2018-03-02 14:34:39","Python Selenium - One session browser","<java><python><selenium><selenium-webdriver><webdriver>","2","1","1746"
"49059196","2018-03-01 21:45:42","0","","<p>This is the correct answer with the addition of wait time and screenshot:
import unittest
import time</p>

<p>from selenium import webdriver
from selenium.webdriver.common.action_chains import ActionChains</p>

<p>class LoginTest(unittest.TestCase):</p>

<pre><code>def setUp(self):
    self.driver = webdriver.Chrome()
    self.driver.get(""https://www.rosoka.com"")
    self.driver.save_screenshot('rosoka.png')
    time.sleep(10)

def test_login(self):
    rosoka_username = ""****""
    rosoka_password = ""***""

    user_portal = self.driver.find_element_by_xpath('//*[@id=""om-leaf-om-u1-570991293-8""]/span/span')
    hover = ActionChains(self.driver).move_to_element(user_portal)
    hover.perform()

    login_field = self.driver.find_element_by_id('edit-name')
    login_field.clear()
    login_field.send_keys(rosoka_username)

    pass_field = self.driver.find_element_by_id('edit-pass')
    pass_field.clear()
    pass_field.send_keys(rosoka_password)

    login_button = self.driver.find_element_by_id('edit-submit')
    login_button.click()
    time.sleep(10)


def tearDown(self):
    self.driver.quit()
</code></pre>

<p>if <strong>name</strong> == '<strong>main</strong>':
    unittest.main()</p>
","9260533","","","0","1211","dsmith","2018-01-24 06:32:09","19","13","0","0","48794637","","2018-02-14 19:17:27","0","125","<p>So I have Python 2.7.10. I have Selenium 3.5.9. I have the current version of PyCharm and I set up the local interpreter. I am trying to run a unitest on my company's website and I am getting back:</p>

<blockquote>
  <p>Ran 0 tests in 0.000s</p>
  
  <p>OK</p>
</blockquote>

<p>This is my code:</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
import unittest

class LoginTest(unittest.TestCase):

    def setUp(self):
        self.driver = webdriver.Chrome()
        self.driver.get(""https://www.rosoka.com/"")

    def test_Login(self):
        driver = self.driver
        rosokaUsername = ""*****@rosoka.com""
        rosokaPassword = ""******""
        loginFieldID = ""edit-name""
        passFieldID = ""edit-pass""
        loginButtonXpath = ""//input[@value ='Log in']""

        loginFieldElement = WebDriverWait(driver, 10).until(lambda driver: find_element_by_id(loginFieldID))
        passFieldElement = WebDriverWait(driver, 10).until(lambda driver: find_element_by_id(passFieldID))
        loginButtonElement = WebDriverWait(driver, 10).until(lambda driver: find_element_by_xpath(loginButtonXpath))

        loginFieldElement.clear()
        loginFieldElement.send_keys(rosokaUsername)
        passFieldElement.clear()
        passFieldElement.send_keys(rosokapassword)
        loginButtonElement.click()

    def tearDown(self):
        self.driver.quit()

    if __name__ == '__main__':
        unittest.main()
</code></pre>

<p>Can someone help?</p>
","9260533","4794459","2018-02-14 21:20:45","First time running PyCharm ChromeDriver test","<python><selenium>","2","2","1516"
"49059236","2018-03-01 21:49:05","5","","<p><strong>Direct answer</strong>: No, you cannot disable the stack limit; it's there to avoid using up all the available stack space, which would crash your run without any Traceback information.</p>

<p>Also, note that it's not <em>possible</em> to have an infinite stack size: each stack frame occupies RAM; you'll eventually run out and crash the system.</p>

<p><strong>Workaround</strong>: If you can handle a hard crash, then simply use <code>sys.setrecursionlimit</code> to set it beyond the physical limits of your system (which are system-dependent).</p>

<p><strong>Real solution</strong>: as Juan already noted, you can simply re-code your recursion as a loop.</p>
","4785185","","","0","677","Prune","2015-04-14 00:37:53","54183","8845","3232","13592","49059133","49059236","2018-03-01 21:40:53","1","364","<p>So I was trying to make a simple program that would calculate the sum of the harmonic series and then print the results. But then the recursion limit stops it from going on.</p>

<p>Here is the program:</p>

<pre><code>def harm_sum(n):
    if n &lt; 2:
        return 1
    else: 
return (1 / n) + (harm_sum(n - 1))

x = 1
while True:
    print(x, harm_sum(x))
    x += 1
</code></pre>

<p>I want the program to keep on running despite the recursion limit is there a way to do that? </p>
","9431267","9431267","2018-03-01 21:45:02","Is there a way to set the recursion limit to infinite in Python?","<python><python-3.x>","1","4","491"
"49059248","2018-03-01 21:50:38","1","","<p>You need to specify an aggregation function with <code>groupby</code>, for example <code>sum</code>. In addition, it's likely you want the result to be a <code>pd.DataFrame</code> without setting index to <code>groupby</code> columns. This can be achieved by setting <code>as_index=False</code>.</p>

<p>Try this:</p>

<pre><code>import pandas as pd

df = pd.DataFrame({'group1':list('aaaabbbb'),
                   'group2':list('ccccbbbb'),
                   'val':[1,3,3,2,5,6,6,2],
                   'id':[1,1,2,2,2,3,3,3]})

newdf = df.groupby(['group1', 'group2'], as_index=False).sum()
newdf.loc[:, newdf.columns != 'val']
</code></pre>

<p>One way to demonstrate this in more detail:</p>

<pre><code>newdf = df.groupby(['group1', 'group2'])
print(type(newdf))        # &lt;class 'pandas.core.groupby.DataFrameGroupBy'&gt;
print(type(newdf.sum()))  # &lt;class 'pandas.core.frame.DataFrame'&gt;
</code></pre>
","9209546","","","0","921","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49059164","49059248","2018-03-01 21:43:21","0","20","<p>So I was wondering WHY the following is not possible and HOW to get around it. </p>

<p>I've taken a data frame, grouped by one column, and set it to a new variable. Now I want to do something with that data frame and it produced an error</p>

<pre><code>df = pd.DataFrame({'group':list('aaaabbbb'),
                   'val':[1,3,3,2,5,6,6,2],
                   'id':[1,1,2,2,2,3,3,3]})
df    
newdf = df.groupby(""group"")
newdf.loc[:, newdf.columns != 'val']

df = pd.DataFrame({'group1':list('aaaabbbb'),
                   'group2':list('ccccbbbb'),
                   'val':[1,3,3,2,5,6,6,2],
                   'id':[1,1,2,2,2,3,3,3]})
df    
newdf = df.groupby([""group1"",""group2""])
newdf.loc[:, newdf.columns != 'val']


AttributeError: Cannot access callable attribute 'loc' of 'DataFrameGroupBy' objects, try using the 'apply' method
</code></pre>

<p>I use both of these data frames to create an iqr like the following</p>

<pre><code>Q1 = df1.quantile(0.15)
Q3 = df1.quantile(0.85)
IQR = Q3 - Q1
df1 = pd.DataFrame(IQR).reset_index()
</code></pre>
","2725751","2725751","2018-03-01 21:53:40","Excluding a column after grouping by in pandas","<python><pandas>","1","0","1061"
"49059266","2018-03-01 21:51:36","1","","<p>To generalize the stereo-vision pipeline (look <a href=""http://vision.deis.unibo.it/~smatt/Seminars/StereoVision.pdf"" rel=""nofollow noreferrer"">here</a> for more in-depth):</p>

<ol>
<li>Find the intrinsic/extrinsic values of each camera <a href=""https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#camera-calibration-and-3d-reconstruction"" rel=""nofollow noreferrer"">(good illustration here)</a></li>
<li>Solve for the transformation that will rectify your cameras' images <a href=""http://www.sci.utah.edu/~gerig/CS6320-S2012/Materials/CS6320-CV-F2012-Rectification.pdf"" rel=""nofollow noreferrer"">(good illustration here)</a></li>
<li>Capture a pair of images</li>
<li>Transform the images according to Step 2.</li>
<li>Perform stereo-correspondence on that pair of rectified images</li>
</ol>

<p>If we can assume that your cameras are going to remain perfectly stationary (relative to each other), you'll only need to perform Steps 1 and 2 one time after camera installation. </p>

<p>That leaves you with <strong>image capture</strong> (duh) and the <strong>image rectification</strong> as general stereo-vision tasks that can be done without the two cameras communicating. </p>

<p>Additionally, there are some pre-processing techniques (you could try <a href=""https://pdfs.semanticscholar.org/717d/efc1d7f67496e2f4770412eb3b096d46ed6a.pdf"" rel=""nofollow noreferrer"">this</a> and <a href=""https://www.researchgate.net/publication/221625747_Enhanced_Real-time_Stereo_Using_Bilateral_Filtering"" rel=""nofollow noreferrer"">this</a>) that have been shown to improve the accuracy of some stereo-correspondence algorithms. These could also be done on each of your image-capture platforms individually.</p>
","9391707","","","0","1748","mthor","2018-02-21 15:04:28","28","4","0","0","49056020","49059266","2018-03-01 18:04:43","0","112","<p>I have a decent amount of experience with OpenCV and am currently familiarizing myself with stereo vision. I happen to have two <a href=""http://jevois.org/"" rel=""nofollow noreferrer"">JeVois cameras</a> (don't ask why) and was wondering if it was possible to run some sort of code on each camera to distribute the workload and cut down on processing time. It needs to be so that each camera can do part of the overall process (without needing to talk to each other) and the computer they're connected to receives that information and handles the rest of the work. If this is possible, does anyone have any solutions or tips? Thanks in advance!</p>
","7028547","","","OpenCV decentralized processing for stereo vision","<python><c++><opencv>","1","1","650"
"49059287","2018-03-01 21:53:07","0","","<p>You can try using dnspython's <a href=""http://www.dnspython.org/docs/1.15.0/dns.resolver.Resolver-class.html"" rel=""nofollow noreferrer"">resolver class</a>, which has a nameservers list attached to it.</p>

<pre><code>import dns.resolver
resolver = dns.resolver.Resolver()
resolver.nameservers
# Returns ['8.8.8.8', '8.8.4.4', '8.8.8.8'] on my pc
</code></pre>
","1825510","","","0","363","Randy Butts","2012-11-15 02:42:53","16","4","0","0","49058273","","2018-03-01 20:34:15","-1","109","<p>Using Python, is there a way using psutil or something else to return the output of ""ipconfig /displaydns"" or something similar?</p>

<p>Spawning a cmd process and running the command is not an option.</p>
","1314011","","","Using python how to display dns","<python><python-2.7><psutil>","2","0","209"
"49059292","2018-03-01 21:53:28","1","","<p>start and stop are inclusive rather than one or the other (usually stop is excluded) and without imports, and using generators</p>

<pre><code>def rangef(start, stop, step, fround=5):
    """"""
    Yields sequence of numbers from start (inclusive) to stop (inclusive)
    by step (increment) with rounding set to n digits.

    :param start: start of sequence
    :param stop: end of sequence
    :param step: int or float increment (e.g. 1 or 0.001)
    :param fround: float rounding, n decimal places
    :return:
    """"""
    try:
        i = 0
        while stop &gt;= start and step &gt; 0:
            if i==0:
                yield start
            elif start &gt;= stop:
                yield stop
            elif start &lt; stop:
                if start == 0:
                    yield 0
                if start != 0:
                    yield start
            i += 1
            start += step
            start = round(start, fround)
        else:
            pass
    except TypeError as e:
        yield ""type-error({})"".format(e)
    else:
        pass


# passing
print(list(rangef(-100.0,10.0,1)))
print(list(rangef(-100,0,0.5)))
print(list(rangef(-1,1,0.2)))
print(list(rangef(-1,1,0.1)))
print(list(rangef(-1,1,0.05)))
print(list(rangef(-1,1,0.02)))
print(list(rangef(-1,1,0.01)))
print(list(rangef(-1,1,0.005)))
# failing: type-error:
print(list(rangef(""1"",""10"",""1"")))
print(list(rangef(1,10,""1"")))
</code></pre>

<blockquote>
  <p>Python 3.6.2 (v3.6.2:5fd33b5, Jul  8 2017, 04:57:36) [MSC v.1900 64
  bit (AMD64)]</p>
</blockquote>
","2175524","","","0","1556","Goran B.","2013-03-15 20:35:52","439","130","72","1","477486","477635","2009-01-25 10:20:43","671","691111","<p>Is there a way to step between 0 and 1 by 0.1? </p>

<p>I thought I could do it like the following, but it failed:</p>

<pre><code>for i in range(0, 1, 0.1):
    print i
</code></pre>

<p>Instead, it says that the step argument cannot be zero, which I did not expect.</p>
","49701","355230","2017-02-08 22:37:38","How to use a decimal range() step value?","<python><floating-point><range>","33","5","275"
"49059302","2018-03-01 21:54:16","0","","<p>Figured it out - I didn't realize that the results sets clause can have multiple result sets so you need use this syntax:</p>

<pre><code>with result sets (([id] int null));
</code></pre>

<p>Then if you Python returns multiple sets:</p>

<pre><code>with result sets ((A int null), (B int null), (C int null));
</code></pre>
","462477","","","0","328","sisdog","2010-09-30 04:57:54","1717","210","59","11","49033818","","2018-02-28 16:06:16","0","48","<p>I'm using Python in TSQL and trying to output data but getting the syntax error below. Any ideas?</p>

<pre><code>execute sp_execute_external_script 
@language = N'Python',
@script = N'
import pandas as pd
from pandas import DataFrame

OutputDataSet = pd.DataFrame({ ""id"" : 1.})
'
with result sets ([id] int null);
</code></pre>

<p><strong>Msg 102, Level 15, State 1, Line 9
    Incorrect syntax near 'id'.</strong></p>
","462477","","","SQLServer Python Output","<python><sql-server>","1","0","424"
"49059305","2018-03-01 21:54:38","2","","<p>Okay so I finally worked it out...</p>

<p>I uninstalled Python3.6 and deleted all relevant folders.</p>

<p>I then went to Control Panel>Programs>Progams and Features and repaired my Python2.7 program. pip works now (I think it got messed up since I tried to rename the universal pip.exe file -> don't do that!!). </p>

<p>After re-downloading Python3.6, I put my universal pip.exe download from Python3 in a different directory so the Path would not get it confused. I now have Paths for both pip2 and pip3 and all is okay.</p>

<p>Thanks for your help!</p>
","9430920","","","0","563","Atlas King","2018-03-01 19:58:34","26","1","4","0","49057888","","2018-03-01 20:07:39","1","7972","<p>I've seen many threads about this, and have tried all options except for completely wiping Python off of my machine and re-downloading everything...</p>

<p>I'm using a Windows 10, 64-bit machine, and had already downloaded Python2.7. Commands like 'C:\>pip install seaborn' were not an issue.</p>

<p>I recently downloaded Python3.6, and now my pip will not work - it returns the error in the title.</p>

<p>I have added <code>C:\Python27, C:\Python36, C:\Python27\Scripts, C:\Python36\Scripts</code> to my Path, and still it won't work.</p>

<p>If I type in the command <code>C:\&gt;python27 -m pip install seaborn</code>, however, the pip works. I am really confused why I can no longer just type in pip install  and have it work.</p>

<p>Thanks in advance!</p>
","9430920","8372104","2018-03-01 20:24:05","Pip error: Fatal error in launcher: Unable to create process using '""'","<python><python-3.x><python-2.7><pip><python-3.6>","4","0","768"
"49059363","2018-03-01 21:59:15","2","","<p>If someone is looking for an inverse transformation (i.e. given an element index <code>idx</code>, figure out which <code>(i, j)</code> element corresponds to it), here is a resonably vectored solution:</p>

<pre><code>def actual_indices(idx, n):
    n_row_elems = np.cumsum(np.arange(1, n)[::-1])
    ii = (n_row_elems[:, None] - 1 &lt; idx[None, :]).sum(axis=0)
    shifts = np.concatenate([[0], n_row_elems])
    jj = np.arange(1, n)[ii] + idx - shifts[ii]
    return ii, jj

n = 5
k = 10
idx = np.random.randint(0, n, k)
a = pdist(np.random.rand(n, n))
b = squareform(a)

ii, jj = actual_indices(idx, n)]
assert np.allclose(b[ii, jj, a[idx])
</code></pre>

<p>I used it to figure out indexes of closest rows in a matrix.</p>

<pre><code>m = 3  # how many closest
lowest_dist_idx = np.argpartition(-a, -m)[-m:]
ii, jj = actual_indices(lowest_dist_idx, n)  # rows ii[0] and jj[0] are closest
</code></pre>
","232371","232371","2018-03-01 22:57:06","0","911","Ben Usman","2009-12-15 19:07:01","3275","457","442","0","13079563","13079806","2012-10-26 01:21:08","59","37460","<p><code>scipy.spatial.distance.pdist</code> returns a condensed distance matrix. From <a href=""http://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html"" rel=""noreferrer"">the documentation</a>:</p>

<blockquote>
  <p>Returns a condensed distance matrix Y. For each  and  (where ), the metric dist(u=X[i], v=X[j]) is computed and stored in entry ij.</p>
</blockquote>

<p>I thought <code>ij</code> meant <code>i*j</code>. But I think I might be wrong. Consider</p>

<pre class=""lang-py prettyprint-override""><code>X = array([[1,2], [1,2], [3,4]])
dist_matrix = pdist(X)
</code></pre>

<p>then the documentation says that <code>dist(X[0], X[2])</code> should be <code>dist_matrix[0*2]</code>. However, <code>dist_matrix[0*2]</code> is 0 -- not 2.8 as it should be. </p>

<p>What's the formula I should use to access the similarity of a two vectors, given <code>i</code> and <code>j</code>?</p>
","629191","1403604","2019-01-04 11:52:13","How does condensed distance matrix work? (pdist)","<python><numpy><scipy>","7","0","921"
"49059369","2018-03-01 21:59:45","0","","<p>I know what the problem was.
My application when it was being deployed was single threaded, not multithreaded.
I changed my worker number and that fixed everything.</p>
","8539771","","","0","172","tommyshere","2017-08-30 18:59:26","11","9","0","0","48833111","49059369","2018-02-16 18:48:46","0","42","<p>I'm doing a <code>requests.get(url='url', verify=False),</code> from my django application hosted on an Ubuntu server from AWS, to a url that has a Django Rest Framework. There are no permissions or authentication on the DRF, because I'm the one that made it. I've added headers such as </p>

<p><code>headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}</code>, but wasn't able to get any content.</p>

<p>BUT when I do run <code>./manage.py shell</code> and run the exact same command, I get the output that I need!</p>

<p>EDIT 1:
So I've started using <code>subprocess.get_output(""curl &lt;url&gt; --insecure"", shell=True)</code> and it works, but I know this is not a very ""nice"" way to do things.</p>
","8539771","8539771","2018-02-16 19:10:59","Why do I not get any content with python requests get, but still a 200 response?","<python><django><python-requests>","1","2","806"
"49059395","2018-03-01 22:01:51","0","","<p>if you want to set a text counter you do not need to use <code>keyboard_on_key_down</code>, you just need to catch the text change for them we use <code>bind</code>, then we can use a lambda function to update the values since the bind returns the instance and the property changed, to set the value we use <code>setattr</code>:</p>

<pre><code>from kivy.app import App
from kivy.uix.label import Label
from kivy.uix.textinput import TextInput
from kivy.uix.boxlayout import BoxLayout


class MyApp(App):
    def build(self):
        layout = BoxLayout(orientation='vertical')
        answer = TextInput(multiline=False, text="""", size_hint=(1, 0.5))
        ansLen = Label(bold=True, halign=""center"", text="""", size_hint=(1, 0.5))

        answer.bind(text=lambda instance, text: setattr(ansLen, ""text"", str(len(text))))
        layout.add_widget(answer)
        layout.add_widget(ansLen)
        return layout


if __name__ == '__main__':
    MyApp().run()
</code></pre>
","6622587","","","1","974","eyllanesc","2016-07-21 23:29:11","114264","27275","2584","21000","49059214","49059395","2018-03-01 21:47:13","0","164","<p>again! I'm trying to add a character counter to my TextInput widget, but I don't know what parameters to pass for the four arguments, or much on how they're supposed to function. I checked the documentation, but it was putting me further into the woods. Anyway, here are the relevant snippets.</p>

<pre><code>def charsLeft(window, keycode, text, modifiers):
     # Do some magic, pass some parameters, and then...
     ansLen.text = str(len(hidden.text) - len(answer.text))
</code></pre>

<p>And here's the code for my layout:</p>

<pre><code>ansLen = Label(bold=True, halign=""center"", size_hint=(.2, .5), text_size=self.size, valign=""middle"")
answer = TextInput(id=""sbt"", multiline=False, size_hint=(.8, .5), text="""")
answer.bind(keyboard_on_key_down=charsLeft)
</code></pre>

<p>I figure since it's on virtually every website, it ought to be fairly straightforward. I just don't know what I don't know here.</p>
","5638513","5638513","2018-03-02 01:16:38","Kivy Character Counter from TextInput","<python><kivy><textinput>","1","0","918"
"49059414","2018-03-01 22:03:34","9","","<p>You have two problems in your code (use option <code>-a</code> to make it visible):</p>

<ol>
<li>The indexing of numpy array isn't <a href=""http://cython.readthedocs.io/en/latest/src/tutorial/numpy.html#efficient-indexing"" rel=""noreferrer"">efficient</a></li>
<li>You have forgotten <code>int</code> in <code>cdef sum=0</code></li>
</ol>

<p>Taking this into account we get:</p>

<pre><code>cpdef int f(np.ndarray[np.int_t] f):  ##HERE
    assert f.dtype == np.int
    cdef int array_length =  f.shape[0]
    cdef int sum = 0                  ##HERE
    cdef int k
    for k in range(array_length):
        sum += f[k]
    return sum
</code></pre>

<p>For the loop the following code:</p>

<pre><code>int __pyx_t_5;
int __pyx_t_6;
Py_ssize_t __pyx_t_7;
....
__pyx_t_5 = __pyx_v_array_length;
for (__pyx_t_6 = 0; __pyx_t_6 &lt; __pyx_t_5; __pyx_t_6+=1) {
   __pyx_v_k = __pyx_t_6;
   __pyx_t_7 = __pyx_v_k;
   __pyx_v_sum = (__pyx_v_sum + (*__Pyx_BufPtrStrided1d(__pyx_t_5numpy_int_t *, __pyx_pybuffernd_f.rcbuffer-&gt;pybuffer.buf, __pyx_t_7, __pyx_pybuffernd_f.diminfo[0].strides)));
</code></pre>

<p>}</p>

<p>Which is not that bad, but not as easy for the optimizer as the normal code written by human. As you have already pointed out, <code>__pyx_pybuffernd_f.diminfo[0].strides</code> isn't known at compile time and this prevents vectorization.</p>

<p>However, you would get better results, when using <a href=""http://cython.readthedocs.io/en/latest/src/userguide/memoryviews.html"" rel=""noreferrer"">typed memory views</a>, i.e:</p>

<pre><code>cpdef int mf(int[::1] f):
    cdef int array_length =  len(f)
...
</code></pre>

<p>which leads to a less opaque C-code - the one, at least my compiler, can better optimize: </p>

<pre><code> __pyx_t_2 = __pyx_v_array_length;
  for (__pyx_t_3 = 0; __pyx_t_3 &lt; __pyx_t_2; __pyx_t_3+=1) {
    __pyx_v_k = __pyx_t_3;
    __pyx_t_4 = __pyx_v_k;
    __pyx_v_sum = (__pyx_v_sum + (*((int *) ( /* dim=0 */ ((char *) (((int *) __pyx_v_f.data) + __pyx_t_4)) ))));
  }
</code></pre>

<p>The most crucial thing here, is that we make it clear to the cython, that the memory is continuous, i.e. <code>int[::1]</code> compared to <code>int[:]</code> as it is seen for numpy-arrays, for which a possible <code>stride!=1</code> must be taken into account.</p>

<p>In this case, the cython-generated C-code results in the <a href=""https://godbolt.org/g/tdr963"" rel=""noreferrer"">same assembler</a> as <a href=""https://godbolt.org/g/mRJQfD"" rel=""noreferrer"">the code</a> I would have written. As crisb has pointed out, adding <code>-march=native</code> would lead to vectorization, but in this case the assembler of both functions would be slightly different again.</p>

<p>However, in my experience, compilers have quite often some problems to optimize loops created by cython and/or it is easier to miss a detail which prevents the generation of really good C-code. So my strategy for working-horse-loops is to write them in plain C and use cython for wrapping/accessing them - often it is somewhat faster, because one can also use dedicated compiler flags for this code-snipped without affecting the whole Cython-module.</p>
","5769463","5769463","2018-03-04 19:23:29","3","3167","ead","2016-01-10 11:01:05","16524","1022","2657","521","49058949","49059414","2018-03-01 21:26:38","5","856","<p>I need to get an overview of the performance one can get from using Cython in high performance numerical code. One of the thing I am interested in is to find out if an optimizing C compiler can vectorize code generated by Cython. So I decided to write the following small example:</p>

<pre><code>import numpy as np
cimport numpy as np
cimport cython

@cython.boundscheck(False)
@cython.wraparound(False)
cpdef int f(np.ndarray[int, ndim = 1] f):
    cdef int array_length =  f.shape[0]
    cdef int sum = 0
    cdef int k
    for k in range(array_length):
        sum += f[k]
    return sum
</code></pre>

<p>I know that there are Numpy functions that does the job, but I would like to have an easy code in order to understand what is possible with Cython. It turns out that the code generated with:</p>

<pre><code>from distutils.core import setup
from Cython.Build import cythonize

setup(ext_modules = cythonize(""sum.pyx""))
</code></pre>

<p>and called with:</p>

<pre><code>python setup.py build_ext --inplace
</code></pre>

<p>generates a C code which look likes this for the loop:</p>

<pre><code>for (__pyx_t_2 = 0; __pyx_t_2 &lt; __pyx_t_1; __pyx_t_2 += 1) {
  __pyx_v_sum = __pyx_v_sum + (*(int *)((char *) 
    __pyx_pybuffernd_f.rcbuffer-&gt;pybuffer.buf +
    __pyx_t_2 * __pyx_pybuffernd_f.diminfo[0].strides)));
}
</code></pre>

<p>The main problem with this code is that the compiler does not know at compile time that <code>__pyx_pybuffernd_f.diminfo[0].strides</code> is such that the elements of the array are close together in memory. Without that information, the compiler cannot vectorize efficiently.</p>

<p>Is there a way to do such a thing from Cython?</p>
","3763545","-1","2018-05-03 14:53:11","Generating SIMD instructions from Cython code","<python><cython>","1","7","1686"
"49059418","2018-03-01 22:04:02","0","","<pre><code>In [1]: pd_daytable.groupby('days').apply(lambda x: x.merge(pd_busjouney))\
                   .set_index(['days', 'bus'])

Out[1]: 
          journey
days bus         
Mon  A         60
     B         60
Tue  A         60
     B         60
</code></pre>
","567620","","","0","266","ely","2011-01-07 23:55:27","44893","4128","1562","318","49059299","49059441","2018-03-01 21:53:53","0","24","<p>I have two dataframe with single index. I want to combine them into one but with two-level index. </p>

<pre><code>import pandas as pd  
import numpy as np  
busjouney={'bus':['A','B'],'journey':[60,60]}  
daytable={'days':['Mon','Tue'],'journey':[60,60]}  
pd_busjouney=pd.DataFrame(busjouney)  
pd_daytable=pd.DataFrame(daytable)  
</code></pre>

<p>I would like to combine these two data frames into one with two-level index like below:  </p>

<pre><code>days bus journey  
Mon  A   60  
     B   60  
Tue  A   60
     B   60
</code></pre>

<p>My cumbersome way is to create a dataframe with rows in Days and Columns in Bus and values as 60. Then use <code>pd.melt</code>and give index names. Anybody has better ideas? </p>
","9430674","","","Combine two single-index dataframe in rows to one with multi-level index","<python><pandas>","2","1","730"
"49059441","2018-03-01 22:05:55","0","","<p>Here is one way:</p>

<pre><code>df = pd_daytable.merge(pd_busjouney, how='left', on='journey')\
                .set_index(['days', 'bus'])

#           journey
# days bus         
# Mon  A         60
#      B         60
# Tue  A         60
#      B         60
</code></pre>
","9209546","","","0","279","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49059299","49059441","2018-03-01 21:53:53","0","24","<p>I have two dataframe with single index. I want to combine them into one but with two-level index. </p>

<pre><code>import pandas as pd  
import numpy as np  
busjouney={'bus':['A','B'],'journey':[60,60]}  
daytable={'days':['Mon','Tue'],'journey':[60,60]}  
pd_busjouney=pd.DataFrame(busjouney)  
pd_daytable=pd.DataFrame(daytable)  
</code></pre>

<p>I would like to combine these two data frames into one with two-level index like below:  </p>

<pre><code>days bus journey  
Mon  A   60  
     B   60  
Tue  A   60
     B   60
</code></pre>

<p>My cumbersome way is to create a dataframe with rows in Days and Columns in Bus and values as 60. Then use <code>pd.melt</code>and give index names. Anybody has better ideas? </p>
","9430674","","","Combine two single-index dataframe in rows to one with multi-level index","<python><pandas>","2","1","730"
"49059444","2018-03-01 22:06:03","1","","<p>In a URL, what travels after # is known as hash. In an HTTP request that reaches a server (server side) this data does not travel to the server. Therefore, on the server side, it is not possible to retrieve it (web browsers do not send this data in the HTTP request).</p>

<p>However, on the client side it is possible. In Javascript you could do:</p>

<p>window. location. hash</p>
","8275063","","","0","386","Daniel Garrido","2017-07-08 12:53:13","79","8","1","0","49059349","","2018-03-01 21:57:39","2","60","<p>How can I get param from URL after #?</p>

<p>Example:</p>

<pre><code>http://localhost/addAccount/#code=qwerty
</code></pre>

<p>I tried use <code>url = request.path</code> and <code>url.spit('/')</code> but it isn't working becasuse <code>request.path</code> don't read string after # in url.</p>
","9431330","","","How get param from URL after # in python","<python><django>","2","1","302"
"49059447","2018-03-01 22:06:13","0","","<p>dont try to parse urls manually - use the stdlib <a href=""https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlparse"" rel=""nofollow noreferrer""><code>urllib.parse.urlparse</code></a><br>
function (<a href=""https://docs.python.org/2/library/urlparse.html"" rel=""nofollow noreferrer""><code>urlparse.urlparse</code></a> on python2):</p>

<pre><code>from urllib.parse import urlparse  # from urlparse import urlparse on py2
scheme = urlparse('http://localhost/addAccount/#code=qwerty')
print(scheme.fragment)
</code></pre>

<p>prints out:</p>

<pre><code>code=qwerty
</code></pre>

<p>Unfortunately you cannot get from the server-side the <a href=""https://en.wikipedia.org/wiki/Fragment_identifier"" rel=""nofollow noreferrer"">fragement</a> of the url (data after the #). AFAIK all browsers wont send the fragement to the server (the fragement can be used only on client side code (e.g. javascript).</p>

<p>Quoting <a href=""https://en.wikipedia.org/wiki/Fragment_identifier#Basics"" rel=""nofollow noreferrer"">Wikipedia</a>:</p>

<blockquote>
  <p>When an agent (such as a Web browser) requests a web resource from a Web server, the agent sends the URI to the server, but does not send the fragment. Instead, the agent waits for the server to send the resource, and then the agent processes the resource according to the document type and fragment value.[2]</p>
</blockquote>
","7438048","7438048","2018-03-02 10:51:18","2","1386","ShmulikA","2017-01-18 21:53:44","1711","165","721","9","49059349","","2018-03-01 21:57:39","2","60","<p>How can I get param from URL after #?</p>

<p>Example:</p>

<pre><code>http://localhost/addAccount/#code=qwerty
</code></pre>

<p>I tried use <code>url = request.path</code> and <code>url.spit('/')</code> but it isn't working becasuse <code>request.path</code> don't read string after # in url.</p>
","9431330","","","How get param from URL after # in python","<python><django>","2","1","302"
"49059453","2018-03-01 22:06:49","2","","<p>yes there is <code>pystemd</code> </p>

<p><a href=""https://github.com/facebookincubator/pystemd"" rel=""nofollow noreferrer"">https://github.com/facebookincubator/pystemd</a></p>

<p>the tl;dr; ussage is</p>

<pre><code>with Unit(b'postfix.service') as service:
    service.Unit.Start('replace')
</code></pre>

<p>also provides nice interface to <code>pystemd.run</code> and <code>sd_notify</code></p>

<p>readme and _docs folder have a lot of code examples... feel free to ask anithing</p>
","2452406","","","1","492","aleivag","2013-06-04 15:31:36","1036","27","6","1","49020092","49059453","2018-02-28 00:21:48","0","227","<p>I would like to implement the <strong>systemd</strong> functionality from python script. Start and stop the services in Linux machine from python script using third party library.</p>

<pre><code>e.g: sudo systemctl start application.service
</code></pre>

<p>I know there is a library which support the <strong>systemd</strong> kind of functionality, i.e DBUS</p>

<pre><code>import dbus
sysbus = dbus.SystemBus()
</code></pre>

<p>But, I am looking for an best library other than dbus. Any ideas...</p>
","1720713","1720713","2018-02-28 22:00:46","Are there any new python library support systemd functionality other than DBUS","<python><systemd>","1","3","508"
"49059505","2018-03-01 22:11:19","1","","<p>Here is one way, but I wish there was an in-built way to do this.</p>

<pre><code>import pandas as pd

df = pd.DataFrame({'A': [11, 11, 22, 22, 33, 33],
                   'B': [3, 6, 1, 2, 4, 4]})

g = df.groupby('A', as_index=False).agg({'B': ['min', 'max']})

g.columns = ['_'.join(col).strip() if col[1] else col[0] for col in g.columns.values]

#     A  B_min  B_max
# 0  11      3      6
# 1  22      1      2
# 2  33      4      4
</code></pre>
","9209546","9209546","2018-03-01 22:27:34","3","455","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49059409","49059505","2018-03-01 22:02:57","1","401","<p>After some aggregation, my dataframe looks something like this</p>

<pre><code>  A     B
        B_min   B_max
0 11     3       6       
1 22     1       2
2 33     4       4
</code></pre>

<p>How do I make the columns be <code>A</code>, <code>B_min</code> and <code>B_max</code>, without any nesting? Simple and standard. I've tried <code>reindex_axix()</code> and <code>unstack()</code>, but nothing worked.</p>
","2475195","","","Flatten nested pandas dataframe columns","<python><pandas><dataframe><multi-index>","1","2","417"
"49059546","2018-03-01 22:14:49","1","","<p>Apparently </p>

<pre><code>pip install python-opencv
</code></pre>

<p>is not working at all and should not be used. After I installed Opencv from their website it worked</p>
","3977420","","","0","179","Peter111","2014-08-26 03:48:17","343","60","29","0","48561126","49059546","2018-02-01 10:59:11","1","1316","<p>I installed opencv on my Ubuntu 14.04 system system with</p>

<pre><code>pip install python-opencv
</code></pre>

<p>my Python version is 2.7.14</p>

<pre><code>import cv2
cv2.__version__
</code></pre>

<p>tells me that I have the OpenCV version 3.4.0.</p>

<p>After that I wanted to follow the tutorial on the OpenCV website </p>

<pre><code>import numpy as np
import cv2 as cv
img = cv.imread('messi5.jpg',0)
print img
</code></pre>

<p>It works fine until this point, but then I am supposed to enter </p>

<pre><code>cv.imshow('image',img)
</code></pre>

<p>and I get the following error:</p>

<pre><code>QObject::moveToThread: Current thread (0x233cdb0) is not the object's thread (0x2458430).
Cannot move to target thread (0x233cdb0)

QObject::moveToThread: Current thread (0x233cdb0) is not the object's thread (0x2458430).
Cannot move to target thread (0x233cdb0)

QPixmap: Must construct a QApplication before a QPaintDevice
</code></pre>

<p>Does anyone know what the problem is?</p>
","3977420","","","Python OpenCV imshow fails","<python><opencv><ubuntu-14.04>","3","9","996"
"49059552","2018-03-01 22:15:27","0","","<p>If I'm understanding what you're asking, you're looking for something along the lines of Chai JS. Fortunately, someone has written a python library that approximates it, also called <a href=""https://pypi.python.org/pypi/chai"" rel=""nofollow noreferrer"">Chai</a>. Your testcase would look something like this:</p>

<pre><code>FormatFilesCheck(files):
    expect(formatter.status).equals(installed)
    for prep in prework:
        do prep
        expect(prep).equals(what_prep_should_look_like)
        for file in files:
            format file
            expect(file).equals(what_file_should_look_like)
    clean up work
    # your expect/assert statements to make sure everything was cleaned up
</code></pre>
","1825510","","","1","714","Randy Butts","2012-11-15 02:42:53","16","4","0","0","49058338","49059552","2018-03-01 20:38:26","0","75","<p>I'm trying to make a testing system for continuous integration and I want to be able to have checks that do specific operations, like formatting files in a specific way, and those checks need to have a flow to them. </p>

<p>Example:</p>

<pre><code>FormatFilesCheck(files):
    Test(see if formatter is installed)
    for prep in prework:
        Test(do prep)
        for file in files:
            Test(try formatting file)
    Test(clean up work)
</code></pre>

<p>I was wondering if there is a python library out there that handles test control. Obviously there is unittest but from what I can tell it's meant linear testing, i.e. testing with dependencies.</p>

<p>If unittest has this capability an example would be amazing.</p>

<p>*edit: What I'm really looking for is a framework with unittest like capabilities for error handling and assertions which allows me to write checks and have them plug into it.</p>

<p>Thanks ahead of time</p>
","8395359","8395359","2018-03-01 23:45:08","Python library for continuous integration testing","<python><continuous-integration><integration-testing>","1","0","952"
"49059556","2018-03-01 22:15:36","2","","<p>So, assuming you know that you are working with a JSON and how to deserialize:</p>

<pre><code>&gt;&gt;&gt; import json
&gt;&gt;&gt; s = """"""{
...   ""parameter_010"": false,
...   ""parameter_009"": false,
...   ""parameter_008"": false,
...   ""parameter_005"": ""CMAX"",
...   ""parameter_004"": ""L"",
...   ""parameter_007"": false,
...   ""parameter_006"": ""R"",
...   ""parameter_001"": ""Foo"",
...   ""id"": 7542,
...   ""parameter_003"": ""D"",
...   ""parameter_002"": ""M""
... }""""""
&gt;&gt;&gt; d = json.loads(s)
</code></pre>

<p>If your <code>parameter_nnn</code> always and strictly follow this format, you can simply sort the items filtered by your requirements (since lexicographical sorting is what you want!):</p>

<pre><code>&gt;&gt;&gt; sorted([(k,v) for k, v in d.items() if v and k.startswith('parameter')])
[('parameter_001', 'Foo'), ('parameter_002', 'M'), ('parameter_003', 'D'), ('parameter_004', 'L'), ('parameter_005', 'CMAX'), ('parameter_006', 'R')]
</code></pre>

<p>If you just want the values, just do another pass:</p>

<pre><code>&gt;&gt;&gt; [v for _,v in sorted([(k,v) for k, v in d.items() if v and k.startswith('parameter')])]
['Foo', 'M', 'D', 'L', 'CMAX', 'R']
&gt;&gt;&gt;
</code></pre>

<p>Note, you are going to have to loop somehow...</p>

<p>A more readable version:</p>

<pre><code>&gt;&gt;&gt; selection = [(k,v) for k, v in d.items() if v and k.startswith('parameter')]
&gt;&gt;&gt; [v for _,v in sorted(selection)]
['Foo', 'M', 'D', 'L', 'CMAX', 'R']
</code></pre>

<h3> EDIT: Major Caveat </h3>

<p>Note, if the values can be <code>0</code> or any other falsy value that you actually want, then this won't work, so for example:</p>

<pre><code>&gt;&gt;&gt; pprint(d)
{'id': 7542,
 'parameter_001': 'Foo',
 'parameter_002': 'M',
 'parameter_003': 'D',
 'parameter_004': 'L',
 'parameter_005': 'CMAX',
 'parameter_006': 'R',
 'parameter_007': False,
 'parameter_008': False,
 'parameter_009': False,
 'parameter_010': False,
 'parameter_011': 0}
&gt;&gt;&gt; selection = [(k,v) for k, v in d.items() if v and k.startswith('parameter')]
&gt;&gt;&gt; [v for _, v in sorted(selection)]
['Foo', 'M', 'D', 'L', 'CMAX', 'R']
</code></pre>

<p>So if you want to filter instances of <em><code>False</code></em> specifically (and not <code>0</code>) then you have to use <em><code>is</code></em>:</p>

<pre><code>&gt;&gt;&gt; selection = [(k,v) for k, v in d.items() if v is not False and k.startswith('parameter')]
&gt;&gt;&gt; [v for _, v in sorted(selection)]
['Foo', 'M', 'D', 'L', 'CMAX', 'R', 0]
</code></pre>
","5014455","5014455","2018-03-01 22:35:39","4","2527","juanpa.arrivillaga","2015-06-16 08:18:23","42745","9720","6722","648","49059461","49059556","2018-03-01 22:07:44","0","34","<p>I have the following Python dict:</p>

<pre><code>{
  'parameter_010': False, 
  'parameter_009': False, 
  'parameter_008': False, 
  'parameter_005': 'C&lt;sub&gt;MAX&lt;/sub&gt;', 
  'parameter_004': 'L', 
  'parameter_007': False, 
  'parameter_006': 'R', 
  'parameter_001': 'Foo', 
  'id': 7542, 
  'parameter_003': 'D', 
  'parameter_002': 'M'
}
</code></pre>

<p>As seen there are a number of fields named <code>parameter_nnn</code> where <code>nnn</code> is a sequential number. Some are <code>False</code> and others have values populated.</p>

<p>I would like to generate a list with just the <code>parameter_nnn</code> field values which, but just the ones which contains a given value, sorted by number from <code>001</code> upwards.</p>

<p>So in this specific case the desired output is:</p>

<pre><code>[""Foo"", ""M"", ""D"", ""L"", ""CMAX"", ""R""]
</code></pre>

<p>Which would be the pythonic way of doing this? I obviously can start iterating but wondering if there is something better than that.</p>

<p>Python 2.7</p>
","5328289","5328289","2018-03-01 22:14:34","Python - Convert certain fields of a dict into a list","<python><python-2.7>","3","2","1032"
"49059559","2018-03-01 22:15:55","0","","<p>I think the get method should be used in one element of the ResultSet (not on the whole set). I mean, where you do:</p>

<pre><code>product.get('value')
</code></pre>

<p>try:</p>

<pre><code>product[0].get('value')
</code></pre>
","8275063","","","1","233","Daniel Garrido","2017-07-08 12:53:13","79","8","1","0","49059489","49059575","2018-03-01 22:10:15","0","472","<p>When I try to scrape a value from a website and put it into a payload request I get the error: </p>

<pre><code>AttributeError: 'ResultSet' object has no attribute 'get'
</code></pre>

<p>This is my code:</p>

<pre><code>resumeURL='url'
response=self.session.get(resumeURL,headers=headers)
soup=BeautifulSoup(response.content, ""html.parser"")

product=soup.find_all('input',{'name':'_CsrfToken', 'type':'hidden'})
payload = {
    '_CsrfToken':product.get('value')
</code></pre>

<p>When I change <code>find_all</code> to <code>find</code> I get the error:</p>

<pre><code>AttributeError: 'NoneType' object has no attribute 'get'
</code></pre>

<p>What am I doing wrong?</p>
","7227102","113962","2018-03-01 22:14:08","Python: AttributeError: 'ResultSet' object has no attribute 'get'","<python><beautifulsoup>","2","5","676"
"49059575","2018-03-01 22:17:54","1","","<p>Taken straight from the beautiful soup <a href=""https://www.crummy.com/software/BeautifulSoup/bs4/doc/#miscellaneous"" rel=""nofollow noreferrer"">documentation</a>:</p>

<blockquote>
  <p>AttributeError: 'ResultSet' object has no attribute 'foo' - This usually happens because you expected find_all() to return a single tag or string. But find_all() returns a <em>list</em> of tags and strings–a ResultSet object. You need to iterate over the list and look at the .foo of each one. Or, if you really only want one result, you need to use find() instead of find_all().</p>
</blockquote>

<p>So if you want all the results -and not just the one- you need to iterate over all your ResultSet (e.g. <code>product</code>) and look for the <code>.get</code> of each one.
So something like:</p>

<pre><code>for val in product:
  #check the val.get('value') for each member of list
  print val.get('value')
</code></pre>
","7253993","7253993","2018-03-01 22:22:58","2","913","kingJulian","2016-12-05 20:30:56","1230","104","93","16","49059489","49059575","2018-03-01 22:10:15","0","472","<p>When I try to scrape a value from a website and put it into a payload request I get the error: </p>

<pre><code>AttributeError: 'ResultSet' object has no attribute 'get'
</code></pre>

<p>This is my code:</p>

<pre><code>resumeURL='url'
response=self.session.get(resumeURL,headers=headers)
soup=BeautifulSoup(response.content, ""html.parser"")

product=soup.find_all('input',{'name':'_CsrfToken', 'type':'hidden'})
payload = {
    '_CsrfToken':product.get('value')
</code></pre>

<p>When I change <code>find_all</code> to <code>find</code> I get the error:</p>

<pre><code>AttributeError: 'NoneType' object has no attribute 'get'
</code></pre>

<p>What am I doing wrong?</p>
","7227102","113962","2018-03-01 22:14:08","Python: AttributeError: 'ResultSet' object has no attribute 'get'","<python><beautifulsoup>","2","5","676"
"49059576","2018-03-01 22:18:17","0","","<p>Here is one solution:</p>

<pre><code>list(zip(*sorted(i for i in d.items() if i[0].startswith('parameter') and i[1])))[1]

# ('Foo', 'M', 'D', 'L', 'C&lt;sub&gt;MAX&lt;/sub&gt;', 'R')
</code></pre>

<p><strong>Explanation</strong></p>

<ul>
<li>We filter for 2 conditions: key starts with 'parameter' and value is Truthy.</li>
<li><code>sorted</code> on <code>d.items()</code> returns a list of tuples sorted by dictionary key.</li>
<li><code>list(zip(*..))[0]</code> returns a tuple of values after the previous filtering and sorting.</li>
<li>I haven't dealt with <code>&lt;sub&gt;&lt;/sub&gt;</code> as I have no idea where this is from and what logic should be applied to remove this (and other?) tagging.</li>
</ul>
","9209546","","","2","725","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49059461","49059556","2018-03-01 22:07:44","0","34","<p>I have the following Python dict:</p>

<pre><code>{
  'parameter_010': False, 
  'parameter_009': False, 
  'parameter_008': False, 
  'parameter_005': 'C&lt;sub&gt;MAX&lt;/sub&gt;', 
  'parameter_004': 'L', 
  'parameter_007': False, 
  'parameter_006': 'R', 
  'parameter_001': 'Foo', 
  'id': 7542, 
  'parameter_003': 'D', 
  'parameter_002': 'M'
}
</code></pre>

<p>As seen there are a number of fields named <code>parameter_nnn</code> where <code>nnn</code> is a sequential number. Some are <code>False</code> and others have values populated.</p>

<p>I would like to generate a list with just the <code>parameter_nnn</code> field values which, but just the ones which contains a given value, sorted by number from <code>001</code> upwards.</p>

<p>So in this specific case the desired output is:</p>

<pre><code>[""Foo"", ""M"", ""D"", ""L"", ""CMAX"", ""R""]
</code></pre>

<p>Which would be the pythonic way of doing this? I obviously can start iterating but wondering if there is something better than that.</p>

<p>Python 2.7</p>
","5328289","5328289","2018-03-01 22:14:34","Python - Convert certain fields of a dict into a list","<python><python-2.7>","3","2","1032"
"49059614","2018-03-01 22:21:06","1","","<p>The technically correct answer is that chaining comprehensions doesn't work like that; you have to do </p>

<pre><code>if tname == list[0] or tname == list[1] or tname == list[2]:
</code></pre>

<p>But have you considered using <code>in</code>?</p>

<pre><code>if tname in list:
</code></pre>

<p>or similarly:</p>

<pre><code>if tname not in list:
</code></pre>

<p>Also, I'd advise against using <code>list</code> as the name of your list, as that's also the name of a type!</p>
","3791827","","","1","484","ACascarino","2014-06-30 21:25:39","1430","37","66","33","49059588","","2018-03-01 22:19:13","-4","42","<p>I'm trying to make this code work but I can't seem to find the right solution.</p>

<pre><code>while True:
    tname = input(""Please enter the unit of the temperature: "")
    list=[""Celsius"",""Kelvin"",""Fahrenheit""]
    if tname == list[0] or list[1] or list[2]:
        break
    elif tname is not list[0] or list[1] or list[2]:
        print(""Not a valid unit. Please try again."")
</code></pre>

<p>I want the program to stop whenever either Celsius, Kelvin or Fahrenheit is typed but the program stops regardless of what I write. Do you guys know to fix it? Thanks in advance</p>
","9426072","","","Python issues if/elif","<python>","1","5","584"
"49059620","2018-03-01 22:21:25","0","","<p>Many aspects of IPython's behavior can be controlled via settings in the user's IPython config files, which typically are in <code>~/.ipython/</code>.  A user can create multiple <em>profiles</em>, each with different settings of the config parameters. Each profile has its settings in a separate folder in the <code>.ipython</code> folder.  The default profile is in <code>profile_default</code>, and the main file in there for customizing behavior is <code>ipython_config.py</code>.  By default, it is almost entirely commented, with commented lines showing the config variables and their default settings.  Uncomment or insert lines to alter behavior.</p>

<p>To change how IPython behaves at the end of running a script, use:</p>

<pre><code>c.TerminalIPythonApp.force_interact = True
</code></pre>

<p>Then when the script ends (or raises an exception), IPython will keep running and present you with a prompt.  This is the same behavior as <code>ipython -i</code>.</p>

<p>I use this setting in my default profile, because this is the way I <em>always</em> want IPython to behave.  If that's not the case for you, you could create a profile with this behavior, to use just when you want this behavior.  Or just keep using the (evidently undocumented) <code>-i</code> option.</p>

<p>IPython configuration documentation is available here:  <a href=""http://ipython.readthedocs.io/en/stable/config/intro.html#the-ipython-directory"" rel=""nofollow noreferrer"">Introduction to IPython configuration — IPython documentation</a>, with the <code>force_interact</code> option described here: <a href=""http://ipython.readthedocs.io/en/stable/config/options/terminal.html#configtrait-TerminalIPythonApp.force_interact"" rel=""nofollow noreferrer"">Terminal IPython options — IPython documentation</a>.</p>
","3353984","3353984","2018-04-15 04:29:00","0","1800","Tom Loredo","2014-02-26 02:38:51","91","9","46","0","4138145","4138203","2010-11-09 20:18:19","35","15907","<p>I am often asked to debug Python scripts written by others.  I would like to send these scripts to IPython so it will drop into an IPython shell at the point the script fails.</p>

<p>Unfortunately, I cannot find a way to send (required) command-line options required by the scripts.</p>

<p>IPython assumes everything in  is for IPython when I pass the script and its options as:</p>

<pre><code>ipython &lt;script_name&gt; &lt;script_options&gt;
</code></pre>

<p>Is there a solution or workaround?</p>
","310399","1066031","2014-11-04 14:31:53","Command-line options to IPython *scripts*?","<python><ipython>","5","0","508"
"49059644","2018-03-01 22:23:02","1","","<p>IIUC..<code>cumsum</code>?</p>

<pre><code>df.x.cumsum()
Out[864]: 
date
2017-07-30     1
2017-07-31     3
2017-08-01     6
2017-08-02    10
Name: x, dtype: int64
</code></pre>

<p>Updated</p>

<pre><code>n=2
s=n**(np.arange(len(df)))[::-1]
df.x.rolling(window=len(df),min_periods=1).apply(lambda x : sum(x*s[-len(x):]))
Out[894]: 
date
2017-07-30     1.0
2017-07-31     4.0
2017-08-01    11.0
2017-08-02    26.0
Name: x, dtype: float64
</code></pre>
","7964527","7964527","2018-03-01 22:39:46","3","454","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49059594","","2018-03-01 22:19:53","0","102","<p>If we have a Pandas DataFrame containing the following values</p>

<pre><code>            x          
date
2017-07-30  1
2017-07-31  2
2017-08-01  3
2017-08-02  4
</code></pre>

<p>how can we create a new column <code>y</code> whose value is calculated using </p>

<pre><code>today's y = 2*(previous day's y) + (today's x)
</code></pre>

<p>for the oldest date, <code>y</code> will be <code>1</code></p>

<p><strong>Expected Result:</strong></p>

<pre><code>            x       y     
date
2017-07-30  1       1
2017-07-31  2       4
2017-08-01  3       11
2017-08-02  4       26
</code></pre>

<p><strong>Attempt:</strong></p>

<pre><code>import pandas as pd 

d = {
    'date': ['2017-07-30', '2017-07-31', '2017-08-01', '2017-08-02'],
    'x': [1,2,3,4]
}
df = pd.DataFrame.from_dict(d).set_index('date')
df['y'] = 1
df['y'] = df['y'].shift(1)*2 + df['x']
print(df)
</code></pre>

<p><strong>Attempt's Result</strong></p>

<pre><code>            x    y
date
2017-07-30  1  NaN
2017-07-31  2  4.0
2017-08-01  3  5.0
2017-08-02  4  6.0
</code></pre>
","741099","741099","2018-03-01 22:26:02","Create New Pandas DataFrame Column with Values using Previous Row","<python><python-3.x><pandas><numpy>","2","0","1054"
"49059690","2018-03-01 22:26:56","0","","<p>The issue is here</p>

<pre><code>yt = D(Ta/Te -1)**-1 * (e**-t/Ta - e**-t/Te)
</code></pre>

<p>There is no implicit multiplication in python, so when you attempt to do <code>D(Ta/Te - 1)</code> it is being interpreted as a function call rather than D multiplied by what is in the bracket. </p>

<p>Rewrite it like this</p>

<pre><code>yt = D*(Ta/Te -1)**-1 * (e**-t/Ta - e**-t/Te)
</code></pre>
","9371607","","","1","400","Joshua Yonathan","2018-02-16 21:24:27","203","25","66","2","49059621","49059690","2018-03-01 22:21:25","0","53","<p>I am getting the following error in python, and I am not sure why. I am trying to model how meth affects mice.</p>

<p>Here is my code, and the functions that are created in my code: </p>

<pre><code>from scipy import array, linspace
from scipy import integrate
from matplotlib.pyplot import *
def Temp2(z, t, Ta, Te, wexc, yexc, winhib, yinhib, whd, yhd, wexctoinhib, winhibtomdl, whdtospn, yspn, Tt):
    # Dependence of Meth Concentration 
    #    dx
    #    -- = -x/Ta
    #    dt
    #
    #    dy
    #    -- = x/Ta - y/Te
    #    dt
    # x = interperitoneal 
    # y = blood
    # Ta is the time constant of Meth in the absorbtion
    # Te is the time constant of Meth in elimination
    x = z[0] # Rabbits density
    y = z[1] # Sheep density
    T = z[2]
    D = int(x=1)
    yt = D(Ta/Te -1)**-1 * (e**-t/Ta - e**-t/Te)
    Pexc = (1+tanhx)*[wexc*yt*yexc]
    Pinhib = (1+tanhx)*[winhib*yt*yinhib]
    Phd = (1+tanhx)*[whd*yt*yhd]
    Pmdl = wexctoinghib*Pexc-winhibtomdl*Pinhib
    Pspn = Pmdl + whdtospn*Phd+yspn
    V = array([-x/Ta, x/Ta - y/Te, (Pspn-(T-T0))/Tt])
    return V

def main():
    # set up our initial conditions
    IC0 = 1
    BC0 = 0
    T0 = 37
    z0 = array([IC0, BC0, T0])

    # Parameters
    Ta = 8.25
    Te = 57.5
    wexc = 1.225
    yexc = -0.357
    winhib = 1.335
    yinhib = 1.463
    whd = 0.872
    yhd = -3.69
    wexctoinhib = 7.47
    winhibtomdl = 6.38
    whdtospn = 5.66
    yspn = -3.35
    Tt = 89.2

    # choose the time's we'd like to know the approximate solution
    t = linspace(0., 1., 60)

    # and solve
    xode= integrate.odeint(Temp2, z0, t, args=(Ta, Te,  wexc, yexc, winhib, yinhib, whd, yhd, wexctoinhib, winhibtomdl, whdtospn, yspn, Tt))
    print (xode)    
main()
</code></pre>

<p>Ignore the #s as they do not relate to what the code is saying. Here is the error I am getting: </p>

<pre><code>yt = D(Ta/Te -1)**-1 * (e**-t/Ta - e**-t/Te)
</code></pre>

<p>TypeError: 'int' object is not callable</p>

<p>I am not sure what is wrong, and how I can fix this? Can anyone help me?</p>
","9431412","","","TypeError: 'int' object is not callable Modeling in python","<python><modeling>","1","2","2065"
"49059702","2018-03-01 22:27:46","1","","<p>Here's the proper way to display text:</p>

<pre><code>import gi
gi.require_version('Gtk', '3.0')

from gi.repository import Gtk, Gdk, GLib
import os

textview = Gtk.TextView()
textview.set_name(""TextView"")
buf = Gtk.TextBuffer()
textview.set_buffer(buf)
buf.set_text(""This is a test message\n"")

style_provider = Gtk.CssProvider()

css = """"""
#TextView{
    background-color: black;
}
""""""
style_provider.load_from_data(bytes(css.encode()))
    Gtk.StyleContext.add_provider_for_screen(
    Gdk.Screen.get_default(), style_provider,
    Gtk.STYLE_PROVIDER_PRIORITY_APPLICATION
    )

for color in (""red"", ""yellow"", ""green"", ""blue"", ""white""):
    buf.insert_markup(
        buf.get_end_iter(),
        '&lt;span color=""{:s}""&gt;This is a test message&lt;/span&gt;\n'.format(color),
         -1)

win = Gtk.Window()
win.connect('delete-event', Gtk.main_quit)
win.add(textview)
win.show_all()


Gtk.main()
</code></pre>

<p>This is a lot easier, by the way.</p>

<p><strong>Edit:</strong> Include color.</p>
","6150775","6150775","2018-03-03 13:16:55","4","1007","theGtknerd","2016-04-03 02:26:21","2646","407","191","15","49026950","","2018-02-28 10:12:52","1","339","<p>I'm trying to use a Vte terminal widget to display text from my python script.</p>

<p>I'm not setting the working directory or emulator, I just want a empty terminal that handles text and ansi escape sequences</p>

<p>I have this piece of code, it works in python 2.7:</p>

<pre><code>import gi
gi.require_version('Gtk', '3.0')
gi.require_version('Vte', '2.91')

from gi.repository import Gtk, Vte
from gi.repository import GLib
import os

terminal     = Vte.Terminal()
terminal.spawn_sync(
    Vte.PtyFlags.DEFAULT,
    None,
    [],
    [],
    GLib.SpawnFlags.DO_NOT_REAP_CHILD,
    None,
    None,
    )

win = Gtk.Window()
win.connect('delete-event', Gtk.main_quit)
win.add(terminal)
win.show_all()

terminal.feed('hello') #string to display

Gtk.main()
</code></pre>

<p>but it doesn't work in python 3.5, all I get is a blank terminal.</p>
","9423142","","","Python - How to Write Text to a GTK+ Vte Terminal widget?","<python><python-3.x><gtk3>","1","2","851"
"49059713","2018-03-01 22:28:29","0","","<pre><code>import collections

dicty = {
  ""parameter_010"": False, 
  ""parameter_009"": False, 
  ""parameter_008"": False, 
  ""parameter_005"": ""CMAX"", 
  ""parameter_004"": ""L"", 
  ""parameter_007"": False, 
  ""parameter_006"": ""R"", 
  ""parameter_001"": ""Foo"", 
  ""id"": 7542, 
  ""parameter_003"": ""D"", 
  ""parameter_002"": ""M""
}
result = []

od = collections.OrderedDict(sorted(dicty.items()))
for k, v in od.iteritems():
    if v != False and ""parameter"" in k:
        result.append(v)
print(result)
</code></pre>
","7587370","","","0","505","Carlo André Alva","2017-02-19 05:15:54","1","6","0","0","49059461","49059556","2018-03-01 22:07:44","0","34","<p>I have the following Python dict:</p>

<pre><code>{
  'parameter_010': False, 
  'parameter_009': False, 
  'parameter_008': False, 
  'parameter_005': 'C&lt;sub&gt;MAX&lt;/sub&gt;', 
  'parameter_004': 'L', 
  'parameter_007': False, 
  'parameter_006': 'R', 
  'parameter_001': 'Foo', 
  'id': 7542, 
  'parameter_003': 'D', 
  'parameter_002': 'M'
}
</code></pre>

<p>As seen there are a number of fields named <code>parameter_nnn</code> where <code>nnn</code> is a sequential number. Some are <code>False</code> and others have values populated.</p>

<p>I would like to generate a list with just the <code>parameter_nnn</code> field values which, but just the ones which contains a given value, sorted by number from <code>001</code> upwards.</p>

<p>So in this specific case the desired output is:</p>

<pre><code>[""Foo"", ""M"", ""D"", ""L"", ""CMAX"", ""R""]
</code></pre>

<p>Which would be the pythonic way of doing this? I obviously can start iterating but wondering if there is something better than that.</p>

<p>Python 2.7</p>
","5328289","5328289","2018-03-01 22:14:34","Python - Convert certain fields of a dict into a list","<python><python-2.7>","3","2","1032"
"49059724","2018-03-01 22:29:36","0","","<p>A dataframe isn't a matrix. They are both collections of rows, but a dataframe doesn't have a strict ordering of those rows.</p>

<p>If you have a column in your dataframe which indicates the <code>row_num</code> of that row then you could apply a <code>map</code> function to set all columns with <code>index &lt; row_num</code> to zero.</p>

<p><a href=""https://spark.apache.org/docs/2.2.0/mllib-data-types.html#distributed-matrix"" rel=""nofollow noreferrer"">There are matrix types in Spark</a>, and if you use those you'll have access to row and column indices. This datatype can be used something like a tuple of a <code>((x, y), Value)</code>, with coordinates pointing to values. You would then simply set a value to zero when <code>y &gt; x</code>.</p>

<hr>

<p>You say you have looked into numpy but it would break the concurrent benefit of Spark. I assume you mean the distributed, parallel nature of Spark? If your data is small enough to fit on a single machine, i.e. doesn't need to be distributed, then you'll certainly get better performance from numpy. Would highly recommend looking into it in depth.</p>
","146077","","","0","1124","Kirk Broadhurst","2009-07-28 00:21:46","20551","3245","2448","271","49059508","","2018-03-01 22:11:49","0","69","<p>I've got a distance matrix in a PySpark data frame, and I'm attempting to take the upper (or lower) triangle of the data and have the results in another data frame.</p>

<p>For example, I'm trying to transform this:</p>

<blockquote>
  <p>1, 2, 3, 4</p>
  
  <p>2, 1, 2, 3</p>
  
  <p>3, 2, 1, 2</p>
  
  <p>4, 3, 2, 1</p>
</blockquote>

<p>Into this:</p>

<blockquote>
  <p>1, 2, 3, 4</p>
  
  <p>0, 1, 2, 3</p>
  
  <p>0, 0, 1, 2</p>
  
  <p>0, 0, 0, 1</p>
</blockquote>

<p>I've looked into numpy, but from what I've read that would break the concurrent benefit of Spark.</p>
","9431216","","","PySpark - how do I take the upper triangle of a distrance matrix in a data frame?","<python><pyspark>","1","0","582"
"49059734","2018-03-01 22:30:23","2","","<p>I would guess that the flights are not being put on the queue. <code>map(q.put, flights)</code> is lazy, and is never accessed so it is as if it didn't happen. I would just iterate.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>def main_scraper(flights):
  print(""main scraper was called, got: "")
  print(flights)
  data = []
  q = Queue()
  for flight in flights:
      q.put(flight)
  for i in range(0,  5):
      t = Thread(target = scraper_worker, args = (q, data))
      t.daemon = True
      t.start()
  q.join()
  return data</code></pre>
</div>
</div>
</p>
","1766739","","","2","736","Boyd Johnson","2012-10-22 21:59:07","142","19","11","0","49038347","49059734","2018-02-28 20:53:23","0","1379","<p>I am trying to make concurrent API calls with python.
I based my code on the solution (first answer) presented in this thread: <a href=""https://stackoverflow.com/questions/2632520/what-is-the-fastest-way-to-send-100-000-http-requests-in-python"">What is the fastest way to send 100,000 HTTP requests in Python?</a></p>

<p>Currently, my code is broken.
I have a main function which creates the queue, populates it, initiates the threads, starts them, and joins the queue.
I also have a target function which should make the get requests to the API.</p>

<p>The difficulties I am experiencing right now is that 
the target function does not execute the necessary work.
<strong>The target is called, but it acts as the queue is empty.</strong>
The first print is executed (""inside scraper worker""), while the second (""inside scraper worker - queue NOT empty"") is not.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>def main_scraper(flights):
  print(""main scraper was called, got: "")
  print(flights)
  data = []
  q = Queue()
  map(q.put, flights)
  for i in range(0,  5):
      t = Thread(target = scraper_worker, args = (q, data))
      t.daemon = True
      t.start()
  q.join()
  return data</code></pre>
</div>
</div>
</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>def scraper_worker(q, data):
  print(""inside scraper worker"")
  while not q.empty():
    print(""inside scraper worker, queue not empty"")
    f = q.get()
    url = kiwi_url(f)
    response = requests.get(url)
    response_data = response.json()
    results = parseResults(response_data)
    q.task_done()
    print(""task done. results:"")
    print(results)
    #f._price = results[0][""price""]
    #f._url = results[0][""deep_link""]
    data.append(results)
  return data</code></pre>
</div>
</div>
</p>

<p>I hope this is enough information for you to help me out. 
Otherwise, I will rewrite the code in order to create a code that can be run by anyone.</p>
","8339550","","","concurrent requests with queue and thread","<python><python-3.x><concurrency><request>","1","0","2264"
"49059738","2018-03-01 22:30:46","0","","<p>If you want to select all <code>a</code> elements where the first non-empty <code>text()</code> node contains the string <code>(hidden)</code> then use this XPath:</p>

<pre><code>//a[@id='contact-link' and contains(text(),' (hidden) ')]
</code></pre>

<p>But this only works for the first node.</p>
","1305969","","","1","303","zx485","2012-04-01 06:55:46","18067","3723","5096","1305","49059592","49059738","2018-03-01 22:19:46","0","42","<p>I am having an issue finding text inside this element. There are no errors when the driver starts. Is my syntax correct? </p>

<pre><code>&lt;span id=""container"" class=""contact-wrap""&gt;
&lt;a id=""contact-link"" href=""contact.html""&gt;&lt;i class=""icon""&gt;&lt;/i&gt; (hidden) &lt;span 
class=""contact-address""&gt;&lt;/span&gt;&lt;/a&gt;
&lt;/span&gt; 
</code></pre>

<p>Have Tried</p>

<pre><code>driver.find_elements_by_xpath(""//*[@id='contact-link']/span[2][contains(text(),' (hidden) ')]"")
</code></pre>
","9262648","9262648","2018-03-01 22:27:32","Issue finding xpath","<python><selenium><xpath><selenium-webdriver><selenium-chromedriver>","2","1","510"
"49059752","2018-03-01 22:32:04","8","","<pre><code>def nfor(data, n=1):
    if n == 1:
        yield from iter(data)
    else:
        for element in data:
            yield from nfor(element, n=n-1)
</code></pre>

<p>Demo:</p>

<pre><code>&gt;&gt;&gt; for i in nfor(['ab', 'c'], n=1):
...     print(i)
...     
ab
c
&gt;&gt;&gt; for i in nfor(['ab', 'c'], n=2):
...     print(i)
...     
a
b
c
</code></pre>
","674039","674039","2018-03-01 22:35:42","7","369","wim","2011-03-23 23:40:27","187587","12233","9064","5087","49059681","","2018-03-01 22:26:08","6","87","<p>I currently have a bit of Python code that looks like this:</p>

<pre><code>for set_k in data:
    for tup_j in set_k:
        for tup_l in tup_j:
</code></pre>

<p>The problem is, I'd like the number of nested <em>for</em> statements to differ based on user input. If I wanted to create a function which generated n number of <em>for</em> statements like those above, how might I go about doing that? </p>
","4839906","","","How to create a function for recursively generating iterating functions","<python><for-loop><recursion><user-input>","1","1","410"
"49059762","2018-03-01 22:33:21","2","","<p>I think you have to <code>vectorize</code> <code>f</code> first:</p>

<pre><code>&gt;&gt;&gt; np.fromfunction(np.vectorize(f), (5, 5), dtype=int)
array([[ 1,  1,  1,  1,  1],
       [ 2,  3,  3,  3,  3],
       [ 3,  4,  5,  5,  5],
       [ 4,  6,  7,  8,  8],
       [ 5,  7,  8,  9, 10]])
</code></pre>

<p>Indeed, <code>fromfunction</code> passes the coordinates not one-by-one but in one go:</p>

<pre><code>&gt;&gt;&gt; def f(i, j):
...     print(i, j)
...     return sum((i+1)//k for k in range(1, j+2))
... 
&gt;&gt;&gt; np.fromfunction(f, (5, 5), dtype=int)
[[0 0 0 0 0]
 [1 1 1 1 1]
 [2 2 2 2 2]
 [3 3 3 3 3]
 [4 4 4 4 4]] [[0 1 2 3 4]
 [0 1 2 3 4]
 [0 1 2 3 4]
 [0 1 2 3 4]
 [0 1 2 3 4]]
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/home/paul/local/lib/python3.6/site-packages/numpy/core/numeric.py"", line 1914, in fromfunction
    return function(*args, **kwargs)
  File ""&lt;stdin&gt;"", line 3, in f
TypeError: only integer scalar arrays can be converted to a scalar index
</code></pre>
","7207392","7207392","2018-03-01 22:39:23","2","1052","Paul Panzer","2016-11-24 23:39:00","37645","7185","734","1","49059667","49059762","2018-03-01 22:25:00","1","287","<p>I'm trying to create a matrix whose value at index (i,j) will be <code>f(i,j),</code> for a function that I'm defining.  I'm trying to do this with <code>numpy.fromfunction</code> and I haven't been able to get it to work.  Here's the code</p>

<pre><code>import numpy as np

def f(i,j):
    return sum((i+1)//k for k in np.arange(1,j+2))

def M(N):
    shape = np.array([N,N])
    np.fromfunction(f, shape,dtype = np.int)

A= M(5)   
</code></pre>

<p>I get the error </p>

<blockquote>
  <p>builtins.TypeError: only length-1 arrays can be converted to Python scalars</p>
</blockquote>

<p>in the call to <code>fromfunction</code> and I suppose it must have to do with <code>np.arange</code>.  </p>

<p>Originally, I had <code>range(1,j+2)</code> but then I got the error </p>

<blockquote>
  <p>TypeError: only integer scalar arrays can be converted to a scalar index</p>
</blockquote>

<p>Can you tell me what I need to do, please?</p>
","908293","908293","2018-03-01 22:47:49","How can I use a range inside numpy.fromfunction?","<python><numpy>","1","7","942"
"49059780","2018-03-01 22:35:34","5","","<p>A one-liner using only the standard library works starting with Python 3.3. You can get a local timezone aware <code>datetime</code> object using <code>astimezone</code> (as <a href=""https://stackoverflow.com/questions/4530069/python-how-to-get-a-value-of-datetime-today-that-is-timezone-aware/49059780#comment77694396_4530069"">suggested by johnchen902</a>):</p>

<pre><code>from datetime import datetime, timezone

aware_local_now = datetime.now(timezone.utc).astimezone()

print(aware_local_now)
2019-08-02 11:26:32.341817-07:00
</code></pre>
","200234","200234","2019-10-03 18:31:40","0","548","Mihai Capotă","2009-10-31 17:41:19","743","72","1363","12","4530069","4530166","2010-12-25 10:59:49","273","278113","<p>I am trying to subtract one date value from the value of <code>datetime.today()</code> to calculate how long ago something was. But it complains:</p>

<pre><code>TypeError: can't subtract offset-naive and offset-aware datetimes
</code></pre>

<p>The value <code>datetime.today()</code> doesn't seem to be ""timezone aware"", while my other date value is. How do I get a value of <code>datetime.today()</code> that is timezone aware?</p>

<p>Right now, it's giving me the time in local time, which happens to be PST, i.e. UTC - 8 hours. Worst case, is there a way I can manually enter a timezone value into the <code>datetime</code> object returned by <code>datetime.today()</code> and set it to UTC-8?</p>

<p>Of course, the ideal solution would be for it to automatically know the timezone.</p>
","323874","63550","2019-09-19 14:14:14","How do I get a value of datetime.today() in Python that is ""timezone aware""?","<python><datetime><date><timezone>","15","2","797"
"49059785","2018-03-01 22:36:02","1","","<p>Here is a one-liner for you once you read in the file:</p>

<p>INPUT (if read as one string):</p>

<pre><code>output = [t for t in [i for i in s.split('\n') if all(j.isupper() for j in i.split())] if t!='']
</code></pre>

<p>INPUT (if read as file with separate lines):</p>

<pre><code>output = [t for t in [i for i in lines if all(j.isupper() for j in i.split())] if t!='']
</code></pre>

<p>OUTPUT:</p>

<pre><code>['THIS IS A TITLE', 'THIS IS A TITLE', 'THIS IS A TITLE']
</code></pre>
","8146556","","","2","492","rahlf23","2017-06-12 02:38:50","6078","662","435","19","49059091","49059785","2018-03-01 21:37:48","-2","54","<p>Here is my input file:</p>

<pre><code>THIS IS A TITLE

1. THIS IS A SUBTITLE

This is body text.
This is body text.

This is body text.
This is body text.

THIS IS A TITLE

This is body text.

THIS IS A TITLE

1. THIS IS A SUBTITLE

2. THIS IS A SUBTITLE

This is body text.
This is body text.
</code></pre>

<p>I want to create a list of just titles, but not subtitles or body text. How do I do that? So far, I thought of looping through the file, grabbing the line if it <code>isupper()</code>, but that grabs the subtitles too. <code>isalpha()</code> rejects any titles with spaces in the line, so that doesn't work. What can I do? I prefer to loop rather than regex.</p>
","8729810","8729810","2018-03-01 21:54:49","How to parse a file to return a list of uppercase lines without numbers?","<python><regex><loops>","3","0","679"
"49059794","2018-03-01 22:36:20","3","","<p>Here is one way using your suggestion of wrapping in a <code>try</code> / <code>except</code> clause.</p>

<pre><code>from datetime import datetime

def dater(x):
    try:
        return datetime(year=x['year'], month=x['month'], day=x['day'])
    except ValueError:
        return None

df['date'] = df.apply(dater, axis=1)

#    year  month  day       date
# 0  1890      2   29        NaT
# 1  1891      2   29        NaT
# 2  1892      2   29 1892-02-29
# 3  1893      2   29        NaT
# 4  1894      2   29        NaT
# 5  1895      2   29        NaT
# 6  1896      2   29 1896-02-29
# 7  1897      2   29        NaT
# 8  1898      2   29        NaT

df = df.dropna(subset=['date'])

#    year  month  day       date
# 2  1892      2   29 1892-02-29
# 6  1896      2   29 1896-02-29
</code></pre>
","9209546","","","9","806","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49059717","49059913","2018-03-01 22:28:50","1","70","<p>I have source data that uses 31 columns for day values, with a row for each month. I've melted the 31 day columns into a single day column, and now I want to combine the year, month, and day columns into a datetime(?) column so I can sort the rows by year/month/day.</p>

<p>After the melt, my dataframe looks like so:</p>

<pre><code>       year  month day   prcp
0      1893      1  01    0.0
1      1893      2  01    0.0
2      1893      3  01    0.0
3      1893      4  01    NaN
4      1893      5  01    NaN
5      1893      6  01    NaN
6      1893      7  01    NaN
7      1893      8  01    0.0
8      1893      9  01   10.0
9      1893     10  01    0.0
10     1893     11  01    0.0
11     1893     12  01    NaN
12     1894      1  01    NaN
13     1894      2  01    0.0
14     1894      3  01    NaN
...
</code></pre>

<p>Next I'm trying to create a 'time' column that I can sort on, using the year, month, and day columns as arguments to the datetime constructor. I've tried doing this using this approach:</p>

<pre><code>def make_datetime(y, m, d):
    return(datetime(year=y, month=m, day=d))

df['time'] = np.vectorize(make_datetime)(df['year'].astype(int), df['month'].astype(int), df['day'].astype(int))
</code></pre>

<p>The above isn't going to get me there since it fails in cases where the month/day columns don't make sense together, such as February 29th during non-leap years, April 31st, etc. What I think I want to do next is to somehow wrap the datetime() call in a try/catch, and when it croaks due to incompatible month/day combinations I should drop the row within the catch block. How would I go about doing that without doing a for loop over all the rows? Or is there a better way to crack this nut?</p>

<p>Thanks in advance for any suggestions or insight.</p>
","85248","","","Pandas: how to drop rows that contain invalid month/day column combinations, such as February 30th?","<python><pandas>","2","0","1802"
"49059818","2018-03-01 22:38:33","10","","<blockquote>
  <p>How should I extract the field names into a string list from the Ordered Dictionary shown below?</p>
</blockquote>

<p>I've extended your code to include the solution</p>

<pre><code>from simple_salesforce import Salesforce

#(credentials hidden)
sf = Salesforce(username=username, password=password,
                security_token=security_token, sandbox=True, 
                client_id='mwheeler App')

desc = sf.Account.describe()  

# Below is what you need
field_names = [field['name'] for field in desc['fields']]
soql = ""SELECT {} FROM Account"".format(','.join(field_names))
results = sf.query_all(soql)

# Alternative method to retrieve results
# I don't have any recommendation which to use
results = sf.bulk.Account.query(soql)
</code></pre>

<p>I realize the question was posted a while ago, just want it to have a complete solution. </p>
","1348960","","","0","869","orion11","2012-04-22 00:37:19","175","9","3","0","47536503","49059818","2017-11-28 16:33:03","5","4303","<p>I'm using Python Simple-Salesforce to query data via SOQL. I know that ""SELECT *"" is not supported in SOQL syntax, so I want to create a Python script to gather a string list of all fields to insert into the SELECT statement. Below is how I am describing the Account Object:</p>

<pre><code>from simple_salesforce import Salesforce
from simple_salesforce import SFType

#(credentials hidden)
sf = Salesforce(username=username, password=password,
                security_token=security_token, sandbox=True, 
                client_id='mwheeler App')

desc = sf.Account.describe()  
print(desc)
</code></pre>

<p>How should I extract the field names into a string list from the Ordered Dictionary shown below?</p>

<p><strong>desc</strong>:</p>

<p>OrderedDict([('actionOverrides', []), ('activateable', False), ('childRelationships', [OrderedDict([('cascadeDelete', False), ('childSObject', 'Account'), ('deprecatedAndHidden', False), ('field', 'ParentId'), ('junctionIdListNames', []), ('junctionReferenceTo', []), ('relationshipName', 'ChildAccounts'), ('restrictedDelete', False)]), OrderedDict([('cascadeDelete', True), ('childSObject', 'AccountCleanInfo'), ('deprecatedAndHidden', False), ('field', 'AccountId'), ......</p>

<p>I will be using the string list to select all fields:</p>

<pre><code>query = sf.query_all(""SELECT string_list FROM Account"")
</code></pre>
","8691976","2142505","2019-02-18 20:01:53","Python Simple Salesforce Select All Fields","<python><salesforce><soql><simple-salesforce>","2","0","1376"
"49059830","2018-03-01 22:39:32","1","","<p>A MLP Classifier is a neural network. In essence, it needs to be trained for multiple iterations (epochs) before it learns appropriate weights on the hidden layers using backpropagation, after which it can classify correctly.</p>

<p>If you look at sklearns implementation, there is a default parameter called <code>max_iter</code></p>

<blockquote>
  <p><strong>max_iter</strong> : int, optional, default 200</p>
  
  <p>Maximum number of iterations. The solver iterates until convergence (determined by ‘tol’) or this number of iterations. For stochastic solvers (‘sgd’, ‘adam’), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.</p>
</blockquote>

<p>Essentially, it runs for 200 epochs before giving you your accuracy of 0.98. This is why you need to run the same graph in tensorflow 200 times (I assume 50 as you've stated is also enough) to get the exact same output.</p>
","6339948","242311","2018-03-01 23:20:46","0","959","Adit Sanghvi","2016-05-16 08:56:43","77","19","2","0","47113596","","2017-11-04 17:38:26","4","401","<p>I am new to Tensorflow, having previously extensively used scikit-learn. As one of my first exercises in trying to transition to TensorFlow, I'm trying to reproduce some of the results I obtained with scikit-learn's MLPClassifier.</p>

<p>When I use the MLPClassifier with mostly default settings, I get up to 98% accuracy on the test set. However, when I implement what I believe is an equivalent single layer ANN in TensorFlow, I get less than 90% accuracy on the test set. The only way I can get TensorFlow to yield similar accuracy is to train over the training set multiple (> 50) times.</p>

<p>Any idea on where the difference may be coming from? Or is there any implementation of the sklearn MLPClassifier in Tensorflow to which I can compare my code?</p>

<p>As far as I am concerned, I am using the same optimizer (Adam), the same learning rate, L2 regularization with the same parameter, the same activation function (ReLU) and softmax evaluation at the output layer.</p>

<p>My implementation of the TensorFlow graph is the following:</p>

<pre><code>n_units = 500

X = tf.placeholder(tf.float32, [None, n_features])
Y = tf.placeholder(tf.float32, [None, n_classes])    

# Create weights for all layers
W_input = tf.Variable(tf.truncated_normal([n_features, n_units]))
W_out = tf.Variable(tf.truncated_normal([n_units, n_classes]))

# Create biases for all layers
b_1 = tf.Variable(tf.zeros([n_units]))
b_2 = tf.Variable(tf.zeros(([n_classes])))

# Mount layers
hidden_layer = tf.nn.relu(tf.matmul(X, W_input) + b_1)
logits = tf.matmul(hidden_layer, W_out) + b_2

# Get all weights into a single list
all_weights = tf.concat([tf.reshape(W_input, [-1]), tf.reshape(W_out, [-1])], 0)

# Compute loss function
cross_entropy = tf.reduce_mean(
    tf.losses.softmax_cross_entropy(onehot_labels=Y, logits=logits))

# Compute regularization parameter
regularizer = 0.0001*tf.nn.l2_loss(all_weights)

# Train step
train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy + regularizer)

# Get number of correct predictions
correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))

# Class prediction
prediction = tf.argmax(tf.nn.softmax(logits), 1)

# Get accuracy
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
</code></pre>

<p>My implementation of the sklearn model is simply:</p>

<pre><code>clf = neural_network.MLPClassifier(hidden_layer_sizes = (500,), random_state=42)
</code></pre>
","","","","Reproducing scikit-learn's MLPClassifier in TensorFlow","<python><tensorflow><scikit-learn>","1","0","2440"
"49059913","2018-03-01 22:46:14","3","","<p>You can pass your df derictly to <code>to_datetime</code></p>

<pre><code>pd.to_datetime(df,errors='coerce')
Out[905]: 
#          NaT
#          NaT
#   1892-02-29
#          NaT
#          NaT
#          NaT
#   1896-02-29
#          NaT
#          NaT
dtype: datetime64[ns]
df['New']=pd.to_datetime(df,errors='coerce')
df.dropna()
Out[907]: 
   year  month  day        New
#  1892      2   29 1892-02-29
#  1896      2   29 1896-02-29
</code></pre>
","7964527","","","1","455","WeNYoBen","2017-05-04 16:45:29","164847","15327","4764","689","49059717","49059913","2018-03-01 22:28:50","1","70","<p>I have source data that uses 31 columns for day values, with a row for each month. I've melted the 31 day columns into a single day column, and now I want to combine the year, month, and day columns into a datetime(?) column so I can sort the rows by year/month/day.</p>

<p>After the melt, my dataframe looks like so:</p>

<pre><code>       year  month day   prcp
0      1893      1  01    0.0
1      1893      2  01    0.0
2      1893      3  01    0.0
3      1893      4  01    NaN
4      1893      5  01    NaN
5      1893      6  01    NaN
6      1893      7  01    NaN
7      1893      8  01    0.0
8      1893      9  01   10.0
9      1893     10  01    0.0
10     1893     11  01    0.0
11     1893     12  01    NaN
12     1894      1  01    NaN
13     1894      2  01    0.0
14     1894      3  01    NaN
...
</code></pre>

<p>Next I'm trying to create a 'time' column that I can sort on, using the year, month, and day columns as arguments to the datetime constructor. I've tried doing this using this approach:</p>

<pre><code>def make_datetime(y, m, d):
    return(datetime(year=y, month=m, day=d))

df['time'] = np.vectorize(make_datetime)(df['year'].astype(int), df['month'].astype(int), df['day'].astype(int))
</code></pre>

<p>The above isn't going to get me there since it fails in cases where the month/day columns don't make sense together, such as February 29th during non-leap years, April 31st, etc. What I think I want to do next is to somehow wrap the datetime() call in a try/catch, and when it croaks due to incompatible month/day combinations I should drop the row within the catch block. How would I go about doing that without doing a for loop over all the rows? Or is there a better way to crack this nut?</p>

<p>Thanks in advance for any suggestions or insight.</p>
","85248","","","Pandas: how to drop rows that contain invalid month/day column combinations, such as February 30th?","<python><pandas>","2","0","1802"
"49059935","2018-03-01 22:47:45","1","","<p>You can use GAE Flexible by building custom runtime for C as it has been explained in this <a href=""https://cloud.google.com/appengine/docs/flexible/custom-runtimes/build"" rel=""nofollow noreferrer"">link</a>. As it has mentioned:</p>

<blockquote>
  <p>A custom runtime allows you to easily deploy and run web applications written in any language.</p>
</blockquote>
","2240433","","","0","368","Majico","2013-04-03 12:38:45","2533","86","66","4","49058788","49088672","2018-03-01 21:13:41","2","103","<p>As far as I understand it <code>scipy</code> can't be used with GAE as the former uses C code. Is there a workaround for it? If not, can you recommend a package similar to <code>scipy</code> that I could use on GAE? Specifically, I'm trying to use the <code>brentq</code> method from <code>scipy.optimize</code>.</p>

<p>Thank you,
Alex</p>
","9429926","7478455","2018-03-01 22:07:48","SciPy and App Engine","<python><google-app-engine><scipy>","2","0","344"
"49059945","2018-03-01 22:48:36","1","","<p>You almost certainly want to have your missiles start with the velocity of the launching ship (in addition to some speed in the direction the ship is facing).</p>

<p>You might replace the <code>direction</code> argument to <code>Missile.__init__</code> with a <code>velocity</code> parameter that you save directly as <code>self.velocity</code> (with no multiplication). The <code>Player.shoot</code> method can then be modified to pass an appropriate value that takes both the ship's orientation and velocity into account:</p>

<pre><code>def shoot(self):
    # create and add missile object to the group
    missile = Missile(self.rect.center,
                      self.velocity + 50 * self.acceleration,     # new value here!
                      player.acceleration.as_polar()[1])
    all_sprites.add(missile)
    missiles.add(missile)
</code></pre>

<p>You might want to use a smaller multiple of ship's the acceleration vector, rather than the <code>50</code> I copied from your current code, since it won't be the only component of the missile's velocity any more.</p>
","1405065","","","0","1082","Blckknght","2012-05-19 12:23:30","70324","3947","2807","517","49059522","49059945","2018-03-01 22:13:07","0","48","<p>There seems to be a weird offset when the bullets are shot from the ship in certain angles while the ship is moving. Also if the ship is shooting in the same direction is heading then the bullet speed is lower.
I tried to work with some SO answers and that's what I came up with:</p>

<pre><code>import sys
import pygame
from pygame.locals import *
vec = pygame.math.Vector2

pygame.init()
FPS = 60
fps_clock = pygame.time.Clock()
WIDTH = 800
HEIGHT = 800
DISPLAY = pygame.display.set_mode((WIDTH, HEIGHT))
BLACK = (0, 0, 0)
BLUE = (0, 0, 255)

MAX_SPEED = 7

class Player(pygame.sprite.Sprite):
    """"""This class represents the Player.""""""

    def __init__(self):
        """"""Set up the player on creation.""""""
        pygame.sprite.Sprite.__init__(self)
        self.image = pygame.Surface((70, 50), pygame.SRCALPHA)
        pygame.draw.polygon(self.image, (50, 120, 180), ((35, 0), (0, 35), (70, 35)))
        self.original_image = self.image
        self.position = vec(WIDTH / 2, HEIGHT / 2)
        self.rect = self.image.get_rect(center=self.position)
        self.vel = vec(0, 0)
        self.acceleration = vec(0, -0.2)  # The acceleration vec points upwards.
        self.angle_speed = 0
        self.angle = 0

    def update(self):
        """"""Update the player's position.""""""
        keys = pygame.key.get_pressed()
        if keys[K_LEFT]:
            self.angle_speed = -2
            player.rotate()
        if keys[K_RIGHT]:
            self.angle_speed = 2
            player.rotate()
        # If up is pressed, accelerate the ship by
        # adding the acceleration to the velocity vector.
        if keys[K_UP]:
            self.vel += self.acceleration
        if keys[K_SPACE]:
            player.shoot()
        # max speed
        if self.vel.length() &gt; MAX_SPEED:
            self.vel.scale_to_length(MAX_SPEED)

        self.position += self.vel
        self.rect.center = self.position

    def rotate(self):
        # rotate the acceleration vector
        self.acceleration.rotate_ip(self.angle_speed)
        self.angle += self.angle_speed
        if self.angle &gt; 360:
            self.angle -= 360
        elif self.angle &lt; 0:
            self.angle += 360
        self.image = pygame.transform.rotate(self.original_image, -self.angle)
        self.rect = self.image.get_rect(center=self.rect.center)

    def wrap_around_screen(self):
        """"""Wrap around screen.""""""
        if self.position.x &gt; WIDTH:
            self.position.x = 0
        if self.position.x &lt; 0:
            self.position.x = WIDTH
        if self.position.y &lt;= 0:
            self.position.y = HEIGHT
        if self.position.y &gt; HEIGHT:
            self.position.y = 0

    def shoot(self):
        # create and add missile object to the group
        missile = Missile(self.rect.center, self.acceleration, player.acceleration.as_polar()[1])
        all_sprites.add(missile)
        missiles.add(missile)


class Missile(pygame.sprite.Sprite):
    """"""This class represents the bullet.
     A missile launched by the player's ship.
     """"""

    def __init__(self, position, direction, angle):
        """"""Initialize missile sprite.
         Take the position, direction and angle of the player.
         """"""
        pygame.sprite.Sprite.__init__(self)
        self.image = pygame.Surface([4, 10], pygame.SRCALPHA)
        self.image.fill(BLUE)
        # Rotate the image by the player.angle
        self.image = pygame.transform.rotozoom(self.image, angle, 1)
        # Pass the center of the player as the center of the bullet.rect.
        self.rect = self.image.get_rect(center=position)
        self.position = vec(position)  # The position vector.
        self.velocity = direction * 50  # Multiply by desired speed.

    def update(self):
        """"""Move the bullet.""""""
        self.position += self.velocity  # Update the position vector.
        self.rect.center = self.position  # And the rect.

        if self.rect.x &lt; 0 or self.rect.x &gt; WIDTH or self.rect.y &lt; 0 or self.rect.y &gt; HEIGHT:
            self.kill()


all_sprites = pygame.sprite.Group()
player = Player()
all_sprites.add(player)
missiles = pygame.sprite.Group()

while True:
    for event in pygame.event.get():
        if event.type == QUIT:
            pygame.quit()
            sys.exit()

    player.wrap_around_screen()
    all_sprites.update()

    DISPLAY.fill(BLACK)
    all_sprites.draw(DISPLAY)
    pygame.display.set_caption('angle {:.1f} accel {} accel angle {:.1f}'.format(
        player.angle, player.acceleration, player.acceleration.as_polar()[1]))
    pygame.display.update()
    fps_clock.tick(FPS)**
</code></pre>

<p>Any help would be appreciated</p>
","7534895","","","pygame - Bullet sprite wrong offset from the ship angle (Vectors2)","<python><pygame>","2","0","4688"
"49059955","2018-03-01 22:49:39","0","","<p>The only problem there is that <code>.rotozoom</code> uses the angles in counter-clockwise, while  the <code>.as_polar</code> vector method returns the angle in clockwise direction (one might expect <code>.as_polar</code> to yield an anti-clockwise angle, given what was learned in past math classes, but the Y axis on Surfaces points downwards, while math classes usually had Y pointing upwards). </p>

<p>TL;DR: You just have to invert the angle passed in the call to rotozoom:</p>

<pre><code>self.image = pygame.transform.rotozoom(self.image, -angle, 1)
</code></pre>

<p>You probably will also want to swap the width X height of your missile:</p>

<pre><code>self.image = pygame.Surface([10, 4], pygame.SRCALPHA)
</code></pre>
","108205","","","0","735","jsbueno","2009-05-16 17:35:21","62274","3753","2414","235","49059522","49059945","2018-03-01 22:13:07","0","48","<p>There seems to be a weird offset when the bullets are shot from the ship in certain angles while the ship is moving. Also if the ship is shooting in the same direction is heading then the bullet speed is lower.
I tried to work with some SO answers and that's what I came up with:</p>

<pre><code>import sys
import pygame
from pygame.locals import *
vec = pygame.math.Vector2

pygame.init()
FPS = 60
fps_clock = pygame.time.Clock()
WIDTH = 800
HEIGHT = 800
DISPLAY = pygame.display.set_mode((WIDTH, HEIGHT))
BLACK = (0, 0, 0)
BLUE = (0, 0, 255)

MAX_SPEED = 7

class Player(pygame.sprite.Sprite):
    """"""This class represents the Player.""""""

    def __init__(self):
        """"""Set up the player on creation.""""""
        pygame.sprite.Sprite.__init__(self)
        self.image = pygame.Surface((70, 50), pygame.SRCALPHA)
        pygame.draw.polygon(self.image, (50, 120, 180), ((35, 0), (0, 35), (70, 35)))
        self.original_image = self.image
        self.position = vec(WIDTH / 2, HEIGHT / 2)
        self.rect = self.image.get_rect(center=self.position)
        self.vel = vec(0, 0)
        self.acceleration = vec(0, -0.2)  # The acceleration vec points upwards.
        self.angle_speed = 0
        self.angle = 0

    def update(self):
        """"""Update the player's position.""""""
        keys = pygame.key.get_pressed()
        if keys[K_LEFT]:
            self.angle_speed = -2
            player.rotate()
        if keys[K_RIGHT]:
            self.angle_speed = 2
            player.rotate()
        # If up is pressed, accelerate the ship by
        # adding the acceleration to the velocity vector.
        if keys[K_UP]:
            self.vel += self.acceleration
        if keys[K_SPACE]:
            player.shoot()
        # max speed
        if self.vel.length() &gt; MAX_SPEED:
            self.vel.scale_to_length(MAX_SPEED)

        self.position += self.vel
        self.rect.center = self.position

    def rotate(self):
        # rotate the acceleration vector
        self.acceleration.rotate_ip(self.angle_speed)
        self.angle += self.angle_speed
        if self.angle &gt; 360:
            self.angle -= 360
        elif self.angle &lt; 0:
            self.angle += 360
        self.image = pygame.transform.rotate(self.original_image, -self.angle)
        self.rect = self.image.get_rect(center=self.rect.center)

    def wrap_around_screen(self):
        """"""Wrap around screen.""""""
        if self.position.x &gt; WIDTH:
            self.position.x = 0
        if self.position.x &lt; 0:
            self.position.x = WIDTH
        if self.position.y &lt;= 0:
            self.position.y = HEIGHT
        if self.position.y &gt; HEIGHT:
            self.position.y = 0

    def shoot(self):
        # create and add missile object to the group
        missile = Missile(self.rect.center, self.acceleration, player.acceleration.as_polar()[1])
        all_sprites.add(missile)
        missiles.add(missile)


class Missile(pygame.sprite.Sprite):
    """"""This class represents the bullet.
     A missile launched by the player's ship.
     """"""

    def __init__(self, position, direction, angle):
        """"""Initialize missile sprite.
         Take the position, direction and angle of the player.
         """"""
        pygame.sprite.Sprite.__init__(self)
        self.image = pygame.Surface([4, 10], pygame.SRCALPHA)
        self.image.fill(BLUE)
        # Rotate the image by the player.angle
        self.image = pygame.transform.rotozoom(self.image, angle, 1)
        # Pass the center of the player as the center of the bullet.rect.
        self.rect = self.image.get_rect(center=position)
        self.position = vec(position)  # The position vector.
        self.velocity = direction * 50  # Multiply by desired speed.

    def update(self):
        """"""Move the bullet.""""""
        self.position += self.velocity  # Update the position vector.
        self.rect.center = self.position  # And the rect.

        if self.rect.x &lt; 0 or self.rect.x &gt; WIDTH or self.rect.y &lt; 0 or self.rect.y &gt; HEIGHT:
            self.kill()


all_sprites = pygame.sprite.Group()
player = Player()
all_sprites.add(player)
missiles = pygame.sprite.Group()

while True:
    for event in pygame.event.get():
        if event.type == QUIT:
            pygame.quit()
            sys.exit()

    player.wrap_around_screen()
    all_sprites.update()

    DISPLAY.fill(BLACK)
    all_sprites.draw(DISPLAY)
    pygame.display.set_caption('angle {:.1f} accel {} accel angle {:.1f}'.format(
        player.angle, player.acceleration, player.acceleration.as_polar()[1]))
    pygame.display.update()
    fps_clock.tick(FPS)**
</code></pre>

<p>Any help would be appreciated</p>
","7534895","","","pygame - Bullet sprite wrong offset from the ship angle (Vectors2)","<python><pygame>","2","0","4688"
"49059974","2018-03-01 22:51:15","1","","<p>Assigning to the variable doesn't update the list, it's just a temporary reference to the value that's in the array.</p>

<p>Use <code>enumerate</code> to get the list index, then you can replace it with the result.</p>

<pre><code>for index, arr in enumerate(myList):
    myList[index] = np.column_stack([arr,5*arr[:,2]-arr[:,1])])
</code></pre>

<p>Also, avoid using the names of built-in classes and functions as your own variable names. <code>list</code> is a standard class.</p>
","1491895","","","6","487","Barmar","2012-06-29 18:12:29","477375","68451","6422","3351","49059917","49060683","2018-03-01 22:46:43","1","140","<p>This is a follow-up post from a previous question of mine: <a href=""https://stackoverflow.com/questions/49058472/referring-to-arrays-in-a-for-loop?noredirect=1#comment85123191_49058472"">Referring to arrays in a for-loop</a>.</p>

<p>I would like to generalize the solution proposed there in order to be able to complete more complex tasks, such as attaching a column to each array that contains the result of some calculation:</p>

<pre><code>import numpy as np
list=[one, two, three]

for arr in list:
    arr=np.column_stack([arr,5*arr[:,2]-arr[:,1])])
</code></pre>

<p>All three arrays have the same dimensions.</p>
","8682794","","","Iterating over a list of arrays while making changes to each array","<python><arrays><python-3.x><numpy><for-loop>","4","0","623"
"49059978","2018-03-01 22:51:28","0","","<p>From what I understand from the lines of code here <a href=""https://keras.io/preprocessing/image/"" rel=""nofollow noreferrer"">https://keras.io/preprocessing/image/</a> and there <a href=""https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py"" rel=""nofollow noreferrer"">https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py</a>, yes it iterates through all samples, and stops when <code>number_batches &gt;= len(x_train) / batch_size</code>. It does that for each epoch, but the batches might be different for each epoch if <code>shuffle = True</code>.</p>
","8253769","","","0","603","kluu","2017-07-04 12:11:46","1719","153","1098","19","49034250","","2018-02-28 16:28:41","0","1501","<p>From the Keras Preprocessing ImageDataGenerator module, the flow_from_directory method is used to create an Iterator from a directory containing sub-directories of images.  The Iterator runs indefinitely creating batches of images.  My question is, does it iterate through every sample per epoch?  </p>

<p>For example, if I have 300 image total, and my batch size is 30, if I do 10 steps, does it iterate through every single sample once?  Or is each step an independent random sample from the entire dataset?  If we do iterate through every sample, what happens when I have a sample size not divisible by batch size (like 304 images)?  At step 11, does the iterator know to get the last 4 samples first, then get another 26 samples from the whole dataset?</p>
","3880039","","","Does Keras flow_from_directory iterate through every sample in a directory?","<python><tensorflow><keras>","1","1","765"
"49059981","2018-03-01 22:51:41","2","","<pre><code>new_list = [my_list[i:i + 5] for i in xrange(0, len(my_list), 5)]
</code></pre>

<p>What's happening here is that takes chunks of data from 0 - 5, 5 - 10, etc. to create sub lists</p>
","6388994","","","6","195","Usernamenotfound","2016-05-27 03:40:14","1131","157","36","67","49059938","49059981","2018-03-01 22:47:50","-1","62","<p>In python how can I create a list of lists after every 5th item?</p>

<pre><code>my_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
</code></pre>

<p>Expected output:</p>

<pre><code>new_list = [['a', 'b', 'c', 'd', 'e'], ['f', 'g', 'h', 'i', 'j']....]
</code></pre>
","8210371","","","How to create list of lists after every nth item","<python>","1","1","360"
"49059986","2018-03-01 22:52:05","1","","<p>What you describe is a recursive calculation and in pandas general way to do is to use <code>expanding</code> objects with a custom function:</p>

<pre><code>from functools import reduce  # Python 3
df['x'].expanding().apply(lambda r: reduce(lambda prev, value: 2*prev + value, r))
Out: 
date
2017-07-30     1.0
2017-07-31     4.0
2017-08-01    11.0
2017-08-02    26.0
Name: x, dtype: float64
</code></pre>

<p>See <a href=""https://stackoverflow.com/a/41790304/2285236"">one of my previous answers</a> for a detailed discussion on performance of <code>expanding</code>. (tl;dr: a for loop is generally better.)</p>
","2285236","","","0","617","ayhan","2013-04-16 06:47:14","42470","4534","3523","1930","49059594","","2018-03-01 22:19:53","0","102","<p>If we have a Pandas DataFrame containing the following values</p>

<pre><code>            x          
date
2017-07-30  1
2017-07-31  2
2017-08-01  3
2017-08-02  4
</code></pre>

<p>how can we create a new column <code>y</code> whose value is calculated using </p>

<pre><code>today's y = 2*(previous day's y) + (today's x)
</code></pre>

<p>for the oldest date, <code>y</code> will be <code>1</code></p>

<p><strong>Expected Result:</strong></p>

<pre><code>            x       y     
date
2017-07-30  1       1
2017-07-31  2       4
2017-08-01  3       11
2017-08-02  4       26
</code></pre>

<p><strong>Attempt:</strong></p>

<pre><code>import pandas as pd 

d = {
    'date': ['2017-07-30', '2017-07-31', '2017-08-01', '2017-08-02'],
    'x': [1,2,3,4]
}
df = pd.DataFrame.from_dict(d).set_index('date')
df['y'] = 1
df['y'] = df['y'].shift(1)*2 + df['x']
print(df)
</code></pre>

<p><strong>Attempt's Result</strong></p>

<pre><code>            x    y
date
2017-07-30  1  NaN
2017-07-31  2  4.0
2017-08-01  3  5.0
2017-08-02  4  6.0
</code></pre>
","741099","741099","2018-03-01 22:26:02","Create New Pandas DataFrame Column with Values using Previous Row","<python><python-3.x><pandas><numpy>","2","0","1054"
"49059999","2018-03-01 22:53:11","6","","<p>I found this to be useful for quickly visualizing interaction data sourced as a CSV file from PostgreSQL. [Output below reformatted for readability.]</p>

<pre><code>## PSQL ['DUMMY' DATA]:

[interactions_practice]# \copy (SELECT gene_1, gene_2 FROM interactions
  WHERE gene_1 in (SELECT gene_2 FROM interactions))
  TO '/tmp/a.csv' WITH CSV      -- &lt;&lt; note: no terminating "";"" for this query

## BASH:

[victoria@victoria ~]$ cat /tmp/a.csv                                                                                                      

  APC,TP73
  BARD1,BRCA1
  BARD1,ESR1
  BARD1,KRAS2
  BARD1,SLC22A18
  BARD1,TP53
  BRCA1,BRCA2
  BRCA1,CHEK2
  BRCA1,MLH1
  BRCA1,PHB
  BRCA2,CHEK2
  BRCA2,TP53
  CASP8,ESR1
  CASP8,KRAS2
  CASP8,PIK3CA
  CASP8,SLC22A18
  CDK2,CDKN1A
  CHEK2,CDK2
  ESR1,BRCA1
  ESR1,KRAS2
  ESR1,PPM1D
  ESR1,SLC22A18
  KRAS2,BRCA1
  MLH1,CHEK2
  MLH1,PMS2
  PIK3CA,BRCA1
  PIK3CA,ESR1
  PIK3CA,RB1CC1
  PIK3CA,SLC22A18
  PMS2,TP53
  PTEN,BRCA1
  PTEN,MLH3
  RAD51,BRCA1
  RB1CC1,SLC22A18
  SLC22A18,BRCA1
  TP53,PTEN


## PYTHON 3.5 VENV (ANACONDA):

&gt;&gt;&gt; import networkx as nx
&gt;&gt;&gt; import pylab as plt
&gt;&gt;&gt; G = nx.read_edgelist(""/tmp/a.csv"", delimiter="","")

&gt;&gt;&gt; G.edges()

  [('CDKN1A', 'CDK2'), ('MLH3', 'PTEN'), ('TP73', 'APC'), ('CHEK2', 'MLH1'),
   ('CHEK2', 'BRCA2'), ('CHEK2', 'CDK2'), ('CHEK2', 'BRCA1'), ('BRCA2', 'TP53'),
   ('BRCA2', 'BRCA1'), ('KRAS2', 'CASP8'), ('KRAS2', 'ESR1'), ('KRAS2', 'BRCA1'),
   ('KRAS2', 'BARD1'), ('PPM1D', 'ESR1'), ('BRCA1', 'PHB'), ('BRCA1', 'ESR1'),
   ('BRCA1', 'PIK3CA'), ('BRCA1', 'PTEN'), ('BRCA1', 'MLH1'), ('BRCA1', 'SLC22A18'),
   ('BRCA1', 'BARD1'), ('BRCA1', 'RAD51'), ('CASP8', 'ESR1'), ('CASP8', 'SLC22A18'),
   ('CASP8', 'PIK3CA'), ('TP53', 'PMS2'), ('TP53', 'PTEN'), ('TP53', 'BARD1'),
   ('PMS2', 'MLH1'), ('PIK3CA', 'SLC22A18'), ('PIK3CA', 'ESR1'), ('PIK3CA', 'RB1CC1'),
   ('SLC22A18', 'ESR1'), ('SLC22A18', 'RB1CC1'), ('SLC22A18', 'BARD1'), ('BARD1', 'ESR1')]

&gt;&gt;&gt; G.number_of_edges()
  36

&gt;&gt;&gt; G.nodes()

  ['CDKN1A', 'MLH3', 'TP73', 'CHEK2', 'BRCA2', 'KRAS2', 'CDK2', 'PPM1D', 'BRCA1',
   'CASP8', 'TP53', 'PMS2', 'RAD51', 'PIK3CA', 'MLH1', 'SLC22A18', 'BARD1', 'PHB', 'APC', 'ESR1', 'RB1CC1', 'PTEN']

&gt;&gt;&gt; G.number_of_nodes()
  22

&gt;&gt;&gt; from networkx.drawing.nx_agraph import graphviz_layout

&gt;&gt;&gt; ## nx.draw(G, pos=graphviz_layout(G))

## DUE TO AN UNIDENTIFIED BUG, I GET THIS ERROR THE FIRST TIME RUNNING THIS
## COMMAND; JUST RE-RUN IT:

&gt;&gt;&gt; nx.draw(G, pos=graphviz_layout(G), node_size=1200, node_color='lightblue',
    linewidths=0.25, font_size=10, font_weight='bold', with_labels=True)

  QGtkStyle could not resolve GTK. Make sure you have installed the proper libraries.

&gt;&gt;&gt; nx.draw(G, pos=graphviz_layout(G), node_size=1200, node_color='lightblue',
    linewidths=0.25, font_size=10, font_weight='bold', with_labels=True)

&gt;&gt;&gt; plt.show()    ## plot1.png [opens in matplotlib popup window] attached
</code></pre>

<p>It is difficult to decrease congestion in these static networkx / matplotlib plots; one workaround is to increase the figure size, per this StackOverflow Q/A: <a href=""https://stackoverflow.com/questions/36255964/high-resolution-image-of-a-graph-using-networkx-and-matplotlib"">High Resolution Image of a Graph using NetworkX and Matplotlib</a> :</p>

<pre><code>&gt;&gt;&gt; plt.figure(figsize=(20,14))
  &lt;matplotlib.figure.Figure object at 0x7f1b65ea5e80&gt;

&gt;&gt;&gt; nx.draw(G, pos=graphviz_layout(G), node_size=1200, node_color='lightblue',
    linewidths=0.25, font_size=10, font_weight='bold', with_labels=True, dpi=1000)

&gt;&gt;&gt; plt.show()    ## plot2.png attached

## RESET OUTPUT FIGURE SIZE TO SYSTEM DEFAULT:

&gt;&gt;&gt; plt.figure()
  &lt;matplotlib.figure.Figure object at 0x7f1b454f1588&gt;
</code></pre>

<p><strong>plot1.png</strong>
<a href=""https://i.stack.imgur.com/J1sB1.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/J1sB1.png"" alt=""plot1.png""></a></p>

<p><strong>plot2.png</strong>
<a href=""https://i.stack.imgur.com/IjCjs.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/IjCjs.png"" alt=""plot2.png""></a></p>

<p>Bonus -- shortest path:</p>

<pre><code>&gt;&gt;&gt; nx.dijkstra_path(G, 'CDKN1A', 'MLH3')
['CDKN1A', 'CDK2', 'CHEK2', 'BRCA1', 'PTEN', 'MLH3']
</code></pre>
","1904943","1904943","2018-03-01 23:39:23","2","4363","Victoria Stuart","2012-12-14 19:03:26","1764","743","1163","2","21978487","21990980","2014-02-24 03:40:54","30","29688","<p>I am having some problems in visualizing the graphs created with python-networkx, I want to able to reduce clutter and regulate the distance between the nodes (I have also tried spring_layout, it just lays out the nodes in an elliptical fashion). Please advise.
<img src=""https://i.stack.imgur.com/LeJWB.png"" alt=""enter image description here""></p>

<p>Parts of code:</p>

<pre><code>nx.draw_networkx_edges(G, pos, edgelist=predges, edge_color='red', arrows=True)
nx.draw_networkx_edges(G, pos, edgelist=black_edges, arrows=False, style='dashed')
# label fonts
nx.draw_networkx_labels(G,pos,font_size=7,font_family='sans-serif')
nx.draw_networkx_edge_labels(G,pos,q_list,label_pos=0.3)
</code></pre>
","356922","","","Improving Python NetworkX graph layout","<python><networkx>","4","0","703"
"49060008","2018-03-01 22:53:56","0","","<p>This works under 3 conditions:</p>

<ol>
<li>Turn your input into a list of dictionaries.</li>
<li>Drop duplicates or specify a suitable aggregation function.</li>
<li>Convert string <code>fieldvalue</code> column to numeric.</li>
</ol>

<p><strong>Solution</strong></p>

<pre><code>df = pd.DataFrame(rec).drop_duplicates(['date', 'name', 'fieldname'])
df['fieldvalue'] = pd.to_numeric(df['fieldvalue'], downcast='integer')

dfs = {k: pd.pivot_table(df[df['name'] == k], index=['date'],
          columns=['fieldname'], values=['fieldvalue']) \
          for k in set(df['name'])}
</code></pre>

<p><strong>Result</strong></p>

<p>Since I have used the <code>drop_duplicates</code> option above, you may see different results to your desired output.</p>

<pre><code>{'Brian':            fieldvalue      
fieldname      dinner lunch
date                       
2018-01-21         13    11
2018-01-22          8    12
2018-01-23         15    11,

 'Anna':            fieldvalue      
fieldname      dinner lunch
date                       
2018-01-21          8    11
2018-01-22          9    13
2018-01-23         15    11,

 'John':            fieldvalue      
fieldname      dinner lunch
date                       
2018-01-21          9    10
2018-01-22          8    11
2018-01-23          5    12}
</code></pre>
","9209546","","","2","1320","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49058366","49060008","2018-03-01 20:40:55","1","65","<p>I am trying to have my data (lists with dictionaries) structured, to do that I used pandas df.</p>

<p>I was trying to replicate without using pandas, I tried with zip and pop, but I couldn't reach anything similar to what I get using pandas df.</p>

<p>Even with pandas df pivot, the output is what I want but I am loosing the 'name', and I would like to have the data structured for all names.</p>

<p>My question is can I get a similar output without using pandas, and why it is not printing a table for all names?</p>

<pre><code>rec =[{'date': u'2018-01-21', 'name' : u'John', 'fieldname': u'lunch', 'fieldvalue': u'10'},
 {'date': u'2018-01-21', 'name' : u'John', 'fieldname': u'dinner', 'fieldvalue': u'9'},
 {'date': u'2018-01-22', 'name' : u'John', 'fieldname': u'lunch', 'fieldvalue': u'11'},
 {'date': u'2018-01-22', 'name' : u'John', 'fieldname': u'dinner', 'fieldvalue': u'8'},
 {'date': u'2018-01-23', 'name' : u'John', 'fieldname': u'lunch', 'fieldvalue': u'12'},
 {'date': u'2018-01-23', 'name' : u'John', 'fieldname': u'dinner', 'fieldvalue': u'5'}]
[{'date': u'2018-01-21', 'name' : u'Anna', 'fieldname': u'lunch', 'fieldvalue': u'11'},
 {'date': u'2018-01-21', 'name' : u'Anna', 'fieldname': u'dinner', 'fieldvalue': u'8'},
 {'date': u'2018-01-22', 'name' : u'Anna', 'fieldname': u'lunch', 'fieldvalue': u'13'},
 {'date': u'2018-01-22', 'name' : u'Anna', 'fieldname': u'dinner', 'fieldvalue': u'9'},
 {'date': u'2018-01-23', 'name' : u'Anna', 'fieldname': u'lunch', 'fieldvalue': u'11'},
 {'date': u'2018-01-23', 'name' : u'Anna', 'fieldname': u'dinner', 'fieldvalue': u'15'}]
[{'date': u'2018-01-21', 'name' : u'John', 'fieldname': u'lunch', 'fieldvalue': u'14'},
 {'date': u'2018-01-21', 'name' : u'John', 'fieldname': u'dinner', 'fieldvalue': u'3'},
 {'date': u'2018-01-22', 'name' : u'John', 'fieldname': u'lunch', 'fieldvalue': u'16'},
 {'date': u'2018-01-22', 'name' : u'John', 'fieldname': u'dinner', 'fieldvalue': u'9'},
 {'date': u'2018-01-23', 'name' : u'John', 'fieldname': u'lunch', 'fieldvalue': u'12'},
 {'date': u'2018-01-23', 'name' : u'John', 'fieldname': u'dinner', 'fieldvalue': u'9'}]
[{'date': u'2018-01-21', 'name' : u'Brian', 'fieldname': u'lunch', 'fieldvalue': u'11'},
 {'date': u'2018-01-21', 'name' : u'Brian', 'fieldname': u'dinner', 'fieldvalue': u'13'},
 {'date': u'2018-01-22', 'name' : u'Brian', 'fieldname': u'lunch', 'fieldvalue': u'12'},
 {'date': u'2018-01-22', 'name' : u'Brian', 'fieldname': u'dinner', 'fieldvalue': u'8'},
 {'date': u'2018-01-23', 'name' : u'Brian', 'fieldname': u'lunch', 'fieldvalue': u'11'},
 {'date': u'2018-01-23', 'name' : u'Brian', 'fieldname': u'dinner', 'fieldvalue': u'15'}]

df(rec)

         date fieldname fieldvalue  name
0  2018-01-21     lunch         10  John
1  2018-01-21    dinner          9  John
2  2018-01-22     lunch         11  John
3  2018-01-22    dinner          8  John
4  2018-01-23     lunch         12  John
5  2018-01-23    dinner          5  John

df(rec).pivot(index='date', columns='fieldname', values='fieldvalue')

fieldname  dinner lunch
date                   
2018-01-21      9    10
2018-01-22      8    11
2018-01-23      5    12
</code></pre>

<p>Output desired:</p>

<pre><code>Anna
fieldname  dinner lunch
date                   
2018-01-21      9    10
2018-01-22      8    11
2018-01-23      5    12

John
fieldname  dinner lunch
date                   
2018-01-21      9    10
2018-01-22      8    11
2018-01-23      5    12

Brian
fieldname  dinner lunch
date                     
2018-01-21      9    10
2018-01-22      8    11
2018-01-23      5    12
</code></pre>
","9310195","9310195","2018-03-01 21:07:23","Structured data, dictionaries inside lists","<python><python-2.7><list><pandas><dictionary>","1","5","3596"
"49060057","2018-03-01 22:58:05","1","","<p>This might count as a bit of a hack, but try this:</p>

<pre><code>df.letters.value_counts().sort_index(ascending=False).plot(kind='barh')
</code></pre>
","8008776","","","0","156","Peter Leimbigler","2017-05-14 01:39:16","5876","736","465","96","49059956","49060061","2018-03-01 22:49:39","-1","3336","<p>I have a dataframe where i am trying to count the occurrence of each value.
I plot it as horizontal bar but cant get it to be sorted.</p>

<pre><code>df = pd.DataFrame(['A','A','A','B','B','C'],columns = ['letters'])

df.value_counts()

A 3
B 2
C 1
</code></pre>

<p><a href=""https://i.stack.imgur.com/OQTU9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OQTU9.png"" alt=""enter image description here""></a></p>

<p>How can i get it sorted in a descending manner?</p>
","2800939","","","pandas plot value counts barplot in descending manner","<python><pandas><matplotlib><seaborn>","2","0","489"
"49060061","2018-03-01 22:58:20","1","","<p>You can do it by changing your plotting line like this </p>

<pre><code>df.letters.value_counts().sort_values().plot(kind = 'barh')
</code></pre>
","4097623","","","3","149","A.Gharbi","2014-10-01 06:02:01","66","30","45","0","49059956","49060061","2018-03-01 22:49:39","-1","3336","<p>I have a dataframe where i am trying to count the occurrence of each value.
I plot it as horizontal bar but cant get it to be sorted.</p>

<pre><code>df = pd.DataFrame(['A','A','A','B','B','C'],columns = ['letters'])

df.value_counts()

A 3
B 2
C 1
</code></pre>

<p><a href=""https://i.stack.imgur.com/OQTU9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OQTU9.png"" alt=""enter image description here""></a></p>

<p>How can i get it sorted in a descending manner?</p>
","2800939","","","pandas plot value counts barplot in descending manner","<python><pandas><matplotlib><seaborn>","2","0","489"
"49060074","2018-03-01 22:59:32","0","","<p>Using the json python library should work.
Each element in the json is a dictionary. For each dictionary the value can be a string, a dictionary (etc) or also an array (collection of elements).
To access the value of a dictionary with key <code>k</code> you do <code>d['k']</code>. If its value is an array then you specify the index: <code>d['k'][0]</code></p>

<p>As example take the following json file:</p>

<pre><code>{""menu"": {
  ""id"": ""file"",
  ""value"": ""File"",
  ""popup"": {
    ""menuitem"": [
      {""value"": ""New"", ""onclick"": ""CreateNewDoc()""},
      {""value"": ""Open"", ""onclick"": ""OpenDoc()""},
      {""value"": ""Close"", ""onclick"": ""CloseDoc()""}
    ]
  }
}}
</code></pre>

<p>and play with this code <code>menuitem</code> is an array:</p>

<pre><code>import json

f = open(""test.json"")
a = f.read()
jj = json.loads(a)
print(a)
print(type(jj))
print(type(jj['menu']['popup']['menuitem']))
for el in jj['menu']['popup']['menuitem']:
    print(el['value'])
</code></pre>
","1714692","","","0","978","Francesco Boi","2012-10-02 14:56:13","3103","726","1001","418","49051373","","2018-03-01 14:03:21","0","117","<p>Python 2.7</p>

<p>I am new to python and this is my first post for help. </p>

<p>I am sending a post request to the web and having a json file returned. It looks like this:</p>

<p><a href=""https://i.stack.imgur.com/NzIQs.jpg"" rel=""nofollow noreferrer"">json Example</a></p>

<p>if i do:</p>

<blockquote>
  <p>print data['result']</p>
</blockquote>

<p>I get all the items listed</p>

<p>if i do:</p>

<blockquote>
  <p>print data['result']['recordtype'] </p>
</blockquote>

<p>I get ""list indices must be integers, not str"" (because I need ['result'][0]['recordtype']? but that would limit it to only the first item)</p>

<p>I can get ""some"" info with:</p>

<blockquote>
  <p>print(data['result'](type is a list)</p>
  
  <p>print(data['result'][0])(type is a dict)</p>
  
  <p>print(data['result'][0]['columns'](type is a dict)</p>
</blockquote>

<p>But this only returns the first item. ([0]). Any other attempts gets me a ""must be integer not str"". </p>

<p>Ultimately, I would like to enter item ""id"" and have all the attributes ""itemid"", ""displayname"", ""columns"", etc returned for that item as variables. (""columns"" will vary from json file to json but the rest should remain uniform) </p>

<p>Questions:</p>

<p>How can I loop through all these items based on the ""id"" value and return all the values associated with that item as variables?</p>
","9420470","9420470","2018-03-01 18:28:32","Python parsing json file into something usable","<python><json>","3","1","1357"
"49060090","2018-03-01 23:01:09","0","","<p>I'm afraid the solution you are referencing can only be generalized to in-place changes to the array. Anything that changes the size will AFAIK create a new array.</p>

<p>So this</p>

<pre><code>&gt;&gt;&gt; X,Y,Z = (np.arange(i+1, i+10, dtype=float).reshape(3, 3) for i in range(3))
&gt;&gt;&gt; L = [X,Y,Z]
&gt;&gt;&gt; for arr in L:
...    np.sin(arr, out=arr)
</code></pre>

<p>or this</p>

<pre><code>&gt;&gt;&gt; for arr in L:
...     arr[1] = arr[1, ::-1]
</code></pre>

<p>will work.</p>

<p>You can even replace the entire array, as long as you do it in-place:</p>

<pre><code>&gt;&gt;&gt; for arr in L:
...     arr[...] = 1.7
</code></pre>

<p>But this</p>

<pre><code>&gt;&gt;&gt; for arr in L:
...    np.append(arr, arr[-1])
</code></pre>

<p>will not change the original arrays but create new ones. Assigning back to <code>arr</code> won't help because it just rebinds the name <code>arr</code> to the new object.</p>
","7207392","7207392","2018-03-01 23:09:41","0","935","Paul Panzer","2016-11-24 23:39:00","37645","7185","734","1","49059917","49060683","2018-03-01 22:46:43","1","140","<p>This is a follow-up post from a previous question of mine: <a href=""https://stackoverflow.com/questions/49058472/referring-to-arrays-in-a-for-loop?noredirect=1#comment85123191_49058472"">Referring to arrays in a for-loop</a>.</p>

<p>I would like to generalize the solution proposed there in order to be able to complete more complex tasks, such as attaching a column to each array that contains the result of some calculation:</p>

<pre><code>import numpy as np
list=[one, two, three]

for arr in list:
    arr=np.column_stack([arr,5*arr[:,2]-arr[:,1])])
</code></pre>

<p>All three arrays have the same dimensions.</p>
","8682794","","","Iterating over a list of arrays while making changes to each array","<python><arrays><python-3.x><numpy><for-loop>","4","0","623"
"49060092","2018-03-01 23:01:15","0","","<p>After writing this, I went and read a few tutorials about the new API.</p>

<p>I managed to solve, hopefully in the ""right"" TF way.</p>

<p>The new <code>Dataset</code> API allowed me to do this.</p>

<p>All my tensors come from a generator. This generator returns 3 numpy arrays and a label for each instance of the input data.</p>

<p>E.g.:</p>

<pre><code>def generate_tensor_set(arg_example):
    &lt;get the data in some way, maybe using arg_example&gt;
    return x0, x1, x2, y
</code></pre>

<p>From the generator I created an input function that uses a dataset created from the generator. The <code>lambda</code> is used to pass parameters to the generator in  <code>from_generator</code> </p>

<pre><code>def my_input_fn(batch_size):
    ds = tf.data.Dataset().from_generator(lambda:generate_tensor_set(arg_example=an_arg),
        output_types = (tf.float32, tf.float32, tf.float32, tf.int32)
        output_shapes = (tf.Tensorshape([3]),
                         tf.Tensorshape([2]),
                         tf.Tensorshape([2,2])))
    ds.batch(batch_size)
    x0, x1, x2, label = ds.make_one_shot_iterator().get_next()
    return {""x0"": x0, ""x1"": x1, ""x2"": x2}, label
</code></pre>

<p>The <code>tf.int32</code> in the input function is just because I used <code>sparse_softmax_cross_entropy</code> which wants an <code>int32</code> as input for labels (I guess, using that solved my issues).</p>

<p>Then a model function:</p>

<pre><code>def model_function(features, labels, mode, params):
    y0 = tf.layers.dense(features['x0'], units = 1)
    y1 = tf.layers.dense(features['x1'], units = 1)
    y2 = tf.layers.dense(features['x2'], units = 1)
    y_concat = tf.concat([y0,y1,y2],1)
    y = tf.layers.dense(y_concat, units = 1)
    logits = tf.layers.dense(y_concat, units = 2)

    &lt;loss, train_op, a bunch of other stuff&gt;
</code></pre>

<p>The <code>bunch of other stuff</code> is decently described in the <a href=""https://www.tensorflow.org/get_started/custom_estimators"" rel=""nofollow noreferrer"">custom estimator documentation</a></p>

<p>Then, </p>

<pre><code>my_feature_columns = [  tf.feature_column.numeric_column(""x0"", shape=(3), dtype=tf.float32),
                        tf.feature_column.numeric_column(""x1"", shape=(2), dtype=tf.float32),
                        tf.feature_column.numeric_column(""x2"", shape=(2,2), dtype=tf.float32)]

classifier_mymodel = tf.estimator.Estimator(
    model_fn = model_function,
    params = {'feature_columns': my_feature_columns})

classifier_mymodel.train(input_fn = lambda: my_input_fn(batch_size = 16)
</code></pre>
","3018260","","","0","2594","mic","2013-11-21 15:37:51","591","61","54","16","48999962","49060092","2018-02-27 02:00:56","0","511","<p>I have been searching for the best way to do this for a week now, and I am giving up.</p>

<p>I am trying to build a tensorflow model that learns from three different features for each input. The issue is that the features have different shapes.</p>

<p>E.g.: </p>

<pre><code>elem0 = {'feat0':[1,3,5],'feat1':[1,2],'feat2':[[0,1],[1,1]]}
elem1 = {'feat0':[0,5,1],'feat1':[2,9],'feat2':[[0,0],[1,0]]}
elem2 = {'feat0':[5,3,7],'feat1':[3,6],'feat2':[[1,1],[1,0]]}
</code></pre>

<p>The best I could do was to create three ""columns"" in tf, as follows:</p>

<pre><code>x0 = tf.placeholder(tf.float32, shape = (None, 3), name = 'feat0')
x1 = tf.placeholder(tf.float32, shape = (None, 2), name = 'feat1')
x2 = tf.placeholder(tf.float32, shape = (None, 2, 2), name = 'feat2')

y0 = tf.layers.dense(x0, units = 1)
y1 = tf.layers.dense(x1, units = 1)
y2 = tf.layers.dense(x2, units = 1)

y_concat = tf.concat([y0,y1,y2],1)

y = tf.layers.dense(y_concat, units = 1)
</code></pre>

<p>The ""issue"" with that is that I have no idea if I should, and if so, how, use the new <code>Dataset</code> class in tensorflow.</p>

<p>As of now, I can run my model with</p>

<pre><code>init = tf.global_variables_initializer()
sess.run(init)
res = sess.run(y, {x0:[elem0[feat0],elem1[feat0],elem2[feat0]],
                   x1:[elem0[feat1],elem1[feat1],elem2[feat1]], 
                   x2:[elem0[feat2],elem1[feat2],elem2[feat2]]
})
</code></pre>

<p>What I would really like is having the chance to create a dataset iterator over my elements, returning the three ""columns"" of data. </p>

<p>Something like:</p>

<pre><code>def generate_tensor_set():
    &lt;some code, maybe getting my inputs from a SQL db&gt;
    return x0_batch, x1_batch, x2_batch
</code></pre>
","3018260","3018260","2018-02-27 02:24:12","Combine data with different shapes for tensorflow","<python><tensorflow>","1","0","1749"
"49060100","2018-03-01 23:01:51","2","","<p>If you're talking about <a href=""https://introcs.cs.princeton.edu/python/code/stdio.py.html"" rel=""nofollow noreferrer"">this</a> library (which isn't a standard library, just something someone wrote), it looks like mostly a bunch of convenience functions for reading different datatypes from stdin.</p>

<p>As far as the difference between <code>stdio.write</code> and <code>print</code>, <code>stdio.write</code> looks to be a shim that works in both python 2 and 3 that will encode whatever unicode or byte string you have to utf-8 before it tries to write it, potentially to prevent encoding errors for some consoles that will try to encode out to ascii and fail.</p>

<pre><code>def write(x=''):
    """"""
    Write x to standard output.
    """"""
    if (sys.hexversion &lt; 0x03000000):
        x = unicode(x)
        x = x.encode('utf-8')
    else:
        x = str(x)
    sys.stdout.write(x)
    sys.stdout.flush()
</code></pre>
","1547004","1547004","2018-03-01 23:06:51","4","934","Brendan Abel","2012-07-23 21:32:10","21194","1323","1935","497","49059992","","2018-03-01 22:52:48","1","1765","<p>I looked everywhere but I didn't find anything about it.
In my school, We use stdio.write or stdio.writeln instead of print.
Is there a difference betweeen them? and I don't understand that functions' purpose. Are there anyone to explain to me very clearly?</p>

<p>Thank you so much for replying. </p>
","9277888","","","What is stdio.write in python?","<python>","1","7","306"
"49060117","2018-03-01 23:03:10","0","","<p>This happened to me. I fixed it by using <code>color</code> instead of <code>c</code>.</p>

<pre><code>plt.scatter(clustered_training_data[y==i, 0], clustered_training_data[y==i, 1], color=my_cmap(i / 3.0), label=labels[i], s=50, marker='o', edgecolor='white', alpha=0.7)
</code></pre>
","3474956","","","0","289","kilojoules","2014-03-29 04:28:36","3513","581","1160","23","29712994","","2015-04-18 04:44:47","0","1369","<p>I am making this bar plot:
<img src=""https://i.stack.imgur.com/K5oi2.png"" alt=""enter image description here""></p>

<p>... using this code segment:</p>

<pre><code>my_cmap = plt.get_cmap('copper')

plt.figure()
plt.set_cmap(my_cmap)
plt.pcolormesh(xx, yy, Z)

labels = ['Negative', 'Negative (doubtful)', 'Positive (doubtful)', 'Positive' ]
for i in [0, 1, 2, 3] :
    plt.scatter(clustered_training_data[y==i, 0], clustered_training_data[y==i, 1], c=my_cmap(i / 3.0), label=labels[i], s=50, marker='o', edgecolor='white', alpha=0.7)

plt.scatter(lda_trans_eval[q == -1, 0], lda_trans_eval[q == -1, 1], c='green', label='Your patient', s=80, marker='h', edgecolor='white')

plt.legend(prop={'size':8})
</code></pre>

<p>Only one (second) color is always blue, regardless of chosen color map. Corresponding data points are correctly colored in the plot and I can't see the reason why pyplot colors the second label differently.</p>
","1851207","","","Wrong scatter label color in pyplot legend","<python><matplotlib><graph>","2","2","933"
"49060151","2018-03-01 23:06:54","1","","<p>For what it's worth, when I create custom 404 / 500 templates I find it easier to setup a temporary class based TemplateView and then once I'm finished designing them they get moved into the templates folder where Django looks for them. The reason is, once you get past the DEBUG issue your next obstacle will likely be getting your static files served; in a typical setup they will not be served on your development machine when DEBUG = False (unless you've configured it to do so). It's significant because the template you are creating may rely upon those files (css, js files etc). Either way:</p>

<p>1) Make sure it reads exactly as:</p>

<pre><code>DEBUG = False
</code></pre>

<p>2) Make sure it's not nested in kind of if / else statement or something like that. </p>

<p>3) In your development environment you can keep ALLOWED_HOSTS = ['localhost'] to suppress the domain warning. </p>

<p>4) If all else fails you could start a new project in a different directory and compare the auto generated settings.py file to what you have.</p>
","7412551","","","0","1049","brandondavid","2017-01-13 01:08:03","121","11","12","0","49059772","","2018-03-01 22:34:31","0","884","<p>I'm trying to develop 404 and 500 error custom templates for my Django project.</p>

<p>When I change DEBUG to False, Django always returns me:</p>

<blockquote>
  <p>You're seeing this error because you have DEBUG = True in your Django settings file. Change that to False, and Django will display a standard 404 page.</p>
</blockquote>

<p>After change ALLOWED_HOSTS to ['.domain.com', 'www.domain.com'] I obtain:</p>

<blockquote>
  <p>Invalid HTTP_HOST header: 'domain.com'. You may need to add u'domain.com' to ALLOWED_HOSTS.</p>
</blockquote>

<p>What am I doing wrong? Why Django does not recognize the variable?</p>
","7804233","7804233","2018-03-01 22:47:43","Django doesn't recognize DEBUG = False","<python><django>","2","4","626"
"49060152","2018-03-01 23:06:58","0","","<p>You can use Unicode to get superscripts and subscripts. For example your text in second button can be <code>text: 'Hellow\u2074'</code>,  which is <code>Hellow</code> with a superscript 4. Check out <a href=""https://docs.python.org/3.6/howto/unicode.html"" rel=""nofollow noreferrer"">unicode HOWTO</a> and <a href=""https://unicode-table.com/en/blocks/superscripts-and-subscripts/"" rel=""nofollow noreferrer"">superscripts-and-subscripts</a></p>
","7254633","","","3","444","John Anderson","2016-12-06 00:34:51","6181","650","15","2","49051262","49087118","2018-03-01 13:57:27","0","156","<p>As the title suggest, apart from the text in the center on the button I want to put text in any of the corners of the button. One possible way to do so is to use a background image. But I want to know, can it really be done?</p>

<pre><code>import kivy
from kivy.app import App
from kivy.uix.gridlayout import GridLayout
from kivy.uix.button import Button
from kivy.lang import Builder
Builder.load_string(""""""
&lt;ButtonGridLayout&gt;:
    rows: 2
    padding: 10
    spacing: 10
    Button:
        text: 'Hello'
    Button:
        text: 'Hellow'
"""""")
class ButtonGridLayout(GridLayout):
    pass
class ButtonApp(App):
    def build(self):
        return ButtonGridLayout()
if __name__=='__main__':
    ButtonApp().run()
</code></pre>

<p>Right there inside the blue circle in this image
<a href=""https://i.stack.imgur.com/38lBk.png"" rel=""nofollow noreferrer"">ButtonApp</a></p>
","8363478","8363478","2018-03-02 11:36:50","Kivy- Is it possible to add superscript or subscript text to button","<python><kivy>","2","0","883"
"49060153","2018-03-01 23:07:02","1","","<p>Loopy isn't usually the way to go with pandas. Here's one solution.</p>

<pre><code>import pandas as pd

df = pd.DataFrame({'A': [1, 1, 1, 1],
                   'B': [2, 2, 2, 2],
                   'C': [3, 3, 3, 3],
                   'D': [4, 4, 4, 4],
                   'E': [5, 5, 5, 5]})

lst = [2, 3, 4]

df = df.drop([x for x in df if any((df[x]==i).all() for i in lst)], 1)

#    A  E
# 0  1  5
# 1  1  5
# 2  1  5
# 3  1  5
</code></pre>
","9209546","","","0","453","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49059715","49060153","2018-03-01 22:28:45","1","71","<p>I have a dataframe that I am trying to drop some columns from, based on their content. If all of the rows in a column have the same value as one of the items in a list, then I want to drop that column. I am having trouble doing this without messing up the loops. Is there a better way to do this, or some error I can fix?  I am getting an error that says:</p>

<pre><code>IndexError: index 382 is out of bounds for axis 0 with size 382
</code></pre>

<p>Code:</p>

<pre><code>def trimADAS(df):
    notList = [""Word Recall Test"",""Result""]
    print(""START"")
    print(len(df.columns))
    numCols = len(df.columns)
    for h in range(numCols): #  for every column
        for i in range(len(notList)):   #   for every list item
            if df[df.columns[h]].all() == notList[i]:   #   if all column entries == list item
                print(notList[i])   #   print list item
                print(df[df.columns[h]])    #   print column
                print(df.columns[h])    #   print column name
                df.drop([df.columns[h]], axis = 1, inplace = True)  #   drop this column
                numCols -= 1
    print(""END"")
    print(len(df.columns))
    print(df.columns)
    return()
</code></pre>
","2831637","","","Drop columns if all entries in column match item from a list in Pandas","<python><pandas>","1","2","1215"
"49060177","2018-03-01 23:09:27","1","","<p>Don't forget that in Python, variables are references to values. The iteration variable is a variable, so assigning a new value to this variable do not change the iterable.</p>

<p>In this case, why not use lists comprehensions ?</p>

<pre><code>import numpy as np
my_list = [one, two, three]

my_list = [np.column_stack([arr,5*arr[:,2]-arr[:,1])]) for arr in list]
</code></pre>

<p>And please, don't shadow <code>list</code>type…</p>
","8633776","8633776","2018-03-01 23:28:22","0","439","Darko Stankovski","2017-09-19 12:48:42","116","17","2","0","49059917","49060683","2018-03-01 22:46:43","1","140","<p>This is a follow-up post from a previous question of mine: <a href=""https://stackoverflow.com/questions/49058472/referring-to-arrays-in-a-for-loop?noredirect=1#comment85123191_49058472"">Referring to arrays in a for-loop</a>.</p>

<p>I would like to generalize the solution proposed there in order to be able to complete more complex tasks, such as attaching a column to each array that contains the result of some calculation:</p>

<pre><code>import numpy as np
list=[one, two, three]

for arr in list:
    arr=np.column_stack([arr,5*arr[:,2]-arr[:,1])])
</code></pre>

<p>All three arrays have the same dimensions.</p>
","8682794","","","Iterating over a list of arrays while making changes to each array","<python><arrays><python-3.x><numpy><for-loop>","4","0","623"
"49060180","2018-03-01 23:09:44","1","","<p>A possible quick fix : </p>

<pre><code># coding: utf8
import json
d = json.loads(""""""{""mykey"": {""readme"": ""Café""}}"""""", encoding='latin1')
print d['mykey']['readme'].encode('latin1')
</code></pre>
","9238288","","","1","199","jackw11111","2018-01-19 04:36:57","455","159","590","1","48975692","","2018-02-25 16:21:57","5","422","<p>When running this code with <code>python myscript.py</code> from Windows console cmd.exe (i.e. <em>outside</em> of Sublime Text), it works:</p>

<pre><code># coding: utf8
import json
d = json.loads(""""""{""mykey"": {""readme"": ""Café""}}"""""")
print d['mykey']['readme']
</code></pre>

<blockquote>
  <p>Café</p>
</blockquote>

<p>When running it inside Sublime Text 2 with <kbd>CTRL+B</kbd>, it fails:</p>

<ul>
<li><p>Either like this (by default):</p>

<blockquote>
  <p>print d['mykey']['readme']<br>
  UnicodeEncodeError: 'ascii' codec can't encode character u'\xe9' in position 3: ordinal not in range(128)<br>
  [Finished in 0.1s with exit code 1]</p>
</blockquote></li>
<li><p>or like this, after applying the solution <a href=""https://stackoverflow.com/a/39583630/1422096"">from this answer</a> of <a href=""https://stackoverflow.com/questions/39576308/printing-utf-8-in-python-3-using-sublime-text-3"">printing UTF-8 in Python 3 using Sublime Text 3</a> (i.e. adding <code>""env"": {""PYTHONIOENCODING"": ""utf8""},</code> in the build system):</p>

<blockquote>
  <p>[Decode error - output not utf-8]<br>
  [Decode error - output not utf-8]<br>
  [Finished in 0.1s]  </p>
</blockquote></li>
<li><p>adding <code>""encoding"": ""utf-8""</code> in the Python Sublime-build file doesn't help either</p></li>
</ul>

<p><strong>How to <code>print</code> properly in Sublime Text 2 (for Windows) console, if it contains some UTF8 char?</strong></p>

<p>Note: this is <em>not</em> a duplicate of <a href=""https://stackoverflow.com/questions/39576308/printing-utf-8-in-python-3-using-sublime-text-3"">printing UTF-8 in Python 3 using Sublime Text 3</a>, I already linked to this question before.</p>

<p>Here is the <code>Python.sublime-build</code> file:</p>

<pre><code>{ ""cmd"": [""python"", ""-u"", ""$file""],
""file_regex"": ""^[ ]*File \""(...*?)\"", line ([0-9]*)"",
""selector"": ""source.python"",
""variants"": [ { ""name"": ""Run"", ""file_regex"": ""^[ ]*File \""(...*?)\"", line ([0-9]*)"", ""cmd"": [""C:\\Python27-64\\python.exe"", ""-u"", ""$file""] } ] }
</code></pre>

<p>(I tried with and without <code>""env"": ...</code>, with and without <code>""encoding"": ...</code>)</p>
","1422096","1422096","2018-03-01 11:52:09","Printing utf-8 strings in Sublime Text 2's console with Windows 7","<python><windows><python-2.7><character-encoding><sublimetext2>","3","2","2138"
"49060198","2018-03-01 23:10:51","1","","<p>There is no attribute <code>fillColors</code>: it's singular, <code>fillColor</code>; you can't simply change the name and expect the parser to figure out what you mean.</p>

<p>As TemporalWolf already led you toward, the documentation shows how to do this with a loop.  In your case, something like:</p>

<pre><code>for index, color in enumerate(colores):
    pc.slices[i].fillColor  = colores[i]
</code></pre>

<p>This assumes that you have <code>len(colores)</code> slices in your chart.</p>
","4785185","","","1","498","Prune","2015-04-14 00:37:53","54183","8845","3232","13592","49059837","49060198","2018-03-01 22:40:28","-2","476","<p>I have a pie chart with 6 slices, and I am looking forward to change the default colors that appear in the pie chart.
As far as I found , using the <code>.fillColor</code> I can change the color of a slice.</p>

<pre><code>pie_chart = Drawing(200, 200)
pc = Pie()
pc.x = 65
pc.y = 15
pc.width = 150
pc.height = 150
pc.data = [65,13,12,9,1]
pc.labels = ['Name','Another','Yet Another','Test','Stack','Flow')

We can change the color of a slice using:
pc.slices[1].fillColor=red
</code></pre>

<p>However I am looking forward to change the color of all 6 slices and therefore I tried:</p>

<pre><code>colores=[red,brown,violet,yellow,green,pink]
pc.slices.fillColors=colores
</code></pre>

<p>And it outputs the error:</p>

<pre><code>AttributeError: Illegal attribute 'fillColors' in class WedgeProperties
</code></pre>

<p>My question is : How can I change the color of each slice in a single line of code? Is there any property to do so?</p>
","7836530","","","fill the slices with different colors on a pie chart","<python><graph><reportlab>","1","2","946"
"49060199","2018-03-01 23:10:54","1","","<p>Finally solved the issue. Well, that seems definitely pandas' bug. I used directly the .sas7bdat library by typing this(installing):</p>

<pre><code>pip install sas7bdat
</code></pre>

<p>Then I run the following code:</p>

<pre><code>import sas7bdat
from sas7bdat import *

file_name = file_path + ""cars.sas7bdat""
foo = SAS7BDAT(file_name)
my_df = foo.to_data_frame()
my_df = my_df.head()
print(my_df)
</code></pre>

<p>After running the above code, I get the following output in Python:</p>

<p><a href=""https://i.stack.imgur.com/8pXHZ.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8pXHZ.jpg"" alt=""enter image description here""></a></p>

<p>So, I get the output with correct data types displayed.</p>

<p>Hope pandas developers find out a solutions for the mentioned bug above.</p>
","3288051","","","4","808","user3288051","2014-02-08 19:36:40","150","42","8","1","49059421","","2018-03-01 22:04:24","1","761","<p>I have a <a href=""http://www.principlesofeconometrics.com/sas/cars.sas7bdat"" rel=""nofollow noreferrer"">SAS dataset</a> and when I run it I get the following output on SAS:</p>

<p><a href=""https://i.stack.imgur.com/YMDxI.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YMDxI.jpg"" alt=""enter image description here""></a></p>

<p>I also have the following Python code which gets the .sas7bdat file and displays the output, i.e. here the first five observations.</p>

<pre><code>import pandas as pd
file_name = ""cars.sas7bdat""
my_df = pd.read_sas(file_name)
my_df = my_df.head()
print(my_df)
</code></pre>

<p><a href=""https://i.stack.imgur.com/HSZ4H.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HSZ4H.jpg"" alt=""enter image description here""></a></p>

<p>As you can see, it doesn't work correct when it comes to integer data types. CYL and WGT variables are integers but are not displaying correctly if I use pandas' <a href=""http://pandas.pydata.org/pandas-docs/version/0.20/generated/pandas.read_sas.html"" rel=""nofollow noreferrer"">read_sas function</a>.</p>

<p>Any idea what heck is going on with this?</p>
","3288051","","","Pandas fails with correct data type while reading a SAS file","<python><pandas><types><sas>","2","1","1152"
"49060215","2018-03-01 23:12:23","1","","<p>I think this is because the result of the middlewares <code>mezzanine.core.middleware.FetchFromCacheMiddleware</code> and <code>mezzanine.core.middleware.UpdateCacheMiddleware</code></p>

<p>Check about it here - <a href=""http://mezzanine.jupo.org/docs/caching-strategy.html#cache-middleware"" rel=""nofollow noreferrer"">http://mezzanine.jupo.org/docs/caching-strategy.html#cache-middleware</a>. </p>

<p>You should remove these to get the desired result</p>
","808236","","","1","460","iamkhush","2011-06-21 10:30:29","1882","286","75","5","49057423","49060215","2018-03-01 19:36:50","0","165","<p>With the following I created a Page that handles a post request.</p>

<p>Mezzanine 4.2.3
Django 1.10.8
Python 2.7.10
PostgreSQL 9.6.3
Darwin 17.4.0</p>

<p>Here is my <code>models.py</code> for the Page.</p>

<pre><code>from mezzanine.pages.models import Page
from django.db import models

class MyCustomPage(Page):
    a_field = models.CharField(max_length=100)
</code></pre>

<p>Here is my <code>page_processors.py</code> for the Page.</p>

<pre><code>from django.views.decorators.cache import never_cache
from django.contrib import messages
from .forms import MyCustomForm
from .utils import do_something_specific
from .models import MyCustomPage
from mezzanine.pages.page_processors import processor_for
from django.shortcuts import redirect


@never_cache
@processor_for(MyCustomPage)
def my_custom_page(request, page):

    if request.method == ""POST"":
        form = MyCustomForm(request.POST)

        if form.is_valid():
            do_something_specific(form.cleaned_data)
            messages.success(request, ""Your post request was a success!"")
            return redirect(page.get_absolute_url())

        else:
            return {
                ""form"": form,
            }

    else:  # is GET request
        return {
            ""form"": MyCustomForm(),
        }
</code></pre>

<p>The <code>@never_cache</code> decorator seems to prevent the python code from being cached, however the template is being cached. Meaning, if I post to the url, it will call <code>do_something_specific(form.cleaned_data)</code> and that will happen, and it even seems to set the <code>messages.success</code>. But then when I do a regular get request the next time on the page, it will use the cached template and the <code>messages.success</code> message will be there.</p>

<p>For what it is worth, I am using redis as my caching backend. I was using memcached but got the same exact results. I use the caching for a different part of my application.  Also, I'm pretty familiar with caching. I use it  a lot in all of my applications. This seems to be something that is related to mezzanines caching.</p>

<p>Ideally I'd just like to completely disable caching for mezzanine and ONLY cache what I explicitly tell it to cache, nothing else.</p>

<p>Update:</p>

<p>@iamkhush Yes, using <code>redis-server monitor</code> I can verify the key is the same. Here is what I do. Clear cache. Runserver. GET the URL in browser. Cache does not exist so it renders the template and SETs it in cache. Then, I fill out the form and POST. the page_processor runs all of the code in my ""if POST"" block. Then it goes to the cache and GETs with the key, which exists. So instead of re-rendering template, it just gets whatever is in cache so the success message doesn't get into the template. I refresh a few times, it GETs same key. So I clear cache, run server, visit url, no cache so template is rendered and it picks up the success message(s), that html is then SET in cache. If I refresh(re-GET) the url, it will retrieve the template from cache.</p>
","495679","495679","2018-03-01 22:31:53","In Django Mezzanine, how to I prevent caching on a page_processor?","<python><django><caching><mezzanine>","1","2","3045"
"49060220","2018-03-01 23:12:46","2","","<p>Credit to @eryksun, who helped solve this in the comments.</p>

<p>The issue is that I am using 32 bit Python, and <code>wsl.exe</code> is only in <code>C:/Windows/System32</code>. The problem with this is that Python is looking in <code>C:/Windows/SysWOW64</code> for the executable instead.</p>

<blockquote>
  <p><code>wsl.exe</code> is only 64-bit, and you're looking in <code>SysWOW64</code> instead of the real <code>System32</code> because you're using 32-bit Python. – eryksun</p>
</blockquote>

<p>Because WSL only supports 64-bit systems, I ended up just running my code with 64-bit Python. However, and alternate solution if you only use Py32 would be to access <code>SysWOW64</code> directly, using the system root environment variable and <code>os.path.join</code>.</p>

<blockquote>
  <p>In Windows 7+, the real <code>System32</code> directory is accessible in a 32-bit process as ""SysNative"". Unfortunately this virtual directory isn't available in a native 64-bit process, so you need to first check whether it exists. For example: <code>sysnative = os.path.join(os.environ['SystemRoot'], 'SysNative'); if os.path.exists(sysnative): ...</code>. – eryksun </p>
</blockquote>
","2512078","","","0","1193","spikespaz","2013-06-22 16:38:07","856","219","171","4","49039323","49060220","2018-02-28 22:00:52","2","249","<p>I am trying to use <code>shutil.which</code> to check if the Linux Subsystem is installed on Windows 10.</p>

<p>Using the Windows <code>where</code> command in Command Prompt, I can see the location of the <code>wsl.exe</code> executable.</p>

<pre><code>C:\Users\spike&gt;where wsl
C:\Windows\System32\wsl.exe
</code></pre>

<p>The above shows that WSL does exist, and is in my system <code>PATH</code>.
When I use the <code>which</code> function in Python, it says that the executable was not found.</p>

<pre><code>print(which(""wsl""))  # Returns None
</code></pre>

<p>Just to make sure that <code>which</code> works, I test it on <code>cmd.exe</code>.</p>

<pre><code>print(which(""cmd""))  # Returns ""C:\Windows\System32\cmd.exe""
</code></pre>

<p>That works. Well, what if I make a system shell call with the command that <em>did</em> work?</p>

<pre><code>print(system(""where wsl""))  # Returns 1
</code></pre>

<p>Exit code 1, the command <code>wsl</code> was not found.
So I test it on <code>cmd.exe</code> again.</p>

<pre><code>print(system(""where cmd""))  # Returns 0
</code></pre>

<p>Okay, so that <em>does</em> work. What is the problem?</p>

<p>For each Python 3 example assume these imports.</p>

<pre><code>from shutil import which
from os import system
</code></pre>

<p>Why can Python not find <code>wsl.exe</code> even though it is proven to exist?</p>

<p>Thanks.</p>
","2512078","","","Python shutil.which not working with wsl.exe","<python><windows><python-3.x><shell><shutil>","2","3","1390"
"49060233","2018-03-01 23:13:16","0","","<p>Replacing your <code>response</code> call with this code seems to work. The reason is that you weren't passing in the cookie properly.</p>

<pre><code>response = requests.get(
    'https://www.nalpcanada.com/Page.cfm',
    params={'PageID': 33},
    cookies={'DISPLAYNUM': '100000000'}
)
</code></pre>

<p>The only other issue I came across was that a <code>ValueError</code> was being raised by this line when certain links (like <code>YLaw Group</code>) don't seem to have ""offers"" and/or ""seeking"".</p>

<pre><code>print('Hireback Rate:', int(offers) / int(seeking))
</code></pre>

<p>I just commented out the line since you will have to decide what to do in those cases.</p>
","8079103","","","2","682","G_M","2017-05-29 00:31:33","3102","440","139","287","49059672","49060233","2018-03-01 22:25:41","0","33","<p>I am quite new to Python and am building a web scraper, which will scrape the following page and links in them: <a href=""https://www.nalpcanada.com/Page.cfm?PageID=33"" rel=""nofollow noreferrer"">https://www.nalpcanada.com/Page.cfm?PageID=33</a></p>

<p>The problem is the page's default is to display the first 10 search results, however, I want to scrape all 150 search results (when 'All' is selected, there are 150 links).</p>

<p>I have tried messing around with the URL, but the URL remains static no matter what display results option is selected. I have also tried to look at the Network section of the Developer Tools on Chrome, but can't seem to figure out what to use to display all results. </p>

<p>Here is my code so far:</p>

<pre><code>import bs4
import requests
import csv
import re

response = requests.get('https://www.nalpcanada.com/Page.cfm?PageID=33')
soup = bs4.BeautifulSoup(response.content, ""html.parser"")
urls = []

for a in soup.findAll('a', href=True, class_=""employerProfileLink"", text=""Vancouver, British Columbia""):
    urls.append(a['href'])

pagesToCrawl = ['https://www.nalpcanada.com/' + url + '&amp;QuestionTabID=47' for url in urls]

for pages in pagesToCrawl:
    html = requests.get(pages)
    soupObjs = bs4.BeautifulSoup(html.content, ""html.parser"")

    nameOfFirm = soupObjs.find('div', class_=""ip-left"").find('h2').next_element

    tbody = soupObjs.find('div', {""id"":""collapse8""}).find('tbody')
    offers = tbody.find('td').next_sibling.next_sibling.next_element
    seeking = tbody.find('tr').next_sibling.next_sibling.find('td').next_sibling.next_sibling.next_element

    print('Firm name:', nameOfFirm)
    print('Offers:', offers)
    print('Seeking:', seeking)
    print('Hireback Rate:', int(offers) / int(seeking))
</code></pre>
","9431238","9431238","2018-03-01 23:05:39","Displaying all search results in Python web scraper","<python><web-scraping>","1","0","1785"
"49060237","2018-03-01 23:13:32","0","","<p>Needed something similar and implemented a more straightforward recursive solution. In-place updates dict 'd'.</p>

<pre><code>from Collections import MutableMapping

def merge(d, v):
    """"""
    Merge two dictionaries.

    Merge dict-like `v` into dict-like `d`. In case keys between them are the same, merge
    their sub-dictionaries where possible. Otherwise, values in `v` overwrite `d`.
    """"""
    for key in v:
        if key in d and isinstance(d[key], MutableMapping) and isinstance(v[key], MutableMapping):
            d[key] = merge(d[key], v[key])
        else:
            d[key] = v[key]
    return d
</code></pre>

<p>Example 1:</p>

<pre><code>a = {0: {0: ""a""},
     1: [0, 1, 2]}

b = {0: {1: ""b""},
     1: [3, 4, 5]}

&gt;&gt;&gt; merge(a, b)
{0: {0: 'a', 1: 'b'}, 1: [3, 4, 5]}
</code></pre>

<p>Example 2:</p>

<pre><code>a = {0: {0: 'a'},
     1: [0, 1, 2],
     2: [9, 9],
     3: {'a': {1: 1, 2: 2}, 'b': [0, 1]}}

b = {0: {1: 'b'},
     1: [3, 4, 5],
     2: {22: 22, 33: 33},
     3: {'a': {2: 22, 3: 33}, 'b': [99, 88]}}

&gt;&gt;&gt; merge(a, b) 
{0: {0: 'a', 1: 'b'},
 1: [3, 4, 5],
 2: {22: 22, 33: 33},
 3: {'a': {1: 1, 2: 22, 3: 33}, 'b': [99, 88]}}
</code></pre>
","8005373","","","0","1200","Hans Bouwmeester","2017-05-13 00:19:23","149","18","87","1","22693513","22696048","2014-03-27 16:23:54","2","900","<p>I have two dictionaries, and what I'm trying to do is a bit odd. Basically, I want to merge them. That's simple enough. But they're hierarchies of of dictionaries, and I want to merge them in such a way that if an item in a dictionary is itself a dictionary and exists in both, I want to merge those dictionaries as well. If it's not a dictionary, I want the values from the second dictionary to overwrite the values from the first one. Something sort of like this:</p>

<pre><code>a = {0: {0: ""a""},
     1: [0, 1, 2]}

b = {0: {1: ""b""},
     1: [3, 4, 5]}

Merge(a, b)

#output:
{0: {0: ""a"",
     1: ""b""},
 1: [3, 4, 5]}
</code></pre>

<p>Does that make sense? Because the key ""0"" contained a dictionary in both a and b, it merged those dictionaries as well. But in the case of the second key, it was a list so it just overwrote it.</p>

<p>So I suppose I'll be looking at some kind of recursive function? Not quite sure how to approach this one.</p>

<p>Thanks!</p>

<p>Edit: I forgot to mention one pretty crucial detail:</p>

<p>I need a function that works in both 2.6.2 and 2.7.3.</p>
","1031253","1031253","2014-03-28 07:31:51","Merging hierarchy of dictionaries in Python","<python><dictionary><merge>","3","2","1094"
"49060246","2018-03-01 23:14:32","3","","<p>You have to swap x and y when you change orientation.</p>

<pre><code>df = pd.DataFrame(['A','A','A','B','B','C'],columns = ['letters'])
data =df.letters.value_counts()
sns.barplot(y = data.index, x = data, orient='h')
</code></pre>

<p><a href=""https://i.stack.imgur.com/7nAzv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7nAzv.png"" alt=""enter image description here""></a></p>
","3044692","","","0","403","omdv","2013-11-28 06:49:59","925","78","94","5","49060138","49060246","2018-03-01 23:05:37","0","903","<p>I can plot a normal bar plot with searborn, but when i specify <code>orient = 'h'</code> nothing shows up in my plot.</p>

<pre><code>df = pd.DataFrame(['A','A','A','B','B','C'],columns = ['letters'])
data =df.letters.value_counts()
sns.barplot(x = data.index, y = data)
</code></pre>

<p><a href=""https://i.stack.imgur.com/fd1Y8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fd1Y8.png"" alt=""enter image description here""></a></p>

<p>With <strong>orient</strong>:</p>

<p><a href=""https://i.stack.imgur.com/e4O9y.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/e4O9y.png"" alt=""enter image description here""></a></p>
","2800939","","","seaborn horizontal bar plot not showing plot","<python><matplotlib><seaborn>","1","0","660"
"49060255","2018-03-01 23:15:17","0","","<p><em>(Posted solution on behalf of the OP)</em>.</p>

<p>To solve the issue, I used str.split() to break up the indivudal fields in the rows of my CSV, so that they could be selected and held by a variable. The accepted answer shows the solution I used, but this is my final code in case this wasn't clear</p>

<pre><code>with open ('details.csv', 'r') as stalking:
        stalkingReader=csv.reader(stalking)
        valid4=False
        for column in stalkingReader:
            if user in column[3]:
                valid4=True
                print(""Here are the details for user {}... "".format(user))
                splitter=row.split(',')
                name=splitter[0]
                age=splitter[1]
                year=splitter[2]
                print(""Name: {}"".format(name))
                print(""Age: {}"".format(age))
                print(""Year Group: {}"".format(year))
                postReport()
    if valid4==False:
        print(""Sorry Fergus, this user doesn't seem to be in our records."")
</code></pre>
","472495","","","0","1032","halfer","2009-12-04 12:21:00","15261","28231","10542","10440","49036842","49036892","2018-02-28 19:07:53","0","52","<p>I'm making a program in school where users are quizzed on certain topics and their results are saved into a csv file. I've managed to print off the row with the highest score, but this doesn't look very neat.</p>

<pre><code>with open ('reportForFergusTwo.csv', 'r') as highScore:
            highScoreFinder=highScore
            valid3=False
            for row in highScoreFinder:
                if subjectInput in row:
                    if difficultyInput in row:
                        if ('10' or '9' or '8' or '7' or '6' or '5' or '4' or '3' or '2' or '1') in row:
                            valid3=True
                            print(""The highest score for this quiz is:"",row)
</code></pre>

<p>For example: it says, ""The highest score for this quiz is: chemistry,easy,10,Luc16"" but I would prefer it to say something like ""The highest score for this quiz is: 10"" and ""This score was achieved by: Luc16"", rather than just printing the whole row off, with unnecessary details like what the quiz was on.</p>

<p>My CSV file looks like this:</p>

<pre><code>Subject,Difficulty,Score,Username
language,easy,10,Luc16
chemistry,easy,10,Luc16
maths,easy,9,Luc16
chemistry,easy,5,Eri15
chemistry,easy,6,Waf1
chemistry,easy,0,Eri15
</code></pre>

<p>I thought that maybe if I could find a way to take the individual results (the score and username) and put them into their own individual variables, then it would be much easier to present it the way I want, and be able to reference them later on in the function if I need them to be displayed again.</p>

<p>I'm just fairly new to coding and curious if this can be done, so I can improve the appearance of my code.</p>

<p>Edit: To solve the issue, I used str.split() to break up the indivudal fields in the rows of my CSV, so that they could be selected and held by a variable. The accepted answer shows the solution I used, but this is my final code in case this wasn't clear</p>

<pre><code>with open ('details.csv', 'r') as stalking:
        stalkingReader=csv.reader(stalking)
        valid4=False
        for column in stalkingReader:
            if user in column[3]:
                valid4=True
                print(""Here are the details for user {}... "".format(user))
                splitter=row.split(',')
                name=splitter[0]
                age=splitter[1]
                year=splitter[2]
                print(""Name: {}"".format(name))
                print(""Age: {}"".format(age))
                print(""Year Group: {}"".format(year))
                postReport()
    if valid4==False:
        print(""Sorry Fergus, this user doesn't seem to be in our records."")
</code></pre>
","","","2018-02-28 20:46:05","Is there any way to put a single result from a CSV into a variable?","<python><python-3.6>","4","2","2663"
"49060266","2018-03-01 23:16:33","6","","<p>There are several ways.</p>

<p><strong>Pandonic</strong></p>

<pre><code>df = df.loc[:, ~df.columns.str.endswith('_o')]]

df = df[df.columns[~df.columns.str.endswith('_o')]]]
</code></pre>

<p><strong>List comprehensions</strong></p>

<pre><code>df = df[[x for x in df if not x.endswith('_o')]]

df = df.drop([x for x in df if x.endswith('_o')], 1)
</code></pre>
","9209546","9209546","2018-03-01 23:21:48","2","367","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49060217","49060266","2018-03-01 23:12:28","2","1321","<p>I have a dataframe with a lot of columns using the suffix '_o'. Is there a way to drop all the columns that has '_o' in the end of its label?</p>

<p>In <a href=""https://stackoverflow.com/questions/45844382/python-pandas-drop-columns-that-start-with-string"">this post</a> I've seen a way to drop the columns that start with something using the filter function. But how to drop the ones that end with something?</p>
","5606352","472495","2018-03-05 13:55:48","Drop multiple columns that end with certain string in Pandas","<python><pandas>","3","0","418"
"49060271","2018-03-01 23:17:04","1","","<p>A simple solution would be to construct a list of distinct words for each file and check for common words. </p>

<p>Python's Set datatype would be very helpful in this case.
<a href=""https://docs.python.org/3.6/library/stdtypes.html#set"" rel=""nofollow noreferrer"">https://docs.python.org/3.6/library/stdtypes.html#set</a></p>
","808236","","","1","329","iamkhush","2011-06-21 10:30:29","1882","286","75","5","49060184","49060272","2018-03-01 23:09:54","2","37","<p>I have 2 files containing multiple strings, <code>fileA.txt</code> and <code>fileB.txt</code>.</p>

<blockquote>
  <p>fileA.txt:</p>
</blockquote>

<pre><code>hello hi 
how
</code></pre>

<blockquote>
  <p>fileB.txt:</p>
</blockquote>

<pre><code>hello how are you
</code></pre>

<p>I am trying to write a program that will see if a string exists in both files. If it does, print the string or multiple strings. </p>

<p>The results would print ""hello"", and ""how"" as they exist in both files.</p>

<p>I am having trouble executing this as I have only been able to work with strings that I define, rather than unknown strings in the file:</p>

<pre><code>with open(""fileA.txt"", 'r') as fileA, open (""fileB.txt"") as fileB:
    for stringsA in fileA:

        for stringsB in fileB:

            if stringsA in stringsB:
                print(""true"")
</code></pre>

<p>Any assistance would be appreciated.</p>
","8939405","","","Python - printing strings that exists in 2 files","<python><python-3.x><file>","3","0","910"
"49060272","2018-03-01 23:17:10","5","","<p>Files iterate by <em>lines</em>, not <em>words</em>.  You'll have to split the words:</p>

<pre><code>&gt;&gt;&gt; with open('fileA.txt') as a, open('fileB.txt') as b:
...     a_words = set(a.read().split())
...     b_words = set(b.read().split())
...     print('\n'.join(a_words &amp; b_words))
...     
hello
how
</code></pre>
","674039","","","1","332","wim","2011-03-23 23:40:27","187587","12233","9064","5087","49060184","49060272","2018-03-01 23:09:54","2","37","<p>I have 2 files containing multiple strings, <code>fileA.txt</code> and <code>fileB.txt</code>.</p>

<blockquote>
  <p>fileA.txt:</p>
</blockquote>

<pre><code>hello hi 
how
</code></pre>

<blockquote>
  <p>fileB.txt:</p>
</blockquote>

<pre><code>hello how are you
</code></pre>

<p>I am trying to write a program that will see if a string exists in both files. If it does, print the string or multiple strings. </p>

<p>The results would print ""hello"", and ""how"" as they exist in both files.</p>

<p>I am having trouble executing this as I have only been able to work with strings that I define, rather than unknown strings in the file:</p>

<pre><code>with open(""fileA.txt"", 'r') as fileA, open (""fileB.txt"") as fileB:
    for stringsA in fileA:

        for stringsB in fileB:

            if stringsA in stringsB:
                print(""true"")
</code></pre>

<p>Any assistance would be appreciated.</p>
","8939405","","","Python - printing strings that exists in 2 files","<python><python-3.x><file>","3","0","910"
"49060273","2018-03-01 23:17:13","0","","<p>EDIT: I just noticed that <code>message</code> is only being used for the signature, and is not being included in the request.  I think you probably need something like <code>data = requests.get(url + report, data=message, headers=headers)</code>.</p>

<p>Old, almost certainly incorrect theory is below:</p>

<p>Since it works for an empty message, my guess is that it has to do with the byte encoding of the message.  The utf-16 or utf-32 encodings of the empty message will be the same as the utf-8, but they will differ for non-empty messages.</p>

<p>So perhaps try <code>message.encode('utf-16')</code> or <code>message.encode('utf-32')</code>?  The API docs should describe this detail of how auth is done.</p>

<p>Is it possible to link to the docs for the API, or is it internal?</p>
","1164871","1164871","2018-03-01 23:20:42","5","796","mgsloan","2008-08-17 19:40:24","2874","295","25","3","49059920","","2018-03-01 22:46:54","0","200","<p>I'm attempting to pull JSON data from an API and struggling to nail down the source of my problems. Currently I get accurate data if message = """" but so far any non-empty query parameters return a 403 error. The API documentation asks for parameters to be formatted as ""customerCode=XXX"" and  I've been able to produce valid queries in the API Sandbox. I assume the problem is somewhere in the getSignature function, but I've rewritten it a few ways and .encode() or bytes() gives me the same result. If the code looks coherent and it's a syntax error on my end I can reach out to the support team. Again, when message is an empty string I get valid results back so I'm puzzled. Error occurs on all tested Report pages with multiple different query parameters tested per page. Relevant import functions are not pasted here but are included in the code. </p>

<pre><code>#Current hash
def getSignature(message):
    hashed = hmac.new(key, message.encode('utf-8') , hashlib.sha256)
    return base64.b64encode(hashed.digest())


#Header per API specs
def getData(report, message):
    headers = {
        'Content-Type' : 'application/json',
        'Accept' : 'application/json',
        'api-auth-id' : api_id,
        'api-auth-signature' : getSignature(message)                
    }

    data = requests.get(url + report, headers=headers)
    data = data.json()

    return data
</code></pre>
","4288953","","","HMAC API authentication issues in Python","<python><hmac><api-authorization>","1","0","1399"
"49060275","2018-03-01 23:17:37","0","","<p>The problem you are having does not have anything to do with pandas but rather with the JSON decoding. <code>json.loads(...)</code> only supports one JSON object. Your <code>rawdata</code> has 2 JSON objects in it. Thus when it reaches the second line it tells you there is extra data. You can see a potential solution to that in <a href=""https://stackoverflow.com/a/26620772/4032503"">this</a> answer.</p>

<p>In short, you can do something like this:</p>

<pre><code>def parse_json_stream(stream):
    decoder = json.JSONDecoder()
    while stream:
        obj, idx = decoder.raw_decode(stream)
        yield obj
        stream = stream[idx:].lstrip()

parsed_data = list(parse_json_stream(rawdata))
print(parsed_data)

[[{'APPL': 1.067638}, {'AAPL': -1.996081}], [{'MSFT': 0.086638}, {'MSFT': -0.926081}]]
</code></pre>

<p>As for converting it to a DataFrame, it depends on how you want to organize your data.</p>
","4032503","","","0","920","noslenkwah","2014-09-11 20:12:29","677","49","18","14","49059757","49060275","2018-03-01 22:32:39","0","451","<p>I have following JSON structure coming from a Flask Rest API.
It is more than one JSON based on how many assets we query for and I am not able 
to convert it to Pandas dataframe.</p>

<pre><code>from flask import Flask
import requests
import pandas as pd
import json

url = ""http://localhost:5000/getpqdata""
random_cols = ['AAPL', 'MSFT']
JsonOutput = {'Assets': random_cols}

headers = {'Content-type': 'application/json'}
response = requests.post(url, json=JsonOutput, headers=headers)

rawdata = response.text
</code></pre>

<p>rawdata is coming as below:    </p>

<pre><code>rawdata = '''[{""APPL"": 1.067638}, {""AAPL"": -1.996081}]
        [{""MSFT"": 0.086638}, {""MSFT"": -0.926081}]'''

data = json.loads(rawdata)

df = pd.DataFrame(data)
print(df)
</code></pre>

<p>It gives following error.</p>

<pre><code>C:\Python36&gt;python D:\Python\pyarrow\RestfulAPI\test.py
Traceback (most recent call last):
File ""D:\Python\pyarrow\RestfulAPI\test.py"", line 36, in &lt;module&gt;
data = json.loads(rawdata)
File ""C:\Python36\lib\json\__init__.py"", line 354, in loads
return _default_decoder.decode(s)
File ""C:\Python36\lib\json\decoder.py"", line 342, in decode
raise JSONDecodeError(""Extra data"", s, end)
json.decoder.JSONDecodeError: Extra data: line 2 column 13 (char 54)
</code></pre>
","2394843","","","Multiple Json in Flask Response to convert to Pandas DataFrame","<python><json><pandas><rest><flask>","1","0","1287"
"49060276","2018-03-01 23:17:44","1","","<p>Find the <code>DJANGO_SETTINGS_MODULE</code> environment variable within your project.</p>

<p>The value of it is in <code>python</code> path syntax. Use it to locate the settings file since it is the one getting used by <code>django</code> and make sure that <code>DEBUG = False</code>. Additionally you could add a <code>print</code> statement which gives some visual feedback on server start.</p>

<p>Restart your development server after you have saved the configuration by executing <code>python manage.py runserver</code>.</p>
","7727583","7727583","2018-03-01 23:35:54","0","536","Yannic Hamann","2017-03-17 14:09:15","2030","188","286","4","49059772","","2018-03-01 22:34:31","0","884","<p>I'm trying to develop 404 and 500 error custom templates for my Django project.</p>

<p>When I change DEBUG to False, Django always returns me:</p>

<blockquote>
  <p>You're seeing this error because you have DEBUG = True in your Django settings file. Change that to False, and Django will display a standard 404 page.</p>
</blockquote>

<p>After change ALLOWED_HOSTS to ['.domain.com', 'www.domain.com'] I obtain:</p>

<blockquote>
  <p>Invalid HTTP_HOST header: 'domain.com'. You may need to add u'domain.com' to ALLOWED_HOSTS.</p>
</blockquote>

<p>What am I doing wrong? Why Django does not recognize the variable?</p>
","7804233","7804233","2018-03-01 22:47:43","Django doesn't recognize DEBUG = False","<python><django>","2","4","626"
"49060291","2018-03-01 23:18:49","1","","<p>As stated by roganjosh in the comments, the problem here is that the <code>input()</code> function returns a string, not an integer (which is what the <code>if</code>/<code>elif</code> statements are checking for). To solve it, convert the result of the input to an integer like so: </p>

<pre><code>action = int(input(""""""Enter attack. \n 1. Check Hero life \n 2. Check 
Enemy life \n 3. Attack the enemy \n 4. Attack the hero \n""""""))
</code></pre>
","9363594","","","1","452","Jono 2906","2018-02-15 07:26:55","1079","118","988","19","49060163","49060291","2018-03-01 23:07:46","0","50","<p>Example being: I am trying to get the print statement from Hero.checkLife to print when I input 1. I did a little testing and it seems like it correctly gets the input but just skips the if/elif statements. Not sure why, any tips would be greatly appreciated. The formatting is correct in python but copying into here didn't go super smoothly. </p>

<pre><code>class Hero:
    life = 200
    def checkLife(self):
        if self.life &lt;= 0:
            print(""Oh no! Hero has fallen"")
        else:
            print(""Hero has "" + str(self.life)+ "" life!"")
    def attackedByEnemy(self):
        self.life -= 45

class Enemy:
    life = 115
    def checkLife(self):
        if self.life &lt;= 0:
            print(""Enemy has fallen!"")
        else:
            print(""Enemy has "" + str(self.life)+ "" life!"")
    def attakedByHero(self):
        self.life -= 55

hero = Hero()
enemy = Enemy()

while Enemy.life &gt; 0:
    action = input(""Enter attack. \n 1. Check Hero life \n 2. Check 
    Enemy life \n 3. Attack the enemy \n 4. Attack the hero \n"")
    if action == 1:
        hero.checkLife()
    elif action == 2:
        enemy.checkLife()
    elif action == 3:
        enemy.attakedByHero()
    elif action == 4:
        hero.attackedByEnemy()
</code></pre>
","9431520","7708542","2018-03-02 06:43:59","Missing output in a switch-case statement","<python><python-3.x>","1","2","1269"
"49060301","2018-03-01 23:19:26","0","","<p>You can check if <code>""school""</code> exists in the current element of iteration:</p>

<pre><code>array = ['I love school', 'I hate school', 'I hate bananas', 'today is friday', 'worldcup is great']
new_array = [i for i in array if ""school"" in i]
</code></pre>

<p>Output:</p>

<pre><code>['I love school', 'I hate school']
</code></pre>
","7326738","","","2","342","Ajax1234","2016-12-21 16:39:57","49079","3709","2930","360","49060262","49060356","2018-03-01 23:16:21","3","113","<p>I have these lists:</p>

<pre><code>array = ['I love school', 'I hate school', 'I hate bananas', 'today is 
friday', 'worldcup is great']

#finalArray is initially an empty list
finalArray = []  
</code></pre>

<p>I want to save those indexes of ""array"" that contain the word ""school"" into ""finalArray"". Meaning that ""finalArray"" should become like this:</p>

<pre><code>['I love school', 'I hate school']
</code></pre>

<p>I tried the following code which does not do the job:</p>

<pre><code>if ""school"" in array:
    finalArray = array.index(""school"")
</code></pre>

<p>Why is it not working? Is there a better way to do this?</p>
","5619967","","","storing indexes of an array which contains a certain word(s) into another array in Python","<python><list>","6","0","637"
"49060303","2018-03-01 23:19:31","1","","<p>You first want to get a list of all unique strings in <code>fileA</code>.  Then get a similar unique list for <code>fileB</code>.  Then compare the two.  Using <code>set</code>'s makes the comparison easier.</p>

<pre><code>def get_strings_from_file(f):
    return set([s.strip() for s in f.read().split() if s.strip()])

def main():
    with open(""fileA.txt"", 'r') as fileA, open (""fileB.txt"") as fileB:
        stringsA = get_strings_from_file(fileA)
        stringsB = get_strings_from_file(fileB)
        return stringsA.intersection(stringsB)
</code></pre>
","1547004","","","1","565","Brendan Abel","2012-07-23 21:32:10","21194","1323","1935","497","49060184","49060272","2018-03-01 23:09:54","2","37","<p>I have 2 files containing multiple strings, <code>fileA.txt</code> and <code>fileB.txt</code>.</p>

<blockquote>
  <p>fileA.txt:</p>
</blockquote>

<pre><code>hello hi 
how
</code></pre>

<blockquote>
  <p>fileB.txt:</p>
</blockquote>

<pre><code>hello how are you
</code></pre>

<p>I am trying to write a program that will see if a string exists in both files. If it does, print the string or multiple strings. </p>

<p>The results would print ""hello"", and ""how"" as they exist in both files.</p>

<p>I am having trouble executing this as I have only been able to work with strings that I define, rather than unknown strings in the file:</p>

<pre><code>with open(""fileA.txt"", 'r') as fileA, open (""fileB.txt"") as fileB:
    for stringsA in fileA:

        for stringsB in fileB:

            if stringsA in stringsB:
                print(""true"")
</code></pre>

<p>Any assistance would be appreciated.</p>
","8939405","","","Python - printing strings that exists in 2 files","<python><python-3.x><file>","3","0","910"
"49074209","2018-03-01 23:20:34","1","","<p>This takes directory 'tar_file' in path 'tar_path' and creates a zipped version called of it called 'tar_file_file.tgz'. Then unzips contents into directory 'hello'</p>

<pre><code>import os
import tarfile
from contextlib import closing

fun = ""/users/me/temp/fun/""
tar_path = ""{0}tar_file"".format(fun)
hello = '{0}hello'.format(fun)

def makedir(dir_path):
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)

makedir(fun)
os.chdir(fun)
makedir(hello)

    #create tgz, enable gzip, create archive file
def make_tarfile(output_filename, source_dir):
    with closing(tarfile.open(output_filename, ""w:gz"")) as tar:
        tar.add(source_dir, arcname = os.path.basename(source_dir))
    tar.close()

    #extract, unpack in gzip format, read archived content
def extract_tarfile(output_filename, source_dir):
    t = tarfile.open(output_filename, ""r:gz"")
    t.extractall(source_dir)


make_tarfile('tar_file_file.tgz', tar_path)
extract_tarfile('tar_file_file.tgz', hello)
</code></pre>
","9458280","","","0","1006","Xandy","2018-03-07 17:54:50","20","10","0","0","49074208","49074209","2018-03-01 16:45:23","0","50","<p>I'm new to programming and I have been given the task of translating shell commands to python as a way of automating a processs. The following are the commands: </p>

<pre><code>$ cd /users/me/repos/
$ mv -i file file-1.0.0
$ tar cfz file-1.0.0.tgz file-1.0.0
$ mv -i file-1.0.0 file
$ tar xfz file-1.0.0.tgz
</code></pre>

<p>I know how to do it except the tar commands. I'm not sure what they do and how to implement them in Python. </p>
","9458280","6106791","2018-03-02 18:18:09","How do I translate the ""tar"" shell commands into Python","<linux><shell><python><tar>","1","5","443"
"49060316","2018-03-01 23:20:43","1","","<p>You need to iterate through the array, looking to see whether the target word, <code>school</code> is in that array element.  Then drop the index into your list.</p>

<pre><code>final_array = [i for i in range(len(array)) if ""school"" in array[i]]
</code></pre>

<p>Output:</p>

<pre><code>[0, 1]
</code></pre>

<p>Your original attempt didn't do that: <code>index</code> could find the location of <code>school</code> in a sentence, not the location of the sentence <em>containing</em> <code>school</code> in the array.</p>

<p>Improvement with more Pythonic technology:</p>

<pre><code>[i for i, phrase in enumerate(array) if ""school"" in phrase]
</code></pre>
","4785185","4785185","2018-03-01 23:26:13","3","664","Prune","2015-04-14 00:37:53","54183","8845","3232","13592","49060262","49060356","2018-03-01 23:16:21","3","113","<p>I have these lists:</p>

<pre><code>array = ['I love school', 'I hate school', 'I hate bananas', 'today is 
friday', 'worldcup is great']

#finalArray is initially an empty list
finalArray = []  
</code></pre>

<p>I want to save those indexes of ""array"" that contain the word ""school"" into ""finalArray"". Meaning that ""finalArray"" should become like this:</p>

<pre><code>['I love school', 'I hate school']
</code></pre>

<p>I tried the following code which does not do the job:</p>

<pre><code>if ""school"" in array:
    finalArray = array.index(""school"")
</code></pre>

<p>Why is it not working? Is there a better way to do this?</p>
","5619967","","","storing indexes of an array which contains a certain word(s) into another array in Python","<python><list>","6","0","637"
"49060330","2018-03-01 23:21:53","2","","<p>in docker-compose the services that are on same network can access each other by its name, you dont even have to expose the ports to host. so your docker-compose.yaml can be simplified to:</p>

<pre><code>version: '3'
services:
receiver:
    build: ./app
    command: ""--host 0.0.0.0 --port 3000""
requester:
    build: ./app
    command: ""--host 0.0.0.0 --port 4000""
</code></pre>

<p>and inside the container requester you can access the other one with </p>

<pre><code>ping receiver
</code></pre>

<p>that resolves the name and you can verify the port is also open, for example with <code>netcat</code></p>

<pre><code>nc -z receiver 3000 -v
</code></pre>
","2894123","","","2","661","Mazel Tov","2013-10-18 09:45:20","1307","219","52","132","49059877","49060330","2018-03-01 22:43:41","1","502","<p>I'd like to have two Docker <code>containers</code>, which are defined in the same <code>docker-compose.yaml</code> file to be able to share a <code>network</code> and interact with each others' exposed ports. I'm running all of this on Docker for Mac.</p>

<p>In order to do so, I've set up a couple docker containers that are running a tiny <a href=""http://flask.pocoo.org/"" rel=""nofollow noreferrer"">Flask</a> server which can either return a ""Hello"" or make a request to another server (see below for details). So far, I've been unable to allow the two apps to communicate with each other.</p>

<p>What I've tried so far:</p>

<ul>
<li><code>expose</code>ing the relevant ports</li>
<li><code>publish</code>ing the ports and mapping them 1:1 with the host</li>
<li>For <code>flask</code> using both <code>localhost</code> and <code>0.0.0.0</code> as the --host arg</li>
<li><code>curl</code> from one container to another (using both <code>localhost:&lt;other_container_port&gt;</code> and <code>0.0.0.0:&lt;other_container_port&gt;</code></li>
<li>Using the implicit <code>network</code> as per the docs</li>
<li>Explicit <code>network</code> definition </li>
</ul>

<p>All of the above examples give me a <code>Connection Refused</code> error, so I feel like I'm missing something basic about Docker networking. </p>

<p>The <a href=""https://docs.docker.com/compose/networking/"" rel=""nofollow noreferrer"">Networking in Compose</a> doc mentions the following:</p>

<blockquote>
  <p>When you run docker-compose up, the following happens:</p>
  
  <p>...</p>
  
  <ol start=""3"">
  <li>A container is created using db’s configuration. It
  joins the network myapp_default under the name db.</li>
  </ol>
</blockquote>

<p>And their example appears to have all the separate services be able to communicate without any network definitions, which leads me to believe that I probably should not need to define a network either.</p>

<p>Below is my docker-compose.yaml file - all the files can be found at <a href=""https://gist.github.com/funseiki/12a0cc9c32e6b8aab31cb0d1a6f0f7eb"" rel=""nofollow noreferrer"">this gist</a>:</p>

<pre><code>version: '3'
services:
    receiver:
        build: ./app
        # Tried with/without expose
        expose:
            - 3000
        # Tried with/without ports
        ports:
            - 3000:3000
        # Tried with/without 0.0.0.0
        command: ""--host 0.0.0.0 --port 3000""
        # Tried with/without explicit network
        networks:
          - mine
    requester:
        build: ./app
        expose:
            - 4000
        ports:
            - 4000:4000
        # This one's ip is 0.0.0.0, so we can access from host
        command: ""--host 0.0.0.0 --port 4000""
        networks:
          - mine
networks:
  mine: {}
</code></pre>

<p>The app.py file:</p>

<pre><code>@app.route(""/"")
def hello():
    return ""Hello from {}"".format(request.host)

@app.route(""/request/&lt;int:port&gt;"")
def doPing(port):
     location = ""http://localhost:{}/"".format(port)
     return requests.get(location, timeout=5).content
</code></pre>
","865883","865883","2018-03-03 19:11:04","Docker Compose: Allowing Network Interactions Between Services","<python><macos><docker><networking><docker-compose>","1","0","3089"
"49060352","2018-03-01 23:23:54","4","","<p>DeltaFetch only keeps record of the requests that yield items in its database, which means only those will be skipped by default.</p>

<p>However, you are able to customize the key used to store a record by using the <a href=""https://github.com/scrapy-plugins/scrapy-deltafetch#supported-scrapy-request-meta-keys"" rel=""nofollow noreferrer""><code>deltafetch_key</code></a> meta key. If you make this key the same for the requests that call <code>parse_A()</code> as for those created inside <code>parse_A()</code>, you should be able to achieve the effect you want.</p>

<p>Something like this should work (untested):</p>

<pre><code>from scrapy.utils.request import request_fingerprint

# (...)

    def parse_A(self, response):
        # (...)
        yield scrapy.Request(
            response.urljoin(page_B),
            callback=self.parse_B,
            meta={
                'item': item.load_item(),
                'deltafetch_key': request_fingerprint(response.request)
            }
        )
</code></pre>

<p>Note: the example above effectively replaces the filtering of requests to <code>parse_B()</code> urls with the filtering of requests to <code>parse_A()</code> urls. You might need to use a different key depending on your needs.</p>
","975755","","","1","1258","stranac","2011-10-02 19:53:05","17050","525","103","13","49059526","49060352","2018-03-01 22:13:18","1","83","<p>I am now scraping this website on a daily basis, and am using DeltaFetch to ignore pages which have already been visited (a lot of them).</p>

<p>The issue I am facing is that for this website, I need to first scrape page A, and then scrape page B to retrieve additional information about the item. DeltaFetch works well in ignoring requests to page B, but that also means that every time the scraping runs, it runs requests to page A regardless of whether it has visited it or not.</p>

<p>This is how my code is structured right now:</p>

<pre><code># Gathering links from a page, creating an item, and passing it to parse_A
def parse(self, response):
    for href in response.xpath(u'//a[text()=""詳細を見る""]/@href').extract():
        item = ItemLoader(item=ItemClass(), response=response)
        yield scrapy.Request(response.urljoin(href), 
                                callback=self.parse_A,
                                meta={'item':item.load_item()})

# Parsing elements in page A, and passing the item to parse_B
def parse_A(self, response):
    item = ItemLoader(item=response.meta['item'], response=response)
    item.replace_xpath('age',u""//td[contains(@class,\""age\"")]/text()"")
    page_B = response.xpath(u'//a/img[@alt=""周辺環境""]/../@href').extract_first()
    yield scrapy.Request(response.urljoin(page_B), 
                            callback=self.parse_B,
                            meta={'item':item.load_item()})

# Parsing elements in page B, and yielding the item
def parse_B(self, response):
    item = ItemLoader(item=response.meta['item'])
    item.add_value('url_B',response.url)
    yield item.load_item()
</code></pre>

<p>Any help would be appreciated to ignore the first request to page A when this page has already been visited, using DeltaFetch.</p>
","8853612","8853612","2018-03-01 22:22:35","Ignoring requests while scraping two pages","<python><scrapy><scrapy-spider><scrapinghub>","1","0","1787"
"49060353","2018-03-01 23:24:11","0","","<p><strong>tl;dr</strong>: Your measurement is off, not the datetimes: You're comparing two times from different timezones, so the result should be the difference between the timezones, and it is.</p>

<hr>

<p>So this is why it's better to work in UTC:</p>

<p>In Python 2.7:</p>

<p>Using your raw:</p>

<pre><code>&gt;&gt;&gt; print datetime.datetime.utcfromtimestamp(raw/1000.0)
... print datetime.datetime.fromtimestamp(raw/1000.0)
... 
2016-04-06 14:27:04.358000
2016-04-06 07:27:04.358000
</code></pre>

<p>7 hrs different</p>

<p>Using a modified date outside Daylight Savings Time:</p>

<pre><code>&gt;&gt;&gt; print datetime.datetime.utcfromtimestamp(1456952824)
... print datetime.datetime.fromtimestamp(1456952824)
... 
2016-03-02 21:07:04
2016-03-02 13:07:04
</code></pre>

<p>8 hours different</p>

<p>This is happening because <code>raw</code> and <code>0</code> in the local time are in different timezones (Daylight Savings Time vs Standard):</p>

<pre><code>&gt;&gt;&gt; print datetime.datetime.utcfromtimestamp(raw/1000.0)
... print datetime.datetime.fromtimestamp(raw/1000.0)
... 
2016-04-06 14:27:04.358000
2016-04-06 07:27:04.358000

&gt;&gt;&gt; print datetime.datetime.utcfromtimestamp(0)
... print datetime.datetime.fromtimestamp(0)
...
1970-01-01 00:00:00
1969-12-31 16:00:00
</code></pre>

<p>If you stick to utc, no issues.</p>

<blockquote>
  <p>but the local datetime is still bizarrely 5 hours off of the UTC time,
  even when my system is set to CST or UTC-6.</p>
</blockquote>

<p>Because on that <code>raw</code> date, your local time would be CDT (-5):</p>

<pre><code>user@TS-E31:~$ date --date @1459952824
Wed Apr  6 07:27:04 PDT 2016
user@TS-E31:~$ date --date @0
Wed Dec 31 16:00:00 PST 1969
</code></pre>
","3579910","3579910","2018-03-01 23:46:13","0","1745","TemporalWolf","2014-04-28 04:31:04","5574","984","678","35","49059954","49060353","2018-03-01 22:49:12","0","223","<p>I have a test record with a UNIX millisecond timestamp since epoch value of <code>1459952824358</code></p>

<p>I am writing Python 2.x program using the fastavro library. That takes the <code>1459952824358</code> integer UNIX millisecond timestamp and converts it to a local datetime value of <code>2016-04-06T09:27:04.358000</code>. When I try to convert that back to a integer UNIX millisecond timestamp value I end up one hour off. I can replicate this conversion problem outside of the fastavro library with plain Python datetime:</p>

<pre><code>import datetime
import time

raw = 1459952824358

local_dt = datetime.datetime.fromtimestamp(raw / 1000.0)
local_dt.isoformat() # '2016-04-06T09:27:04.358000'

back = int((local_dt - datetime.datetime.fromtimestamp(0)).total_seconds() * 1.0e3)
back - raw # 3600000
</code></pre>

<p>I can convert to a UTC datetime and back successfully:</p>

<pre><code>import datetime
import time

raw = 1459952824358

utc_dt = datetime.datetime.utcfromtimestamp(raw / 1000.0)
utc_dt.isoformat() # '2016-04-06T14:27:04.358000'

back = int((utc_dt - datetime.datetime.utcfromtimestamp(0)).total_seconds() * 1.0e3)
back - raw # 0
</code></pre>

<p>What is odd is that my system is set to CST or UTC-6, yet Python produces a local datetime that is <em>five</em> hours off of the UTC value rather than six.</p>

<p>While, my specific project requires Python 2 compatibility, I try the Python 3 <code>timestamp</code> function which correctly gives me back the original timestamp value without the hour drift, but the local datetime is still bizarrely 5 hours off of the UTC time, even when my system is set to CST or UTC-6.</p>

<pre><code>import datetime
import time

raw = 1459952824358

local_dt = datetime.datetime.fromtimestamp(raw / 1000.0)
local_dt.isoformat() # '2016-04-06T09:27:04.358000'

back = int(local_dt.timestamp() * 1000)
back - raw # 0
</code></pre>

<p>I try the same example in Java 9 on my same laptop, just to see what it produces:</p>

<pre><code>import java.time.*

long raw = 1459952824358L;

Instant i = Instant.ofEpochMilli(raw)
ZonedDateTime zdtUtc = ZonedDateTime.ofInstant(i, ZoneOffset.UTC)
// UPDATE: This line was my original attempt. It was wrong because it uses the current daylight savings setting, not the one of the given date.
ZonedDateTime zdtLocal = zdtUtc.withZoneSameInstant(ZonedDateTime.now().getOffset())
// This next line will choose the current geography, but choose the daylight savings setting based on the date, which is what I expected.
ZonedDateTime zdtLocal = zdtUtc.withZoneSameInstant(ZoneId.systemDefault())

long deltaFromUtc = zdtUtc.toInstant().toEpochMilli() - raw
long deltaFromLocal = zdtLocal.toInstant().toEpochMilli() - raw
</code></pre>

<p>It returns back the exact original timestamp value regardless of utc/local.</p>

<p>UPDATE: Basically, Python 2.x can't properly convert a local datetime value to UTC without extra libraries. Python 3.x can, and Python 2.x has extra libraries to do this, but out of the box, it can't.</p>
","1767106","1767106","2018-03-02 04:11:34","Python Timestamp + Datetime Conversion","<python><datetime>","1","0","3033"
"49060356","2018-03-01 23:24:23","1","","<p>Your solution is not working since you're checking for the whole word 'school' in your example array. To accomplish what you want you have to traverse the list and check each element for containing 'school':</p>

<pre><code>array = ['I love school', 'I hate school', 'I hate bananas', 'today is friday', 'worldcup is great']
finalArray = []

for element in array:
    if 'school' in element.lower():
        finalArray.append(element)
</code></pre>

<p>Please note that I have added a lower() to each checked element to make sure that your program will also catch 'School' in the input list.</p>
","9294857","","","1","599","le_affan","2018-01-31 13:56:48","316","15","26","2","49060262","49060356","2018-03-01 23:16:21","3","113","<p>I have these lists:</p>

<pre><code>array = ['I love school', 'I hate school', 'I hate bananas', 'today is 
friday', 'worldcup is great']

#finalArray is initially an empty list
finalArray = []  
</code></pre>

<p>I want to save those indexes of ""array"" that contain the word ""school"" into ""finalArray"". Meaning that ""finalArray"" should become like this:</p>

<pre><code>['I love school', 'I hate school']
</code></pre>

<p>I tried the following code which does not do the job:</p>

<pre><code>if ""school"" in array:
    finalArray = array.index(""school"")
</code></pre>

<p>Why is it not working? Is there a better way to do this?</p>
","5619967","","","storing indexes of an array which contains a certain word(s) into another array in Python","<python><list>","6","0","637"
"49060365","2018-03-01 23:25:07","1","","<p>To use <code>df.filter()</code> properly here you could use it with a <a href=""https://www.regular-expressions.info/lookaround.html"" rel=""nofollow noreferrer"">lookbehind</a>:</p>

<pre><code>&gt;&gt;&gt; df = pd.DataFrame({'a': [1, 2], 'a_o': [2, 3], 'o_b': [4, 5]})

&gt;&gt;&gt; df.filter(regex=r'.*(?&lt;!_o)$')
   a  o_b
0  1    4
1  2    5
</code></pre>
","7954504","","","0","362","Brad Solomon","2017-05-02 22:46:50","17319","2728","4299","1920","49060217","49060266","2018-03-01 23:12:28","2","1321","<p>I have a dataframe with a lot of columns using the suffix '_o'. Is there a way to drop all the columns that has '_o' in the end of its label?</p>

<p>In <a href=""https://stackoverflow.com/questions/45844382/python-pandas-drop-columns-that-start-with-string"">this post</a> I've seen a way to drop the columns that start with something using the filter function. But how to drop the ones that end with something?</p>
","5606352","472495","2018-03-05 13:55:48","Drop multiple columns that end with certain string in Pandas","<python><pandas>","3","0","418"
"49060378","2018-03-01 23:26:18","1","","<p>The problem is being caused because you're shadowing a builtin keyword of Python: <code>list</code>.</p>

<p>Never create variables with names of builtin keywords.</p>

<p>Your code works perfectly fine if you choose another variable name:</p>

<pre><code>&gt;&gt; string = 'abc'
&gt;&gt; my_list = list(string)
&gt;&gt; print(my_list)
['a', 'b', 'c']
</code></pre>

<p>I suspect you're getting a <code>TypeError</code> because you previously assigned a tuple to a variable called <code>list</code>.</p>
","797744","","","0","507","DBedrenko","2011-06-14 13:34:09","2738","491","2167","785","49060342","49060378","2018-03-01 23:23:12","2","45","<p>I got so frustrated because of this error message here and couldn't figure out what went wrong with such a simple code:</p>

<pre><code>secret_word_list = list('trang')

TypeError: 'tuple' object is not callable
</code></pre>

<p><code>secret_word_list</code> is a new variable. where does the 'tuple' type come from? Also if I assign the string to a variable, can I cast it to a string just by calling its name. For example:</p>

<pre><code>string = 'abc'
list = list(string)
</code></pre>

<p>I tried but the same error message kept popping up.</p>

<p>Also, I write this in Spyder. If I wrote in PythonTutor, things would go well.</p>

<p>Thank you in advance for your time!</p>
","9185955","","","Could not cast a String to a List","<python><types>","2","4","685"
"49060381","2018-03-01 23:26:23","0","","<ul>
<li><p>Navigate to your python installation folder</p></li>
<li><p>Navigate to lib</p></li>
<li><p>Navigate to site-packages</p></li>
<li><p>Make a new file called <code>any_thing_you_want.pth</code></p></li>
<li><p>Type <code>.../src/utils/helpers.py</code> inside that file with your favorite text editor</p></li>
</ul>

<p>Note: the ellipsis before <code>scr/utils/helpers.py</code> will look something like: <code>C:/Users/blahblahblah/python_folders/scr...</code> <strong>&lt;- YOU DO NEED THIS!</strong></p>

<p>This is a cheap way out but it keeps code clean, and is the least complicated. The downside is, for every folder your modules are in, example.pth will need them. Upside: works with Windows all the way up to Windows 10</p>
","4089335","","","0","745","Corpus Shmorpus","2014-09-28 22:25:13","6","47","5","0","48759465","","2018-02-13 04:28:48","10","1943","<p>I'm trying to keep a data science project well-organized so I've created a directory inside my <code>src</code> directory called <code>utils</code> that contains a file called <code>helpers.py</code>, which contains some helper functions that will be used in many scripts. What is the best practice for how I should import <code>func_name</code> from <code>src/utils/helpers.py</code> into a file in a totally different directory, such as <code>src/processing/clean_data.py</code>?</p>

<p>I see <a href=""https://stackoverflow.com/questions/4383571/importing-files-from-different-folder"">answers</a> to this question, and I've implemented a solution that works, but this feels ugly:</p>

<pre><code> sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))))
</code></pre>

<p>Am I doing this right? Do I need to add this to every script that wants to import <code>func_name</code>, like <code>train_model.py</code>?</p>

<p>My current project folder structure:</p>

<pre><code>myproject
    /notebooks
        notebook.ipynb
    /src
        /processing
            clean_data.py
        /utils
            helpers.py
        /models
            train_model.py
        __init__.py
</code></pre>

<p>Example files:</p>

<pre><code># clean_data.py

import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))))
from src.utils.helpers import func_name

func_name()


# helpers.py

def func_name():
    print('I'm a helper function.')
</code></pre>
","2569531","3154233","2018-02-13 04:38:12","Do I need to add my project directory to the system path in every script to import a function from another directory?","<python>","7","4","1542"
"49060393","2018-03-01 23:27:12","1","","<p>Here's what it does when I run your code in a fresh interpreter:</p>

<pre><code>&gt;&gt;&gt; secret_word_list = list('trang')
&gt;&gt;&gt; secret_word_list
['t', 'r', 'a', 'n', 'g']
&gt;&gt;&gt; 
</code></pre>

<p>In other words, it behaves as expected.
If you take a closer look at the error you get, you can understand that Python sees that a tuple is being called:</p>

<pre><code>TypeError: 'tuple' object is not callable
</code></pre>

<p>The only call is on <code>list</code>.
Therefore, <code>list</code> is a tuple.
This can only mean that <code>list</code> has been rebound somewhere in your code.</p>

<p>You need to find the line where you wrote something like</p>

<pre><code>list = ...
</code></pre>

<p>and use a different name instead of <code>list</code>.</p>
","7051394","7051394","2018-03-01 23:27:53","0","780","Right leg","2016-10-21 05:34:32","10078","892","2001","414","49060342","49060378","2018-03-01 23:23:12","2","45","<p>I got so frustrated because of this error message here and couldn't figure out what went wrong with such a simple code:</p>

<pre><code>secret_word_list = list('trang')

TypeError: 'tuple' object is not callable
</code></pre>

<p><code>secret_word_list</code> is a new variable. where does the 'tuple' type come from? Also if I assign the string to a variable, can I cast it to a string just by calling its name. For example:</p>

<pre><code>string = 'abc'
list = list(string)
</code></pre>

<p>I tried but the same error message kept popping up.</p>

<p>Also, I write this in Spyder. If I wrote in PythonTutor, things would go well.</p>

<p>Thank you in advance for your time!</p>
","9185955","","","Could not cast a String to a List","<python><types>","2","4","685"
"49060399","2018-03-01 23:27:54","0","","<p><code>enumerate</code> is one Pythonic solution to extract indices:</p>

<pre><code>arr = ['I love school', 'I hate school', 'I hate bananas',
       'today is friday', 'worldcup is great']

res = [i for i, j in enumerate(arr) if 'school' in j]

# [0, 1]
</code></pre>

<p>If you want values, the logic is simpler:</p>

<pre><code>res = [i for i in arr if 'school' in i]

# ['I love school', 'I hate school']
</code></pre>

<p>A list comprehension gives the same result as appending to a list via a for loop, except it is highly optimised.</p>
","9209546","","","0","547","jpp","2018-01-12 14:47:22","109049","18235","7890","3496","49060262","49060356","2018-03-01 23:16:21","3","113","<p>I have these lists:</p>

<pre><code>array = ['I love school', 'I hate school', 'I hate bananas', 'today is 
friday', 'worldcup is great']

#finalArray is initially an empty list
finalArray = []  
</code></pre>

<p>I want to save those indexes of ""array"" that contain the word ""school"" into ""finalArray"". Meaning that ""finalArray"" should become like this:</p>

<pre><code>['I love school', 'I hate school']
</code></pre>

<p>I tried the following code which does not do the job:</p>

<pre><code>if ""school"" in array:
    finalArray = array.index(""school"")
</code></pre>

<p>Why is it not working? Is there a better way to do this?</p>
","5619967","","","storing indexes of an array which contains a certain word(s) into another array in Python","<python><list>","6","0","637"
"49060411","2018-03-01 23:28:45","1","","<p>If you do not wish to reuse the variables, than you should not be using <code>tf.get_variable</code>. A simple <code>tf.Variable</code> should work and not have the conflict you are seeing.</p>

<p>You can see <a href=""https://www.tensorflow.org/versions/r1.0/programmers_guide/variable_scope#understanding_tfget_variable"" rel=""nofollow noreferrer"">this page</a> in the tensorflow documentation for more: their first example explains that an entirely new set of variables will be created when the example function is called again. They then explain how to avoid this, but it seems that in this case that is exactly what you want.</p>
","5116726","5116726","2018-03-01 23:37:28","2","637","mbrig","2015-07-14 19:55:34","754","80","142","191","49058510","","2018-03-01 20:53:22","2","197","<p>I am trying to implement a deep neural network, where I want to experiment with the number of hidden layers. In order to avoid error-prone code repetition, I have placed the creation of the layers in a for-loop, as follows:</p>

<pre><code>def neural_network_model(data, layer_sizes):
    num_layers = len(layer_sizes) - 1 # hidden and output layers
    layers = [] # hidden and output layers

    # initialise the weights
    for i in range(num_layers):
        layers.append({
            'weights': tf.get_variable(""W"" + str(i+1),
                       [layer_sizes[i], layer_sizes[i+1]], 
                       initializer = tf.contrib.layers.xavier_initializer()),
             'biases': tf.get_variable(""b"" + str(i+1), [layer_sizes[i+1]], 
                       initializer = tf.zeros_initializer())
        })
        ...
</code></pre>

<p>The list <code>layer_sizes</code> given as input looks something like this:</p>

<pre><code>layer_sizes = [num_inputs, num_hl_1, num_hl_2, ..., num_hl_n, num_outputs]
</code></pre>

<p>When I ran this code for the first time I had no problems. However, when I changed <code>layer_sizes</code> to have a different number of layers, I got an error:</p>

<pre><code>ValueError: Variable W1 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope
</code></pre>

<p>I understand that this is because of the naming of the layers (which I don't even care about). How can I work around this and allow renaming when rerunning? I've done some googling and the solution seems to lie in the use of <code>with tf.variable_scope()</code>, but I can't figure out exactly how.</p>

<p>EDIT - Just to be clear: I do not want to reuse any names or variables. I just want to (re-)initialise the weights and biases every time <code>neural_network_model</code> is called.</p>
","7064415","7064415","2018-03-01 23:17:41","Unable to share/rename variable in TensorFlow","<python><variables><tensorflow><scope>","3","3","1846"
"49060435","2018-03-01 23:30:40","0","","<p>You're building a graph every time you try to predict. Instead, build your graph first and then just call session.run when you want to predict.</p>
","992489","","","1","151","Alexandre Passos","2011-10-13 00:38:14","4601","943","21","4","49030273","","2018-02-28 13:03:34","-1","120","<p>I have trained a TensorFlow model and it worked fine when tested with one img. But when I wanted to test more than one img, an error occurred.</p>

<p><strong>Error:</strong></p>

<blockquote>
<pre><code>Traceback (most recent call last):
  File ""C:\Anaconda\lib\site-packages\tensorflow\python\client\session.py"", line 1139, in _do_call
    return fn(*args)
  File ""C:\Anaconda\lib\site-packages\tensorflow\python\client\session.py"", line 1121, in _run_fn
    status, run_metadata)
  File ""C:\Anaconda\lib\contextlib.py"", line 89, in __exit__
    next(self.gen)
  File ""C:\Anaconda\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: Key Variable_10 not found in checkpoint
     [[Node: save_1/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_save_1/Const_0_0, save_1/RestoreV2_2/tensor_names, save_1/RestoreV2_2/shape_and_slices)]]
</code></pre>
</blockquote>

<p>During handling of the above exception, another exception occurred:</p>

<blockquote>
<pre><code>Traceback (most recent call last):   File ""C:/Users/Louis Song/Desktop/LetsFuckDog/captcha_server.py"", line 317, in &lt;module&gt;
    fuck_captcha(""data/bv22.jpg"")   File ""C:/Users/Louis Song/Desktop/LetsFuckDog/captcha_server.py"", line 251, in fuck_captcha
    saver.restore(sess, tf.train.latest_checkpoint('.'))   File ""C:\Anaconda\lib\site-packages\tensorflow\python\training\saver.py"", line 1548, in restore
    {self.saver_def.filename_tensor_name: save_path})   File ""C:\Anaconda\lib\site-packages\tensorflow\python\client\session.py"", line 789, in run
    run_metadata_ptr)   File ""C:\Anaconda\lib\site-packages\tensorflow\python\client\session.py"", line 997, in _run
    feed_dict_string, options, run_metadata)   File ""C:\Anaconda\lib\site-packages\tensorflow\python\client\session.py"", line 1132, in _do_run
    target_list, options, run_metadata)   File ""C:\Anaconda\lib\site-packages\tensorflow\python\client\session.py"", line 1152, in _do_call
    raise type(e)(node_def, op, message) tensorflow.python.framework.errors_impl.NotFoundError: Key Variable_10 not found in checkpoint      [[Node: save_1/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT],
_device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_save_1/Const_0_0, save_1/RestoreV2_2/tensor_names, save_1/RestoreV2_2/shape_and_slices)]]
Caused by op 'save_1/RestoreV2_2', defined at:   File ""C:/Users/Louis Song/Desktop/LetsFuckDog/captcha_server.py"", line 317, in &lt;module&gt;
    fuck_captcha(""data/bv22.jpg"")   File ""C:/Users/Louis Song/Desktop/LetsFuckDog/captcha_server.py"", line 249, in fuck_captcha
    saver = tf.train.Saver()   File ""C:\Anaconda\lib\site-packages\tensorflow\python\training\saver.py"", line 1139, in __init__
    self.build()   File ""C:\Anaconda\lib\site-packages\tensorflow\python\training\saver.py"", line 1170, in build
    restore_sequentially=self._restore_sequentially)   File ""C:\Anaconda\lib\site-packages\tensorflow\python\training\saver.py"", line 691, in build
    restore_sequentially, reshape)   File ""C:\Anaconda\lib\site-packages\tensorflow\python\training\saver.py"", line 407, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)   File ""C:\Anaconda\lib\site-packages\tensorflow\python\training\saver.py"", line 247, in restore_op
    [spec.tensor.dtype])[0])   File ""C:\Anaconda\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 640, in restore_v2
    dtypes=dtypes, name=name)   File ""C:\Anaconda\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
    op_def=op_def)   File ""C:\Anaconda\lib\site-packages\tensorflow\python\framework\ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)   File ""C:\Anaconda\lib\site-packages\tensorflow\python\framework\ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()
</code></pre>
</blockquote>

<p>NotFoundError (see above for traceback): Key Variable_10 not found in checkpoint     [[Node: save_1/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT],
_device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_save_1/Const_0_0, save_1/RestoreV2_2/tensor_names, save_1/RestoreV2_2/shape_and_slices)]]</p>

<p><strong>Demo code:</strong></p>

<pre><code>def crack_captcha():
output = crack_captcha_cnn()

saver = tf.train.Saver()
with tf.Session() as sess:
    saver.restore(sess, tf.train.latest_checkpoint('.'))
    n = 1
    while n &lt;= 10:
        name, image = get_name_and_image()
        print(image.shape)
        print(name)
        if image.shape !=(60, 160, 3):
            print('原始图片错误，请核查')
            pass
        else:
            image = convert2gray(image)
        # middle=image.flatten() /255
        try:
            image = image.flatten() / 255
            predict = tf.argmax(tf.reshape(output, [-1, MAX_CAPTCHA, ALL_SET_LEN]), 2)
            text_list = sess.run(predict, feed_dict={X: [image], keep_prob: 1})
            text = text_list[0].tolist()
            vector = np.zeros(MAX_CAPTCHA * ALL_SET_LEN)
            i = 0
            for n in text:
                vector[i * ALL_SET_LEN + n] = 1
                i += 1

            print(vector)
            predict_text = vec2name(vector)
            print(""正确: {}  预测: {}"".format(name, predict_text))
            if name !=predict_text:
                print('预测失败')
                global error_time
                error_time+=1
            else:
                print('预测成功')
                global correct_time
                correct_time+=1
            n += 1
            print(n)
        except TypeError as e :
            print(e)
            n += 1
            print(n)
            pass
</code></pre>

<p><strong>Magic reason:</strong></p>

<p>When I call more than once <code>crack_captcha</code> function, here is the error. But when I just call one time <code>crack_captcha</code> function, It can give my predict result.</p>
","6323576","1033581","2019-05-21 02:40:38","A magic error about TensorFlow when recognize more than one img(Key Variable_10 not found in checkpoint)","<python><tensorflow>","2","1","6064"
"49060471","2018-03-01 23:33:51","0","","<p>I don't think the tensorflow decode_raw and numpy's np.save are compatible.</p>
","992489","","","0","83","Alexandre Passos","2011-10-13 00:38:14","4601","943","21","4","49050287","49060471","2018-03-01 13:01:31","0","528","<p>I am a tensorflow beginner, trying to read numpy arrays stored on disk into TF using the TextLineReader. But when I read the arrays in TF, I see values different from the original array. Could someone please point to the mistake I am making here? Please see a sample code below. Thanks </p>

<pre><code>import tensorflow as tf
import numpy as np
import csv

#Write two numpy arrays to disk 
a = np.arange(15).reshape(3, 5)
np.save(""a.npy"",a,allow_pickle=False)

b = np.arange(30).reshape(5, 6)
np.save(""b.npy"",b,allow_pickle=False)

with open('files.csv', 'w') as csvfile:
    filewriter = csv.writer(csvfile, delimiter=',')
    filewriter.writerow(['a.npy', 'b.npy'])


# Load a csv with the two array filenames

csv_filename = ""files.csv""
filename_queue = tf.train.string_input_producer([csv_filename])

reader = tf.TextLineReader()
_, csv_filename_tf = reader.read(filename_queue)


record_defaults = [tf.constant([], dtype=tf.string), tf.constant([], dtype=tf.string)]
filename_i,filename_j = tf.decode_csv(
    csv_filename_tf, record_defaults=record_defaults)

file_contents_i = tf.read_file(filename_i)
file_contents_j = tf.read_file(filename_j)

bytes_i = tf.decode_raw(file_contents_i, tf.int16)
array_i = tf.reshape(tf.cast(tf.slice(bytes_i, [0], [3*5]), tf.int16), [3, 5])

bytes_j = tf.decode_raw(file_contents_j, tf.int16)
array_j = tf.reshape(tf.cast(tf.slice(bytes_j, [0], [5*6]), tf.int16), [5, 6])

with tf.Session() as sess:
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    a_out, b_out = (sess.run([array_i, array_j]))

    print(a)
    print(a_out)

    coord.request_stop()
    coord.join(threads)
</code></pre>

<p>Here is the output that I get:</p>

<p>Expected output (a)</p>

<pre><code>[[ 0  1  2  3  4]
 [ 5  6  7  8  9]
 [10 11 12 13 14]]
</code></pre>

<p>Received output: (a_out)</p>

<pre><code>[[20115 19797 22864     1   118]
 [10107 25956 25459 10098  8250]
 [15399 14441 11303 10016 28518]]
</code></pre>
","2340190","","","Reading numpy arrays from disk in tensorflow","<python><numpy><tensorflow>","3","0","1989"
"49060484","2018-03-01 23:35:05","0","","<p>The traceback has the answer:</p>

<pre><code>  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 91, in recommander
    usager_matrice = matrice_similarite.index(id_usager)
AttributeError: 'NoneType' object has no attribute 'index'
</code></pre>

<p>This simply means that <code>matrice_similarite</code> is <code>None</code>.
Now when you read the traceback to the top, you see that the failing call to <code>recommander</code> is in <code>main</code>, with the line:</p>

<pre><code>print(
    ""Pour la personne"",
    id_usager,
    "", nous recommandons l'ami"",
    recommander(id_usager, reseau, matrice_similarite))
</code></pre>

<p>At this point, <code>matrice_similarite</code> has been defined as follows:</p>

<pre><code>matrice_similarite = calculer_scores_similarite(reseau)
</code></pre>

<p>And as one would expect, <code>calculer_scores_similarite</code> returns nothing, hence <code>None</code>.
Reading the definition of this function, I guess you simply forgot to return the matrix you're computing, so adding the following should do:</p>

<pre><code>return matrice_similarite
</code></pre>
","7051394","","","6","1118","Right leg","2016-10-21 05:34:32","10078","892","2001","414","49060351","49060484","2018-03-01 23:23:42","0","58","<p>I'm currently working on a little side project yet having multiple issues.
I'm reading a file within the folder where the project is that holds data for 10 users. </p>

<p>Right now, I'm getting this error : </p>

<pre><code>Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1668, in &lt;module&gt;
    main()
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1662, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1072, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 133, in &lt;module&gt;
    main()
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 120, in main
    print(""Pour la personne"" , id_usager , "", nous recommandons l'ami"" , recommander(id_usager, reseau, matrice_similarite))
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 91, in recommander
    usager_matrice = matrice_similarite.index(id_usager)
AttributeError: 'NoneType' object has no attribute 'index'
</code></pre>

<p>As for the code itself... It's pretty big.</p>

<pre><code>def ouvrir_fichier(nomFichier):
    """""" Ne pas oublier les docstring

    """"""
    try:
        fp = open(nomFichier, 'r')
        return fp
    except:
        return print(""Le fichier n'existe pas. Veuillez réessayer."")

def lire_fichier(fp):
    """""" Ne pas oublier les docstring""""""
    # Lis n et initialise une liste vide --
    #    où il y a une liste vide pour chaque usager du réseau
    #    ensuite lis le reste du fichier et ajouter l'information à reseau

    liste1 = fp.readlines()
    n = int(liste1[0])
    liste2 = liste1[1:]

    reseau = [[] for i in range(n)]
    for i in liste2:
        i = i.replace(""\n"", """")
        data = i.split("" "")
        valeur1 = int(data[0])
        valeur2 = int(data[1])
        reseau[valeur1].append(valeur2)
        reseau[valeur2].append(valeur1)
    fp.close()
    return reseau

def trouver_nombre_elements_communs_entre_listes(liste1, liste2):
    """""" Ne pas oublier les docstring""""""
    compteur_amis_commun = 0
    for element in liste1:
        if element in liste2:
            compteur_amis_commun = compteur_amis_commun + 1
    return compteur_amis_commun


def initialiser_matrice(n):
    """"""
    Crée une matrice nxn, initialisée avec des zéros et retourne la matrice.
    Args:
        n (int): dimension de la matrice nxn
    Returns:
        matrice (list): matrice initialisée

    """"""
    matrice = []
    for ligne in range(n):  # pour chacune des lignes dans n
        matrice.append([])  # créer une ligne (liste) et l'initialiser à 0
        for colonne in range(n):
            matrice[ligne].append(0)  # ajouter un 0 pour chaque n colonne
    return matrice


def calculer_scores_similarite(reseau):
    """""" Ne pas oublier les docstring""""""
    n = len(reseau)
    matrice_similarite = initialiser_matrice(n)
    liste1 = []
    liste2 = []
    compteur_liste1 = 0
    compteur_liste2 = 0

    for element_liste1 in reseau:
        liste1 = element_liste1
        for element_liste2 in reseau:
            liste2 = element_liste2
            compteur_amis_commun = trouver_nombre_elements_communs_entre_listes(liste1, liste2)
            matrice_similarite[compteur_liste1][compteur_liste2] = compteur_amis_commun
            compteur_liste2 = compteur_liste2 + 1
        compteur_liste1 = compteur_liste1 + 1
        compteur_liste2 = 0

    return matrice_similarite


def recommander(id_usager,reseau,matrice_similarite):
    """""" Ne pas oublier les docstring""""""

    usager_matrice = matrice_similarite.index(id_usager)
    ami_recommande = matrice_similarite.index(max(usager_matrice))
    max_value = max(matrice_similarite.index(usager_matrice))

    if ami_recommande == id_usager:
        max_value = max_value - 1

    ami_recommande = matrice_similarite.index(max_value)

    while True:
        if ami_recommande == reseau.index(ami_recommande):
            ami_recommande = reseau.index(max_value, ami_recommande + 1)
            return True

    return ami_recommande

def main():

    nomFichier = input(""Nom du fichier contenant le réseau: "")
    reseau = lire_fichier(ouvrir_fichier(nomFichier))
    n = len(reseau)
    matrice_similarite = calculer_scores_similarite(reseau)
    while True:

        while True:

            id_usager = int(input(""Entrer l'ID de l'usager pour lequel vous voulez une recommandation (entre 0 et {}):"".format(n)))
            if 0 &lt;= id_usager and id_usager &lt; n:
                calculer_scores_similarite(reseau)
                print(""Pour la personne"" , id_usager , "", nous recommandons l'ami"" , recommander(id_usager, reseau, matrice_similarite))
                continue
            else:
                print(""Erreur: l'usager doit être un nombre entier entre "", 0, ""et"", n - 1, ""inclusivement.\n"")

        autreRecommandation = input(""Voulez-vous une autre recommandation (oui/non)?"")
        if autreRecommandation.lower() == ""oui"":
            return True
        else:
            print(""Merci d'avoir utiliser le programme de recommandation d'amis."")
            break

if __name__ == ""__main__"":
    main()
</code></pre>

<p>Most of the content seems to be working fine until I get to part where I need to recommend a user identification. I'll try to work on the doc string as well in the meantime but I could totally use a little bit of help as to debug this. I tested most of the code on another .py project until I hit the function ""recommander""</p>

<p>Thanks</p>

<p>First Edit : </p>

<p>I did forget to apply the Return. I changed it and it is now in the def. Now however... I seem to be having this error. </p>

<pre><code>Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1668, in &lt;module&gt;
    main()
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1662, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1072, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 132, in &lt;module&gt;
    main()
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 119, in main
    print(""Pour la personne"" , id_usager , "", nous recommandons l'ami"" , recommander(id_usager, reseau, matrice_similarite))
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 89, in recommander
    usager_matrice = matrice_similarite.index(id_usager)
ValueError: 0 is not in list
</code></pre>
","7541497","7541497","2018-03-02 00:03:47","Python - Multiple errors","<python>","2","1","7293"
"49060485","2018-03-01 23:35:07","2","","<p>No, not that I am aware. At the moment we are only providing glibc-based Python wheels for Linux users. To use pyarrow on Alpine Linux you would need to build from source -- I am not aware of anyone having tested the library on this platform, though.</p>
","776560","","","2","258","Wes McKinney","2011-05-30 17:04:03","63311","18580","99","12","49059779","49060485","2018-03-01 22:35:32","1","1790","<p>I am trying to install pyarrow using pip in my alpine docker image,but pip is unable to find the package. </p>

<p>I'm using the following Dockerfile:</p>

<pre><code>FROM python:3.6-alpine3.7

RUN apk add --no-cache musl-dev linux-headers g++

RUN pip install pyarrow
</code></pre>

<p>output:</p>

<pre><code>Sending build context to Docker daemon  4.096kB
Step 1/3 : FROM python:3.6-alpine3.7
3.6-alpine3.7: Pulling from library/python
ff3a5c916c92: Pull complete
471170bb1257: Pull complete
d487cc70216e: Pull complete
9358b3ca3321: Pull complete
78b9945f52f1: Pull complete
Digest: 
sha256:10bd7a59cfac2a784bedd1e6d89887995559f00b61f005a101845ed736bed779
Status: Downloaded newer image for python:3.6-alpine3.7
---&gt; 4b00a94b6f26
Step 2/3 : RUN apk add --no-cache musl-dev linux-headers g++
---&gt; Running in d024d0b961a6
fetch http://dl-
cdn.alpinelinux.org/alpine/v3.7/main/x86_64/APKINDEX.tar.gz
fetch http://dl-
cdn.alpinelinux.org/alpine/v3.7/community/x86_64/APKINDEX.tar.gz
(1/18) Upgrading musl (1.1.18-r2 -&gt; 1.1.18-r3)
(2/18) Installing libgcc (6.4.0-r5)
(3/18) Installing libstdc++ (6.4.0-r5)
(4/18) Installing binutils-libs (2.28-r3)
(5/18) Installing binutils (2.28-r3)
(6/18) Installing gmp (6.1.2-r1)
(7/18) Installing isl (0.18-r0)
(8/18) Installing libgomp (6.4.0-r5)
(9/18) Installing libatomic (6.4.0-r5)
(10/18) Installing pkgconf (1.3.10-r0)
(11/18) Installing mpfr3 (3.1.5-r1)
(12/18) Installing mpc1 (1.0.3-r1)
(13/18) Installing gcc (6.4.0-r5)
(14/18) Installing musl-dev (1.1.18-r3)
(15/18) Installing libc-dev (0.7.1-r0)
(16/18) Installing g++ (6.4.0-r5)
(17/18) Upgrading musl-utils (1.1.18-r2 -&gt; 1.1.18-r3)
(18/18) Installing linux-headers (4.4.6-r2)
Executing busybox-1.27.2-r7.trigger
OK: 190 MiB in 51 packages
Removing intermediate container d024d0b961a6
---&gt; 8039ae62bbe7
Step 3/3 : RUN pip install pyarrow
---&gt; Running in ecd1d7bc630c
Collecting pyarrow
 Could not find a version that satisfies the requirement pyarrow (from 
 versions: )
No matching distribution found for pyarrow
The command '/bin/sh -c pip install pyarrow' returned a non-zero code: 1
</code></pre>

<p>Has anyone community able to install pyarrow in alpine container?</p>
","9224067","","","Installing pyarrow in alpine docker","<python><docker><alpine><pyarrow>","2","0","2199"
"49060515","2018-03-01 23:37:29","0","","<p>You have small error in your code.</p>

<p>On line 102 you call:
<code>matrice_similarite = calculer_scores_similarite(reseau)</code></p>

<p>and function <code>calculer_scores_similarite</code> doesn't have return value</p>

<p>you need to add in that function <code>return matrice_similarite</code> as last line of function.</p>
","2304156","","","1","334","PerunSS","2013-04-21 11:05:37","398","50","75","8","49060351","49060484","2018-03-01 23:23:42","0","58","<p>I'm currently working on a little side project yet having multiple issues.
I'm reading a file within the folder where the project is that holds data for 10 users. </p>

<p>Right now, I'm getting this error : </p>

<pre><code>Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1668, in &lt;module&gt;
    main()
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1662, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1072, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 133, in &lt;module&gt;
    main()
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 120, in main
    print(""Pour la personne"" , id_usager , "", nous recommandons l'ami"" , recommander(id_usager, reseau, matrice_similarite))
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 91, in recommander
    usager_matrice = matrice_similarite.index(id_usager)
AttributeError: 'NoneType' object has no attribute 'index'
</code></pre>

<p>As for the code itself... It's pretty big.</p>

<pre><code>def ouvrir_fichier(nomFichier):
    """""" Ne pas oublier les docstring

    """"""
    try:
        fp = open(nomFichier, 'r')
        return fp
    except:
        return print(""Le fichier n'existe pas. Veuillez réessayer."")

def lire_fichier(fp):
    """""" Ne pas oublier les docstring""""""
    # Lis n et initialise une liste vide --
    #    où il y a une liste vide pour chaque usager du réseau
    #    ensuite lis le reste du fichier et ajouter l'information à reseau

    liste1 = fp.readlines()
    n = int(liste1[0])
    liste2 = liste1[1:]

    reseau = [[] for i in range(n)]
    for i in liste2:
        i = i.replace(""\n"", """")
        data = i.split("" "")
        valeur1 = int(data[0])
        valeur2 = int(data[1])
        reseau[valeur1].append(valeur2)
        reseau[valeur2].append(valeur1)
    fp.close()
    return reseau

def trouver_nombre_elements_communs_entre_listes(liste1, liste2):
    """""" Ne pas oublier les docstring""""""
    compteur_amis_commun = 0
    for element in liste1:
        if element in liste2:
            compteur_amis_commun = compteur_amis_commun + 1
    return compteur_amis_commun


def initialiser_matrice(n):
    """"""
    Crée une matrice nxn, initialisée avec des zéros et retourne la matrice.
    Args:
        n (int): dimension de la matrice nxn
    Returns:
        matrice (list): matrice initialisée

    """"""
    matrice = []
    for ligne in range(n):  # pour chacune des lignes dans n
        matrice.append([])  # créer une ligne (liste) et l'initialiser à 0
        for colonne in range(n):
            matrice[ligne].append(0)  # ajouter un 0 pour chaque n colonne
    return matrice


def calculer_scores_similarite(reseau):
    """""" Ne pas oublier les docstring""""""
    n = len(reseau)
    matrice_similarite = initialiser_matrice(n)
    liste1 = []
    liste2 = []
    compteur_liste1 = 0
    compteur_liste2 = 0

    for element_liste1 in reseau:
        liste1 = element_liste1
        for element_liste2 in reseau:
            liste2 = element_liste2
            compteur_amis_commun = trouver_nombre_elements_communs_entre_listes(liste1, liste2)
            matrice_similarite[compteur_liste1][compteur_liste2] = compteur_amis_commun
            compteur_liste2 = compteur_liste2 + 1
        compteur_liste1 = compteur_liste1 + 1
        compteur_liste2 = 0

    return matrice_similarite


def recommander(id_usager,reseau,matrice_similarite):
    """""" Ne pas oublier les docstring""""""

    usager_matrice = matrice_similarite.index(id_usager)
    ami_recommande = matrice_similarite.index(max(usager_matrice))
    max_value = max(matrice_similarite.index(usager_matrice))

    if ami_recommande == id_usager:
        max_value = max_value - 1

    ami_recommande = matrice_similarite.index(max_value)

    while True:
        if ami_recommande == reseau.index(ami_recommande):
            ami_recommande = reseau.index(max_value, ami_recommande + 1)
            return True

    return ami_recommande

def main():

    nomFichier = input(""Nom du fichier contenant le réseau: "")
    reseau = lire_fichier(ouvrir_fichier(nomFichier))
    n = len(reseau)
    matrice_similarite = calculer_scores_similarite(reseau)
    while True:

        while True:

            id_usager = int(input(""Entrer l'ID de l'usager pour lequel vous voulez une recommandation (entre 0 et {}):"".format(n)))
            if 0 &lt;= id_usager and id_usager &lt; n:
                calculer_scores_similarite(reseau)
                print(""Pour la personne"" , id_usager , "", nous recommandons l'ami"" , recommander(id_usager, reseau, matrice_similarite))
                continue
            else:
                print(""Erreur: l'usager doit être un nombre entier entre "", 0, ""et"", n - 1, ""inclusivement.\n"")

        autreRecommandation = input(""Voulez-vous une autre recommandation (oui/non)?"")
        if autreRecommandation.lower() == ""oui"":
            return True
        else:
            print(""Merci d'avoir utiliser le programme de recommandation d'amis."")
            break

if __name__ == ""__main__"":
    main()
</code></pre>

<p>Most of the content seems to be working fine until I get to part where I need to recommend a user identification. I'll try to work on the doc string as well in the meantime but I could totally use a little bit of help as to debug this. I tested most of the code on another .py project until I hit the function ""recommander""</p>

<p>Thanks</p>

<p>First Edit : </p>

<p>I did forget to apply the Return. I changed it and it is now in the def. Now however... I seem to be having this error. </p>

<pre><code>Traceback (most recent call last):
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1668, in &lt;module&gt;
    main()
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1662, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\pydevd.py"", line 1072, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2017.3.2\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 132, in &lt;module&gt;
    main()
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 119, in main
    print(""Pour la personne"" , id_usager , "", nous recommandons l'ami"" , recommander(id_usager, reseau, matrice_similarite))
  File ""C:/Users/101136/PycharmProjects/tp2/TP2.py"", line 89, in recommander
    usager_matrice = matrice_similarite.index(id_usager)
ValueError: 0 is not in list
</code></pre>
","7541497","7541497","2018-03-02 00:03:47","Python - Multiple errors","<python>","2","1","7293"
"49060551","2018-03-01 23:41:40","0","","<p>You can use the <a href=""https://developers.google.com/resources/api-libraries/documentation/drive/v3/python/latest/"" rel=""nofollow noreferrer"">Drive API</a> to <a href=""https://developers.google.com/resources/api-libraries/documentation/drive/v3/python/latest/drive_v3.files.html#list"" rel=""nofollow noreferrer"">query for files</a> added within a given timeframe that are of a specific type. All the search parameters and syntax for such a query are listed <a href=""https://developers.google.com/drive/v3/web/search-parameters"" rel=""nofollow noreferrer"">here</a>.</p>

<pre><code># Build the Drive service
...

# Query for recent files, with stipulation that their mimetype contains ""spreadsheet""
query = ""mimeType contains 'spreadsheet' and modifiedTime &gt; '""
query += someDateAsUTC_inRFC_3339_String + ""'""

# Execute the query
request = drive.files.list(q=query, .... )
resp = request.execute()
nextPage = resp['nextPageToken']
if resp['files']:
    # Call method to consume files
while nextPage:
    request = drive.files.list_next(request, resp)
    if request:
        resp = request.execute()
        nextPage = resp['nextPageToken']
        if resp['files']:
            # Call method to consume files
    else
        break
# Done
</code></pre>
","9337071","","","1","1259","tehhowch","2018-02-09 07:05:36","7037","2231","946","2132","49060160","49060551","2018-03-01 23:07:33","0","928","<p>I'm trying to get data that lives within a Google Sheet into our Redshift database. I was able to follow the directions from this link: <a href=""https://www.twilio.com/blog/2017/02/an-easy-way-to-read-and-write-to-a-google-spreadsheet-in-python.html"" rel=""nofollow noreferrer"">https://www.twilio.com/blog/2017/02/an-easy-way-to-read-and-write-to-a-google-spreadsheet-in-python.html</a></p>

<p>Is it possible to have it pull data from the most recently added google sheets within a folder (instead of just specifying a single sheet) and write to the Redshift table? </p>

<p>Here is what was used to read the google sheets data into Python: </p>

<pre><code>import gspread
from oauth2client.service_account import ServiceAccountCredentials


# use creds to create a client to interact with the Google Drive API
scope = ['https://spreadsheets.google.com/feeds']
creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)
client = gspread.authorize(creds)

# Find a workbook by name and open the first sheet
# Make sure you use the right name here.
sheet = client.open(""Copy of Legislators 2017"").sheet1

# Extract and print all of the values
list_of_hashes = sheet.get_all_records()
print(list_of_hashes)
</code></pre>
","8659376","9337071","2018-03-01 23:51:04","Getting Google Sheets Data into Redshift","<python><google-sheets><amazon-redshift><google-api-python-client><google-python-api>","1","0","1248"
"49060599","2018-03-01 23:46:38","2","","<pre><code>with open(""file1.txt"", 'r') as file1, open(""file2.txt"", 'w') as file2:
  lines = file1.readlines()
  for line in lines:
      if line.strip()[-1] in 'aeiouy':
          file2.write(line.strip() + "" "" + ""way"" + '\n')
      else:
          file2.write(line.strip()[:-1] + ""ay"" + '\n')
</code></pre>

<p>How about something like this? Uses strip and then adds the newline char back onto the end.</p>
","3566707","","","2","408","Brayden","2014-04-23 23:39:11","191","17","18","3","49060459","49060599","2018-03-01 23:32:53","1","133","<p>I got a file with the following text:</p>

<pre><code>with open(""file1.txt"", ""w"") as file1:
    file1.write(""Thou blind fool, Love, what dost thou to mine eyes\n""
                 ""That they behold, and see not what they see\n""
                 ""They know what beauty is, see where it lies\n""
                 ""Yet what the best is take the worst to be"")
</code></pre>

<p>what I have to do is to create another file and rewrite this text but:
if a string ends with a vowel than I have to put ""way"" after this string 
and if a string ends with a consonant, I have to rewrite the last letter and add ""ay"" to it.</p>

<p>My code is:</p>

<pre><code>def change_str():
    with open(""file1.txt"", ""r"") as file1, open(""file2.txt"", ""w"") as file2:
        lines = file1.readlines()
        for line in lines:
            if line[-1] in ""aiueoy"":
                file2.write(line + "" "" + ""way"")
            else:
                file2.write(line + "" "" + line[-1] + ""ay"")
</code></pre>

<p>So it has only 1 correct output line. It's the last one because it has no ""/n"". In other strings line[-1] == \n and my question is how to ignore it and check the last letter.</p>
","9397534","","2018-03-01 23:36:03","How to ignore \n while indexing","<python>","2","2","1162"
"49060623","2018-03-01 23:50:07","0","","<p>Here's another take on it: a class which acts as a soft limit to the numbers value:</p>

<p>The numbers will never be in an invalid state:</p>

<p><code>SoftPositiveNumber(5) - 20 == 0</code> evaluates to true</p>

<pre class=""lang-py prettyprint-override""><code>from functools import total_ordering

@total_ordering
class SoftPositiveNumber(object):
    """"""This class acts like a number but will not allow
    the contained value to be less than zero""""""
    def __init__(self, value):
        if isinstance(value, SoftPositiveNumber):
            value = value.value
        self.value = value
        if self.value &lt; 0:
            self.value = 0
    def __str__(self):
        return str(self.value)
    def __int__(self):
        return int(self.value)
    def __float__(self):
        return float(self.value)
    def __repr__(self):
        return f""SoftPositiveNumber({self.value})""
    def __eq__(self, other):
        if isinstance(other, SoftPositiveNumber):
            return self.value == other.value
        return self.value == other
    def __lt__(self, other):
        if isinstance(other, SoftPositiveNumber):
            return self.value &lt; other.value
        return self.value &lt; other
    def __iadd__(self, other):
        if isinstance(other, SoftPositiveNumber):
            self.value += other.value
        else:
            self.value += other
        if self.value &lt; 0:
            self.value = 0
        return self
    def __isub__(self, other):
        if isinstance(other, SoftPositiveNumber):
            self.value -= other.value
        else:
            self.value -= other
        if self.value &lt; 0:
            self.value = 0
        return self
    def __add__(self, other):
        if isinstance(other, SoftPositiveNumber):
            return SoftPositiveNumber(self.value + other.value)
        return SoftPositiveNumber(self.value + other)
    def __sub__(self, other):
        if isinstance(other, SoftPositiveNumber):
            return SoftPositiveNumber(self.value - other.value)
        return SoftPositiveNumber(self.value - other)
    __rsub__ = __sub__
    __radd__ = __add__
</code></pre>
","487464","","","0","2158","Bryce Guinta","2010-10-24 05:03:28","1698","202","670","7","7122535","7122613","2011-08-19 13:48:41","3","25837","<p>I am looking for an elegant way to ensure that a given variable remains positive.</p>

<p>I have two variables that hold positive float numbers and I decrement them according to certain conditions. At the end I want to guarantee that I still have positive numbers (or 0 at most). The pseudo code looks something like this:</p>

<pre><code>list = [...]

value1 = N
value2 = M

for element in list:
    if ... :
        value1 -= X
    if ... :
        value2 -= Y
</code></pre>

<p>Is there a more elegant solution than just adding two <code>ifs</code> at the end?</p>
","848330","","","Python - Ensuring a variable holds a positive number","<python><variables><numbers>","4","0","571"
"49060626","2018-03-01 23:50:27","0","","<blockquote>
  <p>Why is it not working? </p>
</blockquote>

<p>Because the <a href=""https://docs.python.org/3/library/array.html?highlight=index#array.array.index"" rel=""nofollow noreferrer"">index(x)</a> method, according to the official Python 3 documentation:</p>

<blockquote>
  <p>Return the smallest i such that i is the index of the first occurrence of x in the array.</p>
</blockquote>

<p>So, if you want <code>finalArray = ['I love school', 'I hate school']</code>,
you don't want indexes (<em>integer numbers</em>), but you want the actual item (<em>in this case a string</em>).</p>

<hr>

<blockquote>
  <p>Is there a better way to do this?</p>
</blockquote>

<p>You can simply iterate over the elements (<em>the strings</em>) of your <code>array</code> and, if the string contains the word ""school"" you can add it to <code>finalArray</code>.</p>

<pre><code>array = ['I love school', 'I hate school', 'I hate bananas', 'today is friday', 'worldcup is great']

finalArray = []

for element in array:  # for each element in the array
    if ""school"" in element:  # check if the word ""school"" appears in the ""element"" string variable
        finalArray.append(element)  # if yes, add the string to ""finalArray"" variable
</code></pre>

<p><strong>Note</strong>: this is not Pythonic code by purpose. <a href=""https://stackoverflow.com/a/49060306/8520828"">Delirious Lettuce's answer</a> contains a Pythonic way of doing it.</p>
","8520828","8520828","2018-03-01 23:55:41","0","1435","davcri","2017-08-26 14:41:42","26","24","5","0","49060262","49060356","2018-03-01 23:16:21","3","113","<p>I have these lists:</p>

<pre><code>array = ['I love school', 'I hate school', 'I hate bananas', 'today is 
friday', 'worldcup is great']

#finalArray is initially an empty list
finalArray = []  
</code></pre>

<p>I want to save those indexes of ""array"" that contain the word ""school"" into ""finalArray"". Meaning that ""finalArray"" should become like this:</p>

<pre><code>['I love school', 'I hate school']
</code></pre>

<p>I tried the following code which does not do the job:</p>

<pre><code>if ""school"" in array:
    finalArray = array.index(""school"")
</code></pre>

<p>Why is it not working? Is there a better way to do this?</p>
","5619967","","","storing indexes of an array which contains a certain word(s) into another array in Python","<python><list>","6","0","637"
"49060630","2018-03-01 23:50:38","3","","<p>If you want to stop it from being printed and clean up your code then use a loop:</p>

<p>Edit: This is a perfect time to use the <code>for-else</code> block of code. In this example, the <code>else</code> clause will only run when the full <code>for-loop</code> has been exhausted i.e it wont run 'You have been blocked from the database' in the event that the correct password was entered (because then the <code>break</code> statement has executed)</p>

<pre><code>password = 'swordfish'

print('The Database is password protected')

for attempts in range(2, -1, -1):
    if input('Please enter password') == password:
        print('Access granted.')
        break
    else:
        print('Wrong password.')
        print('%s attempts remain' % attempts)
else:
    print('You have been blocked from the database')
</code></pre>
","4889267","4889267","2018-03-02 00:00:02","1","835","AK47","2015-05-11 23:07:46","5603","1068","1520","509","49060594","","2018-03-01 23:45:59","2","34","<p>How do I go about stopping 'Access granted' being printed when password is correctly input? Access granted get printed three times when 'swordfish' is entered</p>

<p><img src=""https://pastebin.com/rL9pcuBh"" alt=""enter link description here""></p>

<pre><code>print ('The Database is password protected') # Says the Data base is password protected
print ('please enter password') #say please enter password

password = ('swordfish')
swordfish = 3

password = input()
if password == 'swordfish':

    print ('Access granted.')

else:

 if password != ('swordfish'):


    print ('wrong password.')

    print ('two attempts remain')

 else:
    password = input()

if password == 'swordfish':
    print ('Access granted.')
else:
    password = input()
if password == 'swordfish':
     print ('Access granted.')
else:
    print ('wrong password.')
    print ('one attempt remain')

    password = input()
    if password == 'swordfish':

if password != ('swordfish'):

     print ('You have been blocked from the database')
</code></pre>
","9409411","4889267","2018-03-04 08:08:00","How do I spot 'Access granted' being printed 3 times if password is correct?","<python><python-3.x><python-2.7><loops><input>","3","1","1038"
"49060635","2018-03-01 23:51:09","13","","<p>Another alternative (especially useful if your strings don't map 1-1 to your enum cases) is to add a <code>staticmethod</code> to your <code>Enum</code>, e.g.:</p>

<pre><code>class QuestionType(enum.Enum):
    MULTI_SELECT = ""multi""
    SINGLE_SELECT = ""single""

    @staticmethod
    def from_str(label):
        if label in ('single', 'singleSelect'):
            return QuestionType.SINGLE_SELECT
        elif label in ('multi', 'multiSelect'):
            return QuestionType.MULTI_SELECT
        else:
            raise NotImplementedError
</code></pre>

<p>Then you can do <code>question_type = QuestionType.from_str('singleSelect')</code></p>
","998687","","","1","654","rogueleaderr","2011-10-17 07:23:30","2916","191","2846","9","41407414","41409392","2016-12-31 10:18:59","95","44471","<p>I wonder what's the correct way of converting (deserializing) a string to a Python's Enum class. Seems like <code>getattr(YourEnumType, str)</code> does the job, but I'm not sure if it's safe enough.</p>

<p>Just to be more specific, I would like to convert a <code>'debug'</code>string to an Enum object like this:</p>

<pre><code>class BuildType(Enum):
    debug = 200
    release = 400
</code></pre>
","289912","1000551","2017-10-13 12:18:18","Convert string to Enum in Python","<python><string><serialization><enums><type-conversion>","6","0","406"
"49060637","2018-03-01 23:51:28","0","","<pre><code>print ('The Database is password protected')
print ('please enter password') 

password = ""swordfish""

for i in range(3):
    attempt = input(""Enter the password: "")
    if attempt == password:
        print(""Access Granted"")
        break
    else:
        print(""Wrong password"")
        print(2 - i, ""attempt(s) reamin"")

    if i == 2:
        print(""You have been blocked from the database"")
</code></pre>
","9363594","","","0","422","Jono 2906","2018-02-15 07:26:55","1079","118","988","19","49060594","","2018-03-01 23:45:59","2","34","<p>How do I go about stopping 'Access granted' being printed when password is correctly input? Access granted get printed three times when 'swordfish' is entered</p>

<p><img src=""https://pastebin.com/rL9pcuBh"" alt=""enter link description here""></p>

<pre><code>print ('The Database is password protected') # Says the Data base is password protected
print ('please enter password') #say please enter password

password = ('swordfish')
swordfish = 3

password = input()
if password == 'swordfish':

    print ('Access granted.')

else:

 if password != ('swordfish'):


    print ('wrong password.')

    print ('two attempts remain')

 else:
    password = input()

if password == 'swordfish':
    print ('Access granted.')
else:
    password = input()
if password == 'swordfish':
     print ('Access granted.')
else:
    print ('wrong password.')
    print ('one attempt remain')

    password = input()
    if password == 'swordfish':

if password != ('swordfish'):

     print ('You have been blocked from the database')
</code></pre>
","9409411","4889267","2018-03-04 08:08:00","How do I spot 'Access granted' being printed 3 times if password is correct?","<python><python-3.x><python-2.7><loops><input>","3","1","1038"
"49060638","2018-03-01 23:51:48","0","","<p>You could <strong>try</strong> a <strong>for-loop</strong> :)</p>

<pre><code>for e in range(3):
    a=input()
    if a==""swordfish"":
        print(""Access Granted"")
        break
    else:
        print(""Wrong Password. You have ""+str(3-(e+1))+"" attempts left"")
</code></pre>
","7848065","","","0","280","whackamadoodle3000","2017-04-11 02:43:46","5059","1791","4415","3","49060594","","2018-03-01 23:45:59","2","34","<p>How do I go about stopping 'Access granted' being printed when password is correctly input? Access granted get printed three times when 'swordfish' is entered</p>

<p><img src=""https://pastebin.com/rL9pcuBh"" alt=""enter link description here""></p>

<pre><code>print ('The Database is password protected') # Says the Data base is password protected
print ('please enter password') #say please enter password

password = ('swordfish')
swordfish = 3

password = input()
if password == 'swordfish':

    print ('Access granted.')

else:

 if password != ('swordfish'):


    print ('wrong password.')

    print ('two attempts remain')

 else:
    password = input()

if password == 'swordfish':
    print ('Access granted.')
else:
    password = input()
if password == 'swordfish':
     print ('Access granted.')
else:
    print ('wrong password.')
    print ('one attempt remain')

    password = input()
    if password == 'swordfish':

if password != ('swordfish'):

     print ('You have been blocked from the database')
</code></pre>
","9409411","4889267","2018-03-04 08:08:00","How do I spot 'Access granted' being printed 3 times if password is correct?","<python><python-3.x><python-2.7><loops><input>","3","1","1038"
"49060675","2018-03-01 23:56:43","3","","<p>PostgreSQL is currently only available to GAE Flexible environments and GAE Standard running on Java 8. Python on GAE Standard is not yet supported for PostgreSQL. See <a href=""https://cloud.google.com/sql/docs/postgres/faq#gaeconnect-pg"" rel=""nofollow noreferrer"">FAQ</a> and <a href=""https://cloud.google.com/sql/docs/postgres/connect-app-engine#gaev1-csqlv2"" rel=""nofollow noreferrer"">supported languages here</a>.</p>
","4117290","","","1","425","Kenworth","2014-10-07 13:08:30","537","86","80","19","49045762","49060675","2018-03-01 08:44:35","0","567","<p>I have an app that uses the Python Standard Environment on App Engine. I tried, but failed, to find instructions to connect to Postgres on Cloud SQL.</p>

<p>In the <a href=""https://cloud.google.com/sql/docs/postgres/connect-app-engine"" rel=""nofollow noreferrer"">documentation</a>, under ""App Engine standard environment to Cloud SQL"", I only see instructions for Java.</p>

<p>Is it really the case that there is no way to connect to Postgres on Cloud SQL?</p>
","6905609","","","How to connect to Postgres on Cloud SQL using the Python Standard Environment on App Engine","<python><postgresql><google-app-engine><google-cloud-sql><google-app-engine-python>","2","0","465"
"49060683","2018-03-01 23:57:51","2","","<pre><code>In [59]: one=np.arange(6).reshape(2,3)
In [60]: two=np.arange(6).reshape(2,3)
</code></pre>

<p>Forget about the loop for the moment, and just try to change <code>one</code>:</p>

<pre><code>In [61]: arr = one
In [62]: arr=np.column_stack([arr,5*arr[:,2]-arr[:,1]])
In [63]: arr
Out[63]: 
array([[ 0,  1,  2,  9],
       [ 3,  4,  5, 21]])
In [65]: one
Out[65]: 
array([[0, 1, 2],
       [3, 4, 5]])
</code></pre>

<p>This action has changed <code>arr</code>, but not <code>one</code>.  Originally <code>arr</code> referenced the same object (<code>ndarray</code>) as <code>one</code>, but after the new assignment, it referenced a new array.</p>

<p>In </p>

<pre><code>for arr in alist:
    arr = ....
</code></pre>

<p><code>arr</code> is assigned an element of <code>alist</code>.  But then in the loop it is assigned another something else, without changing the original object.  On the next iteration, <code>arr</code> is assigned the next element in the list, and so on.</p>

<p>You need to keep in mind several things.  </p>

<ul>
<li>how Python assigns values to variables</li>
<li>how Python assigns values to an iteration variable</li>
<li>what functions like <code>column_stack</code> to</li>
</ul>

<p>In your previous question</p>

<pre><code>In [69]: for arg in [one,two]:
    ...:     arg[:,1:] += 10
    ...:     
In [70]: one
Out[70]: 
array([[ 0, 11, 12],
       [ 3, 14, 15]])
In [71]: two
Out[71]: 
array([[ 0, 11, 12],
       [ 3, 14, 15]])
</code></pre>

<p>this works because the <code>arg[:,1:] += 10</code> is modifying the array currently assigned to <code>arg</code>.  An array is <code>mutable</code>; element values can be changed in-place.</p>

<p><code>np.column_stack()</code> does not act in-place.  It makes new array.</p>

<p>About the only way that you can change <code>one</code> and <code>two</code> with a list is a sequence of operations like:</p>

<pre><code>In [72]: newlist=[np.column_stack([arr,5*arr[:,2]-arr[:,1]]) for arg in [one,two]]
In [73]: newlist
Out[73]: 
[array([[ 0,  1,  2,  9,  9],
        [ 3,  4,  5, 21, 21]]), array([[ 0,  1,  2,  9,  9],
        [ 3,  4,  5, 21, 21]])]
In [74]: one
Out[74]: 
array([[ 0, 11, 12],
       [ 3, 14, 15]])
In [75]: one, two = newlist
In [76]: one
Out[76]: 
array([[ 0,  1,  2,  9,  9],
       [ 3,  4,  5, 21, 21]])
</code></pre>

<p><code>In[72]</code> creates a new list, with new arrays. <code>In[75]</code> assigns these new arrays to the variables <code>one</code> and <code>two</code>.  This wipes out their previous references.  In effect I did <code>one=[np.column_stack([one,5*one[:,2]-one[:,1]])</code>, and similarly for <code>two</code>.</p>
","901925","","","1","2659","hpaulj","2011-08-19 06:44:39","130801","8991","3044","37","49059917","49060683","2018-03-01 22:46:43","1","140","<p>This is a follow-up post from a previous question of mine: <a href=""https://stackoverflow.com/questions/49058472/referring-to-arrays-in-a-for-loop?noredirect=1#comment85123191_49058472"">Referring to arrays in a for-loop</a>.</p>

<p>I would like to generalize the solution proposed there in order to be able to complete more complex tasks, such as attaching a column to each array that contains the result of some calculation:</p>

<pre><code>import numpy as np
list=[one, two, three]

for arr in list:
    arr=np.column_stack([arr,5*arr[:,2]-arr[:,1])])
</code></pre>

<p>All three arrays have the same dimensions.</p>
","8682794","","","Iterating over a list of arrays while making changes to each array","<python><arrays><python-3.x><numpy><for-loop>","4","0","623"
"49060689","2018-03-01 23:58:42","1","","<p>CSV writers expect a file handle, not a filename.</p>

<pre><code>with open('filename.csv', 'w') as f:
    writer = csv.writer(f)
    ...
</code></pre>

<p>You probably want a <code>DictWriter</code> instead, by the way.  Don't rely on the order of <code>keys</code> and <code>values</code> matching up.  </p>
","674039","674039","2018-03-02 00:00:56","3","313","wim","2011-03-23 23:40:27","187587","12233","9064","5087","49059551","","2018-03-01 22:15:27","1","270","<p>I am making a call to the AWS API using <code>boto3</code> and <code>Python</code> and I am writing the <code>JSON</code> response to a <code>JSON</code>file. I am then trying to convert the <code>JSON</code> file to a <code>CSV</code> file. When I attempt to do this with the <code>csv writer()</code> method, I get the above error and I am not sure why. </p>

<p><strong>Code:</strong></p>

<pre><code>def ResponseConvert():
    dynamo = boto3.client('dynamodb')

    response = dynamo.scan(
    TableName='XXXX'
    )

    with open('vuln_data.json', 'w') as outfile:
        json.dump(response, outfile, indent=4)

    f = open('vuln_data.json')
    data = json.load(f)
    f.close()

    f = csv.writer(open('vuln_data.csv', 'wb+'))

    f.writerow(data.keys())
    for row in data:
        f.writerow(row.values())

ResponseConvert()
</code></pre>

<p><strong>Traceback:</strong></p>

<pre><code>Traceback (most recent call last):
  File ""response_convert.py"", line 21, in &lt;module&gt;
    ResponseConvert()
  File ""response_convert.py"", line 19, in ResponseConvert
    f.writerow(row.values())
AttributeError: 'unicode' object has no attribute 'values'
</code></pre>
","9419418","9419418","2018-03-02 17:15:55","argument 1 must have a ""write"" method - creating csv file from json","<python><json><csv>","1","7","1179"